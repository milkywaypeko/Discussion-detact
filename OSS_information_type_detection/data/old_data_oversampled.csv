,Text Content,Code
0,Node.js (JavaScript) Wrapper API,Expected Behaviour
1,Because JavaScript is Awesome,Motivation
2,+1!,Social Conversation
3,+1,Social Conversation
4,:+1:,Social Conversation
5,+1,Social Conversation
6,Just what I was searching for.,Social Conversation
7,:+1:,Social Conversation
8,As quoted from the offical website http://www.tensorflow.org/,Motivation
9,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
10,I am new to this whole SWIG thing but searched around and found this. http://www.swig.org/Doc3.0/Javascript.html,Solution Discussion
11,Not really sure how this works.,Solution Discussion
12,Do we need to write swig interface file specifically for Javascript or is it auto-generated when running some commands or is somebody already working on this (this would be awesome) ?,Solution Discussion
13,+1 :+1:,Social Conversation
14,+1,Social Conversation
15,+1,Social Conversation
16,+1,Social Conversation
17,+1,Social Conversation
18,ð,Social Conversation
19,:+1:,Social Conversation
20,+1!,Social Conversation
21,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
22,"Checking out the swig interface files to see if they're going to be helpful, or if I should just use the c++ API.",Solution Discussion
23,+1,Social Conversation
24,+1,Social Conversation
25,+1,Social Conversation
26,+1,Social Conversation
27,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
28,"I would recommend circulating a proposed implementation on the discuss mailing list early on, so that a consensus about where such API might live (in repo / off repo / in 'contrib' directory) can be reached ahead of time.",Solution Discussion
29,Anyone up to write a NodeJS library?,Contribution and Commitment
30,:+1:,Social Conversation
31,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
32,I know there are multiple ways of approaching this however I strongly recommend node-gyp for performance.,Solution Discussion
33,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
34,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
35,:+1:,Social Conversation
36,@Foorack I am willing to contribute it if some people are interested as well.,Contribution and Commitment
37,:+1:,Social Conversation
38,We hope more developers to discuss and contribute.,Contribution and Commitment
39,Thanks @Foorack !,Social Conversation
40,I am willing to contribute.,Contribution and Commitment
41,Thanks for the initiative guys!,Social Conversation
42,@miguelalche Glad to see you're interested!,Social Conversation
43,^^,Social Conversation
44,+1,Social Conversation
45,Hooray for node!,Social Conversation
46,Let's do this.,Social Conversation
47,+1,Social Conversation
48,+1,Social Conversation
49,Here's a writeup on how to load and execute TensorFlow graphs using the C API: https://medium.com/jim-fleming/loading-tensorflow-graphs-via-host-languages-be10fd81876f (source code included),Solution Discussion
50,The proposal will be released in the next week.,Solution Discussion
51,+1,Social Conversation
52,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
53,@jimfleming - like your approach (we're both using ffi ... I did it to get started quickly).,Solution Discussion
54,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
55,Thats my next step.,Task Progress
56,@nikhilk Thanks.,Social Conversation
57,I'm only interested in loading graphs created in python and I think I like the minimalism.,Solution Discussion
58,+1,Social Conversation
59,The proposal is released here with current progress.,Task Progress
60,https://github.com/node-tensorflow/node-tensorflow/tree/1.0.0,Task Progress
61,+1,Social Conversation
62,+1,Social Conversation
63,+1,Social Conversation
64,+1,Social Conversation
65,+1,Social Conversation
66,+1,Social Conversation
67,+1,Social Conversation
68,+1,Social Conversation
69,+1,Social Conversation
70,+1,Social Conversation
71,+1,Social Conversation
72,+1,Social Conversation
73,+1,Social Conversation
74,+1,Social Conversation
75,+1,Social Conversation
76,+1,Social Conversation
77,I am very willing to contribute.,Contribution and Commitment
78,@Foorack please add me to what ever you can!,Social Conversation
79,@pushtheworldllc I'm glad you are interested.,Social Conversation
80,:),Social Conversation
81,+1,Social Conversation
82,+1,Social Conversation
83,+1,Social Conversation
84,+1 :+1:,Social Conversation
85,+1 :+1:,Social Conversation
86,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress
87,The next steps would be to define the areas that the bindings would initially cover (must be within the C++ API ) and start implementing the SWIG interface files for these.,Task Progress
88,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
89,"Additionally, would be great to get some clarity from the tensorflow team on what API's would be good to initially cover as I'm sure their roadmap has many changes on the way, and I wouldn't want to conflict.",Expected Behaviour
90,(cc @martinwicke ? ),Contribution and Commitment
91,+1,Social Conversation
92,+1 :+1:,Social Conversation
93,+1,Social Conversation
94,+1,Social Conversation
95,+1,Social Conversation
96,+1,Social Conversation
97,+1,Social Conversation
98,please try use reactions button --> http://www.geekwire.com/2016/github-adds-reactions-keep-comments-track/ no more +1 comments xD,Social Conversation
99,+1,Social Conversation
100,:+1:,Social Conversation
101,+1,Social Conversation
102,+1,Social Conversation
103,+1,Social Conversation
104,@peterbraden sorry for the prolonged silence.,Social Conversation
105,"We are building out the C++ API, and it will grow over time.",Solution Discussion
106,I expect the most useful bits to be the parts that are needed to run an existing graph.,Solution Discussion
107,"The C++ graph building API is being redone right now, so it's not particularly useful to spend much time on it.",Solution Discussion
108,@martinwicke thanks for the encouragement.,Social Conversation
109,I made an initial stab at it here: https://github.com/tensorflow/tensorflow/pull/2206 - this is just a proof of concept that gets the version string into nodejs.,Task Progress
110,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
111,+10000,Social Conversation
112,+1,Social Conversation
113,+1,Social Conversation
114,# +1,Social Conversation
115,+1,Social Conversation
116,+1,Social Conversation
117,+1,Social Conversation
118,This would be interesting for pure front-end graph exportation for direct Solution Usage on web clients.,Motivation
119,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
120,+1,Social Conversation
121,:+1:,Social Conversation
122,+1,Social Conversation
123,+1,Social Conversation
124,+1,Social Conversation
125,+1,Social Conversation
126,+1,Social Conversation
127,Found this while looking into wether or not bindings existed already.,Social Conversation
128,"Going to learn some tensor flow via the current python API before researching more, but I have built nodejs bindings for C++ libs before and can tell you from experience that swig is the wrong way.",Solution Discussion
129,If you simply use the swig bindings then you will have synchronous blocking code in an async environment.,Solution Discussion
130,"The swig bindings do not run things on IO threads, they execute on the main event loop from what I understand/experienced.",Solution Discussion
131,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
132,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
133,Is there any link related to node-gyp binding for tensor flow API ??,Solution Discussion
134,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
135,What resources do you recommend for working with v8 modules?,Solution Discussion
136,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
137,+1,Social Conversation
138,+1,Social Conversation
139,+1,Social Conversation
140,+1s,Social Conversation
141,Is there any update ??,Task Progress
142,"
REFERENCE",Social Conversation
143,Happy Anniversary TensorFlow !,Social Conversation
144,https://research.googleblog.com/2016/11/celebrating-tensorflows-first-year.html,Social Conversation
145,"I notice TensorFlow is now accessible from Go, Rust and Haskell.",Motivation
146,Why ignore JavaScript ?,Motivation
147,Really waiting for a machine library in JavaScript.,Expected Behaviour
148,+1,Social Conversation
149,+1,Social Conversation
150,ð¯ ð,Social Conversation
151,+1,Social Conversation
152,+1.0000000000000000000000001,Social Conversation
153,+1,Social Conversation
154,+1,Social Conversation
155,+1,Social Conversation
156,+1,Social Conversation
157,I am looking forward to see a official Node.js API.,Social Conversation
158,But I think there are some problems.,Solution Discussion
159,"1.         JavaScript have only 1 thread ,trainning  can block the whole process unless using callbacks or  other tricks.",Solution Discussion
160,"2.         lack of other science labs, like numpy",Solution Discussion
161,3.         JavaScript only support 53bit precision.,Solution Discussion
162,"anyway, JavaScript is awesome!",Motivation
163,Is anybody working on this?,Task Progress
164,Looks very difficult.,Social Conversation
165,+1,Social Conversation
166,very need it!,Social Conversation
167,@stackOverMind.,Social Conversation
168,Did a little search on those bullet points.,Social Conversation
169,I've not tried any of these and they might not be efficient to use / run but it looks like there are things that exist to potentially solve those issues.,Solution Discussion
170,*         [taking advantage of multi processor environments in node js] URL ,Solution Discussion
171,*         [node-lapack] URL ,Solution Discussion
172,*         [Long.js] URL ,Solution Discussion
173,*         [mljs] URL ,Solution Discussion
174,*         [WebMonkeys - node GPU processing] URL ,Solution Discussion
175,+1,Social Conversation
176,+1,Social Conversation
177,+1 pweeettyyy pwease!!!,Social Conversation
178,+1,Social Conversation
179,+1,Social Conversation
180,Looking forward to it.,Social Conversation
181,ð,Social Conversation
182,+1,Social Conversation
183,Looking forward to it.,Social Conversation
184,:+1:,Social Conversation
185,ð,Social Conversation
186,+1,Social Conversation
187,+1.,Social Conversation
188,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
189,+1,Social Conversation
190,"+1 Can't wait, Python is great, Node and JS is great too",Social Conversation
191,+1,Social Conversation
192,+1 just for the sake of it,Social Conversation
193,+1!,Social Conversation
194,+1,Social Conversation
195,![image] URL ,Social Conversation
196,+1 ð,Social Conversation
197,+1,Social Conversation
198,+1 would be cool af,Social Conversation
199,+1 <3,Social Conversation
200,ð,Social Conversation
201,ð,Social Conversation
202,+100,Social Conversation
203,+1,Social Conversation
204,+1,Social Conversation
205,:+1:,Social Conversation
206,+2,Social Conversation
207,+1 ;),Social Conversation
208,mark,Social Conversation
209,+1,Social Conversation
210,+1,Social Conversation
211,+1,Social Conversation
212,+1,Social Conversation
213,+1,Social Conversation
214,+1,Social Conversation
215,+1,Social Conversation
216,+1,Social Conversation
217,+1,Social Conversation
218,+1,Social Conversation
219,:+1:,Social Conversation
220,+1,Social Conversation
221,+1,Social Conversation
222,+1,Social Conversation
223,ðPlease !,Social Conversation
224,+1,Social Conversation
225,+1,Social Conversation
226,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress
227,Does anyone know if there has been any healthy discussion regarding tensorflow and node anywhere else as these +1's don't seem to be doing much :(,Social Conversation
228,+1,Social Conversation
229,# +1,Social Conversation
230,ð,Social Conversation
231,+1,Social Conversation
232,+1,Social Conversation
233,:+1:,Social Conversation
234,it's been 2 years and still no luck?,Task Progress
235,Good.,Social Conversation
236,Fuck Javascript.,Social Conversation
237,+1.0/0.0,Social Conversation
238,Use synaptic https://github.com/cazala/synaptic,Workarounds
239,This is still in progress.,Task Progress
240,https://github.com/tngan/tensornode,Task Progress
241,this could be useful [keras-js] URL ,Solution Discussion
242,Other useful [source] URL .,Solution Discussion
243,"Unfortunately my day job is not coding and it requires proficiency in C++, which I personally don't have.",Social Conversation
244,"By the way CODE does only inference, no training, so no backpropagation.",Motivation
245,"Google developers implemented a small portion of Tensorflow in Javascript in their [playground] URL , the neural network implementation is [here] URL  and does include [back propagation](https://github.com/tensorflow/playground/blob/master/src/nn.ts#L282).",Motivation
246,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
247,+1,Social Conversation
248,+1,Social Conversation
249,**+1**,Social Conversation
250,+1,Social Conversation
251,I'm so happy to hear you're giving this a shot @JIoJIaJIu.,Social Conversation
252,The potential for impact in solving this issue is huge.,Motivation
253,It's our most upvoted issue.,Motivation
254,"At cursory glance, so far you seem to be doing the right thing.",Task Progress
255,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
256,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
257,That way we can build consensus around your vision and help it be the best vision possible.,Social Conversation
258,The TensorFlow team wants the NodeJS community to benefit from TensorFlow.,Motivation
259,So we're absolutely interested in helping the individual devoted to making that happen be successful.,Social Conversation
260,+1,Social Conversation
261,"Hi all, I created the Node.js bridging library for Tensorflow at: https://github.com/yorkie/tensorflow-nodejs without SWIG, it has supported ""predefined graph running"" and very simple ""graph construction"", I'm also planing to support more client features in the future :)",Task Progress
262,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
263,"@yorkie It looks interesting, I will try it out!",Social Conversation
264,However we cannot merge GPL code into TensorFlow.,Action on Issue
265,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
266,@ry sure I can change the license surely :),Action on Issue
267,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
268,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
269,+1,Social Conversation
270,+1,Social Conversation
271,+1,Social Conversation
272,+1,Social Conversation
273,+1,Social Conversation
274,JavaScript APIs for TensorFlow were [announced] URL  earlier this month.,Potential New Issues and Requests
275,See details on the [deeplearn.js] URL  homepage.,Potential New Issues and Requests
276,I'll close this (broad) bug now.,Action on Issue
277,Feel free to open other more specific FRs.,Potential New Issues and Requests
278,Fair enough.,Social Conversation
279,I see now that the bug title references Node.js directly.,Social Conversation
280,@vincentvanhoucke it's not even about node.js in the title.,Social Conversation
281,"Talking about ""deeplearn.js"" and ""Tensorflow API for Javascript"" is like talking about apples & pears.",Social Conversation
282,"First of all - deeplearn.js is a library that only mirrors to some extent ""the style of TensorFlow API"" and operates purely in the browser and the other would be a direct API to whole Tensorflow goodness.",Potential New Issues and Requests
283,"Also, its not even remotely close to being called an alternative to Tensorflow...",Potential New Issues and Requests
284,"maybe for hobbyists but not for commercial use, where one would need clusters of machines to aim the computing process.",Potential New Issues and Requests
285,I think of it as a demo what you can achieve with JavaScript and neural networks...,Potential New Issues and Requests
286,a taste of things to come...,Social Conversation
287,;-),Social Conversation
288,+1,Social Conversation
289,+999,Social Conversation
290,"Jesus christ, stop sending people useless notifications, there's a reason GitHub introduced ð and ð reactions.",Social Conversation
291,+1 and +999 just annoys people and adds no value whatsoever.,Social Conversation
292,+1000,Social Conversation
293,:+1:,Social Conversation
294,+1,Social Conversation
295,+1,Social Conversation
296,#                  ATTENTION,Social Conversation
297,ð Guys please before commenting +1 or +whatever - Please take a look at @k1sul1 's comment,Social Conversation
298,"
REFERENCE",Social Conversation
299,@shahen94 we all saw that but still...,Social Conversation
300,we are js dev.,Social Conversation
301,+1,Social Conversation
302,@BruceHem not really sure how being a js dev correlates with blindly pushing unnecessary spam to the feed...,Social Conversation
303,ð,Social Conversation
304,"You all are aware that ""+1"" just makes this topic unreadable?",Social Conversation
305,"I understand that we all have the desire to support this case but can only deduct that on github's closest thing to ""vote"" functionality is implemented with ""reactions"" not with a count of comments in the thread...",Social Conversation
306,or am I missing something?,Social Conversation
307,;-P,Social Conversation
308,Lol :P this thread died years ago.,Social Conversation
309,.,Social Conversation
310,+1 Googolplex!,Social Conversation
311,+1,Social Conversation
312,"Agreed with @thefill absolutely ""+1"" just makes this topic unreadable, and actually we had community implementations then if anyone wants to use TensorFlow with Node.js or JavaScript, just have a try with the above one or two, I think this might be a good start than comment votes here.",Social Conversation
313,"I was also asking for the help from @ry to make my personal repository to be supported officially, there are few things we have to do like building some example models especially RNN cases, but unfortunately I'm got to work on other fields and have no time for these few months, if someone is interested in making this be happened, email to me, I'd love to guide you how to start.",Potential New Issues and Requests
314,Let's the do something useful for community in best wishes :),Social Conversation
315,"In regards to the current projects that have been started, and specifically the challenges of working with the C API, I have a suggestion on implementation that has worked well for me.",Solution Discussion
316,"Since python is still the most robust, developer-friendly, and full featured wrapper around the Tensorflow API, rather than trying to ""re-create"" the python API for js, why not create bindings directly TO the python API?",Solution Discussion
317,"This would still require first creating a node C++ add-on, but rather than binding to the C API directly, you can employ ""embedded"" python to run python methods directly from C++.",Solution Discussion
318,This is unlike other JS => Python solutions out there that suggest simply spawning a python script...,Solution Discussion
319,a solution not viable for any reasonable size learning problems because of the extensive data transfer cost (time) between the processes.,Solution Discussion
320,"With embedded python however, memory accessed by your python script / numpy arrays directly point to your js Float32Array buffers.",Solution Discussion
321,This solution is working very well for me (though admittedly getting the initial js => C++ => python flow working was kind of a pain).,Solution Discussion
322,"Since I have specific needs, I have not gone through the task of binding to each individual python TensorFlow method, and instead just pass my data and hyper parameters to a few methods that build most of the graph.",Solution Discussion
323,The full individual binding wouldnt be too bad from my current starting point.,Solution Discussion
324,I welcome any thoughts or suggestions on the approach outlined above.,Social Conversation
325,Thanks.,Social Conversation
326,@djimoh5 Awesome thoughts on JavaScript to Python full-featured APIs!,Social Conversation
327,"The other hand, we also could put an implementation of a RPC server for TensorFlow Python APIs with introspection feature, so that JavaScript and other language clients could access the real-time Python.",Solution Discussion
328,"(I will do this when I'm available, aha)",Contribution and Commitment
329,"But here is something about why re-creating some Python features for JavaScript, because they are written in JavaScript, they are more friend to JavaScript developers, and it's easy for that developers to modify the source code to check if something different is possible, not just the get feeds from upstream :)",Solution Discussion
330,+1,Social Conversation
331,I'm also interested in nodejs tensorflow API   to be able to use it in a node-red flows that would chain tensorflows graphs and may be other kinds of data analysis nodes.,Motivation
332,I still don't know much about tensorflow.,Social Conversation
333,It may not be the right place to ask but I'd like to know why others developers look for a nodejs api/add-on for tensorflow ?,Motivation
334,What would be your use cases ?,Motivation
335,@khelkun answer is rather simple: providing mature JavaScript package that allows easy interaction with Tensorflow opens myriad new possibilities.,Motivation
336,"JavaScript operates on every mobile platform, all major desktop Operating systems & in all the browsers so possibilities are endless.",Motivation
337,"Biggest benefits would come for sure from server-side applications that operate on node.js that could directly interact with Tensorflow, but also node-webkit (desktop applications) could potentially spawn dozens of interesting projects.",Motivation
338,"Are the community organizers /admin of this thread not able to simply delete the posts of the those people that intensionally trolling with all the ""+1'sâ maybe even ban them?",Social Conversation
339,Lol,Social Conversation
340,Has anyone working on this integration considered using WebAssembly (wasm)?,Solution Discussion
341,"It is potentially the most elegant solution to this problem, side-stepping all of the JS talking to Python talking to C++, you know.",Solution Discussion
342,"I really don't know much about the internals of TensorFlow, but I believe the C++ parts of TensorFlow could be compiled to wasm (check the MVP features supported, but Unreal Engine 4 was compiled to wasm's predecessor and ran successfully in FireFox).",Solution Discussion
343,"Once the C/C++ API is compiled to wasm, you just need to ensure the necessary API is exposed.",Solution Discussion
344,"wasm will run in Node.js, all major browsers, and even outside of any of those, since it is meant to be an extremely portable bytecode.",Solution Discussion
345,This seems like the best path forward to me.,Social Conversation
346,Related resources/discussion:,Solution Discussion
347,*         https://groups.google.com/forum/#!topic/v8-reviews/DjiUKahI6ak,Solution Discussion
348,*         https://github.com/tomasreimers/tensorflow-emscripten,Solution Discussion
349,+1...,Social Conversation
350,we no longer live in the medieval portion of the information age.,Social Conversation
351,Please support node.js.,Social Conversation
352,Why would anyone need another Javascript library?,Motivation
353,Why would anybody use a JS library to train NNs?,Motivation
354,Javascropt is a bad desigbed language.,Social Conversation
355,@AyalaSaenzJorge lol (since you're trolling why dont I have at it) ...,Social Conversation
356,"How about we LOVE ""badly"" designed languages?",Social Conversation
357,Javascript happens to be to most prevalent language currently in existance..,Motivation
358,more code (on earth) is written in javascript than ANY other high level language..,Motivation
359,And that's a FACT and it's never going away sorry lol,Social Conversation
360,For those of you more serious than this troll Checkout the https://deeplearnjs.org ...,Solution Discussion
361,It is influenced by tensorflow and backed by Google ...,Solution Discussion
362,Maybe rather than starting from scratch we may consider porting that to Node.js instead,Solution Discussion
363,"@somombo yes, it looks really interesting.",Social Conversation
364,"RE: tensorflow + deeplearnjs, see esp:",Solution Discussion
365,*         https://deeplearnjs.org/demos/mnist/mnist.html,Solution Discussion
366,*         https://github.com/PAIR-code/deeplearnjs/issues/238,Potential New Issues and Requests
367,*         https://github.com/PAIR-code/deeplearnjs/issues/407,Potential New Issues and Requests
368,etc,Social Conversation
369,"@AyalaSaenzJorge this is a place for informative comments, not an opinionated-firestarters.",Social Conversation
370,@somombo please see my comment from 26 Aug where I explain why deeplearnjs is irrelevant to this debate.,Solution Discussion
371,Ok sorry for the comment.,Social Conversation
372,+1,Social Conversation
373,"@cpple Remember not to add +1s, they cause noise and have been replaced by reactions.",Social Conversation
374,Try giving the first comment a thumbs up,Social Conversation
375,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
376,Thought I'd share since a number of folks have expressed interest on this issue.,Social Conversation
377,I've created a fork of headless-gl that works with deeplearnjs (which in turn works with tensorflow) - this allows models to be run natively on the GPU from node.js (note that it's only been tested on OSX so far).,Potential New Issues and Requests
378,"You can find the install directions and a basic sample at https://github.com/dfoody/headless-glAnd, of course https://deeplearnjs.org for more details.",Potential New Issues and Requests
379,General directions to install on OSX:CODE,Potential New Issues and Requests
380,And a quick sample to show how it's used together with deeplearnjs:CODE,Potential New Issues and Requests
381,"@dfoody thank you for sharing this with the community but the statement ""which in turn works with tensorflow"" is incorrect.",Social Conversation
382,Also please see my comment from 26 Aug where I explain why deeplearnjs is irrelevant to this debate.,Social Conversation
383,"@nikhilk amazing, keep on going!",Social Conversation
384,I will keep an eye on your project for sure ;-D,Social Conversation
385,+1,Social Conversation
386,[propelml.org] URL  - Looks interesting.,Workarounds
387,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
388,@7ammer propelml.org looks rather promising.,Social Conversation
389,Thanks for sharing this with us ;-),Social Conversation
390,Because NodeJS it's fast!,Motivation
391,;D,Social Conversation
392,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
393,Please note I'm not going to do this.,Contribution and Commitment
394,You can add Node to [workspace.bzl] URL  just like TensorBoard did in [js.bzl](https://github.com/tensorflow/tensorboard/blob/99a7437/third_party/js.bzl#L25).,Solution Discussion
395,Please note TensorFlow can not depend on [rules_nodejs] URL . CODE,Solution Discussion
396,"Now let's say you want you have a Node program, e.g. [tsc.js](https://github.com/tensorflow/tensorboard/blob/99a7437/third_party/js.bzl#L73), which you want to turn into something you can CODE.",Solution Discussion
397,One quick way you could do this in Bazel is by defining a macro in CODE: CODE,Solution Discussion
398,Now for the fun part.,Social Conversation
399,"I would write a single .js file (even if it had to be 30,000 lines long like [tex.web] URL  with zero dependencies other than the Node standard library.",Solution Discussion
400,The inputs for this program would be [ops.pbtxt] URL  and all the other pbtxt files in [api_def/base_api] URL .,Solution Discussion
401,The output to this program would be exactly one gigantic C++ file that talks to [TensorFlow C API] URL  and [Node C++ Addon API] URL  based on [this example] URL .,Solution Discussion
402,CODE,Solution Discussion
403,Then you CODE and bam you've got your NodeJS project all bundled and ready for distribution to places like NPM.,Solution Discussion
404,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
405,"There's a diversity of visions out there on friendly modern high-level idiomatic JS and ML APIs, each catering to different use cases.",Motivation
406,However they could all share this binding in common.,Motivation
407,Please note there are examples of where we already generate language bindings.,Motivation
408,See [tensorflow/go/genop/main.go] URL  and [tensorflow/go/op/generate.go] URL  for inspiration.,Motivation
409,Looks like the TensorFlow team is making this a top priority now: https://js.tensorflow.org/faq/,Social Conversation
410,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
411,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
412,I will close this issue.,Action on Issue
413,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
414,Related and possibly of interest: I managed to get TF running in the browser via Webassembly.,Potential New Issues and Requests
415,See https://humantoanimal.com for a demo; I will be providing more details in the future.,Potential New Issues and Requests
416,"@nuchi, so did you compile the necessary TensorFlow code from the C API to WebAssembly?",Potential New Issues and Requests
417,Or are you using TensorFlow.js?,Potential New Issues and Requests
418,@lastmjs I explain in more detail in the link I provided.,Potential New Issues and Requests
419,Short version: I added Webassembly as an XLA compilation target.,Potential New Issues and Requests
420,I did not use Tensorflow.js in any way.,Potential New Issues and Requests
421,@nuchi Great work!,Social Conversation
422,and I know another WebAssemble research on TensorFlow at here:https://medium.com/@tomasreimers/compiling-tensorflow-for-the-browser-f3387b8e1e1c,Potential New Issues and Requests
423,Glad to see that there's official progress on this.,Social Conversation
424,"I'd love to have fast, parallel GPU compute power at my fingertips with the ease and composability of JS.",Motivation
425,"I started working on a [NodeJS binding for TensorFlow] URL  a while ago, but a haven't had much free time to devote to it lately.",Social Conversation
426,The concept is similar to @jart's suggested approach.,Solution Discussion
427,I had three goals in mind for the project:,Solution Discussion
428,#### 1. Don't require building or installing tensorflow,Solution Discussion
429,"Instead, it should [download and use] URL  the pre-built, multi-platform python binaries and download any needed source files on the fly.",Solution Discussion
430,#### 2. Don't require a complete C++ or JS reproduction or abstraction of the API,Solution Discussion
431,"Instead, it should provide a complete 1-to-1 interface with the C API, [providing convenient JS abstractions] URL  as much as possible.",Solution Discussion
432,#### 3. Don't maintain the C API [bindings] URL  [by] URL  [hand] URL ,Solution Discussion
433,"Instead, it should [use a swig script] URL  to map the core data structures between Tensorflow/stdc++/V8/node and the rest will follow.",Solution Discussion
434,"I got pretty far along with this, but last I remember a was having issues with TF_Session related segfaults.",Solution Discussion
435,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
436,Easy to use batch norm layer.,Expected Behaviour
437,Many non-experts are using the following code http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow?answertab=votes#tab-top.,Motivation
438,It would be nice to have an official batch norm layer given its importance in training DNNs.,Motivation
439,I'm working on some parts of that.,Contribution and Commitment
440,I think some thing wrong with this layer.,Solution Discussion
441,in training every thing is OK and loss decrease very good.,Solution Discussion
442,but in testing I get zero accuracy.,Solution Discussion
443,"By the way in testing when I use is_training=False, I get zero acc.",Solution Discussion
444,"I know batch normalization behave different in train and test phase, as describe in [How does batch normalization behave differently at training time and test time? - Quora] URL .",Solution Discussion
445,I think this implementation is unclear,Solution Discussion
446,"Same here, I have experienced some unexpected behavior with is_training=False.",Solution Discussion
447,What is the correct way to change this flag?,Solution Usage
448,I am currently using a CODE because it does not take CODE by itself.,Solution Usage
449,@pawni You have to use a Python boolean for CODE.,Solution Usage
450,It cannot be a CODE.,Solution Usage
451,@ppwwyyxx well I am doing CODE or is one just supposed to do a CODE and change that outside of the graph when needed?,Solution Usage
452,"Oh I thought you were doing CODE, which is incorrect.",Solution Usage
453,Your current way might have problems as well.,Solution Usage
454,"You'll need to double check that the two CODE op you created share the same scope, otherwise they won't share the underlying mean/variance statistics.",Solution Usage
455,"To do this the CODE argument might help, but I'm not sure because I use my own version of bn layer.",Solution Usage
456,I am using the same scope and CODE.,Solution Usage
457,It seems to work sometimes but I am not too sure.,Solution Usage
458,It would be great if the layer could be added to the documentation with a short explanation how to best handle the change from training to test.,Solution Usage
459,@sguada FYI,Social Conversation
460,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
461,"@pawni If you don't want to worry about about updating moving_mean and moving_variance set updates_collections=None to make sure they are updated in place, otherwise you need to make sure the update_ops added to tf.GraphKeys.UPDATE_OPS are run during training.",Solution Usage
462,"I think tensorflow need 2 hyper methods that change the model state, something like torch.",Potential New Issues and Requests
463,[change model state](https://github.com/torch/nn/blob/master/doc/module.md#training).,Potential New Issues and Requests
464,I think it is very straightforward.,Social Conversation
465,"is there a small script with a very simple NN that shows what is the proper way of using this ""official"" BN layer?",Solution Usage
466,I'd really appreciate it.,Social Conversation
467,is that not the official way to use BN?,Solution Usage
468,"I am confused on how to use it and the SO seems to be outdated and then there is a layer in a different link from the API, just how exactly does one do this?",Solution Usage
469,"sorry for the spamming, but what is wrong with just using something like this: CODE",Solution Usage
470,then its simple to tell tensorflow which one to use with a feed dictionary as in: CODE,Solution Usage
471,"since its unclear if the implementation will change, I wanted to give a suggestion (note its easy to extend to convolutions and stuff I just didn't paste that code).",Social Conversation
472,@pawni @ppwwyyxx did you guys decide if you had to use reuse to true to solve the scoping issue?,Solution Usage
473,@brando90 currently I am doing something like: CODE,Solution Usage
474,"However, I think that #3265 would basically want to implement it like this.",Potential New Issues and Requests
475,A reference could be the dropout implementation here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L433-L435,Potential New Issues and Requests
476,When the updates_collections=None then the updates happens in-place and it is easier to use a tf.cond() to allow is_training being a Tensor a bit more complicated is when the updates are delayed and the the update_ops are run later.,Solution Usage
477,I will try to get the first part in soon.,Contribution and Commitment
478,"@brando90 @pawni he's code works good, but have to change like below CODE",Solution Usage
479,"And when run in training or test time, CODE",Solution Usage
480,@nmhkahn @pawni thanks for the code snippets.,Social Conversation
481,They were very useful in adding batch normalization to my convolution network.,Social Conversation
482,Training seems to work very well.,Solution Usage
483,Testing is not.,Solution Usage
484,"In some versions of the code training accuracies are much higher than testing accuracies, which probably mean I am not sharing batch normalization parameters.",Solution Usage
485,"In other versions of the code I get ""ValueError: Variable conv1/beta already exists, disallowed. Did you mean to set reuse=True in VarScope?"" which seem to indicate that I am trying to relearn the parameter...",Solution Usage
486,when I was trying to reuse.,Solution Usage
487,"Can someone provide an example of how to call the ""def BatchNorm"" function during training and testing so that variable sharing happen correctly.",Solution Usage
488,Thanks for any help.,Social Conversation
489,"UPDATE July 25, 2016:",Social Conversation
490,@nmhkahn @pawni thanks for your comments.,Social Conversation
491,After taking a closer look at the code in contrib I realized what my problem was.,Solution Usage
492,"During training and testing we are either updating or reusing four variables (beta, gamma, moving_mean and moving_variance).",Solution Usage
493,To make those unique I had to set a scope per layer.,Solution Usage
494,I did it like this:,Solution Usage
495,"conv1 = tf.nn.relu(batch_norm_layer(conv2d_stride2_valid(data, W_conv1) + b_conv1, train_phase, scope=""conv1""))",Solution Usage
496,"where batch_norm_layer is similar to the examples from @nmhkahn @pawni, conv2d_stride2_valid is just a def to define a convolutional layer, and W_conv1 and b_conv1 are variables holding the weights and biases.",Solution Usage
497,I could probably remove the bias term because we are using batch normalization.,Solution Usage
498,The net is working well now.,Solution Usage
499,I noticed after plotting accuracies in training and test mode that the testing accuracies start climbing after the training accuracies.,Solution Usage
500,In retrospect it make sense since we are collecting dataset statistics for testing.,Solution Usage
501,But it appeared as if I was doing something wrong during my initial tests.,Solution Usage
502,Thanks for your comments and making batch normalization available to the community.,Social Conversation
503,@nmhkahn how is it different from pawni's suggestion?,Solution Usage
504,@brando90 I had a small error in my version which was fixed by nmhkahn (changing CODE to CODE),Solution Usage
505,@diegoAtAlpine I found the same problems - not sure why this is the case though.,Solution Usage
506,"However, the ValueError should be resolved by the code snippet.",Solution Usage
507,Not sure what you want to see how to call it as nmhkahn's examples seems to do the job?,Solution Usage
508,@nmhkahn @pawni @ when you do: CODE doesn't that mean that your using CODE as a placeholder?,Solution Usage
509,People have commented that they want CODE to be a placer holder but thats what I had for my version of it: CODE,Solution Usage
510,is that not correct?,Solution Usage
511,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
512,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
513,is it just me or does adding this BN layer noticeably slows down training of a single epoch?,Solution Discussion
514,@brando90 It slows down training for me as well but I think that this is expected as it needs to calculate some statistics.,Solution Discussion
515,And your version looks good to me.,Social Conversation
516,"BatchNorm is currently very slow (because of all the statistics computed), but they are working on adding a cudnn batchnorm op as said [here](https://github.com/tensorflow/tensorflow/pull/1759#issuecomment-228856467).",Solution Discussion
517,"@nmhkahn  quick question. When you wrote (for testing): CODE in theory, can bx and by be any data set?",Solution Usage
518,i.e. it can still be the **training** set even though we are not training?,Solution Usage
519,(i.e. just to track the train error),Solution Usage
520,@brando90 you're right.,Social Conversation
521,I am also confused regarding is_training and reuse flags.,Social Conversation
522,"I have created a program following the CIFAR example, where my code is structured as in CIFAR:-         Inference-         Loss-         Train",Solution Usage
523,And I am running it in a multi-gpu fashion (for training).,Solution Usage
524,So I have one script for training (similar to cifar10_multigpu.py) and one for testing (similar to cifar10_eval.py).,Solution Usage
525,So CODE,Solution Usage
526,The inference happens with the function MyModel.,Solution Usage
527,"(below is an example of the function, in reality i use more layers and neurons). CODE",Solution Usage
528,I want to perform batch nomalization.,Solution Usage
529,So when I did: CODE,Solution Usage
530,"I got the following error in the training phase:Variable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?",Solution Usage
531,From what I 've been reading in this thread in the training phase I should be using reuse=None.,Solution Usage
532,Have I got this part correct?,Solution Usage
533,"If this is true, then since I am using two GPUS, should I do reuse=None in the first GPU and reuse=True in the second?",Solution Usage
534,Or since I am doing tf.get_variable_scope().reuse_variables() it takes care of itself?,Solution Usage
535,"Finally, in the testing phase, should I have is_training=False and reuse=True?",Solution Usage
536,Any help is greatly appreciated.,Social Conversation
537,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
538,Is it normal that Batch Normalization makes my experiments **worse**?,Solution Usage
539,"I tried it on a 2 layered NN network based on the MNIST beginner tutorial and I consistently get worse results when BN is present: with BN (one with scale and center trained and the other not) accuracy is 0.8423, 0.8221 and without BN accuracy is 0.9477.",Solution Usage
540,My script is present here https://github.com/brando90/tensor_flow_experiments/blob/master/tf_tutorials/beginner_tutorial_MNIST_BN.py,Solution Usage
541,anyone has experienced these problems or is BN just like this and I need to do something else to make it work?,Solution Usage
542,"But what it is important is that either you pass [updates_collections=None](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L142) so the moving_mean and moving_variance are updated in-place, otherwise you will need gather the update_ops and make sure they are run.",Solution Usage
543,I would like to encourage you to use [CODE] URL  or [CODE] URL  to build your model.,Solution Usage
544,CODE,Solution Usage
545,@sguada I changed my old one where I manually tell it to train or not (based on a tf.cond) and now it seems the accuracy is up to ~95's again.,Solution Usage
546,Why was it that I needed to change updates_collections to be None?,Solution Usage
547,Do you mind explaining me why that gave such a big accuracy difference?,Solution Usage
548,Its seems like a non-trivial change (should it None be its default value then if it matters so much?).,Solution Usage
549,Thanks!,Social Conversation
550,:),Social Conversation
551,"Also, I noticed you said it was a placeholder and I didn't need to do it manually.",Solution Usage
552,"However, when I passed a placeholder for is_training it said CODEtf.TensorCODEboolCODEif t is not None:CODEif t:CODE and pointed to batch_norm code.",Solution Usage
553,Maybe It could be nice to show how this placeholder thing should be used because it seems I don't understand how its suppose to be used.,Solution Usage
554,Thanks!,Social Conversation
555,:),Social Conversation
556,@brando90The relevant part of the code is here [L227-256](https://github.com/tensorflow/tensorflow/blob/98d63de3bb2bab7c9a81f83c8ca864741399300c/tensorflow/contrib/layers/python/layers/layers.py#L227-L256).,Solution Discussion
557,As you will notice is there is a CODE statement that forces the updates.,Solution Discussion
558,"I believe that for the code to be used ""right out of the box"" the default should be None.",Solution Usage
559,"As for my comment above [1122](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235433645), I figured out that   tf.get_variable_scope().reuse_variables() takes care of the issue, so  in the training phase the argument reuse of batch_norm should be None.",Solution Usage
560,Use of batch_norm with tf.placeholder CODE,Solution Usage
561,"The problem before was that you were not updating the CODE and CODE after each step, when updates_collections is None it forces the updates as part of the computation.",Solution Usage
562,"However when a network has many batch_norm layers it is more efficient to collect all the update ops and run them together, so each layer don't need to wait for the update to finish.",Solution Usage
563,CODE,Solution Usage
564,I was trying to use batch norm with a 2 layered densely connected NN with the (flatten) MNIST  (and relu units) data set for the task of auto-encoding  and I keep getting a NaN error.,Solution Usage
565,Anyone know why might this be?,Solution Usage
566,Is this ever possible with BN?,Solution Discussion
567,"seem fishy, but it couldn't be my learning set up, rate etc. (but I'd assume it shouldn't because BN should be sort of rubust to this)",Solution Usage
568,@sguada I am not understanding the right way of using CODE specially concerning the flag CODE.,Solution Usage
569,"If I understood correctly if the flag is CODE the network is not efficient, so I should let CODE and then I should collect all the batch_norm updates and run them together.",Solution Usage
570,You collect the batch_norms updates by doing: CODE.,Solution Usage
571,"I have many different models that use different batch_norm layers, this wouldn't work right?: CODE",Solution Usage
572,Could you explain this part with a bit more details?,Solution Usage
573,Thank you very much.,Social Conversation
574,Just put it in seperate collection-keys: CODE CODE,Solution Usage
575,"Nevertheless, the documentation seams to be out-dated.",Solution Usage
576,It tells to do the following: CODE,Solution Usage
577,I replaced it with _tf.tuple()_,Solution Usage
578,"-         ~~I don't know how to access _control_flow_ops.with_dependencies()_. How can I access functions within control_flow_ops module? I have seen other examples just using tf.with_dependecies(), but I cannot do that with Tensorflow 0.10.~~ I found it here: _tf.python.control_flow_ops.with_dependencies()_",Solution Usage
579,**EDIT:**,Social Conversation
580,**EDIT 2:**,Social Conversation
581,"After doing some runs on my network, I have to say that ~~I can not see any performance difference between using  _updates_collections=None_ in contrast to manually fetching _tf.GraphKeys.UPDATE_OPS_ while graph construction~~. Even with heavy use of batch normalization (in total, my _tf.get_collection(tf.GraphKeys.UPDATE_OPS)_ returns 140 Update-Ops, all of them are BN-ops only)",Solution Usage
582,"Edit: Hard to say, if my results are correct, but the whole network indeed seams to be 1.5x faster.",Solution Discussion
583,"As far as I know, BN-statistics are calculated on CPU, not GPU so far.",Solution Discussion
584,Can anyone of you see any performance benefits as well?,Solution Discussion
585,Please share your results :),Social Conversation
586,"Coming back to the performance issue, does the current batch norm layer benfit at all from GPU Solution Usage?",Solution Discussion
587,Anyone has experienced benefits from GPUs with this batch norm implementation?,Solution Discussion
588,You can test for yourself:https://github.com/tensorflow/tensorflow/blob/4addf4b5806cd731949c6582a83f5824599cd1ef/tensorflow/python/ops/batch_norm_benchmark.py,Solution Discussion
589,"Sorry for the spam, but the documentation doesn't really explain how to use this BN with convolution (maybe should be provided somewhere?).",Solution Usage
590,In short how does it figure out that it should apply and learn the same parameters per feature (rather than per activation)?,Solution Discussion
591,(Is there at least a code snippet to do this?),Solution Usage
592,The slim batch_norm wrapper normalizes over the last dimension of your input tensor.,Solution Discussion
593,"So if it's a 2D input tensor coming from a fully connected layer, it normalizes over batch, and thus performs per-activation normalization.",Solution Discussion
594,"If it's a 4D tensor coming from a convolution, it will normalize over the three first dimensions (batch, width, depth), and thus perform per-feature normalization.",Solution Discussion
595,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
596,"@nmhkahn Regarding your code snippet, may I ask why is CODE set to be CODE when CODE?",Solution Usage
597,"I thought in the original paper, CODE and CODE are ""learned along with the original model parameters"".",Solution Discussion
598,"To do that, shouldn't they be only initialized once and then reused in all training steps?",Solution Usage
599,CODE,Solution Usage
600,I greatly appreciate the work that the TF team has put in here to make batch_norm available and effective.,Social Conversation
601,"From my searching, this thread is the best resource for how to use it.",Social Conversation
602,"There are many different problems and ideas flying around here, and it's difficult to figure out the consensus advice for the simplest standard case of how to use the batch_norm layer.",Social Conversation
603,My best attempt to figure that out brought me to the following code: CODE,Solution Usage
604,Then I set is_training_ph to True for training and False for testing.,Solution Usage
605,This doesn't work for me.,Solution Usage
606,"The model trains fine, but the test performance is terrible.",Solution Usage
607,"In contrast, if I maintain is_training_ph=True for test time, it works great.",Solution Usage
608,"Thus, I'm guessing I still have a scope issue so that it's not finding the proper existing variables.",Solution Usage
609,"@davek44 I'm using the same code framework that you are using and I observed the same thing: when turns on CODE during training phase and turns off CODE for validation and/or testing phase, the model trains well like the paper described (model converges faster and I was able to use a larger learning rate), however the testing performance is terrible.",Solution Usage
610,"If I turns on CODE all the time, the model trains the same as without inserting batch norm layer.",Solution Usage
611,"I haven't figured out what I did wrong, I'm planning to use TensorBoard to monitor the parameters.",Solution Usage
612,Would you please update if you diagnose the cause of this behavior?,Solution Usage
613,"tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.",Solution Usage
614,CODE,Solution Usage
615,I see the same poor test performance with that code.,Solution Usage
616,"Without more details is impossible to know, my guesses are that you only train for a few iterations, so the moving_mean and moving_average haven't converge yet.",Solution Usage
617,You can change the batch_size during test to see how the performance degrades as you make your batch smaller.,Solution Usage
618,I had exactly the same problem either with tf.slim batchnorm or with tf.cond and input is_training as a placeholder.,Solution Usage
619,"In the former case, when investigating the trained model, I found out that the moving mean and moving variance consist of all zeros.",Solution Usage
620,"In the latter case, the moving mean and variance look more reasonable (with different values), but if I use is_training=False in test time, the performance is also really bad.",Solution Usage
621,@nmduc @davek44  I wrote some code to track the moving mean and moving variance computed in CODE during training and testing.,Solution Usage
622,"I found out that the value of CODE matters a lot (they use exponential decay to compute moving average and moving variance), with a CODE setting closer to 1.0 (i.e. CODE), moving mean drops to a value closer to 0.",Solution Usage
623,"I did 2 test runs with the exact same code but different CODE settings in the CODE, and my validation/test accuracies seemed more reasonable.",Solution Usage
624,"The test run results with CODE<img width=""784"" alt=""screen shot 2016-11-16 at 1 51 51 pm"" src=""https://cloud.githubusercontent.com/assets/6901075/20361517/dd5dbbd8-ac05-11e6-85ac-5a9e2dec3a2b.png"">",Solution Usage
625,"The test run results with CODE (CODE is the default setting in CODE)<img width=""784"" alt=""screen shot 2016-11-16 at 2 03 58 pm"" src=""https://cloud.githubusercontent.com/assets/6901075/20361605/31729f5e-ac06-11e6-9736-eb9ad2f15de1.png"">",Solution Usage
626,(also seems like larger decay value would require the model to train longer to see validation accuracy change ),Solution Usage
627,Yup that fixed it.,Solution Usage
628,Thanks for sharing your analysis @zhongyuk!,Social Conversation
629,I encourage the developers to consider making decay=0.9 the default.,Solution Discussion
630,Even 0.99 doesn't work well for me.,Solution Discussion
631,"That's the default value in Torch's implementation, too; see the momentum parameter in https://github.com/torch/nn/blob/master/BatchNormalization.lua",Solution Discussion
632,@zhongyuk Thanks a lot for sharing .,Social Conversation
633,It works for me now.,Solution Usage
634,This seems important.,Social Conversation
635,@sguada we should consider the right course of action here before 1.0.,Social Conversation
636,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
637,"I am pretty sure I've never had to tweak that parameter, but it might be a side effect of the distributed setting.",Solution Discussion
638,We could change the default to 0.9 or document better its impact in smaller datasets or few updates.,Solution Discussion
639,"@vincentvanhoucke in our distributed setting we usually do millions of updates so it is ok, however in other cases like the one here which does only a few hundreds of updates it makes a big difference:For example using decay=0.999 has a 0.36 bias after 1000 updates, but that bias goes down to 0.000045 after 10000 updates and to 0.0 after 50000 updates.",Solution Discussion
640,"Just wanted to note that I also have the problem of poor test performance, specifically using small batch sizes (anything smaller than 10 instead of the 200 I used for training diminishes test accuracy).",Solution Usage
641,I've used a tf.placeholder to switch between testing/training mode.,Solution Usage
642,"It's great that this batch normalization layer works for better training convergence, but if you can't apply the model in production, there isn't much of a point in using it.",Motivation
643,Can anyone confirm good test performance with small or single data samples using this batch norm layer?,Solution Usage
644,"I can confirm that test performance is good when using is_training=False with small batches and even with batch_size=1, since it is not using statistic from the batch, but the statistic learnt during training.",Solution Usage
645,Just need to make sure that the statistics have converged with default decay=0.999 that implies at least 50k updates.,Solution Usage
646,"To follow up with TF developer's confirmation, I track the convergence of the statistics with two different CODE settings (and training batch_size=1).",Solution Discussion
647,"With CODE, the statistics converge (bias<0.001) after 550~600 steps of learning/updates.",Solution Discussion
648,"With CODE, the statistics converge (biase<0.001) within within 100 steps of learning/updates.",Solution Discussion
649,"@sguada thanks, does that also mean the output is actually independent of the batch size?",Solution Discussion
650,because I'm noticing very slight changes with big impact on my accuracy (maybe my definition of performance is just more easily affected by this slight change).,Solution Usage
651,"To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size.",Solution Usage
652,"Per value this isn't that much of a difference, but has a big impact when computing vector distances in latent spaces.",Solution Usage
653,"@zhongyuk thanks, I've run about 5k updates with CODE, so it should've converged and testing performance using large batch sizes is fine.",Solution Usage
654,"But even if it didn't, would it result in a difference between training a testing?",Solution Usage
655,"I'd be seeing bad performance during training *and* testing if it hadn't converged, right?",Solution Usage
656,I will investigate some more and see if I can reproduce the issue on another task.,Social Conversation
657,Thanks for the quick feed back so far!,Social Conversation
658,"@dominikandreas If your poor testing performance is caused by statistics not converging, you'd see reasonably good training performance but bad testing performance.",Solution Usage
659,"Because during training, the batch normalization is done using the training batch statistics only.",Solution Discussion
660,"However, during testing time, it's using the moving average statistics of all the training batches to normalize the input tensor.",Solution Discussion
661,"I found and error in my code, batch normalization is working fine now :-)",Solution Usage
662,thanks for your support,Social Conversation
663,"Hi @zhongyuk , how did you keep track of the moving mean and variance?",Solution Usage
664,Thanks!,Social Conversation
665,@rogertrullo Generally I setup TensorBoard to track moving mean and variance.,Solution Usage
666,"Other than that, I also tried fetching statistics through CODE within scope during training and reference to monitor the bias.",Solution Usage
667,"hi,I have same problem as other described that I have good training results but validation/testing is bad after using batch_norm.",Solution Usage
668,"I use the function like this:conv_normed1 = tf.contrib.layers.batch_norm(conv1 + block1_layer3_1_biases, updates_collections=None, scale=True, decay=batch_norm_decay, center=True, is_training=is_training )",Solution Usage
669,decay value is 0.9,Solution Usage
670,do I need to set the reuse flag?,Solution Usage
671,I will glad for any help.,Social Conversation
672,I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.,Solution Usage
673,"When saving and restoring using:saver = tf.train.Saver()it works, but when saving using:saver = tf.train.Saver(tf.trainable_variables() + [global_step])so that I can save storage space (by not saving the gradients etc)on restore there is an error:""uninitialized value unpool4/convc/bn/moving_mean""",Solution Usage
674,Obviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers.,Solution Usage
675,As I have lots of them (nested in many layers) - what is the most efficient way of adding them to the list of values to be saved?,Solution Usage
676,"Also, given that these are trainable variables, why are they not addded to the trainable_variables collection?",Solution Discussion
677,"@mshunshin moving mean and variance are not trainable variables: there are no gradients coming to them, they are just accumulating statistics across minibatches of examples.",Solution Discussion
678,"To save/restore them, you can use tf.global_variables()",Solution Usage
679,for me things started to work when I used this wrapper:CODE,Solution Usage
680,the whole using of scopes and reuse is not clear in this thread for my opinion.,Social Conversation
681,Many thanks.,Social Conversation
682,With tf.global_variables() the save files are much larger as I think it includes the gradients; in the end I used: saver = tf.train.Saver([x for x in tf.global_variables() if 'Adam' not in x.name]),Solution Usage
683,and because the session manager init doesn't initialise them properly: sess.run(tf.variables_initializer([x for x in tf.global_variables() if 'Adam' in x.name])) (Using tf.train.AdamOptimizer),Solution Usage
684,"You can also use tf.model_variables() which contains the variables of the model, i.e. moving_mean",Solution Usage
685,"@sguada Sorry for trouble you, but is it possible to make an example on how to use slim.batch_norm when combined with slim.conv2d/slim.fully_connect in readme.md?",Solution Usage
686,"I'm using slim.batch_norm, but get good training performance and poor validation/test performance.",Solution Usage
687,I think it must be due to improper use of CODE or CODE or some other parameters.,Solution Usage
688,"Though there are many issues on batch normalization, it's hard to find a complete code snippet on how to use it, esp. for how to pass different parameters in different phase.",Solution Usage
689,"Say, in my [mnist_bn] URL  code, I controlled dependencies using CODE and set up CODE as a placeholder.",Solution Usage
690,But validation performance still is poor if I feed {is_training: False}.,Solution Usage
691,"I would greatly appreciate it if there's an official and complete (which means training, validating, testing are all included) batch normalization example.",Solution Usage
692,Thank you in advance!,Social Conversation
693,"hi,you need to set different scope for every time you use batch norm and give it the reuse input according to the training/test phase(TRUE when test FALSE when train) that works for me.",Solution Usage
694,@ishaybee Thanks for you help.,Social Conversation
695,I've found my problem= = **It's due to the cold start of moving_mean/moving_variance.**,Solution Usage
696,"Since I haven't trained enough steps, the estimated moving mean/variance is not that stable.",Solution Usage
697,"The result turns out to be: the model performs pretty well on training mini-batches (you know at the beginning loss goes down quickly), but validation performance is erratic (because the estimated population mean/variance are not stable enough).",Solution Usage
698,"When I trained the model longer, validation accuracy becomes prettier, too.",Solution Usage
699,"**Another important thing is, be sure to use CODE to create train op**.",Solution Usage
700,Do not use tf native CODE.,Solution Usage
701,What's more:1.         [Here is a full example] URL  on how to use BN layer on MNIST dataset.,Solution Usage
702,2.         Use a smaller decay value will accelerate the warm-up phase.,Solution Usage
703,"The default decay is 0.999, for small datasets such like MNIST, you can choose 0.99 or 0.95, and it warms up in a short time.",Solution Usage
704,"@soloice , notice, how in about [comment](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235928564) the following parameter is passed inside to the layer for calling batch_norm: >  batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}",Solution Usage
705,"Without CODEset to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.",Solution Usage
706,Or you may try to run UPDATE_OPS yourself explicitly as one [here](https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-279646674)CODE,Solution Usage
707,Update - I found that I quoted exactly your code and you do use UPDATE_OPS.,Social Conversation
708,"As for ""cold start"", as you see above in discussiion, decreasing BatchNorm running average decay (input param) from default 0.999 to something like 0.95 can speed-up start-up",Solution Usage
709,@pavelbulanov It's very kind of you to help me with this!,Social Conversation
710,I'll try a smaller value of CODE to see how this helps.,Social Conversation
711,"Update: use a small decay (say, 0.9 or 0.95) does help a lot.",Solution Usage
712,Validation loss goes down very quickly when I set CODE to 0.9.,Solution Usage
713,"However, the drawback of small decay is that its effective range is small: The result is dominated by a few recent samples thus it's not a good estimation of population mean/variance.",Solution Usage
714,One needs to balance between quick start (small decay) and a longer effective range (large decay).,Solution Usage
715,"Hi,I tried to implement a batch normalisation layer with the help of the suggestions in this issue, but I still have a >70% error in validation and testing...",Solution Usage
716,I do have a lower decay for non-training calls...,Solution Usage
717,Here is my code:CODE,Solution Usage
718,Thank you in advance.,Social Conversation
719,@Alexivia It seems that you are using two different batch normalization layers?,Solution Usage
720,"You should use only one BN layer (of course, with different CODE parameter).",Solution Usage
721,Thank you for your advice @soloice.,Social Conversation
722,I tried now with just different CODE and CODE parameters:CODE,Solution Usage
723,still don't get good validation and testing results... >70%...,Solution Usage
724,"hi,please see my wrapper above.you should use ""with tf.variable_scope(scope, reuse=reuse):"" I think.",Solution Usage
725,"Hi @ishaybee,I followed your advice, now my code is:CODE",Solution Usage
726,"and I feed CODE and CODE through the feed_dict, but now I get the error CODE",Solution Usage
727,try to feed reuse as a python variable (input of the model) and as placeholder.,Solution Usage
728,"I tried that, and now it stopped complaining about the value...",Solution Usage
729,"but I think that the placeholder value is not being used, because I see no change if I force values to CODE function, and in TensorBoard it's not connected to the graph...",Solution Usage
730,(see attached image)![screen shot 2017-04-03 at 19 54 54] URL ,Solution Usage
731,My code is like this now:**Batch Normalisation wrapper**CODE**Model definition**CODE**Training**CODE**Validation**CODE,Solution Usage
732,"Although is_traning can a placeholder reuse has to be a bool, and it cannot be a tensor nor a placeholder.",Solution Discussion
733,"I'm not sure what are you trying to do, in most cases using static values solve the problem.",Solution Usage
734,For example this pattern works well: CODE,Solution Usage
735,"Unless you need to change the behavior of the model dynamically, you don't need to use a placeholder for is_training.",Solution Usage
736,"The trick is to build the model twice, but sharing the variables the second time.",Solution Usage
737,Thank you @sguada !,Social Conversation
738,"After applying your suggestions, I finally made it to work!",Social Conversation
739,"Being a newer tf user, I found that my test error was crazy and then had to spend a fair amount of time debugging my graph until I realized that batch normalization was the problem.",Solution Usage
740,Then I had to spend more time figuring out that by default the variables tracking the moments don't update unless you use a contrib function for optimization.,Solution Usage
741,"Additionally, it seems like it might make sense to have a parameter to add the control flow dependencies to the op that runs in the training case.",Solution Discussion
742,@danrsc Exactly.,Social Conversation
743,The Solution Usage of BN layer is quite confusing.,Social Conversation
744,"I suggested to add documents or a complete official tutorial on batch normalization, but unfortunately got no response = =",Social Conversation
745,Completely agree.,Social Conversation
746,Reopening for visibility of the documentation issues.,Action on Issue
747,@sguada assigning to you for triaging.,Contribution and Commitment
748,Might be worth getting a tech writer on the case.,Contribution and Commitment
749,Just got confused by this problem last week and wasted 3 days of training...,Social Conversation
750,"@sguada  I have noticed that you said"" tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial"".",Solution Usage
751,"Howerver, the comment in the code isIf CODE doesn't have a constant value, because it is a CODE,# a CODE or CODE then is_training_value will be None and# CODE will be true.",Solution Usage
752,"So if CODE is a CODE or a CODE, it means it can change, so the graph to compute the moments is needed, so the layer builds it.",Solution Discussion
753,Then in running time depending on the value being CODE or CODE would use the batch CODE or the CODE and CODE.,Solution Discussion
754,So during testing you would set the value to CODE and the CODE won't be used.,Solution Usage
755,@sguada @brando90CODE,Solution Usage
756,"I build batchnorm like this, however, the moving mean and moving variable are updated during test, I can not find the reason.",Solution Usage
757,"I tried creating two models like @sguada said, however, my model where is_training=False just crashes.",Solution Usage
758,CODE,Solution Usage
759,"I feel like maybe there should be a concrete example of how to do a batch norm with a fully connected net, as well as with CNNs.",Solution Usage
760,Sucks that I've trained models for days expecting things to work before seeing that everyone trying to use this feature going crazy.,Social Conversation
761,"Interestingly enough, it takes a zillion years to get the model restored after training with batch_norm as well.",Solution Discussion
762,Will most likely wait until TF 2.0 to try something like this again.,Social Conversation
763,@MisayaZ you don't need to create two batch_norm layers you can just pass train_phase (assuming it is a tf.bool) to batch_norm.,Solution Usage
764,"Also you are passing UPDATE_OPS_COLLECTION variables_collections, which changes which collections are the variables added to.",Solution Usage
765,The following should work: CODE,Solution Usage
766,"@OktayGardener not sure what model are you trying to create, it seems that the variables are not saved in your checkpoint.",Solution Usage
767,batch_norm also works with fully_connected layers.,Solution Discussion
768,CODE,Solution Usage
769,"@sguada Thanks, I build a network with bathnorm which is implemented as you mentioned above",Solution Usage
770,CODE,Solution Usage
771,"the speed is slow, I use tensorflow benchmark to get the computation time as below:I tensorflow/core/util/stat_summarizer.cc:392] ============================== Top by Computation Time ==============================I tensorflow/core/util/stat_summarizer.cc:392]               [node type]                [start]                [first]               [avg ms]                   [%]                [cdf%]                [mem KB]              [Name]I tensorflow/core/util/stat_summarizer.cc:392]                    Conv2D                106.164                 51.354                 51.004               23.145%               23.145%                 692.224              conv8/Conv2DI tensorflow/core/util/stat_summarizer.cc:392]                    Conv2D                 85.187                 19.115                 19.283                8.750%               31.896%                 692.224              conv7/Conv2DI tensorflow/core/util/stat_summarizer.cc:392]         SquaredDifference                 11.967                 15.105                 14.331                6.503%               38.399%               11075.584              conv1/batch_norm/moments/sufficient_statistics/SquaredDifferenceI tensorflow/core/util/stat_summarizer.cc:392]                       Mul                 11.970                 14.162                 13.495                6.124%               44.523%               11075.584              conv1/batch_norm/batchnorm/mul_1I tensorflow/core/util/stat_summarizer.cc:392]                    Conv2D                  3.948                  8.170                  7.986                3.624%               48.146%               11075.584              conv1/Conv2DI tensorflow/core/util/stat_summarizer.cc:392]                       Sub                 11.960                 10.176                  7.943                3.604%               51.751%               11075.584              conv1/batch_norm/moments/sufficient_statistics/SubI tensorflow/core/util/stat_summarizer.cc:392]         SquaredDifference                 45.570                  5.908                  7.177                3.257%               55.007%                5537.792              conv2/batch_norm/moments/sufficient_statistics/SquaredDifferenceI tensorflow/core/util/stat_summarizer.cc:392]                       Mul                 45.574                  7.755                  6.902                3.132%               58.140%                5537.792              conv2/batch_norm/batchnorm/mul_1I tensorflow/core/util/stat_summarizer.cc:392]                    Conv2D                 40.692                  5.408                  4.845                2.199%               60.338%                5537.792              conv2/Conv2DI tensorflow/core/util/stat_summarizer.cc:392]                       Sub                 45.563                  6.067                  4.784                2.171%               62.509%                5537.792              con",Solution Discussion
772,"I don't understand why some op in moment are executed during test and it cost a lot of time, such as conv1/batch_norm/moments/sufficient_statistics/SquaredDifference.",Solution Discussion
773,"The moment is not needed in test, why are some ops under moment executed?",Solution Discussion
774,"Hi, Using the above CODE layer in CODE, I'm getting CODE as an output for validation graph while the train graph runs seamlessly.",Solution Usage
775,Is there anything that I might be missing ?,Solution Usage
776,I'm using:CODE,Solution Usage
777,Thanks,Social Conversation
778,"As a follow up, I'm reusing 16 layers of batch_norm.",Solution Usage
779,"However, I found that reusing 4 layers works.",Solution Usage
780,"I've just been noticing that if I kill the tensorflow process and restart it, my error gets worse for a few epochs (i.e. worse than it should be at the last checkpoint).",Solution Usage
781,"I also observe that if I remove batch_norm, this problem goes away.",Solution Usage
782,"After looking at the code for a while, I think this may be because the values of the variables are not restored from the shadow variables as they would be if the ExponentialMovingAverages class were used to manage the moving averages.",Solution Discussion
783,"This also means that if I use a separate process to evaluate, I'm getting whatever the last value of the variable was and not the moving average.",Solution Discussion
784,Am I interpreting this correctly and is this the intended behavior?,Solution Discussion
785,It seems like you want the shadow variable values to be restored...,Solution Discussion
786,The output of the tensor : CODE present in CODE isCODE,Solution Usage
787,How is this even possible ?,Solution Discussion
788,P.S. The batch norm layer is used just after the last fully connected layer of the network and before softmax.,Solution Usage
789,@raghavgoyal14 are you using it with fused=True?,Solution Usage
790,Had a similar problem and it went away when I used the fused version,Solution Usage
791,"@abred : Yes, I used CODE, same problem.",Solution Usage
792,"@sguada  Hi, sguada, I have a problem.",Social Conversation
793,"The definition of contrib.layers.batch_norm in tensorflow:def batch_norm(inputs,decay=0.999,center=True,scale=False,epsilon=0.001,activation_fn=None,param_initializers=None,param_regularizers=None,updates_collections=ops.GraphKeys.UPDATE_OPS,is_training=True,reuse=None,variables_collections=None,outputs_collections=None,trainable=True,batch_weights=None,fused=False,data_format=DATA_FORMAT_NHWC,zero_debias_moving_mean=False,scope=None,renorm=False,renorm_clipping=None,renorm_decay=0.99):scale: If True, multiply by gamma.",Solution Discussion
794,"If False, gamma isnot used.",Solution Discussion
795,Thank you very much.,Social Conversation
796,"When scale=False, gamma is a constant 1.",Solution Discussion
797,@ppwwyyxx Thank you very much for your help.,Social Conversation
798,"I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe.",Solution Usage
799,How to set the param of BatchNormLayer and ScaleLayer in Caffe?,Solution Usage
800,Thank you very much.,Social Conversation
801,"@MisayaZ I was having the same behavior using Batchnorm with a placeholder for ""is_training"".",Solution Usage
802,"I would have preferred to leave it as a placeholder because this way I can do periodic testing during training without redefining the graph, but I decided to use it as a constant and define different behaviors for train vs test, and now the moments are not calculated at test time.",Solution Usage
803,@tano297 Thank you.,Social Conversation
804,I now also use 'is_training' as a constant.,Solution Usage
805,Leave it as a placeholder and do periodic testing will change the value of moving mean and moving variance.,Solution Discussion
806,And the inference time will be longer for it will calculate the mean and variance of the inputs and update the moving mean and moving variance.,Solution Discussion
807,The right way to do testing is to define different behaviors for train and test as you mentioned.,Solution Usage
808,"@tano297 @MisayaZbut doesn't the ""smart_cond"" inCODEmake sure that the updates are only calculated and applied if is_training evaluates to True?",Solution Discussion
809,"@abred Yes indeed, but you are referring to line 391, where it does the update of the moving average within _fused_batch_norm(): CODECODEis_trainingCODETensorCODEVariableCODEPlaceholderCODEneed_updates` will be true.is_training_value = utils.constant_value(is_training)need_updates = is_training_value is None or is_training_valueif need_updates:...outputs = utils.smart_cond(is_training, _force_updates, no_updates)...CODE",Solution Discussion
810,"I am talking about line 753 within batch_norm(): CODECODEis_trainingCODETensorCODEVariableCODEPlaceholderCODEneeds_moments` will be true.is_training_value = utils.constant_value(is_training)need_moments = is_training_value is None or is_training_valueif need_moments:...mean, variance = utils.smart_cond(is_training,_force_updates,moving_vars_fn)...CODE",Solution Discussion
811,"The smart condition in that case (as far as I am concerned) decides wether or not to update the moving averages, but the moments still get calculated.",Solution Discussion
812,"@tano297 you right about that, I was in the wrong place, but still:line 755-770 calculate the moments, but the moments are only used in _force_updates which is only executed if is_training evaluates to True, aren't they?",Solution Discussion
813,And thusCODEshould be equivalent to line 804:CODE,Solution Discussion
814,"if is_training evalutes to False and thus the ""moments""-part of the graph is never used and thus shouldn't be executed",Solution Discussion
815,"but I haven't tested, so I might be wrong about that :)",Social Conversation
816,@tano297 @abred  you right.,Social Conversation
817,"The moving mean and moving variance are changed when I used batchnorm like this: def batch_norm_layer(self, x,train_phase, scope_bn):bn_train = batch_norm(x, decay=0.9, center=False, scale=True,updates_collections=None,is_training=True,reuse=None,variables_collections= [UPDATE_OPS_COLLECTION],trainable=True,scope=scope_bn)bn_inference = batch_norm(x, decay=0.9, center=False, scale=True,updates_collections=None,is_training=False,reuse=True,variables_collections= [UPDATE_OPS_COLLECTION],trainable=True,scope=scope_bn)z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)return z",Solution Usage
818,"I also met the problem that I could get good results when using is_training=True for both training and inference, but get bad results when setting is_training=False during inference (worse than the case using is_training=True).",Solution Usage
819,Am I right?,Social Conversation
820,"BTW, do I need to retrain the model using decay=0.9 from scratch?",Solution Usage
821,"Or resuming training from the checkpoint (i.e., trained when decay=0.999) is also ok?",Solution Usage
822,Thanks!,Social Conversation
823,@nmduc @davek44,Social Conversation
824,Have you guys solved this problem?,Task Progress
825,Thanks!,Social Conversation
826,I was confused after all these comments on how to properly use Batch Norm: So here is what I have.,Social Conversation
827,Please correct me if I'm wrong.,Social Conversation
828,CODE where phase_train_py is a python boolean variable and is_training is a placeholder taking a boolean variable.,Solution Usage
829,"I guess using tf.cond is wrong, otherwise would did the function came with a boolean parameters.",Solution Usage
830,"In other words, if CODE is true, then we should a CODE function for training and another one for testing.",Solution Usage
831,"So, developers allow us to change these boolean variables in order to change the behavior of the function.",Solution Usage
832,So What I am doing is: setting CODE to False while training while CODE to True.,Solution Usage
833,And the opposite while Testing.,Solution Usage
834,"Since we can only change tensors or placeholders with CODE, I changed CODE intentionally before running the graph.",Solution Usage
835,Ex: CODE,Solution Usage
836,AYBE YOU NEED READ THIS,Social Conversation
837,It seems there are still problems with TF v1.3.,Solution Discussion
838,"I'm sure I note the following details, but still failed to use the official CODE, with CODE during evaluation(but when I keep CODE unchanged during evaluation, it is ok):",Solution Usage
839,"1.         CODE,  exponential moving average is actually alpha filter in signal processing, the time to converge is approximately 1/(1-decay) steps of train.",Solution Discussion
840,"For decay=0.999, you need 1/0.001=1000 steps to converge.",Solution Discussion
841,So set the appropriate decay for your training step numbers.,Solution Usage
842,2.         using placeholder to switch between train and test evaluation,Solution Usage
843,3.         useCODE if you don't want to add control dependencies of update op to train_op,Solution Usage
844,4.         set CODE to appropriate value.,Solution Usage
845,"It seems the only way to use the official batch_norm is to build two graphs, one for train and one for evaluation, with CODE and CODE, respectively.",Solution Usage
846,"In this way, you don't need to switch dynamically between train and evaluation.",Solution Usage
847,But this is a stupid way since you need to build more than one graph.,Solution Usage
848,"Finally, I write a moving average by myself, and I find it worked!",Solution Usage
849,It's as follows(based on code on the web and modified by myself) CODE,Solution Usage
850,"Just use the CODE function during building a graph, the is_training parameter is a CODE.",Solution Usage
851,"Then you are free to switch the placeholder to True during train and False during evaluation, with CODE.",Solution Usage
852,Hope it helps the community.,Social Conversation
853,"When you use slim.batch_norm,be sure to use ""slim.learning.create_train_op"" instead of ""tf.train.GradientDecentOptimizer(lr).minimize(loss)"" or other optimizer.",Solution Usage
854,Try it to see if it works!,Social Conversation
855,"@vincentvanhoucke You wrote in another post in this thread: > The slim batch_norm wrapper normalizes over the last dimension of your input tensor. So if it's a 2D input tensor coming from a fully connected layer, it normalizes over batch, and thus performs per-activation normalization. If it's a 4D tensor coming from a convolution, it will normalize over the three first dimensions (batch, width, depth), and thus perform per-feature normalization. @sguada maybe forth being a bit more descriptive about this.",Solution Discussion
856,"Do you mean with ""slim batch_norm wrapper"" the function CODE?",Solution Discussion
857,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
858,"We've been at this for so long that I no longer have a good sense of what's obvious or not, and would welcome clarifying documentation for someone with a fresh perspective on the topic.",Social Conversation
859,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
860,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
861,"Otherwise, remove the CODE label.",Action on Issue
862,Thank you.,Social Conversation
863,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
864,"Otherwise, remove the CODE label.",Action on Issue
865,Thank you.,Social Conversation
866,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
867,"Feature Request: Vector ""File"" interface",Expected Behaviour
868,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
869,Is this in place yet?,Task Progress
870,"Would love to replace standard vector file and in-memory loading with my own Redis (or any other ""shared-memory-system"") interface to allow a distributed cluster of spacy nodes to share the same ""file"".",Expected Behaviour
871,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
872,"Yep, this should work: https://github.com/honnibal/spaCy/blob/master/spacy/vocab.pyx#L320",Solution Discussion
873,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
874,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
875,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
876,This makes spaCy much more useable for including in our docker environment where we literally have 100s of these containers running in parallel and memory is wasted for each instance.,Motivation
877,I'll hopefully have some spare time soon and will write a little pull request now that I know where to look :-),Social Conversation
878,This makes sense.,Social Conversation
879,"I'd like to change the current set up, because I want to support vectors keyed by different information, e.g. vectors keyed by lemma and part-of-speech.",Motivation
880,This lets you see different vectors for CODE and CODE.,Motivation
881,"Digital Reasoning wrote a paper showing this got them good results, and early examination of the vectors is looking good to me too.",Motivation
882,That's actually a really good idea!,Social Conversation
883,Could you link the papers here and I'll have a look at that as well.,Motivation
884,(thinking I might actually do this as part of my master thesis :P ),Social Conversation
885,"In a way this information is already contained in word vectors because two verbs will be seen in more similar contexts than adjectives but guess that by reducing ambiguity and ""false positives"" it could make quite a difference.",Motivation
886,Do you have some form of basic class design for it yet which I should stick to or shall I just come up with something?,Solution Discussion
887,"Here's the paper I mentioned, titled ""sense2vec"": http://arxiv.org/pdf/1511.06388.pdf , by @iamtrask",Motivation
888,Not so!,Social Conversation
889,"The most similar words to CODE might be things like CODE, while the most similar words to CODE might be CODE or CODE.",Motivation
890,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
891,"I've been playing with an extension of this idea, where noun chunks and named entities are also merged.",Potential New Issues and Requests
892,I've trained a model on one month of Reddit comments.,Potential New Issues and Requests
893,"The results at the moment are quite messy, and many of the phrases need to be pruned from the vocab.",Potential New Issues and Requests
894,But there are also some interesting results in there too.,Potential New Issues and Requests
895,Example: CODE,Potential New Issues and Requests
896,The vectors for the verb and noun senses are quite different: CODE,Potential New Issues and Requests
897,"The nearest neighbour of CODE turns out to be a misspelling, that the POS tagger seems to often tag correctly: CODE",Potential New Issues and Requests
898,"I'll be writing more about these vectors, and of course releasing the code. I'd like to sharpen up one or two things and run it on more data first.",Potential New Issues and Requests
899,"I can give you some code to get you started on the POS tagged vectors, though.",Solution Discussion
900,"As much as I dislike dumping state to disk, it's the most practical way to do this.",Solution Discussion
901,"It'd be nice to have the multi-threading sorted out for spaCy, but for now multi-processing is okay, especially for the tagger, which is fast and low-memory.",Solution Discussion
902,Example:https://github.com/honnibal/spaCy/blob/master/examples/pos_tag.py,Solution Discussion
903,Here's how to train Word2Vec on the output using Gensim.,Solution Discussion
904,(@piskvorky): CODE,Solution Discussion
905,That chunking experiment is fantastic.,Social Conversation
906,Love the take -> personal_stance.,Social Conversation
907,"I thought the answer was ""no"", but then I started writing out some ""suggestions"", and I guess I have a clearer idea than I thought :).",Social Conversation
908,Most of these things are demanded by consistency with the rest of the library.,Solution Discussion
909,You can see examples of pretty much all of this in the CODE and CODE classes: Python API:,Solution Discussion
910,"-         Use the CODE, CODE and CODE special methods.",Solution Discussion
911,You don't necessarily have to subclass dict.,Solution Discussion
912,-         All vectors in the same CODE must be the same length.,Solution Discussion
913,"-         The table should allow the user to pass in a key function, which should take a CODE object as an argument, and return a 64-bit unsigned integer (used to key the table)",Solution Discussion
914,"-         The hash will be non-reversible, and it won't be possible to iterate over the keys and get back a useful representation of the integer key.",Solution Discussion
915,This is okay.,Solution Discussion
916,"Otherwise we'll have to store the key strings, which could occupy a lot of memory.",Solution Discussion
917,Implementation details:-         The data should be stored in a PreshMap instance.,Solution Discussion
918,"-         The table should be keyed by a CODE (64 bit unisnged integer), with values being CODE, i.e. raw C arrays of floats.",Solution Discussion
919,-         Allocate the memory using CODE,Solution Discussion
920,A few bonus queries on the chunked model. 1)         The vector space seems like it'll give a good way to show compositionality:,Potential New Issues and Requests
921,"""fair game"" is not a type of game: CODE",Potential New Issues and Requests
922,"A ""class action"" is only very weakly a type of action: CODE",Potential New Issues and Requests
923,But a class action _lawsuit_ is definitely a type of lawsuit: CODE,Potential New Issues and Requests
924,2)         Similarity between entities can be kind of fun. Here's what Reddit thinks of Donald Trump: CODE,Potential New Issues and Requests
925,Discussion of Bill Cosby makes some obvious (and some less obvious) comparisons: CODE,Potential New Issues and Requests
926,Some queries produce more confusing results: CODE,Potential New Issues and Requests
927,I can't say the connection between Carrot Top and Kate Mara is obvious to me.,Social Conversation
928,"I suppose this is true of most things about Carrot Top, so...Fair play.",Social Conversation
929,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
930,Some of Reddit's ideas about food are kind of...interesting.,Social Conversation
931,It seems to think CODE and CODE are very similar: CODE,Potential New Issues and Requests
932,Reddit also thinks hot dogs are practically salad: CODE,Potential New Issues and Requests
933,Just keep telling yourself that Reddit.,Social Conversation
934,Haha that Donald Trump one is quite something.,Social Conversation
935,"Love the link between bacon and broccoli, wonder what adding sentiment into the mix would change about that :P",Potential New Issues and Requests
936,"Isn't this what we want to abstract away behind an interface so we can implement different ways of holding the vectors in memory, i.e. local vs central?",Solution Discussion
937,**Although to be honest...I'm starting to doubt my own idea in terms of if the speed tradeoff is even worth it.**,Solution Discussion
938,"agreed, didn't really mean the information was usable or retrievable, rather that the scoring of vectors **not** using POS tagging is influenced by these ""use cases"" and that making this information explicit seems a natural extension.",Motivation
939,Bit hard to explain my brainfart...but just meant that your idea made sense :),Social Conversation
940,I'll read the paper and dig through some more code to get into it.,Social Conversation
941,But really love the work you're doing.,Social Conversation
942,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
943,"Hmm, maybe you're right. I was immediately thinking of how the C-level API would look.",Solution Discussion
944,We might end up with use-cases where the vectors data is many gigabytes.,Motivation
945,"Like, think trigram vectors, or vectors for subject/verb/object triples.",Motivation
946,"If this occurs, the architecture you had in mind would make a lot of sense to me.",Motivation
947,"A worker takes a few documents off the task queue, aggregates the vocabulary, and asks the vectors service for all vectors active on the batch.",Motivation
948,"Yeah for large vector models it would be a necessity, question is though where supporting that is on your timeline & plans for spaCy.",Task Progress
949,"For me it would be brilliant, because I have 100+ [Celery] URL  workers and the 100M for each instance to load the vector model makes it hard to scale across docker containers.",Motivation
950,"And in the future when we want to load more advanced, and possible context dependant models, and on the fly language switching it would be even more necessary.",Motivation
951,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
952,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
953,"I think there's a design problem here that should be fixed, so we may as well fix it sooner rather than later.",Solution Discussion
954,"Send me an email, matt@spacy.io .",Solution Discussion
955,For now the following work-around could help:,Workarounds
956,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
957,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
958,3.         Avoid the CODE methods on the spaCy objects.,Workarounds
959,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
960,Gensim recommends the CODE library.,Workarounds
961,It seems good to me.,Social Conversation
962,"Hi guys, would appreciate your input on issue https://github.com/piskvorky/gensim/issues/527.",Potential New Issues and Requests
963,"We're in the process of abstracting away particular vector stores (in-memory matrix, sharded on-disk store, approximate kNN index...) from gensim, behind a common API.",Potential New Issues and Requests
964,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests
965,"How do you use such stores in spaCy, what metrics do you employ, what API signatures?",Potential New Issues and Requests
966,"We'd like to end up with something that is flexible enough to cover all standard use cases (CODE, CODE, CODE etc) but still concise and clearly scoped.",Potential New Issues and Requests
967,"This will be used throughout gensim (doc2vec, word2vec, docsim...).",Potential New Issues and Requests
968,Great!,Social Conversation
969,Definitely want to get together on this.,Potential New Issues and Requests
970,Will review.,Potential New Issues and Requests
971,Just to get enlightened: it seems great idea but does that mean that SpaCy and gensim will work together?,Potential New Issues and Requests
972,Do we have a rough plan for the change of APIs?,Potential New Issues and Requests
973,I want spaCy and Gensim to interoperate sanely.,Potential New Issues and Requests
974,"But it's more important that both libraries stay internally consistent, and they have fairly different API norms.",Potential New Issues and Requests
975,"I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency.",Potential New Issues and Requests
976,I'm guessing Gensim would hesitate to depend on spaCy.,Potential New Issues and Requests
977,"Among other things, we support a narrower range of platforms.",Potential New Issues and Requests
978,"So, I'd say it's more of a design thing.",Potential New Issues and Requests
979,We'd like to figure out what sort of work-flows are required.,Potential New Issues and Requests
980,Yes.,Social Conversation
981,"I hope to discuss what kinds of behaviour people expect from such ""vector stores"", so we can design a sane API.",Potential New Issues and Requests
982,We've been using an external server for word2vec for over a year now.,Potential New Issues and Requests
983,It would be great to be able to plug it in spaCy.,Potential New Issues and Requests
984,Currently we are accessing the vector space through the https://github.com/3Top/word2vec-api/ project.,Potential New Issues and Requests
985,A HTTP query will return a base 64 encoding of the vector.,Potential New Issues and Requests
986,"If there is any interest, I would be glad to improve the service to enable communication with spaCy.",Potential New Issues and Requests
987,"Re: fusion of SpaCy and gensim APIs, I personally find the current gensim API tree not as straightforward/simple as scikit-learn (don't mistake me, gensim is extremely uniquely useful, e.g LDA, wikicorpus, etc).",Potential New Issues and Requests
988,"I think it'd be great to introduce an API lineage of scikit-learn flavour, or that simple.",Potential New Issues and Requests
989,"As for SpaCy, I hope there's a portable way to train/retrieve the word embeddings across domains (pharma, legal, finance, etc) and natural languages.",Potential New Issues and Requests
990,"Could we make the underlying workings of word embeddings compositional/consistent as well (what if we need to do text analysis over legal+finance texts, or multi-lingual texts)?",Potential New Issues and Requests
991,"Could SpaCy keep an eye on Apache Flink, Apache Spark, and TensorFlow's about-to-be-released distributed processing framework as well?",Potential New Issues and Requests
992,Please don't give up working on SpaCy.,Social Conversation
993,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests
994,We're definitely not about to give up working on SpaCy!,Social Conversation
995,We're barely getting started.,Social Conversation
996,"Hi, I am new to spacy and NLP and ML.",Social Conversation
997,I was going through the documentation of spacy.,Social Conversation
998,I am trying to make a QnA system.,Potential New Issues and Requests
999,Was wondering if spacy gives a direct method to find similarity between 2 sentences?,Potential New Issues and Requests
1000,I could only find sentence tokenizations and word similarities.,Potential New Issues and Requests
1001,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
1002,Please open a new issue for related bugs.,Action on Issue
1003,Streaming Data Memory Growth,Expected Behaviour
1004,I have been using spacy for streaming data (twitter and news stories mostly) and I believe that the fundamental design of the vocab/StringStore in spacy is problematic for streaming processing.,Motivation
1005,"When used for batch jobs the additional memory overhead of storing a new lexeme struct for each new word form encountered in parsing is negligible compared to the speed gains, and because most text conforms to the assumption that vocabulary size grows logarithmically as the total number of tokens grows linearly this is usually a safe bet.",Motivation
1006,"But for streaming text, especially for social media where new terms are invented by the minute (hashtags and URLs in particular) this assumption no longer holds and the spacy vocabulary storage represents a dynamic element in what should be a completely static production deployment.",Motivation
1007,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
1008,"I first performed some minor preprocessing to remove newlines from the data so that it could be read line by line so that it wouldn't all be kept in memory, then I ran spacy with all models set to false, only the tokenizer loaded.",Observed Bug Behaviour
1009,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
1010,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
1011,This result confirms my hypothesis but also shows that the memory increase really isn't all that significant (especially at the relatively low volume that I am currently processing).,Investigation and Exploration
1012,But it still points to a potential flaw in the design of the library.,Investigation and Exploration
1013,My suggestion/request in the near term would be to have an option to make the vocabulary read only so that users who want to be able to leave spacy alone to do streaming data processing don't need to worry about changing memory requirements.,Expected Behaviour
1014,"In the long term, I think that an optimal solution would be to add some functionality for a timeout on vocabulary entries that aren't loaded at initialization.",Expected Behaviour
1015,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
1016,And _n_ would be user configurable.,Expected Behaviour
1017,My code and results are available here: https://github.com/ELind77/spacy_memory_growth,Investigation and Exploration
1018,Thanks again for continuing to develop such a great library!,Social Conversation
1019,-- Eric,Social Conversation
1020,I really need to fix this issue.,Contribution and Commitment
1021,Thanks.,Social Conversation
1022,Could you test this by CODE ?,Solution Discussion
1023,Sorry this has taken a while.,Social Conversation
1024,I'll test again today/tomorrow and get back to you.,Social Conversation
1025,"I performed the same tests again, both installing from the zip you posted above and installing directly from master (commit 9cd21ad5b5aa664642a2e17925cd7b39eacb9aa9) and got nearly identical results to my previous trials.",Solution Discussion
1026,"If you believe that this is the cause of some kind of memory leak, I think we should really take a look at my testing script and update it as it's very rudimentary and I'm far from an expert profiler.",Investigation and Exploration
1027,"However, I don't think that this is a leak.",Investigation and Exploration
1028,"As I said in my original post, I think that this is just part of how spacy works.",Investigation and Exploration
1029,When parsing things like social media where there are many tokens that occur only once (e.g. links) storing them in the StringStore causes memory bloat.,Investigation and Exploration
1030,"In your comments on https://github.com/spacy-io/spaCy/issues/172 you proposed a batch-processing generator that uses, and then throws away a tokenizer object for each batch in order to help find OOV tokens.",Solution Discussion
1031,"I think that's a fine approach, and could even be done a bit more quickly by asynchronously loading the new English() instance and replacing the old one when the new is ready, but that still leads to quite the slow down.",Solution Discussion
1032,"If your feeling is that spacy is really meant for batch processing and that I should use mini-batches if I want to approximate streaming, I can do that.",Solution Usage
1033,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
1034,-- Eric,Social Conversation
1035,"To clarify a little bit, the current release version has three known places that could be growing in memory use.",Investigation and Exploration
1036,1.         The CODE,Investigation and Exploration
1037,2.         A cache in the CODE,Investigation and Exploration
1038,"3.         The CODE, for tokens that are part of CODE, CODE and CODE patterns.",Investigation and Exploration
1039,The patch I asked you to try out addresses 3.,Solution Discussion
1040,We can also easily address 2.,Solution Discussion
1041,"Addressing 1 is hard, because we currently intern all the strings, which is a much easier policy to implement than something more subtle.",Solution Discussion
1042,Can you report the lengths of the CODE class in your two benchmark cases?,Investigation and Exploration
1043,"There's currently no Python API for inspecting the size of the tokenizer's cache, so it's easiest to do this by elimination.",Investigation and Exploration
1044,"Hi @honnibal, why do you think addressing 1 is so hard?",Solution Discussion
1045,"What about FIFO queue or similar, or something like @ELind77 suggested like: > functionality for a timeout on vocabulary entries that aren't loaded at initialization",Solution Discussion
1046,Do you have any more information on this issue since it cropped up a few months ago?,Investigation and Exploration
1047,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
1048,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
1049,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
1050,Basically memory grows at a logarithmic-ish pace.,Observed Bug Behaviour
1051,We have to deal with it as though it were a memory leak and periodically re-initialize the code.,Observed Bug Behaviour
1052,I ran the benchmark you requested above - collecting metrics on the length of the CODE as memory Solution Usage grows.,Investigation and Exploration
1053,"Here are the results:<img width=""555"" alt=""screen shot 2016-08-16 at 2 24 25 pm"" src=""https://cloud.githubusercontent.com/assets/1669062/17711263/c23cb262-63be-11e6-9aaf-96e9763a00e0.png"">",Investigation and Exploration
1054,Here is the code I used to create the metrics.,Investigation and Exploration
1055,It basically ran until I ran out of memory on a 4G box.,Observed Bug Behaviour
1056,https://github.com/natb1/spaCy/blob/memory-benchmark/spacy/tests/benchmark/test_memory.py,Investigation and Exploration
1057,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
1058,Same problem here.,Social Conversation
1059,Would also be glad to help.,Contribution and Commitment
1060,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
1061,To clarify the current behaviour a little: CODE is currently interning _all_ strings seen.,Observed Bug Behaviour
1062,I agree that this should be changed.,Social Conversation
1063,"I'll discuss the design decision here, so that we can consider the trade-offs.",Social Conversation
1064,I'll start from the beginning:,Social Conversation
1065,why intern the strings?,Investigation and Exploration
1066,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour
1067,"We can't do without 1 entirely â it's too fundamental to how spaCy is working, and we definitely don't want to be making lots of string comparisons.",Investigation and Exploration
1068,Comparing by integer value is pretty important.,Investigation and Exploration
1069,"Consideration 2 is very useful, but it's only really a saving if strings occur multiple times.",Investigation and Exploration
1070,"Certainly, for strings that occur once, there's no advantage.",Investigation and Exploration
1071,And it's also bad to have unbounded memory use on the streaming process.,Investigation and Exploration
1072,So the solution we want to get to is one where a limited number of somewhat common strings are interned in the common vocab.,Solution Discussion
1073,"However, we still need to map _all_ strings, even rare ones, to integers.",Solution Discussion
1074,"We also want the string-to-int table to be consistent, even for rare strings.",Solution Discussion
1075,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour
1076,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
1077,The purpose here is to resolve a string to an integer.,Investigation and Exploration
1078,"Now, this is an integer representation --- so why not just use the hash?",Investigation and Exploration
1079,The problem is we also want the inverse mapping.,Investigation and Exploration
1080,"We therefore store the string, causing the memory growth.",Investigation and Exploration
1081,"If we insist that all integers can always be mapped back to strings, there's no solution.",Solution Discussion
1082,We have to accept the memory growth.,Solution Discussion
1083,"But if we can accept that these strings pass out of date, so that they're around for a while and then they're not, the situation should be manageable.",Solution Discussion
1084,A simple way to achieve this is to extend the CODE so that the mapping is split in two.,Solution Discussion
1085,"There's the main intern area, which holds a fixed number of strings, hopefully the common ones.",Solution Discussion
1086,"But there's also a rolling buffer, in which strings are interned, and then later freed.",Solution Discussion
1087,"This could be a LRU cache, or even something simpler.",Solution Discussion
1088,"Efficiency is not really a problem here: only a small percentage of the encountered tokens will be triggering this logic, so we don't have to make it blazing fast, and it's easy to make sure we operate on contiguous buffers.",Solution Discussion
1089,A slightly more tricky solution is to do some reference counting.,Solution Discussion
1090,The idea here would be for the CODE object to register interest in all OOV strings it owns.,Solution Discussion
1091,"When the ref count of an OOV string drops to 0, it's freed.",Solution Discussion
1092,"This way, if you keep a CODE object in memory, you know that the string lookup will always be well behaved â but if you're letting the CODE objects pass out of scope, your memory won't be growing.",Solution Discussion
1093,"I think for both solutions, we should use the hash of the string as the integer representation for OOV strings.",Solution Discussion
1094,"This means that at least the string-to-int mapping will stay consistent, even if strings are passing out of memory.",Solution Discussion
1095,"The only way to have a problem here is if you hold onto the integer representation, release all of the documents, and later want to recover the string.",Solution Discussion
1096,"In this situation, you'll be out of luck --- but we'll at least know to use an OOV symbol when you try to look up your string.",Solution Discussion
1097,Simply hashing oov tokens sounds good enough to me.,Solution Discussion
1098,"As long as we know theindices of the fist and last characters of the token in the input text, sothat we can look it up if we need to, I don't find saving the token instring store particularly necessary.",Solution Discussion
1099,The input text is currently not saved/represented on the document at the moment.,Solution Discussion
1100,"Instead, we guarantee that the CODE attribute faithfully retains the slice for each token, so that we just have to join the CODE attributes and check whether the token has a trailing space.",Solution Discussion
1101,Yeah I understand.,Social Conversation
1102,"The point I was making was that, since the caller of the CODE object has the full input text string anyways, it shouldn't be a big problem to deal with the slight inconvenience of having to look up the original substring of OOV tokens.",Solution Discussion
1103,I think we're in agreement here.,Social Conversation
1104,"However, I think it's important that we either assume the string is unavailable, or save it ourselves.",Solution Discussion
1105,"Saving the string on the document isn't a huge waste of memory, and it only impacts the API in a few places (e.g., CODE, deserialisation, etc).",Solution Discussion
1106,"So if we want the user to be slicing into the string ever, we should probably switch to saving it.",Solution Discussion
1107,Here's a design that achieves something like the reference counting:,Solution Discussion
1108,"-         Add a CODE member to CODE, which will be a sequence of CODE instances.",Solution Discussion
1109,"-         Already in CODE, we accept a CODE argument, that represents the allocation pool that will own the memory for the created CODE struct.",Solution Discussion
1110,This allows CODE objects to own their OOV lexemes.,Solution Discussion
1111,We need to extend this such that the document also owns the strings.,Solution Discussion
1112,"Relevant code in CODE: https://github.com/spacy-io/spaCy/blob/master/spacy/vocab.pyx#L149 (called by CODE, called by CODE)",Solution Discussion
1113,-         I suggest using CODE as a way of selecting the appropriate child oov store.,Solution Discussion
1114,"This will allow us to have a method CODE that can be called from the CODE, CODE etc instances.",Solution Discussion
1115,"-         We then define a CODE method, which is the Cython way of adding a destructor.",Solution Discussion
1116,"In CODE, we tell the CODE to drop the oov store associated with the CODE object.",Solution Discussion
1117,-         The CODE remains a single source of truth for the string-to-integer mapping.,Solution Discussion
1118,"When decoding an integer, we can search for it in all the OOV stores.",Solution Discussion
1119,"This makes it easier to prevent integers from being ""stranded"".",Solution Discussion
1120,This sounds great!,Social Conversation
1121,"Although probably due to lack of context and familiarity to the code base, I personally would still prefer some simpler approach that can keep the CODE immutable.",Solution Discussion
1122,"e.g. use hashing to map OOV tokens to ints, keep reference to the text string in the CODE object, and obtain CODE strings by indexing on it.",Solution Discussion
1123,Maybe this immutability can help parallelizing other parts of the pipeline too.,Solution Discussion
1124,"Well, I think you could say ""the trap is set"": the existing design is such that the strings have to be globally available.",Solution Discussion
1125,Recall that we're allowing transport to/from numpy arrays.,Solution Discussion
1126,"This means we're expecting to be able to unpack an array of ints and understand some of them as strings, without ties to a particular CODE object.",Solution Discussion
1127,This is the mechanism being used for deserialization.,Solution Discussion
1128,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
1129,But I hope we can all agree that this is just digging ourselves a deeper hole.,Social Conversation
1130,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
1131,Yeah this sounds terrifying.,Social Conversation
1132,"I might be totally wrong, but I expect the feature of converting to/from numpy to only be used internally?",Solution Discussion
1133,"The array doesn't seem to work across different CODE instances if there're OOV tokens, which kind of defeats the purpose of serialization for normal users.",Solution Discussion
1134,So maybe we don't need to worry about breaking user code that uses it?,Solution Discussion
1135,I guess what I was proposing entails always including the original text as part of (de)serialization.,Solution Discussion
1136,"This might be too much refactor work, in which case what you mentioned also sounds great :)",Social Conversation
1137,Implemented ð,Task Progress
1138,"Need to update other modules to reflect the change, and do testing.",Task Progress
1139,Hmm.,Social Conversation
1140,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
1141,So unfortunately I have to move this out of the milestone.,Task Progress
1142,I'll probably get back to it week after next.,Task Progress
1143,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
1144,"This should be enough to keep you all productive, while we try to plan out a prettier, 'automagical' solution/wrapper around this.",Social Conversation
1145,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
1146,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
1147,Summary:-         New CODE keyword argument to CODE,Workarounds
1148,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
1149,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
1150,Example (untested): CODE,Workarounds
1151,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
1152,Call it whenever convenient.,Workarounds
1153,The OOV strings are encoded using the hash of the byte string.,Workarounds
1154,This means that you'll get consistent integer encodings between flushings.,Workarounds
1155,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
1156,"Hopefully, this is logical.",Workarounds
1157,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
1158,"Since serialization is the only way to reuse parsing results in a data pipeline and most real-world docs would have OOV words, this problem is pretty critical.",Workarounds
1159,"When serializing a Doc (with CODE), would it make sense to include the relevant OOV entries?",Solution Usage
1160,"That way, we can deserialize a Doc with only the standard vocab.",Solution Usage
1161,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
1162,"(actually, given a doc, are we guaranteed to get the same packing result if the vocab grows?)",Solution Discussion
1163,Perhaps offer a way for self-contained serialization that doesn't depend on any vocab altogether?,Solution Discussion
1164,(Or only depending on a small set of symbols that are future proof),Solution Discussion
1165,The serialiser backs off to a character codec for OOV words.,Solution Discussion
1166,Incidentally I have regrets about the serialiser.,Solution Discussion
1167,I think I got carried away...,Social Conversation
1168,I don't even remember how much bigger a CODE tuple would be.,Solution Discussion
1169,Does anyone want to run a benchmark?,Solution Discussion
1170,I'm so glad that this has received so much thought and attention!,Social Conversation
1171,@honnibal could we get an update on the current status of this and your thoughts on how best to proceed?,Task Progress
1172,Your suggestion of splitting the string store seems most in line with my thoughts on this.,Solution Discussion
1173,"If that is still the way you are thinking of going with this and you're thinking of using multiple string stores for OOV words, I'd also just like to put out there that it might be a good idea to use some kind of data structure for storing them other than an array, especially if there are a lot of them.",Solution Discussion
1174,"If the integer ids of the multiple StringStores are guaranteed to never overlap a BST might be a good candidate, if they can overlap though you might need to go with something a bit different, like a UnionFind.",Solution Discussion
1175,-- Eric,Social Conversation
1176,#589 issue still exists.,Potential New Issues and Requests
1177,So the workaround doesn't really work.,Workarounds
1178,This is one of the blocking issues for us now.,Motivation
1179,Will a more stable fix be available in next 1.x releases?,Task Progress
1180,Thanks a lot for the work!,Social Conversation
1181,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
1182,I still need to play with is a bit to see how it works but this looks really great.,Social Conversation
1183,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
1184,Thank you so much @honnibal !,Social Conversation
1185,-- Eric,Social Conversation
1186,"Hi @honnibal First of all, thank you for this great tool, we use it as part of NLP in our product.",Social Conversation
1187,"However, our case is very high-load system with streaming data (hundreds of thousands emails per day).",Motivation
1188,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
1189,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
1190,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
1191,So my questions are as follows:1)         Is it planned to deal with this issue somehow?,Task Progress
1192,"From what I see, in version 2.0 the problem still exists.",Task Progress
1193,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
1194,Thanks in advance.,Social Conversation
1195,@azar923 Did you try the CODE mitigation above?,Workarounds
1196,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
1197,This makes everything much easier.,Social Conversation
1198,"@honnibal thank you for quick answer,",Social Conversation
1199,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
1200,"""we can restore the original string store every N documents without causing any problems"" - sorry, did not catch that, how is it restored every N documents?",Solution Discussion
1201,The restoration idea would look like this: CODE,Solution Discussion
1202,This would ensure that strings stay available from only the last 1000 documents.,Solution Discussion
1203,"It works by keeping two copies of the CODE: the active one, and the backup.",Solution Discussion
1204,"The backup tracks the active store for 1000 documents, and then takes over.",Solution Discussion
1205,"We then start a new backup from the original strings data, which adds entries for the next 1000 documents, so that when it takes over, those recent documents' strings will be available.",Solution Discussion
1206,"@honnibal Great, thanks very much for these improvements.",Social Conversation
1207,Will look forward to 2.0 release to try.,Social Conversation
1208,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
1209,"@honnibal  I'm also facing the same issue, (spacy 1.5.0).",Observed Bug Behaviour
1210,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds
1211,Currently using spacy to get the POS tags. (from sentence subtree etc),Motivation
1212,Is there a way to reset the StringStore without reloading the model again ?,Workarounds
1213,The workaround of using set_frozen does not work.,Workarounds
1214,Ref: [v1.5.0_source] URL ,Workarounds
1215,I am experimenting with this workaround with the 1.x version.,Workarounds
1216,So far it is working well.,Workarounds
1217,CODE,Workarounds
1218,Fixed!,Task Progress
1219,(!!!!):tada: :tada: :tada:,Social Conversation
1220,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
1221,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
1222,Please open a new issue for related bugs.,Action on Issue
1223,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
1224,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
1225,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
1226,"I boiled it down to single words, while german words work, english words like 'windows' don't work.",Investigation and Exploration
1227,Steps to reproduce: CODE,Bug Reproduction
1228,Trace CODE,Observed Bug Behaviour
1229,If you use CODE it works fine.,Observed Bug Behaviour
1230,"Also if you execute CODE before the same CODE call, CODE does not raise an exception (a dictionary is built?)",Observed Bug Behaviour
1231,Maybe this is related to this region [syntax/parser.pyx](https://github.com/spacy-io/spaCy/blob/1822bb4ff1e6ceee76fe5e43de4345fab168e65b/spacy/syntax/parser.pyx#L179-L183) CODE,Investigation and Exploration
1232,Same issue here with the german model and CODE on Amazon Linux (also on Ubuntu Server 14.04 LTS) using python 3.5.,Bug Reproduction
1233,"However, blang's minimal example works on my Macbook (OSX 10.11.3) where I don't have OpenMP support in place (obviously only in single-thread).",Bug Reproduction
1234,Setting CODE on Linux doesn't solve the issue for me.,Investigation and Exploration
1235,I just tried this again and it seems to work now (reinstalled spaCy and the german model).,Bug Reproduction
1236,@blang can you confirm?,Investigation and Exploration
1237,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
1238,Or was it a code change?,Task Progress
1239,"Same problem here, working on Windows 10 with German text.",Bug Reproduction
1240,Thought it was German that made it break.,Investigation and Exploration
1241,"I also reinstalled spaCy and the German model yesterday, but this din't fix the problem in my case.",Investigation and Exploration
1242,"I then tried to break it down to a specific sentence, but even after having removed this and succesively the follwoing sentences from my texts, the problem remained the same.",Investigation and Exploration
1243,"As above, if I use nlp(text) everything is fine.",Investigation and Exploration
1244,Steps to reproduce: CODE,Bug Reproduction
1245,raises: CODE,Observed Bug Behaviour
1246,"Curious thing, If you add a comma like this: CODE the error goes away.",Investigation and Exploration
1247,Directly doing: CODE is ok in both cases.,Investigation and Exploration
1248,"I think the CODE method isn't actually to blame here â rather, it reports on an error condition thrown by the CODE method, while the CODE method fails silently in the same situation.",Investigation and Exploration
1249,The issue is arising because the entity recogniser's push-down automaton finds itself in a state with no continuations.,Investigation and Exploration
1250,"I haven't stepped through the automaton yet (if you want to do that, use the methodCODE) to see exactly where the problem is, but I'm pretty sure the error will come from an interaction with entities pre-set by the CODE class.",Investigation and Exploration
1251,"In order to preserve these entities, we restrict the actions of the entity recogniser, so that it can't over-write the previous ones.",Investigation and Exploration
1252,"There's apparently a bug in the logic to introduce this constraint, that's leaving the automaton with no available actions.",Investigation and Exploration
1253,"This results in an invalid predicted action, leading the parser to return a status code (it can't raise an error, as it's in a CODE function).",Investigation and Exploration
1254,This is the status code the CODE method was ignoring.,Investigation and Exploration
1255,This might have something to do with state between the documents (don't know what if any is kept).,Investigation and Exploration
1256,"At first errors were still being produced, but after a few shuffles of the corpus to errors to my surprise went away.",Investigation and Exploration
1257,I'll try to produce a more reliable report of the behaviour.,Social Conversation
1258,**update** so the error going away didn't have anything to do with CODE.,Investigation and Exploration
1259,"However if you take the document that produces the error, pass it through CODE and then call CODE again, it works.",Investigation and Exploration
1260,"An example document where CODE causes the error, removing that one token everything is fine.",Investigation and Exploration
1261,CODE,Investigation and Exploration
1262,"I think I have this taken care of, but I'm not 100% sure.",Social Conversation
1263,Please reopen if it reoccurs.,Action on Issue
1264,The text it tried to parse isn't relevant: CODE but I did update global CODE in a loop while parsing the doc in the same loop.,Observed Bug Behaviour
1265,I'll get back to this if I'll be able to reproduce it with specific steps.,Bug Reproduction
1266,PS: Now I'm getting CODE and I have no idea if it's relevant or not..,Potential New Issues and Requests
1267,Do you have a minute to video chat about this?,Social Conversation
1268,If so click here: https://appear.in/spacy_issue429,Social Conversation
1269,"Sorry, my internet isn't good for video chatting, but I'm happy to text.",Social Conversation
1270,No worries.,Social Conversation
1271,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests
1272,Instead of: CODE,Potential New Issues and Requests
1273,You can do: CODE,Potential New Issues and Requests
1274,Then you can investigate what's going on.,Potential New Issues and Requests
1275,The segfault is caused by matcher.,Potential New Issues and Requests
1276,"The number of matches I have is up to a million, python process eats about 4 GB of ram, and there's still enough for it to grow.",Potential New Issues and Requests
1277,"I could investigate this later, maybe in another issue.",Potential New Issues and Requests
1278,Trying to narrow the scope of ParserStateError right now.,Potential New Issues and Requests
1279,Hmm.,Social Conversation
1280,Is the match proliferation expected for your use-case?,Potential New Issues and Requests
1281,CODE -> CODE,Potential New Issues and Requests
1282,"It won't grow much after this, I'm just curious how much entities it can hold and how it will affect the memory and performance.",Potential New Issues and Requests
1283,Should I open another issue for that segfault? CODE,Potential New Issues and Requests
1284,I can easily make the matches list a numpy array if necessary.,Potential New Issues and Requests
1285,A segfault via the Python API (as opposed to the Cython API) is always a bug.,Potential New Issues and Requests
1286,"So yes, please open an issue.",Potential New Issues and Requests
1287,"I'll do it tomorrow, once I know the steps to reproduce it.",Potential New Issues and Requests
1288,I guess now you have enough info for bug related to current issue.,Social Conversation
1289,Yes.,Social Conversation
1290,Fix should be out soon.,Task Progress
1291,I think this should fix the segfault too â I think they were related.,Potential New Issues and Requests
1292,Closing for now.,Action on Issue
1293,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
1294,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
1295,Not sure if this was an issue with my string or with spaCy's processing.,Investigation and Exploration
1296,"Hi, We are getting a parser state error.",Potential New Issues and Requests
1297,"Here is the trace: Traceback (most recent call last):File ""tests/test_spacy_nlp.py"", line 231, in test_should_return_none_when_spacy_parsing_failsdoc = self.spacy_nlp.parse(query)File ""spacy_nlp.py"", line 49, in parsereturn SpacyDoc(self.__instance.parser(query))File ""lib/python3.5/site-packages/spacy/language.py"", line 328, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 146, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:6114)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:'splash On'",Potential New Issues and Requests
1298,"Here is our test:nlp = spacy.en.English()nlp.matcher.add('splash', 'my entity', {},[ [{LEMMA: 'splash'}, {LEMMA: 'on'}]])nlp('splash On')",Potential New Issues and Requests
1299,"I'm afraid I'm getting this, too, in version 1.5.0: CODE",Potential New Issues and Requests
1300,"All was fine, until I added some matcher rules and an on_match callback: CODEwhere unit is 'BOPD', for example.",Potential New Issues and Requests
1301,The on_match callback is being called.,Potential New Issues and Requests
1302,"Got this error in version 1.7.3: Traceback (most recent call last):File ""<stdin>"", line 1, in <module>File ""/home/ktyao/anaconda3/envs/python27/lib/python2.7/site-packages/spacy/language.py"", line 350, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 207, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:7730)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:u'Meet Linux.Mirai Trojan, a DDoS nightmare'",Potential New Issues and Requests
1303,"I am using a customized tokenizer that merges the three tokens, 'Linux', '.' and 'Mirai', into one token.",Potential New Issues and Requests
1304,"I'm also running in this issue on 1.8.2, nevertheless only after processing multiple documents in parallel:CODE",Potential New Issues and Requests
1305,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
1306,So nevermind :),Social Conversation
1307,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
1308,Please open a new issue for related bugs.,Action on Issue
1309,Fitting additional estimators for ensemble methods,Expected Behaviour
1310,I would like to propose an additional instance method to the ensemble estimators to fit additional sub-estimators.,Expected Behaviour
1311,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
1312,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
1313,I don't think fit_extend is a particularly great name so I'd welcome other suggestions.,Expected Behaviour
1314,Perhaps we would want to hash the features and labels when fit() is called so we can check that the same features and labels are provided to this function.,Solution Discussion
1315,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
1316,This is definitely a feature we want.,Social Conversation
1317,The question is: what would be the best way to implement it (in terms of API)?,Solution Discussion
1318,There is something slightly similar in the adaboost pr: #522.,Motivation
1319,"That implements predicting with a subset of the estimators, which is also very helpful.",Motivation
1320,"What do you think does the scenario / code look like, where a user wants CODE?",Motivation
1321,"It is probably most useful in an interactive setting, righ?",Motivation
1322,"There is  a slightly related function in SGD, CODE.",Solution Discussion
1323,"That is actually for online learning, though, so it gets different data.",Solution Discussion
1324,I'd like to get this feature with adding as little API an names as possible ;),Solution Discussion
1325,"Btw, I wouldn't hash CODE and CODE .",Solution Discussion
1326,I don't see a reason to force the user to provide the same input data.,Solution Discussion
1327,I would like to train a small number of sub-estimators at a time (and wait a relatively short time).,Motivation
1328,"Then test it on my cross-validation set and if my cv score is still falling, I can continue training.",Motivation
1329,As opposed to training a large number of sub-estimators and waiting a long time (several hours for me).,Motivation
1330,That was my motivation.,Social Conversation
1331,I can understand being hesitant about adding another instance method.,Solution Discussion
1332,I thought it might be worthwhile to add another optional parameter to fit() but I saw this quote on the contributing page. > fit parameters should be restricted to directly data dependent variables,Solution Discussion
1333,So I wasn't sure that would be a good idea.,Social Conversation
1334,Would CODE be acceptable?,Solution Discussion
1335,"Then if CODE, we'll then train that many more estimators.",Solution Discussion
1336,"I agree that adding in n_estimators parameter to the prediction method is nice, but I think you'll agree that it solves a different problem.",Solution Discussion
1337,For my problem performing grid search over n_estimators isn't really an option because it takes so long.,Solution Discussion
1338,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
1339,Note that this only work for RandomForest and ExtraTrees.,Workarounds
1340,The same trick cannot be used with Gradient Boosting.,Workarounds
1341,See #1626.,Solution Discussion
1342,Would early stopping be an acceptable solution to you?,Solution Discussion
1343,@amueller I share the same opinion as @glouppe here https://github.com/scikit-learn/scikit-learn/issues/1626#issuecomment-12785168.,Social Conversation
1344,I like early stopping but it doesn't resolve this in my opinion.,Solution Discussion
1345,Ok.,Social Conversation
1346,Then we should look for a solution that allows for early stopping and adding additional estimators.,Solution Discussion
1347,"Thinking about it a bit more, I think the CODE method would be the right interface.",Solution Discussion
1348,In SGD you can call CODE either with the same data or new data and it keeps on learning.,Solution Discussion
1349,"The difference is that in SGD, if you manually iterate over batches, you get the original algorithm out.",Solution Discussion
1350,"For ensembles, that would not be true.",Solution Discussion
1351,You would need to use the whole data on each call to CODE.,Solution Discussion
1352,I like this suggestion.,Social Conversation
1353,What do other people think?,Social Conversation
1354,"Just to clarify, what would exactly happen in CODE in case of ensembles?",Solution Discussion
1355,"Would that add CODE more estimators, whereCODE is the parameter value from the constructor?",Solution Discussion
1356,(or could we change that value?),Solution Discussion
1357,Good question.,Social Conversation
1358,I also thought about that ;),Social Conversation
1359,"actually, you would want to change that, right?",Solution Discussion
1360,you could change that afterwards by CODE but that feels awkward :-/,Solution Discussion
1361,sorry for joining the discussion so late.,Social Conversation
1362,"I agree that we need such a functionality, however, I'm not sure if CODE is the best solution to the problem that @jwkvam describes.",Solution Discussion
1363,In order to do early stopping the user has to write some some code that basically repeatedly calls CODE and then checks the CV error.,Solution Discussion
1364,I'd rather propose the CODE fit parameter that we discussed in the past: CODE where CODE will be called after each iteration and is passed the complete state of the estimator.,Solution Discussion
1365,The callable could also return a value whether or not the training should proceed.,Solution Discussion
1366,Using such an api one could implement not only early stopping but also custom reporting (e.g. interactive plotting the training vs. testing score) and snapshoting (all X iterations dump the estimator object and copy it to some location; this is great if you are running on EC2 spot instances or some other unreliable hardware ;-),Solution Discussion
1367,"Personally, I'd prefer CODE (or CODE) over CODE - warm start is quite implicit - you have to:: CODECODECODE`# if you forget warm_start=True you nuke your previous estimators - quite implicitest.fit(X, y, n_estimators=2000, warm_start=True) # alternatively - more explicitest.fit_more(X, y, n_estimators=1000)CODE",Solution Discussion
1368,"To me, fit_more corresponds really to the partial_fit that we have inother estimators.",Solution Discussion
1369,@pprett I think there should be an easy way to do easy things.,Motivation
1370,"a monitor api is very flexible but actually you want to do early stopping **every time** you use an estimator, right?",Motivation
1371,So there should be no need to write a callback to do that.,Solution Discussion
1372,"Also, it must be compatible with GridSearchCV.",Solution Discussion
1373,I don't think so.,Social Conversation
1374,"In CODE, ""partial"" stands for partial access to the data: you expect that the data does not fit in memory at once so you fit with one chunk at a time and update the model incrementally while scanning through the data.",Solution Discussion
1375,In this case we want to change the number of sub estimators but might want to reuse exactly the same data at each call.,Solution Discussion
1376,For a similar reason ElasticNet has a CODE constructor param instead of a CODE method and SGDClassifier both has a CODE param and a CODE method: they serve different purposes.,Solution Discussion
1377,"I agree that the monitor API would be very useful in general (for dealing with snapshoting, early stopping and such) but would not solve the issue of growing the number of sub-estimators in an interactive manner.",Solution Discussion
1378,We could also have: CODE,Solution Discussion
1379,Or even to grow by 110% (10% more estimators): CODE,Solution Discussion
1380,hum I didn't look to much into the warm start api that we have currently.,Social Conversation
1381,"There is no central documentation for that, right?",Potential New Issues and Requests
1382,We should really think about the organization of the docs.,Potential New Issues and Requests
1383,We got quite some comments on that in the survey :-/,Social Conversation
1384,@ogrisel I'd have to have a look at the SGD implementation to see the details but what is the difference in what actually happens between warm-starts and partial_fit?,Solution Discussion
1385,I think we agree on the point of same /changing data.,Solution Discussion
1386,Does CODE do several epochs and CODE does not?,Solution Discussion
1387,"That would make sense to me, and then we should probably keep them separate.",Solution Discussion
1388,"If we already have the warm-start api, we should definitely ""just"" implement that for the ensemble estimators.",Solution Discussion
1389,CODE just prevents fit to forget about the previous state (assuming that the inner state of the model will likely make it converge faster to the solution of the new call with the new hyperparameter).,Solution Discussion
1390,I think the main difference is the _semantics_: the main idea behindCODE is to converge more quickly - but no matter what valueCODE has you get the same solution!,Solution Discussion
1391,"Partial fit on the other hand, changes the underlying model.",Solution Discussion
1392,Consider thefollowing example: CODE can reuse the fitted weights from clf it might converge more quickly# under the hood,Solution Discussion
1393,"CODE resets the ""training"" state modethe estimator (adaptive learning rate for sgd) CODE",Solution Discussion
1394,Disclaimer: This example might be pedantic because the differences in termsof the learned weights is minimal - but conceptually they are IMHO totallydifferent things...,Social Conversation
1395,The CODE API was initially introduced to allow faster computation of a series of identical linear models when using a path of regularizers CODE.,Solution Discussion
1396,This is somewhat similar to iteratively growing the number of sub-estimators in a boosted ensemble model so we could decide to reuse CODE to adress that use case as well but if this API reveals cumbersome for boosted models it might be better to rethink it now that we have an additional use case.,Solution Discussion
1397,I agree with @pprett's analysis.,Social Conversation
1398,I don't know what to make of @pprett  analysis.,Social Conversation
1399,"In the case of linear models, the estimator will converge to the same result, even when the warm start gets different data than the original fit.",Solution Discussion
1400,"If we ""warm started"" ensembles / trees, that would not be the case.",Solution Discussion
1401,We could try to assure that the data provided when warm starting is the same as the original.,Solution Discussion
1402,"At the moment, ""warm start"" refers to an optimization procedure, which there is none in tree based methods.",Solution Discussion
1403,While CODE retains all of the state of the estimator and just keeps on fitting.,Solution Discussion
1404,"On the other hand, subsequent calls to partial fit on batches lead to the same model as training on the whole data.",Solution Discussion
1405,"Again, this is different from the tree/ensemble case.",Solution Discussion
1406,I feel this goes back to my argument that this is more of a path algorithms than anything else ;),Social Conversation
1407,"So I see two possible solutions: make sure warm-start is always called with the same data, then adding estimators would be warm starting.",Solution Discussion
1408,"If not, we need a third way to refit a given model.",Solution Discussion
1409,"Where are the docs for that currently, btw ;)",Solution Discussion
1410,Why so?,Social Conversation
1411,Let the user decide how and what for he / she want to use CODE for.,Solution Discussion
1412,http://scikit-learn.org/dev/modules/generated/sklearn.linear_model.ElasticNet.html,Solution Discussion
1413,CODE,Solution Discussion
1414,"I agree that giving motivation would be helpful, for instance in this case: ""This is useful to efficiently compute a regularization path of ElasticNet models as done by the :func:CODE function"".",Solution Discussion
1415,I thought the argument was about semantics.,Solution Discussion
1416,I think a semantic is defined by giving the user some guarantee of what will happen.,Solution Discussion
1417,That way the user doesn't need to know all the details of the algorithm.,Solution Discussion
1418,"I thought the guarantee of CODE was ""warm_start doesn't change the result"", while the guarantee of CODE was ""iterating over batches doesn't change the result"".",Solution Discussion
1419,"If there is no guarantee, then I don't see how there can be common semantics.",Solution Discussion
1420,We provide guarantee to the user that if he provides the same data again with warm_start=true he will get the same results (just faster).,Solution Discussion
1421,But we should not prevent the user to use different data if he makes an informed guess that warm starting on the new data will help him solve his problem (e.g. solving on the new data faster if he makes the assumption that the new data is distributed reasonably similarly to the first data and hence starting the optimizer from the previous position should speeds things up).,Solution Discussion
1422,For linear estimators that is ok.,Solution Discussion
1423,"But if you want to use CODE on ensembles, it will have a very different semantic all of a sudden.",Solution Discussion
1424,Indeed growing a boosted ensemble on changing data is weird and probably useless (unless if it's a way to inject some randomization for some meta-meta-ensemble estimator that does bagging on boosted models maybe?).,Solution Discussion
1425,I don't think we should try to enforce that the data does not change across calls though.,Solution Discussion
1426,Let's just document the expected Solution Usage scenario for that option in the docstring instead.,Solution Discussion
1427,ok.,Social Conversation
1428,"So basically the docstring should say ""use warm_start with the same data unless you know exactly what you are doing"".",Solution Discussion
1429,Fine with me.,Social Conversation
1430,Anyone opposed to using CODE?,Solution Discussion
1431,"I still have to have a look at how that is handled in SGD and ENet, though...",Social Conversation
1432,"No, not useless: it's one specific sub-sampling strategy.",Solution Discussion
1433,The practicaldifference with an online method is that you want the batch to be big.,Solution Discussion
1434,So CODE in SGDClassifier can not be used for model selection.,Solution Discussion
1435,"On the other hand, CODE could be used to find the bestCODE.",Solution Discussion
1436,"The more I think about it, the more confusing it gets for me :-/",Social Conversation
1437,"Btw, is there any reason that CODE is an init parameterand CODE is a function?",Solution Discussion
1438,Wouldn't it be easier if CODE also was an init parameter?,Solution Discussion
1439,Because CODE is a specific strategy that might differ from thestrategy used in CODE.,Solution Discussion
1440,I think it would be confusing.,Social Conversation
1441,The goal of CODE is to be abuilding block usable in an out-of-core framework.,Solution Discussion
1442,Using CODE for thispurpose could lead to fairly catastrophic results.,Solution Discussion
1443,I don't understand your argument.,Social Conversation
1444,"What CODE does is basically ""forget model, call CODE"".",Solution Discussion
1445,"Hm maybe what you mean is that CODE might need to do less work than CODE because CODE needs to store the ""sufficient statistics"" of the previous data and fit doesn't need to do that?",Solution Discussion
1446,It can do more.,Social Conversation
1447,Typically it shuffles the data before calling partialfit.,Solution Discussion
1448,It may also divide it into mini batches of a user-selectable size.,Solution Discussion
1449,It might be the case.,Social Conversation
1450,It might be also that fit needs to do additionalwork to turn a large batch dataset into a set of mini-batch ones.,Solution Discussion
1451,hm ok maybe this is not so important right now.,Social Conversation
1452,"I'd like to minimize the number of mechanisms we have in sklearn, and we definitely need one (more?) for efficient model selection.",Potential New Issues and Requests
1453,"In the coordinate decent algorithms, the CODE option was introduced exactly for this purpose.",Potential New Issues and Requests
1454,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests
1455,(just removed a lot of the previous comment as I was repeating myself).,Social Conversation
1456,I don't understand this last remark.,Social Conversation
1457,warm_start is perfectly valid for SGDClassifier (in addition to CODE): right now SGDClassifier does not have convergence check / early stopping.,Solution Discussion
1458,"But as soon as it has, warm_starting will make it possible to compute the regularization path faster, exactly as for ElasticNet.",Solution Discussion
1459,"SGDClassifier does CODE epochs of updates, then stops.",Solution Discussion
1460,Where it ends up after CODE steps depends heavily on where you started.,Solution Discussion
1461,"Even if you do ""early stopping"", this would be early stopping on the validation set, not early stopping of the optimization.",Solution Discussion
1462,SGDClassfier does not have the goal to fully optimize the objective to the end.,Solution Discussion
1463,So where you will end up will depend on the initialization.,Solution Discussion
1464,"In particular, for early stopping (on a validation set!) it could be better to do less iterations, leading to lower bias.",Solution Discussion
1465,"In particular, I don't think a ""regularization path for alpha"" makes sense in the SGD setting.",Solution Discussion
1466,"The ""path"" is a sequence of optima.",Solution Discussion
1467,"SGD will never find the optimum, so the places you'll end up will probably depend as much on the scaling of the learning rate as on the actual regularization.",Solution Discussion
1468,"For linear models, the problem is convex.",Solution Discussion
1469,"If n_iter is big enough, SGD with a good learning schedule will converge to the optimum (if you don't stop before convergence).",Solution Discussion
1470,The convergence speed when getting closer to the optimum is just not as good as coordinate descent  but this is a different issue.,Solution Discussion
1471,so we agree: the models will be different unless n_iter is big enough and the schedule is just right - which are unlikely in practice.,Solution Discussion
1472,also a guarantee of the form âresults will be the same if the other settings are appropriately tunedâ doesn't really sound like a guarantee.,Solution Discussion
1473,So what about CODE,Solution Discussion
1474,Is that an acceptable Solution Usage pattern?,Solution Discussion
1475,Or do you want these as parameters to CODE?,Solution Discussion
1476,"In SGD, CODE is an CODE parameter according to the docs.",Solution Discussion
1477,Let's revive the discussion.,Social Conversation
1478,in #1044 @GaelVaroquaux said he still prefers CODE.,Solution Discussion
1479,"Currently, I think CODE is more in the right direction, but I don't have a strong opinion.",Solution Discussion
1480,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
1481,Or would you like to have another interface using CODE or CODE?,Solution Discussion
1482,What I dislike about using the 'warm_start' is that currently thecontract with scikit-learn estimators is that you can call 'fit' and geta valid/useful answer regardless of the history of the object.,Solution Discussion
1483,"It may gofaster or slower, but it's somewhat fool proof.",Solution Discussion
1484,"If you pass differentdata to an ensemble estimator, and use the 'warm_start' to fit moreestimators, you will get nonsens.",Solution Discussion
1485,I am worried about having to write'defensive' code to avoid such problems.,Solution Discussion
1486,how would CODE work in our setting - is this correct:: CODE,Solution Discussion
1487,so it would take arbitrary CODE or just CODE?,Solution Discussion
1488,"Personally, I'm in favor of a CODE since the use-case that our current CODE serves is quite different and CODE is more explicit.",Solution Discussion
1489,I am also not very happy with the name CODE in case of ensembles.,Solution Discussion
1490,"From my point of view, that name suggests that it will build some estimators out of the total number requested in the constructor, but not more.",Solution Discussion
1491,If we go for CODE then what would be the specification?,Solution Discussion
1492,You set CODE in the constructor and calling CODE append CODE more estimators?,Solution Discussion
1493,Just like @amueller did above?,Social Conversation
1494,"Well I am not against that pattern, but that does not seem very intuitive to me nevertheless.",Solution Discussion
1495,"From a very practical point of view, I like CODE.",Solution Discussion
1496,It is explicit.,Solution Discussion
1497,No explanation required.,Solution Discussion
1498,"However, it adds another function to our API...",Solution Discussion
1499,"(I have no strong opinion yet, these remarks simply reflect what I think at the moment)",Social Conversation
1500,"I am not completely against adding a function, but I wouldn't like it to be to specific to the ensembles.",Solution Discussion
1501,I really do see a connection to the path algorithms so I think sharing an interface would be nice.,Solution Discussion
1502,Consider the following hypothetical situation (maybe not so realistic):,Solution Discussion
1503,Would you also do that via CODE?,Solution Discussion
1504,Or add a CODE function?,Solution Discussion
1505,I guess there is a trade-off between generality and explicitness.,Solution Discussion
1506,"@GaelVaroquaux The contract with CODE is imho that if you iterate over the data in batches, you will get the same result out.",Solution Discussion
1507,That will definitely not be the case if used here.,Solution Discussion
1508,So by design we would break the contract ?!,Solution Discussion
1509,"Thinking about it again, maybe there is room for a new method which we could use to implement #1626.",Solution Discussion
1510,"I wouldn't mind calling it CODE, but in the sense of CODE not in the sense of CODE.",Solution Discussion
1511,So imho we should either do CODE ( + maybe defensive programming ) or add another method that we can generally use to fit along a parameter path.,Solution Discussion
1512,Would CODE then be defensive or not? ;),Solution Discussion
1513,-         1 on defensive.,Solution Discussion
1514,I'd rather document it well and let the user decides whatis good for oneself.,Solution Discussion
1515,I would also be against defensive.,Solution Discussion
1516,I was just wondering if adding the function really solved an issue or if we just added another way to do warm starts.,Solution Discussion
1517,"Both have the same defensive / not-defensive problem, right?",Solution Discussion
1518,My apologies if I'm simply repeating what has already been said.,Social Conversation
1519,"But it seems like you could split estimators into two classes: those that freeze parameters once they are fit (ensembles, DTs), and those that don't (linear models).",Solution Discussion
1520,By that I mean with warm_start you won't refit the first n sub-estimators of an ensemble or the existing splits in a decision tree.,Solution Discussion
1521,The lack of being able to reach anywhere in the parameter space with warm_start for ensembles and DTs makes me think that an instance method would be more appropriate.,Solution Discussion
1522,"If an instance method is chosen, does it need to be more general as @amueller noted?",Solution Discussion
1523,"For what it's worth, I would also be against defensive.",Solution Discussion
1524,"As @GaelVaroquaux pointed out earlier it provides a sub-sampling strategy, for instance, if your training data doesn't fit in main memory.",Solution Discussion
1525,"After some thoughts, I think we should see the bigger picture here.",Social Conversation
1526,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
1527,"What I rather see is a ""combination"" mechanism that would take as input a list of (fitted) estimators and would produce a meta-estimator combining them all.",Solution Discussion
1528,"In practice, I think we can achieve that without adding any new function to our API.",Solution Discussion
1529,"For example, one could simply pass such a list of fitted estimators to the constructor of the meta-ensemble.",Solution Discussion
1530,"In terms of API, one could (roughly) implement such ensembles in the following way:",Solution Discussion
1531,a)         Bagging:,Solution Discussion
1532,"-         constructor: CODE (optional), CODE (>=0), a list CODE of fitted estimators (optional).",Solution Discussion
1533,-         fit: extend CODE with CODE new instances of CODE fitted over (bootstrap copies of) the training samples.,Solution Discussion
1534,"If no base estimator is given, then it is equivalent to combining the estimators in CODE.",Solution Discussion
1535,b) Stacking:,Solution Discussion
1536,"-         constructor: CODE (optional), CODE (>=0), a list CODE of fitted estimators (optional).",Solution Discussion
1537,"-         fit: extend CODE with CODE new instances of CODE fitted of bootstrap samples, then refit a model over the predictions of the estimators.",Solution Discussion
1538,c) Forest:,Solution Discussion
1539,"-         constructor: CODE (optional), CODE (>=0), a list CODE of fitted estimators or a forest (optional).",Solution Discussion
1540,-         fit: extend CODE with CODE new instances of CODE fitted over the training samples. Here we could also check whether the estimators in CODE are forests or decision trees.,Solution Discussion
1541,Forests would be flattened in order to put all trees on the same level.,Solution Discussion
1542,"Also, in such a framework, computation of an ensemble could easily be distributed over several machines: build your estimators; pickle them; then recombine them into one single meta-estimator.",Solution Discussion
1543,"One could even wrap that interface into a MapReduce cluster, without digging into our implementation at all!",Solution Discussion
1544,What do you think?,Social Conversation
1545,I am aware this is only relevant to some kind of ensembles though.,Solution Discussion
1546,"For instance, GBRT and AdaBoost are (in my opinion) more suited to either CODE or CODE.",Solution Discussion
1547,"Just to be clear, to extend a forest, one would do something like: CODE",Solution Discussion
1548,What is the motivation of that interface?,Solution Discussion
1549,I am totally with you in supporting more ensemble methods.,Social Conversation
1550,I just feel it is quite awkward to have a different interface for GBRT and random forest.,Solution Discussion
1551,I don't really see the motivation for that.,Social Conversation
1552,"If the main motivation is to distribute embarassingly parallel jobs, then I think we should attack this by implementing a more powerful parallelization.",Solution Discussion
1553,Doing it the way you described seems pretty manual and hacky.,Solution Discussion
1554,Basically I feel your proposal just solves a very special case and leaves most cases unsolved.,Solution Discussion
1555,Well ok...,Social Conversation
1556,I just feel that extending boosted-like ensembles and average-like ensembles are quite different things.,Solution Discussion
1557,What is the use-case for your interface except parallelization?,Motivation
1558,Or better: in what use cases do you need a different interface for boosted ensembles and bagging?,Motivation
1559,The use case is when you want to combine several estimators together.,Motivation
1560,"It is natural for average-like ensembles, but makes no sense in boosted ensembles.",Motivation
1561,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
1562,"So the setting is that you have trained some bagging estimators and want to combine them together, right?",Motivation
1563,In which setting do you want to do that except for parallelization?,Motivation
1564,It is not so clear to me but maybe I'm overlooking something obvious.,Social Conversation
1565,In case of Stacking the estimators might be completely different (say to you want to merge forests with svms).,Motivation
1566,"(Indirectly, this could also be used to implement subsampling strategies or for monitoring the fitting process.)",Motivation
1567,I'm not sure I get the stacking example.,Social Conversation
1568,"I would have imagined that if we had a stacking interface, you could specify one estimator as the base estimator and another as the one on top.",Motivation
1569,"As I see it, the point of stacking is to combine the predictions of estimators of different nature.",Motivation
1570,"The more diverse they are, often the better.",Motivation
1571,"Ok, so the base estimators would be different.",Solution Discussion
1572,"But then we could also build this into the interface for stacking, right?",Solution Discussion
1573,@jwkvam We recently agreed in #2570 to implement this feature using the CODE parameter.,Task Progress
1574,It is now implemented in GBRT.,Task Progress
1575,I'll try to update the forests with the same mechanism before the release.,Task Progress
1576,"@glouppe You're right, I forgot I had written this for any ensemble.",Social Conversation
1577,But really I just wanted it for GBRT :),Social Conversation
1578,"so in my haste, I decided this issue was resolved.",Social Conversation
1579,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
1580,GridSearchCV parallel execution with own scorer freezes,Observed Bug Behaviour
1581,I have been searching hours on this problem and can consistently replicate it: CODE,Observed Bug Behaviour
1582,"This snippet crashes because of scoring=metrics.make_scorer(metrics.scorer.f1_score, average=""macro"") where metrics refers to sklearn.metrics module.",Investigation and Exploration
1583,"If I cancel out the scoring=... line, the parallel execution works.",Investigation and Exploration
1584,"If I want to use the f1 score as evaluation method, I have to cancel out the parallel execution by setting n_jobs = 1.",Investigation and Exploration
1585,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour
1586,Thanks,Social Conversation
1587,"This is surprising, so we'll have to work out what the problem is and make sure it works!",Social Conversation
1588,Can you please provide a little more detail:,Investigation and Exploration
1589,"-         What do you mean by ""crashes""?",Investigation and Exploration
1590,-         What version of scikit-learn is this?,Investigation and Exploration
1591,"If it's 0.14, does it still happen in the current development version?",Investigation and Exploration
1592,-         Multiprocessing has platform-specific issues.,Investigation and Exploration
1593,What platform are you on? (e.g. CODE),Investigation and Exploration
1594,-         Have you tried it on different datasets?,Investigation and Exploration
1595,"FWIW, my machine has no problem fitting iris with this snippet on the development version of sklearn.",Bug Reproduction
1596,Thank you for your fast reply.,Social Conversation
1597,With crashing I actually mean freezing.,Observed Bug Behaviour
1598,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour
1599,The processes are still there and consume a constant amount of RAM but require no processing time.,Observed Bug Behaviour
1600,"This is scikit-learn version 0.14, last updated and run using Enthought Canopy.",Observed Bug Behaviour
1601,"I am on platform ""Windows-7-6.1.7601-SP1"".",Observed Bug Behaviour
1602,I will go more into depth by providing a generic example of the problem.,Social Conversation
1603,I think it has to do with the GridSearchCV being placed in a for loop.,Investigation and Exploration
1604,"(To not waste too much of your time, you should probably start at the run_tune_process() method which is being called at the bottom of the code and calls the method containing GridSearchCV() in a for loop)",Investigation and Exploration
1605,# Code: CODE,Investigation and Exploration
1606,"Once again, this code works on my computer only when I change n_jobs to 1 or when I don't define a scoring= argument.",Observed Bug Behaviour
1607,Generally multiprocessing in Windows encounters a lot of problems.,Investigation and Exploration
1608,But Idon't know why this should be correlated with a custom metric.,Investigation and Exploration
1609,There'snothing about the average=macro option in 0.14 that suggests it should bemore likely to hang than the default average (weighted).,Investigation and Exploration
1610,"At the developmenthead, this completes in 11s on my macbook, and in 7s at version 0.14(that's something to look into!)",Investigation and Exploration
1611,"Are you able to try this out in the current development version, to see ifit's still an issue?",Investigation and Exploration
1612,"(As a side point, @ogrisel, I note there seems to be a lot more joblibparallelisation overhead in master -- on OS X at least -- that wasn't therein 0.14...)",Potential New Issues and Requests
1613,This has nothing to do with custom scorers.,Investigation and Exploration
1614,This is a [well-known feature](http://docs.python.org/2/library/multiprocessing.html#windows) of Python multiprocessing on Windows: you have to run everything that uses CODE in an CODE block or you'll get freezes/crashes.,Investigation and Exploration
1615,"Maybe we should document this somewhere prominently, e.g. in the README?",Solution Discussion
1616,"Well, the good news is that nowadays joblib gives a meaningful errormessage on such crash, rather than a fork bomb.",Solution Discussion
1617,@GaelVaroquaux does current scikit-learn give that error message?,Solution Discussion
1618,"If so, the issue can be considered fixed, IMHO.",Action on Issue
1619,It should do.,Solution Discussion
1620,The only way to be sure is to check.,Solution Discussion
1621,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
1622,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
1623,"Sorry, but I really don't do Windows :)",Contribution and Commitment
1624,I have a Windows VM.,Contribution and Commitment
1625,I can check.,Contribution and Commitment
1626,It's just a question of finding alittle be of time to do it.,Social Conversation
1627,"@larsmans , you are completely right.",Social Conversation
1628,"The custom scorer object was a mistake of me, the problem lies indeed in the multiprocessing on windows.",Investigation and Exploration
1629,I tried this same code on a Linux and it runs well.,Bug Reproduction
1630,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
1631,@adverley Could you try the most recent version from GitHub on your Windows box?,Investigation and Exploration
1632,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
1633,"Not sure if related, does seem to be.",Social Conversation
1634,"In windows, custom scorer still freezes.",Observed Bug Behaviour
1635,"When it freezes, it shows no error message.",Observed Bug Behaviour
1636,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour
1637,"However, the CPU utilization remains 0 for all python processes.",Observed Bug Behaviour
1638,I am using IPython Notebook.,Observed Bug Behaviour
1639,Can you share the code of the scorer?,Observed Bug Behaviour
1640,It seems a bit unlikely.,Social Conversation
1641,Does your scorer use joblib / n_jobs anywhere?,Investigation and Exploration
1642,"It shouldn't, and that could maybe cause problems (though I think joblib should detect that).",Investigation and Exploration
1643,Sure - here's the full code - http://pastebin.com/yUE26SNs,Observed Bug Behaviour
1644,"The scorer function is ""score_model"", it doesn't use joblib.",Investigation and Exploration
1645,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour
1646,The error message is -CODE,Observed Bug Behaviour
1647,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
1648,"Fix the attribute error, then it'll work.",Solution Discussion
1649,Do you do pylab imports in IPython notebook?,Investigation and Exploration
1650,Otherwise everything should be the same.,Investigation and Exploration
1651,Well I do not know what causes the AttributeError...,Social Conversation
1652,"Though it is most likely related to joblibs, since _it happens only when n_jobs is more than 1_, runs fine with CODE.",Investigation and Exploration
1653,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour
1654,(I realized that the error line was pasted incorrectly above - I edited in the post above.),Social Conversation
1655,I don't use pylab.,Observed Bug Behaviour
1656,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour
1657,"Hum, that is likely related to issues of multiprocessing on windows.",Investigation and Exploration
1658,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
1659,I don't know what the notebook makes of the CODE.,Social Conversation
1660,"Try not defining the metric in the notebook, but in a separate file and import it.",Solution Discussion
1661,I'd think that would fix it.,Solution Discussion
1662,"This is not really related to GridSearchCV, but some interesting interaction between windows multiprocessing, IPython notebook and joblib.",Investigation and Exploration
1663,guys...thanks for the thread.,Social Conversation
1664,"Anyway i should have checked this thread before, wasted 5 hours of my time on this.",Social Conversation
1665,Trying to run in parallel processing.,Observed Bug Behaviour
1666,Thanks a lot :),Social Conversation
1667,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
1668,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour
1669,"When i did not use custom cost function, i did not face these freezes in parallel processing",Observed Bug Behaviour
1670,"The best way of turning these 5 hours into something useful for the project, would be to provide us with a stand-alone example reproducing the problem.",Bug Reproduction
1671,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
1672,I was getting the CODE message.,Observed Bug Behaviour
1673,"As @amueller suggested, importing the custom scorer instead of defining it in the notebook works.",Solution Discussion
1674,I have the exact same problem on OSX 10.10.5,Bug Reproduction
1675,Same here.OSX 10.12.5,Bug Reproduction
1676,Please give a reproducible code snippet.,Bug Reproduction
1677,Just run these lines in a python shell CODE,Bug Reproduction
1678,Note that removing the PCA step from the pipeline solves the issue.,Solution Discussion
1679,"More info: Darwin-16.6.0-x86_64-i386-64bit('Python', '2.7.13 (default, Apr  4 2017, 08:47:57) \n[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.2')",Bug Reproduction
1680,"seeing as you don't use a custom scorer, should we assume that is aseparate issue?",Potential New Issues and Requests
1681,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
1682,At least on my machine.,Observed Bug Behaviour
1683,Importing the scorer also didn't help in my case.,Investigation and Exploration
1684,"Anyway, the symptoms looks similar.",Investigation and Exploration
1685,The script hangs forever and the CPU utilization is low.,Observed Bug Behaviour
1686,"@boazsh thanks a lot for the snippet, it is not deterministic though, can you edit it and use a CODE to make sure the random numbers are always the same on each run.",Bug Reproduction
1687,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
1688,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
1689,Some piece of information useful to have (just add what is missing to your earlier comment https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-320885103): CODE,Investigation and Exploration
1690,"Also how did you install scikit-learn, with pip, with conda, with one of the OSX package managers (brew, etc ...) ?",Investigation and Exploration
1691,Great thanks a lot!,Social Conversation
1692,"Have you answered this one, I can't find your answer ...",Social Conversation
1693,"Sorry, missed it - pip.",Investigation and Exploration
1694,"FWIW, I have no problem running that snippet with: >>> import platform; print(platform.platform())Darwin-16.7.0-x86_64-i386-64bit>>> import sys; print(""Python"", sys.version)Python 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]>>> import numpy; print(""NumPy"", numpy.__version__)NumPy 1.13.1>>> import scipy; print(""SciPy"", scipy.__version__)SciPy 0.19.1>>> import sklearn; print(""Scikit-Learn"", sklearn.__version__)Scikit-Learn 0.18.2",Bug Reproduction
1695,"Could you put verbose=10 in cross_val_predict, too, so that we can perhapssee where it breaks for you?",Investigation and Exploration
1696,@jnothman I am guessing that your conda environment uses MKL and not Accelerate.,Investigation and Exploration
1697,This freezing problem is specific to Accelerate and Python multiprocessing.,Investigation and Exploration
1698,http://scikit-learn.org/stable/faq.html#why-do-i-sometime-get-a-crash-freeze-with-n-jobs-1-under-osx-or-linux for more details.,Investigation and Exploration
1699,pip on the other hand will use wheels that are shipped with Accelerate (at the time of writing).,Investigation and Exploration
1700,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
1701,Nothing is being printed... ![screen shot 2017-08-08 at 16 43 35] URL ,Investigation and Exploration
1702,"@jnothman in case you want to reproduce the problem, IIRC you can create an environment with Accelerate on OSX  with something like:CODE",Bug Reproduction
1703,FWIW I can not reproduce the problem on my OS X VM.,Bug Reproduction
1704,I tried to mimic as close as possible @boazsh's versions: CODE,Bug Reproduction
1705,Hmm actually I can reproduce but your snippet was not a complete reproducer.,Bug Reproduction
1706,Here is an updated snippet: CODE,Bug Reproduction
1707,"In any case, this is a known problem with Accelerate and Python multiprocessing.",Investigation and Exploration
1708,Workarounds exist and have been listed in earlier posts.,Workarounds
1709,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
1710,Having a fix to multiprocessing be dependent on the scikit-learn version is symptomatic of the problems of vendoring....,Solution Discussion
1711,"I recently read the following, which I found interesting:https://lwn.net/Articles/730630/rss",Solution Discussion
1712,I have a similar issue with RandomizedSearchCV; it hangs indefinitely.,Observed Bug Behaviour
1713,"I am using a 3 year old macbook pro, 16GB ram and core i7 and my scikit-learn version is 0.19.",Observed Bug Behaviour
1714,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
1715,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour
1716,"I know from previous runs that it take about 60 min to finish, but I waited a lot longer than that and nothing happens, it just hangs, no error msgs, nothing and my computer heats up and sucks power like there's no tomorrow.",Observed Bug Behaviour
1717,Code below.,Observed Bug Behaviour
1718,So it may have something to do with n_jobs=-1.,Investigation and Exploration
1719,"Still, this code worked fine last Friday!",Observed Bug Behaviour
1720,it just hates Mondays.,Social Conversation
1721,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
1722,CODE,Observed Bug Behaviour
1723,what is crf?,Investigation and Exploration
1724,"just to eliminate the possibility, could you try usingreturn_train_score=False?",Investigation and Exploration
1725,"It is very likely that this @KaisJM's problem is due to the well known limitation on Accelerate with multiprocessing, see our [faq](http://scikit-learn.org/stable/faq.html#why-do-i-sometime-get-a-crash-freeze-with-n-jobs-1-under-osx-or-linux).",Investigation and Exploration
1726,How did you install scikit-learn?,Investigation and Exploration
1727,"Also for future reference, can you paste the output of:CODE",Investigation and Exploration
1728,this was working last Friday!!,Investigation and Exploration
1729,I done nothing since.,Investigation and Exploration
1730,"I think scikit learn is part of anaconda, but I did upgrade with pip (pip install --upgrade sklearn), but thats before I got this problem..",Investigation and Exploration
1731,I ran the code fine after upgrading to 0.19.,Investigation and Exploration
1732,here's the output of the above prints: CODE,Investigation and Exploration
1733,@jnothman : I am using RandomizedSearchCV from sklearn.grid_search which does not have the return_train_score parameter.,Investigation and Exploration
1734,I know sklearn.grid_search is depricated..,Investigation and Exploration
1735,"I will try the one from sklearn.model_selection, but something tells me I will have the same exact issue).",Investigation and Exploration
1736,Updated original comment with more info and code.,Social Conversation
1737,Can you post the output of CODE.,Investigation and Exploration
1738,I would wild guess that by updating scikit-learn with pip you updated numpy with pip too and you got the numpy wheels which uses Accelerate and has the limitation mentioned above.,Investigation and Exploration
1739,Small word of advice:,Social Conversation
1740,*         post a fully stand-alone snippet (for your next issue).,Bug Reproduction
1741,That means anyone can copy and paste it in a IPython session and easily try to reproduce.,Bug Reproduction
1742,This will give you the best chance of getting good feed-back.,Bug Reproduction
1743,"*         if you are using conda, stick to conda to manage packages that are available through conda.",Solution Discussion
1744,Only use pip when you have to.,Solution Discussion
1745,"*         If you insist you want to use CODE, I would strongly recommend you use CODE.",Solution Discussion
1746,"Otherwise if a package dependends, say on numpy, and you happen not to have the latest numpy, numpy will be upgraded with pip, which you do not want.",Solution Discussion
1747,"Oh yeah and BTW, sklearn.grid_search is deprecated you probably want to use sklearn.model_selection at one point not too far down the road.",Solution Discussion
1748,"Good advice, thank you.",Social Conversation
1749,So is the workaround to downgrade numpy?,Workarounds
1750,what limitation are you referring to?,Investigation and Exploration
1751,the FAQ link above?,Investigation and Exploration
1752,"I did read it, but I do not understand this stuff (i'm just an algo guy :) ).",Social Conversation
1753,output of CODE numpy                     1.12.0                    <pip>numpy                     1.12.0                   py27_0numpy                     1.13.1                    <pip>numpydoc                  0.7.0                     <pip>,Investigation and Exploration
1754,Wow three numpy installed I saw two before but never three ...,Social Conversation
1755,"anyway this seems indicative of the problem I was mentioning, i.e. that you have mixed pip and conda which is a bad idea for a given package.",Investigation and Exploration
1756,CODE,Solution Discussion
1757,Hopefully after that you will have a single numpy that uses MKL.,Solution Discussion
1758,"If I were you I would double-check that you don't have the same problem for other core scientific packages, e.g. scipy, etc ...",Solution Discussion
1759,"the reason I resort to pip for some packages is that conda does not have some packages, which actually is very frustrating because I know mixing pip with conda is a bad idea.",Solution Discussion
1760,Next time that happens I'll use the --no-deps option.,Solution Discussion
1761,one thing I should've mentioned is that I installed Spyder within the python env I was working in.,Solution Discussion
1762,"However, I was able to run the code after installing Spyder, both in Spyder and in Jupyter.",Solution Discussion
1763,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
1764,"Something may have happened because of the Spyder install, but then why would it work for a day and then suddenly stop??",Investigation and Exploration
1765,"ok, nothing is working!!",Observed Bug Behaviour
1766,should I just create a new environment (using conda) and re-install everything there?,Solution Discussion
1767,will that solve it or make it worse?,Solution Discussion
1768,Sounds worth a try!,Solution Discussion
1769,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
1770,only one copy of each package etc.,Observed Bug Behaviour
1771,"n_jobs=1 works,but takes forever of course (it worked in the previous env as well).",Observed Bug Behaviour
1772,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
1773,CODE,Observed Bug Behaviour
1774,Then I don't know.,Social Conversation
1775,"The only way we can investigate, is that you post a fully standalone snippet which we can just copy and paste in an IPython sesion and see if we can reproduce the problem.",Bug Reproduction
1776,will try to create a minimal example that reproduces the problem.,Bug Reproduction
1777,I need to do that to debug more efficiently.,Social Conversation
1778,"I read the FAQ entry you refer to about ""Accelerate"".. its not much help for me.",Investigation and Exploration
1779,What I took from it is that fork() NOT followed by exec() call is bad.,Investigation and Exploration
1780,I've done some googling on this and nothing so far even hints at a workaround.,Social Conversation
1781,"Can you point to some more information, more detail about what the problem is?",Investigation and Exploration
1782,"thanks,",Social Conversation
1783,Try this snippet (taken from https://github.com/numpy/numpy/issues/4776):CODE,Investigation and Exploration
1784,*         If this freezes (i.e. it does not finish within one second) that means you are using Accelerate and the freeze is a known limitation with Python multiprocessing.,Investigation and Exploration
1785,The work-around is to not use Accelerate.,Workarounds
1786,On OSX you can do that with conda which uses MKL by default.,Workarounds
1787,You can also use OpenBLAS using conda-forge.,Workarounds
1788,"*         If it does not freeze then you are not using Accelerate, and we would need a stand-alone snippet to investigate.",Investigation and Exploration
1789,will try to reproduce with minimal code. CODE,Bug Reproduction
1790,@GaelVaroquaux scikit-learn is not an app but a library in a rich ecosystem.,Solution Discussion
1791,"If everybody did what we do, everything would come crashing down.",Solution Discussion
1792,That's a pretty clear signal that we need to change.,Solution Discussion
1793,And there are many environments where the opposite is true from that comment.,Solution Discussion
1794,"I used a ubuntu virtual instance in google cloud compute engine (bumpy, spicy, scikit etc were not the most up to date).",Observed Bug Behaviour
1795,The code ran fine.,Observed Bug Behaviour
1796,Then I installed Gensim.,Observed Bug Behaviour
1797,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
1798,After that the code freezes.,Observed Bug Behaviour
1799,I hope this gives a useful clue as to what causes this freeze.,Social Conversation
1800,**after installing Gensim**numpy (1.10.4) updated to numpy (1.13.3)scipy (0.16.1)   updated to scipy (0.19.1),Observed Bug Behaviour
1801,**more info:**,Social Conversation
1802,"Doing some research I found that libblas, liblapack and liblapack_atlas were missing from my /usr/lib/, also I did not see the directory /usr/lib/atlas-base/.",Investigation and Exploration
1803,"I don't know if they were there and installing gensim removed them since it updated numpy etc, but this is likely since the code worked before installing gensim.",Investigation and Exploration
1804,I think the problem is that numpy is using OpenBlas.,Investigation and Exploration
1805,Will switch it to ATLAS and see what happens.,Investigation and Exploration
1806,CODE,Investigation and Exploration
1807,Still the same problem.,Observed Bug Behaviour
1808,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
1809,@paulaceccon are your Numpy and Scipy installations using ATLAS or OpenBLAS?,Investigation and Exploration
1810,It is a bit hard to follow what you have done @KaisJM.,Social Conversation
1811,From a maintainer's point of view what we need is a fully stand-alone python snippet to see if we can reproduce.,Bug Reproduction
1812,"If we can reproduce, only then can we investigate and try to understand what is happening.",Social Conversation
1813,"This requires a non negligible amount of time and effort, I completely agree, but without it, I am afraid that there is not much we can do to investigate the problem you are facing.",Social Conversation
1814,"@KaisJM by the way, this page is out-of-date, since nowadays wheels are available on Linux and contain their own OpenBLAS.",Investigation and Exploration
1815,If you install a released scikit-learn with pip you will be using OpenBLAS.,Investigation and Exploration
1816,@lesteve are you saying that Openblas does not cause a freeze anymore?,Investigation and Exploration
1817,@lesteve paula has posted a snippet that also has the same problem.,Investigation and Exploration
1818,"I can see it's not complete code, but I hope it gives some clue.",Social Conversation
1819,"I can make here snippet ""complete"" and post for you.",Social Conversation
1820,"However, it is clear that the ""out-of-date"" -as you call it- instructions page may not be so out of date.",Investigation and Exploration
1821,The highest likelihood is that OpenBLAS is causing the fees they are talking about in that page.,Investigation and Exploration
1822,These instructions are outdated believe me.,Investigation and Exploration
1823,"If you read in details, it says ""but can freeze joblib/multiprocessing prior to OpenBLAS version 0.2.8-4"".",Investigation and Exploration
1824,I checked a recent numpy wheel and it contains OpenBLAS 0.2.8.18.,Investigation and Exploration
1825,"The freeze they are referring to is the one in https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-334155175, which you don't seem to have.",Investigation and Exploration
1826,Not really no.,Social Conversation
1827,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
1828,"That seems to indicate, that this problem happens in some very specific combination of factors.",Investigation and Exploration
1829,That would be great.,Social Conversation
1830,@lesteve @paulaceccon :I took Paula's excerpt code and made a complete run-able code snippet.,Investigation and Exploration
1831,Just paste it into a Jupyter cell and run it.,Investigation and Exploration
1832,Paula: I could not get this snippet to freeze.,Investigation and Exploration
1833,Notice that n_jobs=-1 and runs fine.,Investigation and Exploration
1834,Would be great if you can take a look and post a version of it that freezes.,Investigation and Exploration
1835,"Notice that you can switch between grid_search module and model_selection module, both ran fine for me.",Investigation and Exploration
1836,CODE,Investigation and Exploration
1837,@KaisJM I think it is more useful if you start from your freezing script and manage to simplify and post a fully stand-alone that freezes for you.,Bug Reproduction
1838,@lesteve Agreed.,Social Conversation
1839,I created a new python2 environment like the one I had before installing Gensim.,Investigation and Exploration
1840,"Code ran fine, NO freeze with n_jobs=-1.",Investigation and Exploration
1841,"What's more, Numpy is using OpenBLAS and has the same config as the environment that exhibits the freeze (the one where Gensim was installed).",Investigation and Exploration
1842,So it seems that openblas is not the cause of this freeze.,Investigation and Exploration
1843,CODE,Investigation and Exploration
1844,@KaisJM  I'm running the same snippet here (windows) and it freezes. CODE,Observed Bug Behaviour
1845,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
1846,I have a similar problem.,Observed Bug Behaviour
1847,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
1848,Running GridSearchCV or RandomizedSearchCV in a loop and  n_jobs > 1 would hang silently in Jupiter & IntelliJ: CODE,Investigation and Exploration
1849,"Followed @lesteve recommendation & checked environment & removed numpy installed with pip: Darwin-16.6.0-x86_64-i386-64bitPython 3.6.1 |Anaconda custom (x86_64)| (default, May 11 2017, 13:04:09)[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]NumPy 1.13.1SciPy 0.19.1Scikit-Learn 0.19.0  $conda list | grep numpygnumpy                   0.2                pipnumpy                     1.13.1            py36_0numpy                     1.13.3           pipnumpydoc              0.6.0             py36_0 $pip uninstall numpy $conda list | grep numpygnumpy                   0.2                      pipnumpy                     1.13.1                  py36_0numpydoc              0.6.0                  py36_0 $conda install numpy -f                                // most likely unnecessary $conda list | grep numpygnumpy                   0.2                       pipnumpy                     1.13.1                   py36_0numpydoc               0.6.0                   py36_0",Solution Discussion
1850,Fixed my problem.,Solution Discussion
1851,@paulaceccon your problem is related to > https://stackoverflow.com/questions/36533134/cant-get-attribute-abc-on-module-main-from-abc-h-py> If you declare the pool prior to declaring the function you are trying to use in parallel it will throw this error. Reverse the order and it will no longer throw this error.,Social Conversation
1852,The following will run your code:CODE,Solution Discussion
1853,with external.py CODEResults running on 8 cores,Solution Discussion
1854,"Fitting 3 folds for each of 54 candidates, totalling 162 fits[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.1s[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:   30.5s finished{'class_weight': {0: 0.51891309, 1: 13.71835531}, 'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 20, 'n_estimators': 400}",Solution Discussion
1855,Issue is still there guys.,Observed Bug Behaviour
1856,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
1857,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
1858,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
1859,Please read https://stackoverflow.com/help/mcve for more details.,Solution Discussion
1860,Still facing this problem with the same sample  code.,Bug Reproduction
1861,"Windows-10-10.0.15063-SP0Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]NumPy 1.14.1SciPy 1.0.0Scikit-Learn 0.19.1",Bug Reproduction
1862,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
1863,Please read https://stackoverflow.com/help/mcve for more details.,Solution Discussion
1864,I suspect this is the same old multiprocessing in windows issue.,Investigation and Exploration
1865,see our FAQ,Solution Discussion
1866,I tested the code in thomberg1's https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-337985212.,Bug Reproduction
1867,OS: Windows 10 x64 10.0.16299.309Python package: WinPython-64bit-3.6.1numpy (1.14.2)scikit-learn (0.19.1)scipy (1.0.0),Bug Reproduction
1868,It worked fine in Jupyter Notebook and command-line.,Bug Reproduction
1869,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
1870,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
1871,Code is from a tutorial : https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/,Observed Bug Behaviour
1872,"I tried changing the n_jobs parameter to 1, -1, but neither of these worked.",Solution Discussion
1873,Any hint?,Solution Discussion
1874,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
1875,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
1876,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
1877,"Thank you @thomberg1 , but addingCODEdid not help.",Observed Bug Behaviour
1878,The problem is still the same,Observed Bug Behaviour
1879,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
1880,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour
1881,@byrony can you provide code to reproduce?,Bug Reproduction
1882,"did you use CODEif __name__ == ""__main__""CODE?",Observed Bug Behaviour
1883,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour
1884,"*         Python 3.6.5,*         scikit-learn 0.19.1,*         Arch Linux,*         CPU cores: 8.",Observed Bug Behaviour
1885,Here is the code I used:CODE,Observed Bug Behaviour
1886,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
1887,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
1888,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
1889,Thanks in advance!,Social Conversation
1890,@amueller I didn't use the CODE.,Observed Bug Behaviour
1891,"Below is my code, it only works when CODE CODE",Observed Bug Behaviour
1892,You're using XGBoost.,Investigation and Exploration
1893,"I don't know what they do internally, it's very possible that's the issue.",Investigation and Exploration
1894,Can you try to see if adding the CODEif __name__CODE helps?,Investigation and Exploration
1895,Otherwise I don't think there's a fix for that yet.,Solution Discussion
1896,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
1897,I can't reproduce without your data and it would be good to reproduce in shorter time.,Social Conversation
1898,"@amueller Ok, I will run it again with 500k rows and will post the results.",Bug Reproduction
1899,Thanks!,Social Conversation
1900,"@amueller, running the script with 50k rows works as expected.",Bug Reproduction
1901,"The script ends correctly, showing the results as follows (sorry, I meant 50k not 500k): ![captura de pantalla de 2018-05-26 13-09-00] URL  ![captura de pantalla de 2018-05-26 13-09-51] URL ",Bug Reproduction
1902,The problem is that I don't know if these results are going to be the best for my whole dataset.,Bug Reproduction
1903,Any advice?,Bug Reproduction
1904,Seems like you're running out of ram.,Investigation and Exploration
1905,"Maybe try using Keras instead, it's likely a better solution for large scale neural nets.",Solution Discussion
1906,"@amueller Oh, ok.",Social Conversation
1907,I will try using Keras instead.,Solution Discussion
1908,Thank you again!,Social Conversation
1909,Rethinking the CategoricalEncoder API ?,Solution Discussion
1910,"Based on some discussions we are having here and issues that are opened, we are having some doubts that CODE  URL  was the good choice of name (and since it is not released yet we have some room for change).",Solution Discussion
1911,So summary of how it is now:,Motivation
1912,-         The class name CODE says what type of data it accepts (categorical data),Motivation
1913,-         The keyword argument CODE specifies *how* to encode those data,Motivation
1914,But what to do in the following cases:,Motivation
1915,"-         We want to add more encoding options (eg binary encoding, mean target encoding, unary encoding, ...).",Motivation
1916,"-         We want to add an option specific to one of the encodings (eg for 'onehot' encoding to drop the first (redundant) column, or for 'ordinal' encoding base the order of the categories on the frequency, ...).",Motivation
1917,"The problem here is that we then need to add additional keyword arguments to CODE that are or are not active depending on what you passed for CODE kwarg, which is not the nicest API design.",Motivation
1918,"For that last problem, we already had this with the CODE option, which was only relevant for 'onehot' and not for 'ordinal', and which we solved with having both 'onehot' and 'onehot-dense' encoding options and not a CODE keyword.",Solution Discussion
1919,But such an approach also does not scale.,Solution Discussion
1920,"There was a related discussion on the naming in that PR, as currently the name says *how* it encodes, not what type of data it gets (in the current design, it accepts already encoded integers, not actual categorical data.",Solution Discussion
1921,"In that regard, to be consistent with CategoricalEncoder, it might better be named OrdinalEncoder because it needs ordinal data as input).",Solution Discussion
1922,What are the options forward:,Solution Discussion
1923,"1)         Keep things as we have it now in master, and be be OK with adding some new options to the single class (an important question which is hard to answer now, is how much new features we will want to add in the future).",Solution Discussion
1924,"2)         Switch the naming scheme and have a bunch of 'categorical encoders' where the name says how it encodes (OnehotEncoder, OrdinalEncoder, and later maybe BinaryEncoder, UnaryEncoder, ...)",Solution Discussion
1925,So it is a bit a trade-off of potential build up of number of classes vs number of keyword arguments in a single class.,Solution Discussion
1926,"One problem with the second approach (and one of the reasons we went with CODE in the first place, even before we added the multiple encoding options), is that there is already a CODE, which has a different API than the CODE.",Solution Discussion
1927,"And, there is not really a good other name we could use for the encoder that does one-hot encoding.",Solution Discussion
1928,"However, I think that, with some temporary ugly hacks, we could reuse the name, if we are OK with deprecating the current attributes (and I think we agree it are not the most useful attributes).",Solution Discussion
1929,"The idea would be that if you fit the class with string data, you get the new behaviour, and if you fit the class with integer data, you get a deprecation warning indicating the default behaviour will change (and indicating which keyword to specify to get rid of the warning).",Solution Discussion
1930,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
1931,Thanks for the summary @jorisvandenbossche.,Social Conversation
1932,"I think I am in favor of option 2: reuse CODE class, deprecate the weird attributes and add a constructor parameter to select the behavior with a future warning that says that the default behavior will change but makes it easy to silence that warning just by passing a value for that option.",Solution Discussion
1933,"The idea of reverting CategoricalEncoder makes me quite sad, but I thinkyou're right that future users would be less mystified by option 2.",Solution Discussion
1934,My mainconcern is that we have tried implementing this as a change to OHE for along time and it never flew.,Solution Discussion
1935,"Perhaps it would be good to attempt themodifications to the OneHotEncoder docstring according to that proposedchange, so we can see if it looks sane.",Solution Discussion
1936,+1 to what Joel said,Social Conversation
1937,â£Sent from my phone.,Social Conversation
1938,Please forgive typos and briefness.â,Social Conversation
1939,"To be clear, it would not be a revert, it would be a refactor / rename that keeps all functionality!",Solution Discussion
1940,"But I also like the ""CategoricalEncoder"" name, that would indeed be sad.",Social Conversation
1941,"That said, I will quickly try to do the changes to have an idea how possible it is to integrate this in OnehotEncoder.",Solution Discussion
1942,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
1943,The main API question is about the format of the input data.,Solution Discussion
1944,"So as a recap, there are **two different ways we currently process the categorical data**:",Solution Discussion
1945,"1)         As actual, not yet encoded (integer or string), categorical data (how it is done in CODE) -> infer categories from the unique values in the training data",Solution Discussion
1946,"2)         As integer, already encoded data (how it is done in the current CODE) -> infer categories from the maximum value in the training data",Solution Discussion
1947,The question is: **do we find both cases worth supporting?**,Solution Discussion
1948,"Thus, in the potentially merged OneHotEncoder, do we keep the ability to do both, or do we fully deprecate and then remove the ability to process ordinal input?",Solution Discussion
1949,"If want the ability to process both, we can add a boolean keyword to specify the input data type (for now I use CODE, but other ideas are CODE,  ...)",Solution Discussion
1950,"For the deprecation period, we have to support both anyway, and also have to introduce a keyword to choose the behaviour (to be able to silence the warning and choose the new behaviour).",Solution Discussion
1951,So in principle we could just keep the keyword afterwards.,Solution Discussion
1952,"Given that we want to handle both, an overview of how OneHotEncoder would work:",Solution Discussion
1953,"-         for now CODE, and we infer the default based on the data",Solution Discussion
1954,-         if int-like data (handled before by OneHotEncoder) CODE is internally set to True and a deprecation warning is raised.,Solution Discussion
1955,"If the user wants to keep the current behaviour, it can manually specify it as CODE to silence the warning.",Solution Discussion
1956,"If the user wants to keep the current behaviour, it can manually specify it as",Solution Usage
1957,"-         if the input is not int-like, we set CODE internally to False and without warning use the new behaviour (= the current CategoricalEncoder behaviour)",Solution Discussion
1958,I'm still not sure what you're suggesting is the practical difference due to inferring categories from the max value.,Motivation
1959,@jnothman I suppose you acknowledge there *can* be a difference in practice?,Motivation
1960,(the output you get depending on the data you have),Motivation
1961,"But whether this difference is important in practice, I don't know.",Social Conversation
1962,That's where I would like to see feedback.,Social Conversation
1963,"Whether anybody actually *wants* this ""max value""-based method, or whether we are fine with (in the future, after deprecation) only having the ""unique values""-based method.",Expected Behaviour
1964,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
1965,Actually deprecating the max-value based categorization would certainly make the implementation (after deprecation) simpler.,Solution Discussion
1966,"And if we choose for that route, I agree the option should rather be CODE rather than CODE/CODE",Solution Discussion
1967,"Remind me what the actual difference in output is, when n_values='auto',please?",Solution Discussion
1968,"I had thought the active_features_ thing made them basicallyidentical, but I'm probably forgetting something.",Solution Discussion
1969,"Aha, that clarifies our misunderstanding :-)",Social Conversation
1970,I misunderstood how the current OneHotEncoder is actually working.,Social Conversation
1971,"Suppose you have one feature with values [2, 3, 5, 2].",Investigation and Exploration
1972,"I thought the current OneHotEncoder would have categories [0, 1, 2, 3, 4, 5] (while current CategoricalEncoder would have categories [2, 3, 5]).",Investigation and Exploration
1973,"But you are right that the CODE is also only [2, 3, 5], essentially making them the same with the default value of CODE.",Investigation and Exploration
1974,"So it is only the case where you pass an integer to CODE (like CODE for categories=[0, 1, 2, 3, 4, 5] in the above case) to specify the number of categories that will actually be an API change (deprecated / removed).",Solution Discussion
1975,Sorry for the confusion.,Social Conversation
1976,"In that light, I think we even don't need the CODE option.",Solution Discussion
1977,The other difference is the handling of unseen categories.,Solution Discussion
1978,"With the current behaviour of the OneHotEncoder, if the unseen values are within the range(0, max), it will not raise an error even if CODE (the default).",Solution Discussion
1979,But also that can be solved separately by in such a case raising a warning that the user should set CODE manually to keep the existing behaviour.,Solution Discussion
1980,"The only feature we would loose is the distinction between unknown categories that are within the range(0, max) (by the current OneHotEncoder not regarded as 'unknown') and those that are bigger than that (> max, those are currently already regarded as unknown by the OneHotEncoder).",Solution Discussion
1981,"unless there is good reason to maintain current behaviour, weshould just have a legacy_mode to slowly bring us to the future.",Solution Discussion
1982,"Can you clarify to which aspect this ""no"" refers?",Solution Discussion
1983,To the fact that I think a CODE is not needed?,Solution Discussion
1984,"yes, to the idea that you can just make something that is both backwardscompatible and what we want going forward",Solution Discussion
1985,That was not what I tried to suggest.,Social Conversation
1986,"I wanted to make clear that think it is possible to not have a CODE keyword, not by having it magically both backwards compat and what we want in the future, but by deprecating the behaviour of the existing keywords.",Solution Discussion
1987,So to be concrete: a non-default value of CODE can be deprecated and has to be replaced by CODE specification.,Solution Discussion
1988,CODE in case of integer data should be set explicitly by the user to choose either full ignoring or full erroring instead of current mix (and otherwise deprecation warning is raised).,Solution Discussion
1989,"so if I do .fit([[5]]).transform([[4]]), for which values of n_values,categories and handle_umknown will that raise an error?",Solution Usage
1990,"can we just make it so that during deprecation, categories must be setexplicitly, and legacy mode with warnings is otherwise in effect?",Solution Discussion
1991,Is thatwhat you are suggesting?,Social Conversation
1992,"Yes, it might be still missing case, but I *think* this is possible (will check by actual coding it next week).",Solution Discussion
1993,The different 'legacy' cases:,Solution Discussion
1994,-         n_values='auto' (the default),Solution Discussion
1995,"-         handle_unknown='ignore'  -> fine, no change in behaviour",Solution Discussion
1996,"-         handle_unknown='error' -> Problem, values in range are still ignored, values above range error",Solution Discussion
1997,-         Possible solution:,Solution Discussion
1998,"-         in fit, if the range is consecutive => fine, no change in behaviour (for all people that now combined LabelEncoder with it, which is a typical use case I think)",Solution Discussion
1999,-         if this is not the case: raise deprecation warning that they have to set categories explicitly to keep this behaviour (and internally use legacy mode),Solution Discussion
2000,-         n_values=value,Solution Discussion
2001,"-         this can be translated to categories=[range(value)] internally, and raise deprecation warning that user should do that themselves in the future",Solution Discussion
2002,-         in this case CODE work as expected,Solution Discussion
2003,"The deprecation warning in case of CODE will only be raise in CODE and not upon construction (which is not really ideal), but it is only in fit that we know that the user is passing it numeric data and not string data.",Solution Discussion
2004,we don't usually raise warnings until fit in any case so don't worry aboutthat.,Solution Discussion
2005,that strategy sounds mostly good.,Social Conversation
2006,"I'm not actually sure if we should be sniffing for strings in the data,though.",Solution Discussion
2007,You basically want it to be: legacy mode is active if categories isnot set *and* if the data is all integers?,Solution Discussion
2008,"One question: if categories and n_values parameters are their default, dowe publish categories_?",Solution Discussion
2009,"If n_values is set explicitly, do we publishcategories_?",Solution Discussion
2010,Yes indeed (in practice it will more or less be the same),Solution Discussion
2011,"I personally would already as much as possible provide the attributes of the new interface, even in legacy mode.",Solution Discussion
2012,So in both case I would calculate CODE (even if it would be a bit more work),Solution Discussion
2013,"So I tried to put the above logic in code (will push some updates to the PR), and I have one more question for the case of integer data when CODE or CODE is not set (typical case for 'legacy_mode').",Task Progress
2014,"The problem lies in the fact that if the inferred categories are simply a consecutive range (0, 1, 2, 3, ... max), there is no difference between the new and old (legacy) behaviour, and we don't necessarily need to raise a deprecation warning.",Solution Discussion
2015,Some possibilities to do in this specific case:,Solution Discussion
2016,"1)         Detect this case (that the inferred categories are a consecutive range), and in that case don't raise a warning.",Solution Discussion
2017,-         This is possible to detect (with a little bit of extra code complexity) as we are already in fit anyhow,Solution Discussion
2018,"-         I *think* this will be a common case when using OneHotEncoder with integer data, and a case where the user actually does not need to worry about our refactoring, so it would be nice to not bother him/her with a warning",Solution Discussion
2019,"2) Always raise a warning, and indicate in the warning message what to do if you are in such a case (in addition to an explanation what to do if you don't have a consecutive range):",Solution Discussion
2020,"-         If they know they have only consecutive ranges as categories, they want to ignore the warning, so we can add to the warning message an explanation how to do this (add a code sample with filterwarnings they can copy paste)",Solution Discussion
2021,"-         A potential advantage of this is that we can also add to the warning message that if they used the LabelEncoder to create the integers, they can now directly use OneHotEncoder (I think this currently is a typical usage pattern).",Solution Discussion
2022,"That way, the warning will also go away",Solution Discussion
2023,3) Always raise a warning but provide a keyword to silence it (eg CODE),Solution Discussion
2024,"-         If we find the advice to use a CODE statement (see point 2 above) too cumbersome, we could also add a keyword to obtain the same result",Solution Discussion
2025,-         Disadvantage of this is introducing a keyword that will not be needed anymore in a few releases when the deprecations are cleaned up.,Solution Discussion
2026,I am personally in favor of option 1 or 2.,Social Conversation
2027,"Using the LabelEncoder before OneHotEncoder seems to be a typical pattern (from a quick github search), and in those case you *always* have consecutive ranges, and there will never be a change in behaviour with the new implementation, so we shouldn't warn for it.",Solution Discussion
2028,"On the other hand, if we warn we can point them to the fact that *if* they used LabelEncoder, they no longer need to do it.",Solution Discussion
2029,Which would be nice to actually give this advice explicitly.,Solution Discussion
2030,The question is how frequently users have such consecutive integers as categories without having used LabelEncoder as the previous step ..,Motivation
2031,"In case we don't provide the CODE keyword, the only way to obtain the new behaviour is by manually passing CODE, which can be a slight inconvenience.",Solution Discussion
2032,"That might be a reason to favor option 3 and give up my objection on introducing a temporary keyword CODE (but also not fully sure it is worth it, as this would be the only case\* where such a keyword is actually needed)",Solution Discussion
2033,"\* this only case = integer data with inferred categories that are not consecutive range, and where you cannot / don't want to set the categories manually or set handle_unknown to ignore.",Solution Discussion
2034,"Sorry for all the long text, but it's quite complex :)",Social Conversation
2035,"We're only talking about the case where n_values is unset, right?",Solution Discussion
2036,"I'm fine with 1., and it would not be any more expensive, since autoalready needs to examine the set of labels.",Solution Discussion
2037,"I could also accept, forsimplicity, a variant of 3.",Solution Discussion
2038,"that was just ""OneHotEncoder running in legacymode. Set categories='auto' for slightly different behaviour without awarning.""",Solution Discussion
2039,"Yes (the other case easily be translated in its equivalent CODE value, with a nice deprecation warning, and without different in new and legacy behaviour)",Solution Discussion
2040,"Ah, that sounds like a good idea!",Social Conversation
2041,(irregardless of whether detecting the consecutive categories case or not).,Solution Discussion
2042,"So we set in the code the default of CODE to None (without changing the semantics of its default), so we know if the user set it explicitly, and in that way it is a nice way to indicate CODE without needing that extra keyword.",Solution Discussion
2043,"Yes, but only if we want to warn every time someone uses it without passingcategories.",Solution Discussion
2044,"It's the cheap implementation approach, but it might beunnecessarily verbose for the users, which is why I would prefer 1 if itcan be done simply.",Solution Discussion
2045,What fresh hell is this :-/,Social Conversation
2046,OR we could name the new one CODEDummyEncoderCODE ;) (though that is a bit conflicting with the DummyClassifier),Solution Discussion
2047,@amueller Don't read all of the above!,Social Conversation
2048,I was just planning to make a nice summary for new readers of the issue.,Social Conversation
2049,The above discussion is overly complicated (also because I was still not fully understanding the current complex behaviour of OneHotEncoder ... :-)),Social Conversation
2050,"I think @GaelVaroquaux was against that because ""one-hot"" is known to be this in more fields (and we already use 'Dummy' for other things in scikit-learn ...)",Solution Discussion
2051,Redoing this for consistency in naming is not worth it imho.,Motivation
2052,We are not consistent in naming anywhere.,Motivation
2053,Could you summarize the discussions that lead to this?,Solution Discussion
2054,"I think ""dummy"" is what statisticians use and it's what pandas uses.",Solution Discussion
2055,"The top post is still accurate and worth a read, and it summarizes the reasoning for not keeping CategoricalEncoder (which does not mean that we need to use OneHotEncoder instead of eg DummyEncoder, that's a separate question)",Solution Discussion
2056,I read the top post.,Social Conversation
2057,"That's what I referred to when I said ""redoing this for consistency is not worth it"".",Motivation
2058,Can you explain that?,Motivation
2059,"With consistency, are you pointing to the naming scheme of ""what it accepts"" vs ""what it does"" ?",Motivation
2060,"If so, that was only a minor reason.",Motivation
2061,For me it is mainly a question of scalability in adding more features to a single class.,Motivation
2062,I don't see how the proposed change would help with the missing values that much.,Motivation
2063,And having incompatible options is something that happens often in scikit-learn.,Motivation
2064,"Not ideal, but also not a big deal imho.",Motivation
2065,"It does not help *as such*, but it makes it less complex to have specific options specifically tailored to the different encoding types.",Motivation
2066,"Currently it is certainly still OK, there are not too many incompatible options (but also partly because I moved CODE into the CODE option).",Motivation
2067,And what if someone wants to add a 'binary encoding'?,Motivation
2068,Or a '(mean) target encoder'?,Motivation
2069,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests
2070,Do you have a link for that?,Potential New Issues and Requests
2071,"Searching for ""CountTransformer"" does not give any results",Potential New Issues and Requests
2072,"Sorry, CountFeaturizer #9614",Potential New Issues and Requests
2073,"It's certainly related, but not exactly a mean target encoding.",Potential New Issues and Requests
2074,"Also, it adds columns, not replaces, so will not yet work out of the box for string categorical data (but that is more feedback on that PR, not to discuss here).",Potential New Issues and Requests
2075,Why is it not mean target encoding?,Potential New Issues and Requests
2076,But yeah let's not divert too much here ;),Social Conversation
2077,So as a summary of the actual questions we need to answer (in this order!):,Solution Discussion
2078,"If not, the idea is to split it in different classes, one class for each type of encoding (currently 'onehot' and 'ordinal' encoding).",Solution Discussion
2079,"2.         If we split in multiple classes, we could (ideally?) use OneHotEncoder for the 'onehot' encoding, but this class already exists.",Solution Discussion
2080,"So, do we integrate the new 'onehot' encoding (which supports strings and has different parameters) in the existing OneHotEncoder class?",Solution Discussion
2081,Or do we choose another name?,Solution Discussion
2082,(eg DummyEncoder),Solution Discussion
2083,"3.         If we choose to integrate into the existing OneHotEncoder, are we OK with the following consequences: we deprecate a bunch of the keywords/attributes of OneHotEncoder, and a specific usecase (automatically ignoring unseen values within the *range* of seen values) will not be possible anymore after deprecation period.",Solution Discussion
2084,Most of the discussion above was about question 3 (the complex details of how to integrate CategoricalEncoder(encoding='onehot') into OneHotEncoder).,Solution Discussion
2085,But let's first agree on a decision for the first 2 questions.,Solution Discussion
2086,the other factor for me is that everyone thinks the current auto mode inOneHotEncoder is weird.,Motivation
2087,its implementation converting coo to csr is alsoweird.,Motivation
2088,it deserves a redesign.,Motivation
2089,"and telling people ""if you want to one hotencode strings, go to CategoricalEncoder instead"" is awkward, because OHEis already intended for categoricals...",Motivation
2090,hrm.,Social Conversation
2091,I guess we kept OneHotEncoder because it's more efficient when it can be used....,Motivation
2092,Ideally we would get rid of all the weird behaviors.,Motivation
2093,I kinda had wanted to deprecate it but then we didn't...,Social Conversation
2094,It's not much more efficient.,Solution Discussion
2095,"And if LabelEncoder had fast paths for intsin range [0, n_values-1], if justified, that would be good enough.",Solution Discussion
2096,"@amueller, are you persuaded by the issue that we ultimately want different additional parameters (e.g. drop_first, nan handling) depending on the encoding, and that justifies having a different discrete encoder for each encoding format?",Motivation
2097,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
2098,not sure if I'll have time before that :-/,Social Conversation
2099,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
2100,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
2101,Consider the dataframe CODE which equals: CODE,Expected Behaviour
2102,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
2103,CODE,Expected Behaviour
2104,This gives: CODE,Expected Behaviour
2105,We can see the features names of the columns with: CODE,Expected Behaviour
2106,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
2107,I don't think we intend to handle that kind of mixed case,Solution Discussion
2108,Thatâs a shame.,Social Conversation
2109,One simple sub case is where a column is numerical but has some missing values.,Motivation
2110,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
2111,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
2112,I have found this a very useful technique.,Social Conversation
2113,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour
2114,but that's not the same as handling arbitrary numeric values asdifferent from strings.,Solution Discussion
2115,That sounds good.,Social Conversation
2116,You are right there are two use cases.,Social Conversation
2117,Let me explain a particular example of where treating numeric values as different from strings has been useful for me.,Social Conversation
2118,It may be that there is a better solution.,Social Conversation
2119,Say you have an integer numeric feature which takes a large range of values.,Potential New Issues and Requests
2120,"However you suspect that for some small values, the precise value is significant.",Potential New Issues and Requests
2121,For larger values you suspect this isnât the case.,Potential New Issues and Requests
2122,"A simple thing to do is to convert all small values to strings, run DictVectorizer as above and then perform feature selection or just use your favorite classifier directly.",Potential New Issues and Requests
2123,So you're using it for a non-linear discretisation?,Potential New Issues and Requests
2124,"The next release islikely to include a fixed-width discretizer, but following on from a logtransform or a quantile transform it should act quite similar to what youwant...",Potential New Issues and Requests
2125,But the log transform might alone be sufficient in your setting.,Potential New Issues and Requests
2126,@jnothman  Yes in a sense except with a twist.,Social Conversation
2127,Say I suspect that some of the values from 1...1024 are meaningful.,Potential New Issues and Requests
2128,That is 22 indicates something specific which is quite different from 21 or 23.,Potential New Issues and Requests
2129,Taking logs won't help here.,Potential New Issues and Requests
2130,But I want to leave all the values over 1024 as numerical as I don't think those specific values mean much.,Potential New Issues and Requests
2131,It sounds like you know too much about your variable for a generictransform to be the sort of thing you need.,Potential New Issues and Requests
2132,"@jnothman  To be a little clearer,  I don't know that 22 is significant.",Potential New Issues and Requests
2133,I just suspect that *some* values are but I don't know which ones or how many there are.,Potential New Issues and Requests
2134,"I have found the ""convert to a string"" and then DictVectorizer method to be very useful for discovering which these are.",Potential New Issues and Requests
2135,"@lesshaste For the issue about NaNs as separate category, see https://github.com/scikit-learn/scikit-learn/issues/10465",Potential New Issues and Requests
2136,"If you want to further discuss the specific non-linear discretization or mixed numeric/string encoding, feel free to open a new issue.",Potential New Issues and Requests
2137,"But would like to keep this one focused on the original issue, i.e. the *naming* and organisation in different classes of the CategoricalEncoder/OneHotEncoder.",Social Conversation
2138,@amueller that's fine.,Social Conversation
2139,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
2140,After that I should also have time again to work on it.,Contribution and Commitment
2141,Sorry for being absent.,Social Conversation
2142,Thanks!,Social Conversation
2143,"@amueller no problem, for me the same :-)",Social Conversation
2144,"But, I am now planning to look at this again.",Contribution and Commitment
2145,So if you could give this a look that would be welcome.,Contribution and Commitment
2146,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
2147,"I think the main question I want to see answered before I put a lot of time in it, is if you are OK with splitting up CategoricalEncoder into multiple classes, and in that case, if you are OK with re-using OneHotEncoder (which means deprecating some of its current (strange) features).",Solution Discussion
2148,Those questions are summarized in https://github.com/scikit-learn/scikit-learn/issues/10521#issuecomment-363851328 and https://github.com/scikit-learn/scikit-learn/issues/10521#issuecomment-364802471.,Solution Discussion
2149,"(and once we agree on that part, there is still a lot to discuss about the actual implementation in the PR :))",Task Progress
2150,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
2151,I'll cautiously say I'm back ;),Social Conversation
2152,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour
2153,P.S. https://github.com/scikit-learn-contrib/categorical-encoding ?,Task Progress
2154,"In the CODE package, all encoders have a CODE argument, similar to the CODE in the old OneHotEncoder (although it does not accept exactly the same kind of values).",Solution Discussion
2155,See eg http://contrib.scikit-learn.org/categorical-encoding/onehot.html,Solution Discussion
2156,So that is related to the current discussion we are having in https://github.com/scikit-learn/scikit-learn/pull/10523 about deprecating CODE or not.,Potential New Issues and Requests
2157,For the rest I think there are not really  conflicting keywords (they have some others specific to dataframes which we won't add to sklearn at this point).,Solution Discussion
2158,The naming for OneHotEncoder and OrdinalEncoder at least is consistent with the CODE package.,Solution Discussion
2159,Additional Language Support,Expected Behaviour
2160,How can I add another language?,Solution Discussion
2161,Would be glad to lend a hand...,Contribution and Commitment
2162,+1.,Social Conversation
2163,I would gladly lend a hand.,Contribution and Commitment
2164,Thanks everyone.,Social Conversation
2165,"The lexemes.bin data file has been constructed in a way that depends on various intermediate data files --- for instance, I processed an unannotated corpus into a list of word counts, and then smoothed the counts with another script, and then consumed the smoothed probabilities with the current quick-and-dirty make_lexicon.py script, which isn't even in this repository yet.",Solution Discussion
2166,"I also need to set up a program to generate Brown clusters, and configure word2vec to generate word vectors.",Solution Discussion
2167,"Finally, I need to document the process, and document the tokenizer file formats, so that I can describe what you'll actually need to do to add new languages.",Solution Discussion
2168,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
2169,I'll say a little bit about what will be required to add new languages.,Solution Discussion
2170,1.         Select an unannotated corpus.,Solution Discussion
2171,This will probably be Wikipedia --- it's a nice way to streamline things across languages.,Solution Discussion
2172,"Another nice solution would be to run a language identification program over Common Crawl dumps, so that we can get text from wider genres.",Solution Discussion
2173,2.         Select an annotated corpus.,Solution Discussion
2174,This will define the tokenization standards that we have to target.,Solution Discussion
2175,"I'll be licensing the data, so you probably won't have direct access to it --- I'll have to do the actual training.",Solution Discussion
2176,"It will probably be nice to give you a web API, so you can run things.",Solution Discussion
2177,"If the API you call is emailing me ""hey, train this model"", well...",Solution Discussion
2178,That sucks.,Solution Discussion
2179,3.         Define tokenization rules.,Solution Discussion
2180,"This is mostly a list of prefix tokenization, a list of suffix tokenization, and a list of special-cases, which are exact-matched.",Solution Discussion
2181,"The ""How It Works"" page says a little bit more about this, but not enough.",Solution Discussion
2182,4.         Write a lemmatizer and morphological analyser.,Solution Discussion
2183,"If there's a WordNet for the language you're targeting, and it's any good, I would prefer to lemmatize to WordNet sense-keys.",Solution Discussion
2184,The BabelNet project is probably the useful way to go about this.,Solution Discussion
2185,"Having written all this, I'm thinking it might be nice to inter-operate closely with Gensim on this.",Solution Discussion
2186,"Gensim will give us the word2vec implementation, and would be a good way to handle the boot-strapping problem: if getting spaCy to work on a new language initially depends on processing a bunch of unannotated data with spaCy, then things are awkward.",Solution Discussion
2187,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
2188,"When I was still using redshift, I used word2vec and gensim to generate word cluster with CODE.",Solution Discussion
2189,"It was fast, but wasn't quite happy with the result until I found [Percy Liang's] URL  word clustering tool.",Solution Discussion
2190,Took days to generate since I have large corpus.,Solution Discussion
2191,"If you need, I've a lot of resources for Portuguese (word2vec, Stanford NE Extractor, ConLL Floresta SintÃ¡tica, POS Tagger (trigram, bigram, n-gram)...) that I've trained for my project.",Solution Discussion
2192,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
2193,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
2194,+1,Social Conversation
2195,Ideally we could develop the concept of explicit _partial support_ of a new language.,Solution Discussion
2196,"For example, tokenisation really works already for most languages.",Solution Discussion
2197,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
2198,Thanks for the documentation on adding languages!,Social Conversation
2199,See Issue #124,Potential New Issues and Requests
2200,Perhaps the corpora from http://corporafromtheweb.org/ are useful here.,Solution Discussion
2201,"They're large, come in several different languages (Dutch, English, French, German, Spanish, Swedish), and are tokenized pretty well.",Solution Discussion
2202,"They're also POS-tagged and lemmatized, but I don't know whether that's needed here.",Solution Discussion
2203,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
2204,"We're still finishing up the blog post etc, but the model is uploaded and can be used from spaCy 0.100.7.",Task Progress
2205,CODE,Solution Usage
2206,We're still refactoring and working on better processes for adding more languages.,Task Progress
2207,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
2208,"Obviously, there's still a lot to do to support more languages.",Task Progress
2209,And I think the idea of partial language support is important and overdue.,Motivation
2210,But --- progress :),Social Conversation
2211,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
2212,"By the way, anyone knows if there is corpora to train dependency parsers or just PoS-taggers to Dutch?",Solution Discussion
2213,"Yes there are corpora for that: Lassy-Klein, Lassy-Groot, and SoNaR.",Solution Discussion
2214,Probably the best thing is to contact the [TST-centrale] URL .,Solution Discussion
2215,"They are undergoing some changes in management, so they might be slow to respond.",Social Conversation
2216,"For questions about Lassy, you can email [Gertjan van Noord](http://www.let.rug.nl/~vannoord/).",Solution Discussion
2217,For questions about SoNaR you can email [Nelleke Oostdijk] URL .,Solution Discussion
2218,"I trained a POS-tagger on the NLCOW14 corpus, which was automatically tagged.",Solution Discussion
2219,"But if you need something fast, then [here] URL  is the repository.",Solution Discussion
2220,"If you just need a parser, try [Alpino] URL .",Solution Discussion
2221,Thanks for your reply!,Social Conversation
2222,"One more questions, does the license associated to those datasets allows to be incorporated into spaCy or use it to process dutch text not within a research context?",Solution Discussion
2223,"I think if you're a researcher yourself, and you don't contribute to SpaCy for money I think it should be OK.",Solution Discussion
2224,If you're a SpaCy employee it might technically be commercial use and the terms and conditions from the TST-centrale are different: I just checked and the license for Lassy-klein for commercial use costs 2000 euros.,Solution Discussion
2225,Same for SoNar-klein.,Solution Discussion
2226,The larger corpora cost more.,Solution Discussion
2227,"Then again, SpaCy is open-source.",Solution Discussion
2228,So you can always try.,Social Conversation
2229,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment
2230,Else there's also [this free smaller treebank] URL  on his website.,Solution Discussion
2231,That should at least get you started.,Social Conversation
2232,And the people at the university of Groningen would probably be happy to see another parser for Dutch so they can compare Alpino to it :),Motivation
2233,Also look around on [Maarten van Gompel] URL 's GitHub [here] URL .,Solution Discussion
2234,"He's worked on memory-based POS tagging for Dutch, among other things.",Solution Discussion
2235,Dank u wel for all the clarifications!,Social Conversation
2236,"You're welcome, but I just realized I forgot to mention http://universaldependencies.org/ which also covers Dutch, and seems to overlap with Lassy.",Solution Discussion
2237,Sorry!,Social Conversation
2238,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
2239,"@geovedi , were you working on Bahasa?",Task Progress
2240,@syllog1sm yes.,Task Progress
2241,it's been awhile tho.,Task Progress
2242,will catch up with the latest commit and regenerate the model.,Task Progress
2243,@geovedi do you have a fork or branch i can check out?,Task Progress
2244,Does anybody plan to add a support for Russian?,Task Progress
2245,Could you please point me to corresponding doc/guide?,Solution Discussion
2246,"I'm also reading pull requests about adding of a German support, do you think the work for adding of Russian support is going to be kind of similar?",Solution Discussion
2247,http://spacy.io/tutorials/add-a-language/,Solution Discussion
2248,is 404'ing,Solution Discussion
2249,http://spacy.io/tutorials/add-a-language/,Solution Discussion
2250,is not working.,Solution Discussion
2251,It seems page is not available (404 Error).,Solution Discussion
2252,P.S: the URL is not working.,Solution Discussion
2253,Thanks,Social Conversation
2254,https://spacy.io/docs/usage/adding-languages,Solution Discussion
2255,"@kaustubhn Sounds great â for more info on how to add languages, see the new link posted above.",Solution Discussion
2256,Hi @davidsbatista.,Social Conversation
2257,Do you have some code to train a model in portuguese?,Solution Discussion
2258,Train what exactly?,Solution Discussion
2259,"For PoS and syntactic parsing there is public available data, for named-entity recognition, is not so easy, there is no public available dataset",Solution Discussion
2260,The training would be what's mentioned in the docs above.,Solution Discussion
2261,At this point PoS would be enough for me.,Solution Discussion
2262,Were you able to implement this in spaCy?,Task Progress
2263,got it: https://spacy.io/docs/usage/adding-languages,Solution Discussion
2264,:),Social Conversation
2265,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
2266,Please open a new issue for related bugs.,Action on Issue
2267,[Enhancement] Redesigning TensorFlow's input pipelines,Solution Discussion
2268,"[**TL;DR:** We're designing a new input pipeline API for TensorFlow, and we'd like to collect your feature requests on this issue.]",Motivation
2269,We've noticed that one of the biggest challenges in getting started with TensorFlow is how to load your own data into your programs.,Motivation
2270,"While TensorFlow has several methods that can be used to build complex input pipelines (such as [CODE] URL , [CODE] URL , etc.), they were designed for a particular use case (processing a static set of files repeatedly), and the average user experience with these methods is not great.",Motivation
2271,For example:,Motivation
2272,"*         Once you reach the end of a pipeline, it becomes closed and you can never use it again in the same session.",Motivation
2273,*         See #2514 and #4535 for feature requests about handling multiple epochs.,Motivation
2274,*         See #7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.,Motivation
2275,"*         The current pipelines use TensorFlow queues and multiple Python threads, which can lead to poor performance (lock contention in the queues and the Python GIL) and hard-to-understand exceptions (CODE).",Motivation
2276,*         See #6845 for a discussion of input pipeline performance.,Motivation
2277,*         See #7525 and [many more Stack Overflow questions] URL  for an example of the confusing error.,Motivation
2278,"*         The pipelines behave poorly if you forget to call CODE: in fact, they hang indefinitely and deadlock the user program.",Motivation
2279,*         See #7945 and [many Stack Overflow questions] URL  for some examples of users who have been bitten by this problem.,Motivation
2280,We're decided to start from a clean slate and redesign the input pipeline API.,Task Progress
2281,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Solution Discussion
2282,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
2283,*         A CODE represents a collection of data elements.,Solution Discussion
2284,Each element  can be a tuple of one or more tensors (e.g. an image and its label).,Solution Discussion
2285,"We will provide methods for creating datasets from tensors, and deriving them from another dataset (e.g. by slicing its elements, repeating its elements, shuffling its elements, batching its elements, mapping a function over its elements, etc.).",Solution Usage
2286,*         An CODE can be created from a CODE.,Solution Discussion
2287,"There will be explicit operations for initializing an iterator, so that it can be reused after you have processed all of the elements in a dataset.",Solution Usage
2288,"A similar pattern turns up in many different settings, including [Java's Stream API] URL , [Scala's collections] URL  (and hence Spark's RDDs), and [.NET's Language Integrated Query] URL .",Motivation
2289,We're announcing this plan early because we want to collect feedback on what features you&mdash;as TensorFlow users&mdash;would like to see in an input pipeline API.,Motivation
2290,What other pain points have we missed?,Motivation
2291,What features do you miss from other systems?,Motivation
2292,What other suggestions do you have?,Motivation
2293,We look forward to hearing from you!,Social Conversation
2294,"A must-have for one of our use cases is ad-hoc creation of data elements via a callback function (which creates tensors on the fly, e.g. using py_func() or through some other means).",Motivation
2295,"More specifically, we currently have a use case where we employ two queues; an outer one, using a string_input_producer (with shuffling), where each string denotes/points to a ""data set"", and the inner queue is then produced by generating a variable amount of samples from each ""data set"".",Motivation
2296,Which and how many samples are generated differs per epoch (potentially conditional on past training behavior).,Motivation
2297,"Actually, we don't even use the nomenclature of an epoch anymore, since the same data is never seen twice, and above mentioned generation/sampling goes beyond the usual data augmentation.",Motivation
2298,"Long story short: With a slightly out-of-the-ordinary use case, we've been hit by pretty much all of the problems you have mentioned above, and our workarounds have not been pretty.",Motivation
2299,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation
2300,(although they can be modeled by its primitives).,Motivation
2301,I am not sure how well the planned Dataset/Iterator API would support this.,Solution Discussion
2302,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour
2303,But without the bane of GIL -- maybe via easy C++/Eigen hooks and thread control on the native side?,Solution Discussion
2304,"Back and forth, via pybind?",Solution Discussion
2305,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
2306,"@kmhofmann We'll certainly support CODE inside a new-style input pipeline (as well as, in general, compositions of any other TensorFlow ops).",Solution Discussion
2307,"I'd like to understand more about your use case, though.",Motivation
2308,"How frequently do you move from one outer ""data set"" to the next?",Motivation
2309,"Are there any specific operations that you perform at the end of a ""data set"" or can your training loop handle the concatenation of records from different ""data sets""?",Motivation
2310,"(Think CODE in C#, CODE in Java and Scala.)",Solution Usage
2311,"So I think you could implement your logic for sampling from a ""data set"" in one of these CODE functions.",Solution Usage
2312,Let me know if any of this is unclear!,Social Conversation
2313,Oh good timing!,Social Conversation
2314,Now I can stop writing my own (horrible) dataset class.,Motivation
2315,Many of the things said already resonate with my experience.,Motivation
2316,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
2317,"I don't want to have 3 different gan classes: each with their own create graph and fit methods, simply because one dataset doesn't fit in memory, the other is an np.array, and the other is generated on the fly.",Motivation
2318,"The use case that affects me the most is [do n times: train for k iter/epoch, validate model, repeat].",Motivation
2319,There are clear problems with queues like you said.,Motivation
2320,"A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.",Motivation
2321,Some other ideas I jotted down while brainstorming my own class:,Expected Behaviour
2322,-         The dataset class (and not the model) should probably the one to have batch_size passed to it.,Expected Behaviour
2323,"It's awkward to ask for batch_size as a parameter during fitting and during dataset/queue creation, and ideally the compute graph doesn't have batch_size baked in.",Motivation
2324,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
2325,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour
2326,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
2327,-         Most importantly we need to address the dequeueing overhead.,Expected Behaviour
2328,I've seen dozens and dozens of cases where (in the profiler; iirc MEMCpyWhatever) was really slow.,Motivation
2329,This was mostly an issue where the GPU would get the data from the CPU.,Motivation
2330,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
2331,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
2332,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
2333,Good point.,Social Conversation
2334,"One thing is that currently the queue operations are ""baked in"" the computation graph, so it's hard to modify anything on the go.",Solution Discussion
2335,A higher abstraction can make it much easier without considering using control flows or other hacks.,Solution Discussion
2336,"For a lot of my use cases, my input data is either 1. not on the file system, or 2. require complex preprocessing unavailable in TensorFlow.",Motivation
2337,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour
2338,"Then a solution I really like to see, is to be able to receive(similar to dequeue) tensors from a different process.",Expected Behaviour
2339,(Like #4836),Expected Behaviour
2340,The benefits are:,Motivation
2341,"1.         Can use whatever tools/languages to produce data from any sources, as long as they're finally sent with certain message protocol.",Motivation
2342,2.         (theoretically) doesn't require an extra python thread in the training process.,Motivation
2343,"3.         If the message protocol supports pub/sub, then (1) multiple training sessions can subcribe and reuse the same input data, which is very useful when trying new models.",Motivation
2344,(2) data can be generated from different machines if the pre-processing is too heavy for a single CPU.,Motivation
2345,These are the features I really missed from a private system I've been using.,Motivation
2346,One disadvantage is that IPC/socket has smaller bandwidth than RAM but usually it's not a bottleneck.,Solution Discussion
2347,"I know this feature may be too far away, but I hope the new design could allow such possible future feature.",Solution Discussion
2348,"@mrry One ""data set"" can be composed of anything between ~500-30,000 dynamically generated samples.",Motivation
2349,"At the moment, we don't perform specific operations at the end of each data set, i.e. everything gets put into the same (large) random shuffle queue, to mix samples between data sets.",Motivation
2350,Please support reading hdf5 file directly.,Expected Behaviour
2351,"Personally, I'm a very big fan of the CODE method of feeding data into the graph.",Motivation
2352,"It is by far the most flexible, makes debugging way easier and makes for much simpler code.",Motivation
2353,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
2354,"Right now, this method starves my GPU all the time, which is a shame because most other DL frameworks (even those based on computational graphs) manage to make this much more performantly.",Motivation
2355,I assume there is more copying/handling going on in the background than would be necessary.,Solution Discussion
2356,I am glad to see this initiative.,Social Conversation
2357,The input pipeline is definitely thesteepest part of the learning curve.,Motivation
2358,I'd like:,Expected Behaviour
2359,"Although, I have not use it yet, I liked what I read in the input pipeline documentation.",Social Conversation
2360,*         More iterators!,Expected Behaviour
2361,They are great.,Motivation
2362,Iterators implementing CODE are great for progress report.,Motivation
2363,*         multiprocessing rather than threading,Expected Behaviour
2364,The CODE class described in the original post already exists in Python: it is a list of tuples.,Motivation
2365,"And what is a ""dataset"", anyway?",Motivation
2366,A collection of train/valid/test data or simply a collection of data?,Motivation
2367,Is it just a file?,Motivation
2368,directory?,Motivation
2369,generator?,Motivation
2370,Are each data item (input/target) couple?,Motivation
2371,Is that always true?,Motivation
2372,Is the dictionary part of the text dataset?,Motivation
2373,The choice of the data container is driven by a lot of constrains depending on its size and the execution environment.,Motivation
2374,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
2375,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
2376,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
2377,"In my experience, it is best defined by CODE and CODE.",Solution Discussion
2378,Here my attempt to translate to small in-memory dataset some of the routines available in the TF's input pipeline for large dataset.,Expected Behaviour
2379,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
2380,*         [cycle_range] URL ,Expected Behaviour
2381,*         [shuffle_iter] URL ,Expected Behaviour
2382,*         [batch_iter] URL ,Expected Behaviour
2383,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
2384,*         [iter_tensors_slice] URL ,Expected Behaviour
2385,*         [iter_shuffle_batch_tensors] URL ,Expected Behaviour
2386,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
2387,+1 to something like feed_dict.,Expected Behaviour
2388,"That's the only way to learn by interacting with external world (training robot arms, Atari games, [Universe] URL  ).",Motivation
2389,It could be made more efficient by avoiding copies.,Solution Discussion
2390,"Like PyTorch, whose Tensors share memory buffers with underlying numpy arrays",Solution Discussion
2391,"I don't know TF as well as others here, so please take my comments with some skepticism:",Social Conversation
2392,"-         With CODE I was able to solve most of my input-related problems, like loading .mat files in a symbolic-ish manner.",Motivation
2393,"The one I'm currently struggling with is the integration of CODE with the ability of picking the source from which the input should come, for having train/val data in the same symbolic variable.",Motivation
2394,#8168,Motivation
2395,"I understand these functions were initially thought for simple use cases, but it would be nice to have more control of the pipeline without the burden of managing _everything_ (e.g. using CODE but being forced to feed queues and manage threads kind of manually).",Motivation
2396,"-         I think CODE-like solutions are not optimal for passing big chunks of data to the train function, like a batch of images, since they're basically a pause in the execution graph to force TF to interact with _python's runtime_.",Solution Discussion
2397,"An in-graph solution sounds better, with pointers to guide the graph execution, like CODE to indicate the input should come from the training pipeline, the model should set batchnorm and dropout (et al) to train mode etc.",Solution Discussion
2398,"This way, TF could better optimize/parallelize the execution, and all solutions would scale.",Solution Discussion
2399,"For example, a CODE receives the number of epochs to be generated but there seems to be no way of knowing the epoch of one sample without counting how many we have already evaluated.",Motivation
2400,right now there are two very divergent paths to getting data into Tensorflow: feed_dict and queues.,Solution Discussion
2401,"queues are wonderful until you don't have a way to manipulate your data natively -- for example, if you want to load a .wav file, chop it into parts, and convert it to a spectrogram.",Solution Discussion
2402,"at that point, you have to write a C++ op (doable, but a context switch + it makes a very inflexible pipeline) or pop back into Python land (slower, but very easy and flexible).",Solution Discussion
2403,it seems like the best compromise between speed and flexibility is to create a TF queue and then make a bunch of Python threads that feed it with data.,Solution Discussion
2404,"this allows you to do flexible data processing in Python (roughly parallelized on the CPU, apart from GIL issues) while maintaining some amount of speed benefit.",Solution Discussion
2405,what if you just formalized that?,Solution Discussion
2406,"the interface would be: push_data, end_of_data (for signaling the end of an epoch), and a dequeue_batch function that feeds the model.",Solution Discussion
2407,"then your code could just load data in Python and stuff it onto the queue in parallel, while the model sits totally separate from all of that.",Solution Discussion
2408,"We should make feed_dict faster (likely by not copying the numpy.arrays like @yaroslavvb mentioned), but that's orthogonal to this change.",Potential New Issues and Requests
2409,"No matter how much we optimize it, feed_dict will never be the fastest way to feed data into a training job.",Potential New Issues and Requests
2410,CODE specifically may not be essential.,Solution Discussion
2411,"To be more precise, we need support for pipelines where learning is done in an online fashion, and training data is generated by a system responding to actions of a TensorFlow network (learning Atari simulator, robotics simulator, robot interacting with real world, etc).",Expected Behaviour
2412,"This is necessary for most of the applications at OpenAI, here's one example -- https://github.com/openai/universe-starter-agent",Motivation
2413,"The fastest option would be to create a TensorFlow op that maintains state, takes actions as input, and generates the training data.",Solution Discussion
2414,Then add a placeholder to specify the action.,Solution Discussion
2415,"My guess is that you're looking for something that can be done completely in Python, though.",Solution Discussion
2416,There may be some mid-point between the two.,Solution Discussion
2417,"I am not sure it this concept has been brought up yet, but I will at least put the problem in my own terms.",Social Conversation
2418,"In dealing with RL problems and the training replay buffer, I couldn't find an easy way to use the Queues to speed up this feeding of samples through the feed_dict.",Motivation
2419,"Also, when randomly creating a sample set, it seemed like the samples were consumed when I wanted them left in the buffer.",Motivation
2420,"What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.",Motivation
2421,"So some concept of ""sample age"" would be nice.",Expected Behaviour
2422,"I am sure using a circular buffer will work to fix to a number of samples, but ""age"" might be of interest as well, maybe passed as part of the tuple, but in the RL case, simply the sequence of the sample being added might cover the age (FIFO).",Solution Discussion
2423,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour
2424,I may not understand the distributed settings that TF data input pipeline API is targeting to solve.,Social Conversation
2425,I can pick up pytorch's dataset API in 5 minutes and it's good enough for all the popular academic datasets.,Motivation
2426,http://pytorch.org/docs/data.html,Motivation
2427,It's great to see new efforts to solve the pain points in TF dataset API.,Social Conversation
2428,Looking forward to a simple/beautiful/flexible API with minimum number of classes/concepts introduced.,Social Conversation
2429,Thanks.,Social Conversation
2430,"@lming Yeah, the first two comments here cover that: by making a Dataset implementation that uses [py_func] URL , it'd be equivalent to the PyTorch implementation.",Solution Discussion
2431,I second @lming's sentiment above.,Social Conversation
2432,Our biggest issue with the current data loading scheme is just that it's very complicated and involves a lot of new concepts.,Motivation
2433,"We don't find it spectacularly difficult to write a multithreaded data loader ourselves in Python, and generally we don't find it overly difficult to ensure that our data loading and preprocessing runs sufficiently quickly that it doesn't actually bottleneck training.",Motivation
2434,"Where we're stuck is that to optimally follow recommendations, we end up in an awkward situation, one of:",Motivation
2435,-         Using CODE and suffering any relevant performance hits,Motivation
2436,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
2437,"-         Reimplementing our data loading and transformation pipeline with TF primitives, perhaps with CODE, but still using the TF API for managing queue runners",Motivation
2438,"The Python threading API isn't perfect, but in general when we're doing mostly non-GIL-taking tasks in NumPy or whatever, the TF queue API seems more of a burden than a help.",Motivation
2439,A couple of concrete use cases that come up for us:,Motivation
2440,-         One of our models is a localization model.,Motivation
2441,"We use scikit-image CODE objects to apply cropping and resizing operations for this model, because those objects let us easily translate our model output back to the original input coordinate space.",Motivation
2442,It seems tricky to square this with a fully tensor-based API.,Motivation
2443,"-         We have data that comes from a large number of imbalanced segments, and in training we use some custom stratified sampling logic to ensure we present examples from each segment evenly.",Motivation
2444,"It's relatively straightforward for us to, in Python, generate a new draw from our original data set for every epoch, but it seems like in the API proposed above, we'd have to figure out how to implement this behavior as an CODE, which seems less straightforward.",Motivation
2445,"We primarily deal with time series data, and prefer to not have to batch preprocess the whole dataset prior to training every unique model input architecture.",Motivation
2446,"In fact, the preprocessed dataset size for one input architecture variant can be easily an order of magnitude larger than the unprocessed file set size.",Motivation
2447,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
2448,"For my use case it seems like CODE could represent a collection of time series, and the CODE would behave like a python iterator/generator and could handle any preprocessing to form batches of examples?",Expected Behaviour
2449,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
2450,Reason: the automatic preevaluation of pending enqueues.,Motivation
2451,"MXNet [IIterator] URL  is a more relevant example than Java's Stream API, Scala's collections (and hence Spark's RDDs), and .NET's Language Integrated Query.",Solution Discussion
2452,"The design enables flexible composition of various components of the input pipeline such as  [ImageRecordIter] URL , [ImageNormalizeIter] URL , [BatchLoader] URL , [PrefetcherIter] URL  and [ImageAugmenter] URL .",Solution Discussion
2453,CODE,Solution Discussion
2454,Caffe [DB] URL  is simpler but still usable.,Solution Discussion
2455,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
2456,Just my 2 cents.,Social Conversation
2457,Happy for this decision.,Social Conversation
2458,I think that a *huge* effort should be placed in tutorials: the hugest difficulty I am having -- and some colleagues with me -- is that the documentation that you can find is quite lousy and not very self-contained.,Motivation
2459,"I would be happy to help, of course.",Contribution and Commitment
2460,Unfortunately the documentation is still lacking further explanations.,Expected Behaviour
2461,I can only find some basic infos in the C++ API docs.,Motivation
2462,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
2463,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
2464,"I think he is right, that extending the documentation and providing better tutorials is highly important.",Motivation
2465,Because otherwise the people will stick with feed_dict inputs until TensorFlow 3.0 and moan about bad performance of TF,Motivation
2466,"I ended up doing some benchmarking for other reasons, and observed comparable performance between CODE and using queues: https://github.com/tensorflow/tensorflow/issues/9322#issuecomment-295775991",Solution Discussion
2467,Feed dict overhead is essentially the cost of doing an extra memcpy (Python->TensorFlow CPU->TensorFlow GPU) vs. using native ops like queues which do (TensorFlow CPU->TensorFlow GPU).,Solution Discussion
2468,"So if this memcpy is small, there should be negligible.",Solution Discussion
2469,"That makes sense, and it's what I was assuming.",Social Conversation
2470,"I think that makes the advice against CODE a bit overblown, though â really the issue seems more like inefficient data feeding that starves the GPUs, rather than the use of CODE itself.",Solution Discussion
2471,@yaroslavvb correct me if I'm wrong but this isn't entirely right.,Social Conversation
2472,Unless you haven't implemented some input pipeline using Pythons Queue library or something similar it will be additionally the time of loading data from disk into memory and eventually preprocess them.,Solution Discussion
2473,"For Images and especially larger batch size, this might take quite a while.",Solution Discussion
2474,Here is where you can really speed things up using TFs input queues because they will load e.g. images into disk ( + preprocess ) on CPU while you are training/evaluating your network on GPU.,Solution Discussion
2475,"When computations are done, you can directly grab the next batch on copy the data on the GPU, without waiting for native Python to load new data into memory.",Solution Discussion
2476,"@kratzert, that's precisely what @taion means by",Social Conversation
2477,"It's hard to do asynchronous preprocessing well, so most users benefit from CODE doing it for them.",Solution Discussion
2478,Is it?,Social Conversation
2479,"By no means I want to defend TFs input queues, but as I read the post of @yaroslavvb he states that the additional time comes (only) from passing memory between native Python and TF ( + GPU).",Solution Discussion
2480,"The only thing I wanted to add is, that if you can't store all your trainings data in memory, also loading memory from disk into memory adds up time to one training cycle.",Solution Discussion
2481,"I can't find any of this statement in the post of @taion, but could be a misunderstanding of my side as I'm not a English native speaker.",Social Conversation
2482,"And I know, that for many cases asynchronous preprocessing is not possible, but for the cases it is (simple training of image classification CNN) TFs input queues help quite a lot.",Solution Discussion
2483,That also applies to CODE.,Solution Discussion
2484,"Data doesn't just appear in the graph without reading it from disk, regardless of whether you do it via Python or TensorFlow's execution engine.",Solution Discussion
2485,"Anyway, I find memapped NumPy arrays via [joblib.cache.Memory] URL  and feed_dict to be quite performant (GPU load over 90% throughout a training session), despite the extra copy.",Solution Discussion
2486,Ah okay so maybe a misunderstanding.,Social Conversation
2487,Thought I made myself clearer.,Social Conversation
2488,I know that data does not appear magically in memory if I use TF.,Solution Discussion
2489,But TF makes it quite easy to place e.g. image loading + preprocessing explicitly on CPU and graph computation on GPU and both is done in parallel.,Solution Discussion
2490,"So while GPU calculates ops on some data, CPU is already loading the next data into memory.",Solution Discussion
2491,"And since this is done in parallel, we are effectively reducing the computational time by the amount of loading data from disk (since this takes usually less time then one forward + backward pass through the networks graph).",Solution Discussion
2492,But yes this only applies for working with CPU + GPU and has no effect if you use CPU only.,Solution Discussion
2493,edit: The maybe only thing I like of TFs input queues is that I the state of the queues (and batch producers) can be observed in Tensorboard.,Solution Discussion
2494,For the rest I fought quite some time to get them running with all the preprocessing I wanted and with queues for testing and validation in the same run.,Solution Discussion
2495,"I would say that aside from the steep learning curve of input pipeline which can be overcome with documentation too, the key missing points are:",Expected Behaviour
2496,"1.         A decent way to make custom preprocessing of the data, whether it be based on queue's or not, the idea of being able to foresee all possible data input needs is doomed.",Motivation
2497,"2.         An easy and established way to change the input pipeline of a graph, after it has been created, because it is the most typical usage pattern.",Motivation
2498,"Current CODE provides such functionality, but it is rather hacky.",Motivation
2499,And documented too (when it comes to CODE).,Motivation
2500,3.         A way to control and monitor the epochs - currently they are rather deeply hidden and unaccessible even simple checks.,Motivation
2501,"I'd support @nicolasdespres for ""no Dataset"" pledge, mainly because all-in-one bundle is not flexible, not future proof and also - not consistent with the TF's paradigm of providing small, stable, well-defined and assemble-able blocks for building custom models.",Motivation
2502,"Having some bundles, predefined ""easy-starter"" wrappers should be welcomed.",Expected Behaviour
2503,I think TF does not really require another attempt to unify the data pre-processing to put it directly *into* the graph.,Solution Discussion
2504,Things get worse if one need custom stuff and on-the-fly generation/modification of data.,Solution Discussion
2505,Typically these modifications are not part of the forward model for a good reason: these operations do not require any backpropagation.,Solution Discussion
2506,"Hence, they should be only loosely coupled.",Solution Discussion
2507,So the ideal input pipeline (everything without backprop) should be quite simple and slim: It should consist of a queue operation which receives data (list of tensors) from **some** source (sockets).,Solution Discussion
2508,#8728 is a good step in this direction with the pros:,Solution Discussion
2509,"-         you can use any library for preprocessing (opencv, nltk, ...)",Solution Discussion
2510,-         prefetching is totally parallel and can be done at any/multiple machine,Solution Discussion
2511,-         the sender-code can be put into any place -- even directly in game-engines or render-engines,Solution Discussion
2512,-         data generation can be done in any programming language (without custom ops),Solution Discussion
2513,"I am not sure, if you really need something else and I do not understand why you really need CODE *in* the graph.",Solution Discussion
2514,"I don't think the proposal here is to get rid of queues entirely, is it?",Solution Discussion
2515,"Dataset-style abstractions are pretty common in this space, and they're quite useful.",Solution Discussion
2516,The existence of a higher-level abstraction doesn't preclude the lower-level API from also existing.,Solution Discussion
2517,"In fact for these kinds of higher-level abstractions, sooner seems better than later â one of the greatest frustrations of reading published TF research code is that the vast majority of codebases use their own idiosyncratic layers library, as opposed to e.g. the ones in CODE or CODE, and these libraries are all different, which makes it more difficult than it should be to share work.",Motivation
2518,I often try to use TensorFlow on very large inputs (potentially >1GB minibatch) with relatively light computation on each minibatch.,Motivation
2519,"These inputs are in a HDF5 file or a Numpy array either on disk or in memory, so I typically feed with CODEfeed_dictCODE, potentially asynchronously into a queue.",Motivation
2520,"When running with multiple GPUs, TensorFlow is not able to even saturate the PCI-e bandwidth to the GPUs because of the memcpy from the feed_dict to the CPU tensor.",Motivation
2521,"As @yaroslavvb mentioned, the CODEfeed_dictCODE memcpy (on a single CPU core?) can be a huge performance bottleneck, and I'd like to see this addressed in any refactor of TensorFlow's input handling.",Motivation
2522,@jhseu You mentioned that you consider removing the CODEfeed_dictCODE copy as orthogonal to this issue.,Potential New Issues and Requests
2523,"Do you know if there's any issue or work being done on removing the copy (at least in some cases, like row-major Numpy arrays with nice strides)?",Potential New Issues and Requests
2524,"@eamartin there have been a number of changes since the beginning of March by @alextp to speed up feed_dict; when the memory is aligned with 16 bytes, I think we share buffers with numpy, so nightly releases may be faster for you.",Potential New Issues and Requests
2525,"The 16 byte alignment issue comes from Eigen, unfortunately, which requires the beginning of the memory addresses to be aligned with 16 bytes.",Potential New Issues and Requests
2526,"I'm not sure why Eigen was not written to handle unaligned first and last ""packets"" so it wouldn't matter.",Potential New Issues and Requests
2527,Would it be possible for numpy to share buffers with tensorflow variableswhen they are returned from a session run?,Potential New Issues and Requests
2528,"I realise this will probably raise all sorts of mutability and stateissues, but these should be avoidable by setting the WRITABLE flag on thereturned numpy arrays to false.",Potential New Issues and Requests
2529,Thanks for the info @vrv (and for the features @alextp ).,Social Conversation
2530,"I did a little looking around, and it looks like https://github.com/tensorflow/tensorflow/commits?author=alextp&since=2017-03-01T06:00:00Z&until=2017-04-01T05:00:00Z are the relevant commits.",Potential New Issues and Requests
2531,"From my checking, these didn't make it into TF 1.1 but hopefully will be in 1.2.",Potential New Issues and Requests
2532,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
2533,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
2534,This concept is inspired by [dask distributed] URL  and other executor frameworks -- I think the flexibility offered by this abstraction is great!,Motivation
2535,"@sjperkins sadly the way our current unit tests are written makes them break if variables are returned without extra copies (because many tests do a = session.run(variable); session.run(update_variable); b = session.run(variable); assertDifferent(a, b) (which fails if they share buffers).",Solution Discussion
2536,I considered making a ConfigProto option to share buffers even when they are not exclusively owned by the C-python bridge but didn't.,Solution Discussion
2537,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
2538,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
2539,I'm giving a shot at migrating to tensorflow for our deep learning models for devices; but the input pipeline is so tightly bound to the rest of the compute graph that its like performing surgery to run inference against it.,Motivation
2540,Example: I trained using TFRecords and input queues; I got my weights/model.,Motivation
2541,I want to perform inference by running my prediction operation; but because the input queue runners etc are part of the graph before that; I am stuck with that mechanism for performing inference.,Motivation
2542,See issue here: http://stackoverflow.com/questions/43708616/tensorflow-inference,Motivation
2543,I like the tf record and queue runner thing now that I'm used to it; the issue is the tight binding to the graph....,Motivation
2544,"This is why tools like tf.estimator.Estimator were developed, to allow foreasier separation of concerns between training and inference and to allowfor swapping of input pipelines.",Solution Usage
2545,Can you use Estimator to write your model?,Solution Usage
2546,Currently I am worried that my training/prediction preprocessing will diverge over time.,Motivation
2547,I would be interested in a pipeline where:,Expected Behaviour
2548,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
2549,"*         There is a clearer distinction between input shapes, for training you usually want batches, but for prediction you often care only about single examples",Motivation
2550,"The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings).",Expected Behaviour
2551,"@mirosval, it seems to me that this might be what CODE is intended for eventually.",Solution Usage
2552,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
2553,"When using CODE, this is very simple, and this is what I'm used to.",Motivation
2554,"I've recently been trying to make the switch from CODE, but this has been (at least in my limited experience) a major difficulty.",Motivation
2555,"The tutorial page [here] URL  mainly just suggests using separate processes, but this can be a pain, especially if I want to do early stopping based on the validation data.",Motivation
2556,"If I could create some sort of input method (Queue, Dataset, whatever) where I can cleanly swap between training and validation inputs, that would be much nicer (again, CODE is great for this, but if it will always be slower, it'd be nice to have a more performant alternative).",Motivation
2557,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
2558,"@kdavis-mozilla that sounds interesting, but the link appears to be dead.",Social Conversation
2559,Is there another reference?,Social Conversation
2560,"@neighthan Sorry, fixed.",Social Conversation
2561,Very promising!,Social Conversation
2562,That is one of my biggest issues with the current API.,Motivation
2563,"That said, looking at SwitchableDataSet, it seems like implementing new kinds of data feeding use cases will be mostly done by implementing use-case specific classes.",Solution Usage
2564,"Will the new programming model also feature an API to, say, implement what the SwitchableDataSet offers and beyond from more generic, lower-level primitives?",Solution Discussion
2565,I'm just wondering about what things users will come up with (w.r.t. data generation and usage) that would otherwise require (specific) additions to the API...,Motivation
2566,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
2567,"Is there any code out there that uses this, even if that code is undocumented?",Solution Usage
2568,I'd like to see an example of it in use.,Solution Usage
2569,I also assume that the dataframes and transforms are intended to be closely integrated with estimators?,Solution Discussion
2570,"At the moment, I don't see how estimators fit (nicely) with the dataframes and transforms.",Solution Discussion
2571,"I see where you have ways to generate feed_fns from dataframes for estimators, but it seems more like an adapter to another approach, instead of part of the pipeline design.",Solution Discussion
2572,I understand this is all very new and under development.,Social Conversation
2573,I really like what I see!,Social Conversation
2574,Keep up the good work.,Social Conversation
2575,"@vonclites That's for interacting with Pandas DataFrame/Series, not the new Dataset construct.",Solution Discussion
2576,@jimfleming It seems to be more general than that.,Solution Discussion
2577,"There are methods to create TensorFlowDataFrames from csv files, dicts, numpy arrays, TFRecords, as well as from pandas.",Solution Discussion
2578,"It follows the nomenclature of pandas, but it also resembles Spark's pipeline, as @mrry mentioned, and has many of the features he described in the original post.",Solution Discussion
2579,I agree that it's fairly generalized and it may be the basis for futurework but this has been available for quite a while and most of the fileshaven't been updated in months.,Solution Discussion
2580,@jimfleming Good point,Social Conversation
2581,First documentation on master under CODE: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data,Task Progress
2582,All this seems pretty amazing !,Social Conversation
2583,Very nice indeed.,Social Conversation
2584,The following iterators would be great:,Expected Behaviour
2585,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
2586,-         [product](https://docs.python.org/2/library/itertools.html#itertools.product),Expected Behaviour
2587,Below is why we need it:,Motivation
2588,"Assume there is a large training data set which is in text format, and we need to convert it into tfrecord format.",Motivation
2589,"Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect!",Motivation
2590,"Then we want to run it faster, we would change the worker count to 20, 30, 40, ...",Motivation
2591,it would be great if we could do this without re-generate the training data.,Motivation
2592,Solution:,Solution Discussion
2593,"First, we need to pass an offset and length together with the filename into Dataset 's constructor.",Solution Discussion
2594,Only filename is not enough.,Solution Discussion
2595,"Second, the file format it self must be seekable(aka. splitable).",Solution Discussion
2596,it should be one of the following:,Solution Discussion
2597,1.         Text format,Solution Discussion
2598,2.         Blocked binary format with paddings.,Solution Discussion
2599,3.         Has an index file.,Solution Discussion
2600,This new API is faster than the old one.,Solution Discussion
2601,"I've integrated this new dataset API into my factoration machine trainer, and it saved me 20% training time.",Solution Discussion
2602,Thanks @mrry,Social Conversation
2603,I feel like the default code for looping over a dataset is a bit ugly with an exception breaking out of a CODE loop:CODE,Solution Usage
2604,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
2605,Like:CODE,Expected Behaviour
2606,If you're using a MonitoredSession and its variants you should still be able to do this: CODE,Solution Usage
2607,"Edit: Sorry, it totally works.",Social Conversation
2608,@jimfleming you're right again ;),Social Conversation
2609,"CODEthe above code prints nothing, just exits after attempting to run past the last batch.",Solution Usage
2610,"However, the following will print ""hit exception"" forever, unless CODE is used. CODE",Solution Usage
2611,Do the [High Performance Benchmarks example] URL  recommendations still apply now that the new [Dataset API] URL  exists?,Solution Discussion
2612,"For instance in the benchmark [RecordInput](https://github.com/tensorflow/tensorflow/blob/e4296aefff97e6edd3d7cee9a09b9dd77da4c034/tensorflow/python/ops/data_flow_ops.py#L2074) is [split into minibatches](https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/preprocessing.py#L356), which I tried to incorporate via #10143 just before I found this.",Solution Discussion
2613,"If those recommendations are all good ones, the datasets API might benefit from the addition of those very same recommendations.",Solution Discussion
2614,Might I suggest updating the benchmarks in accordance with this API and vice versa?,Solution Discussion
2615,"I've had my head down for a while, so there's lots to respond to here:",Social Conversation
2616,*         @sjperkins: Adding CODE and CODE iterators shouldn't be too hard.,Solution Discussion
2617,I'd like to understand your use case a little better.,Motivation
2618,"Do you imagine that most uses will combine exactly two datasets (and hence we might use method chaining to combine them, e.g. CODE, CODE) or will it be more common to combine more datasets (and hence we'd take a similar approach to CODE, e.g. CODE, CODE)?",Motivation
2619,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
2620,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
2621,*         @snnn: Thanks for kicking the tires!,Social Conversation
2622,It's great to hear that the new API brought a speedup for your code...,Solution Discussion
2623,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
2624,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
2625,"I could imagine adding an CODE method internally, which would allow iterators to specialize their behavior in this case (or fall back to using CODE in a loop).",Solution Discussion
2626,"This also seems like it would be important for checkpointing iterators, which might be useful for fault tolerance.",Solution Discussion
2627,"*         @omoindrot: I agree that the CODE construction is pretty ugly, and we should try to find ways to improve it.",Motivation
2628,"The current version is designed to be a drop-in replacement for the queues, which use CODE to signal completion, and various other classes are designed to catch that exception.",Solution Discussion
2629,"Exposing an CODE property would be possible, but it would be tricky to make it work in the way you suggest, because (to avoid an exception being raised) you'd need to guard the training subgraph with a CODE.",Solution Discussion
2630,"Another possibility would be to change the Python API for iterators to use two ops: CODE and CODE (e.g. like the C++ CODE protocol), but that would introduce an additional CODE call, and make it harder to share the iterator between threads.",Solution Discussion
2631,One possibility I've considered is to create a wrapper that turns an CODE-consuming step into a Python iterator.,Solution Discussion
2632,e.g. Some straw-man code: CODE,Solution Discussion
2633,*         @jimfleming and @vonclites: Thanks for looking into the CODE integration.,Social Conversation
2634,"It's great to hear that it ""just works""!",Social Conversation
2635,I think we'll still need to do something better for the more advanced cases where we might want to reinitialize an iterator in the same session.,Solution Discussion
2636,"*         @ahundt: From our initial experiments, the *peak* performance of the benchmark input pipeline is still slightly higher than what you get from using the CODE API.",Solution Discussion
2637,"However, the peak performance is much higher than the throughput of actually using the data to train a model like Inception or ResNet, so you might not notice the difference in regular use.",Solution Discussion
2638,"We're investigating how to close the gap, and it's very likely that we'll incorporate some of the ideas from the benchmark code into the CODE implementation.",Solution Discussion
2639,"In particular, one current limitation of the CODE and CODE implementation is that the entire pipeline runs on a single device, whereas the more explicit code in the benchmarks is able to split the processing across multiple CPU and GPU devices.",Solution Discussion
2640,"For the best performance, it's going to be important to integrate optimizations like the CODE for prefetching data to the GPU before it is needed, and we're working on a way to do that more transparently.",Solution Discussion
2641,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
2642,This is fantastic!,Social Conversation
2643,I'm using it now and loving it.,Social Conversation
2644,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
2645,"I see the reinitializable iterators give us the ability to use the same iterator with multiple datasets but each time you run an init op, it essentially starts over on that dataset.",Solution Usage
2646,I'm currently using the new CODE and CODE apis along with CODE to accomplish this but is there a more direct/natural way in the works?,Solution Usage
2647,Hi @mrry,Social Conversation
2648,Thanks for the workarounds.,Social Conversation
2649,Wanted to let you know I migrated from queues to Dataset and it's been great.,Social Conversation
2650,Definitely going in the right direction.,Social Conversation
2651,There's been a few things that are currently missing and I had to work around:,Motivation
2652,-         Support for SparseTensors.,Expected Behaviour
2653,CODE supports SparseTensor and automatic batching of SparseTensor would make my life a whole lot easier,Motivation
2654,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
2655,This could make things easier too.,Motivation
2656,Keep up the good work!,Social Conversation
2657,@lhlmgr The way i understand that example is that iterator needs to be reinitialized every time you switch between train and validation.,Solution Discussion
2658,"This isn't the end of the world but for large datasets where we are shuffling minibatches, we want a reasonable CODE which means each initialization is quite slow.",Solution Discussion
2659,I find the CODE approach with two separate datasets/iterators to work better/faster in that case.,Solution Discussion
2660,That way we can periodically run through validation data without losing our place int the training set.,Solution Discussion
2661,Maybe here is a good place to refer to my Dataset related questions:,Solution Usage
2662,https://stackoverflow.com/questions/44132579/feed-data-into-a-tf-contrib-data-dataset-like-a-queue,Solution Usage
2663,https://stackoverflow.com/questions/44132307/tf-contrib-data-dataset-repeat-with-shuffle-notice-epoch-end-mixed-epochs,Solution Usage
2664,I really like the new Dataset/Iterator API!,Social Conversation
2665,Here is a feature that would help my use-case:,Motivation
2666,"What I'd like is for CODE and CODE there to output elements in the same order (because they share the CODE step), but with different functions (CODE/CODE) applied.",Expected Behaviour
2667,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
2668,What @drasmuss suggests is very useful for segmentation tasks where both labels and images need to be augmented.,Motivation
2669,"For example the images could very reasonably use bilinear interpolation, but interpolating label values is not okay because a label pixel boundary of 0 and 2 should not be interpolated to the completely different label of 1.",Motivation
2670,"I am only starting to read into the new API, but I want to share two problems that I had with the old Input Queues in concurrence with using MonitoredSession with SessionRunHooks.",Motivation
2671,"We also used two separate queues, one handling input data_files as string names and the other one the resulting input data with preprocessing being done in between those two.",Motivation
2672,We needed to make sure that the enqueue operations fills at least a certain multiple of the batch size into the first queue for our code to run without problems (otherwise the second input queue stalled),Motivation
2673,"Now when I switched from a normal Session to using MonitoredSession and added a logging hook and told it to log the 'accuracy' tensor, it tried in vain to evaluate the first session run call as the hook had added that tensor to the fetch list, but with the queue being still empty there was no way to evaluate accuracy yet.",Motivation
2674,"Problematic was that the program just stopped and waited for some process to begin filling the queue, but there was non, so it just did nothing, but also didn't throw an exception or give any kind of warning, which made understanding what was happening a bit difficult.",Motivation
2675,"Aside from that, we use two different input pipelines for training and validation data that we connect to the network part of our graph alternating through a switch implemented through CODE.",Motivation
2676,1.         Anything that helps me analyze if and where the bottleneck lies in the input pipeline would be great.,Motivation
2677,"For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful.",Expected Behaviour
2678,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
2679,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour
2680,"Something that provides similar functionality as the generator feed function in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/inputs/queues/feeding_functions.py  (but it would be cool if the source of the data could be from an arbitrary source, maybe using a kind of publisher/subscriber model?)",Motivation
2681,Thanks for the hard work.,Social Conversation
2682,I'm digging the new API.,Social Conversation
2683,In the last couple of days I was playing around quite a bit with the new Input API and I think the CODE and CODE classes improve highly the clearness and readability of code (compared to the old input queues).,Solution Usage
2684,Also switching between e.g. training and validation dataset within one session works quite effortless.,Solution Usage
2685,But I have also some questions and suggestions.,Social Conversation
2686,Maybe first a question: Is the CODE class implemented based on queues?,Solution Discussion
2687,Because from the post here it doesn't get clear to me if or if not.,Solution Discussion
2688,In Tensorboard there is no additional information added with the new API about the status of any queue (how many objects are currently queued).,Solution Discussion
2689,"Also observing my CPU/GPU resources/workload I can see, that the GPU workload drops to zero often (I guess in between batches).",Solution Discussion
2690,Then a suggestion:,Solution Discussion
2691,"I think the CODE could be improved, if shuffling is not done only on the _n_ ( = buffer_size) samples in memory, but somehow on the whole list of inputs.",Solution Discussion
2692,For example: I'm storing path to images and labels in a text file.,Solution Discussion
2693,If shuffling is not done already in the text file you can often have thousands of lines after each other of the same class.,Solution Discussion
2694,If I now only work with CODE it can easily happen (depending of the buffer_size) that all elements that get shuffled are anyhow of the same class.,Solution Discussion
2695,The only.,Social Conversation
2696,Maybe some toy example (ignoring labels and only working with image paths) to make my point clearer.,Solution Discussion
2697,For reasons of readability I work with a very small CODE and list of file names.,Solution Discussion
2698,But I guess everyone can imagine the same just with thousands of filenames in the list and a buffer_size e.g. of 5000.,Solution Discussion
2699,CODE,Solution Discussion
2700,This would print something like:CODE,Solution Discussion
2701,"So since there is only a shuffling between the 3 examples in the buffer, the first samples (same for batches) will all have samples only of one class.",Solution Discussion
2702,So unless the shuffling isn't done already in the list of filenames you'll have troubles training any network.,Solution Discussion
2703,"And if the available dataset of images is huge, increasing the buffer_size is often not a solution.",Solution Discussion
2704,"Another problem I see, is that like shuffling currently is implemented, there is no true shuffling of the entire dataset possible.",Solution Discussion
2705,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
2706,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
2707,@mrry  Thanks for the a preview of the new API; I think this is a good starting point!,Social Conversation
2708,"One function that still seems to be missing, but would be essential for one of our primary use cases (see comment above: https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283186552) is a CODEused as inCODE function, where one element of CODE is mapped to one **or more** elements for CODE; i.e. #CODE >= #CODE.",Expected Behaviour
2709,"As far as I understand it, CODE preserves a 1:1 mapping, which is not sufficient for our use case.",Motivation
2710,One concrete example of why this would be useful:,Motivation
2711,Assume CODE is a list of large images (e.g. 8192x8192 each) [with corresponding labels].,Motivation
2712,"Then, CODE is created by (randomly) iterating over each element CODE of CODE, and for each of these elements the function CODE samples a (variable) number of sub-images [and sub-labels] (e.g. 256x256 each) from CODE, taken from various regions of CODE.",Motivation
2713,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
2714,"In another instance, it might return 389 new pairs, etc.",Motivation
2715,The number of elements generated each time is variable and conditional on the properties of element CODE.,Motivation
2716,@kmhofmann I think you can map one example to multiple examples with CODE.,Solution Usage
2717,"Inside your flatmap function, create a new Dataset object with one or multiple examples for every input example.",Solution Usage
2718,"@EdeMeijer That could be -- it's really hard to tell, as the documentation is quite sparse, with no examples.",Solution Usage
2719,(There seem to be two places containing some amount of separate documentation: either on [GitHub] URL  or on [tensorflow.org](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/data/Dataset#flat_map)),Solution Usage
2720,One thing I notice is that the arguments CODE and CODE from CODE are missing in CODE; does that mean no parallel processing is possible?,Solution Usage
2721,Or is this a TODO?,Task Progress
2722,Hard to scope both functionality and feature set...,Solution Usage
2723,I based my suggestion on the one flat_map code example on the github page you linked.,Solution Usage
2724,"There, single string tensors come in (file names) and whole Datasets are emitted in the map function, so that seems pretty clear.",Solution Usage
2725,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
2726,"Ah, thanks, I missed that, as it was in an example about text processing.",Social Conversation
2727,"Still, the function description in the documentation seems a bit sparse, consisting of CODE.",Solution Usage
2728,input_fn has to return features and labels only.,Expected Behaviour
2729,What about extra params which can be used while training progress to customise loss for given input?,Expected Behaviour
2730,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
2731,This would make it easier to coordinate multiple elements of a model that all want to read from the iterator before advancing it one step.,Motivation
2732,"Hi, firstly thanks for this API, Im very keen on using it.",Social Conversation
2733,Primarily I am interested in using it to switch between training and validation datasets in the same process.,Motivation
2734,However I'm confused how one does that in this new paradigm.,Solution Usage
2735,"For instance I see no way to ""get an iterator"" in the middle of a dataset.",Solution Usage
2736,As an example here is a piece of code that demonstrates what I'd like to do.,Solution Usage
2737,"Every few steps in an epoch, I'd like to run a validation op, but the output of this code shows that the iterator never advances ahead of item 0 in either dataset.",Solution Usage
2738,How does one do that?,Solution Usage
2739,"CODE In the above, since we run an init each time to get an iterator pointing to its required dataset, we end up running a training and validation on the first item of each dataset, always.",Solution Usage
2740,How does one modify this to get the updated position of the iterator in each dataset?,Solution Usage
2741,"@nirmalthacker Every time you run an iterator init op, it restarts the iterator.",Solution Usage
2742,Take a look at the documentation here [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data#creating-an-iterator).,Solution Usage
2743,This approach has the limitations i discussed [here](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-303909270).,Solution Discussion
2744,"@jasonkriss , I see - thanks!",Social Conversation
2745,"This is what I have now, and it handles what I wanted.",Solution Usage
2746,Is this what you meant? CODE,Solution Usage
2747,"@nirmalthacker Yep, that's essentially what I meant.",Solution Usage
2748,"Although, at each validation step, I will reinit the validation iterator and run through the full validation dataset.",Solution Usage
2749,But that's certainly the gist of it.,Solution Usage
2750,I'm trying migrating input pipeline from tf.train.string_input_producer & tf.train.shuffle_batch to Dataset APIs.,Solution Usage
2751,"The parameter ""allow_smaller_final_batch"" in tf.train.shuffle_batch(...) is useful when I'd like to assure all batches are evenly divisible by number of gpus.",Solution Usage
2752,"(I'm doing data parallelization on multiple gpus, and the batch_size is multiple of num_gpus).",Solution Usage
2753,Is there any setting for Dataset APIs to drop the final smaller batch if any?,Solution Usage
2754,@winston-li I think you could just use CODE for that.,Solution Usage
2755,"If you know your batch size is for example 32, then something likeCODE",Solution Usage
2756,should do the trick.,Solution Usage
2757,"@ppwwyyxx I believe a custom pipeline could be designed using TF server with distributed runtime, i.e. IPC send/recv ops.",Solution Discussion
2758,It's included in C API so it won't be too hard to port it to other languages.,Solution Discussion
2759,A down side is that you do need package the whole TF runtime wherever you need this pipeline.,Solution Discussion
2760,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
2761,"The design would be similar to the [ExternalShuffleService] URL  in Spark, using an in-memory storage such as LevelDB or LMDB, and a reader client in TF.",Solution Discussion
2762,"If performance is a primary concern then it should be tightly integrated with hardware, i.e. GPU/NVMe/RNIC, etc.",Solution Discussion
2763,@EdeMeijer  Thanks.,Social Conversation
2764,"I thought it should work, but after some experiments, I can't make it work as expected.",Solution Usage
2765,"I followed the guidelines of dataset README.md, with pseudo code like following: def _parse_function(example_proto):features = {""image"": tf.FixedLenFeature((), tf.string, default_value=""""),""label"": tf.FixedLenFeature((), tf.int32, default_value=0)}parsed_features = tf.parse_single_example(example_proto, features)return parsed_features[""image""], parsed_features[""label""] BATCH_SIZE = 256filenames = [""/var/data/file1.tfrecord"", ""/var/data/file2.tfrecord""]dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(_parse_function)dataset = dataset.batch(BATCH_SIZE)dataset = dataset.filter(lambda imgs, lbls: tf.shape(imgs)[0] == BATCH_SIZE)iterator = dataset.make_initializable_iterator()next_element = iterator.get_next()images, labels = next_element # Training cycles for 100 epochs.for _ in range(100):sess.run(iterator.initializer)while True:try:images_r, labels_r = sess.run([images, labels])print(images_r.shape)except tf.errors.OutOfRangeError:break",Solution Usage
2766,"After applied the filter, no data available in training cycles.",Solution Usage
2767,"I found the dataset (after batch, prior to filter) was in this form:",Solution Usage
2768,"(<tf.Tensor 'arg0:0' shape=(?, 43200) dtype=float32>, <tf.Tensor 'arg1:0' shape=(?, 36) dtype=float32>)",Solution Usage
2769,"Looks like the batch dimension is ""?"" (None?), so the predicate always fails...",Solution Usage
2770,or I did something wrong?,Solution Usage
2771,"@winston-li seeing ""?"" as shape is because at that point you're looking at the 'static' shape of the tensor, which isn't always defined (the graph doesn't know in advance how many examples there will be).",Solution Usage
2772,"However, CODE evaluates the dynamic, real-time shape of a tensor, so I thought this should work.",Solution Usage
2773,"However, what I **did** find was that, obviously, we should use Tensorflow ops instead of standard comparisons since the result of CODE is a tensor and not a normal array.",Solution Usage
2774,"My tf version's filter is broken, but if yours works could you try this instead? CODE",Solution Usage
2775,"@EdeMeijer Thank you very much, it works in my case :-)",Social Conversation
2776,It would be nice so see something in this flavor: CODE,Expected Behaviour
2777,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
2778,"I would like to ask again (since there was no reply to my [comment](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-305435143) above: Am I right, that the new input pipeline isn't implemented using Queues?",Solution Discussion
2779,"I did some tests using the new input pipeline to load an preprocess images, but it seems everything is done sequentially and their is only a negligible performance improvement over using e.g. OpenCV to load and preprocess images.",Solution Discussion
2780,"I was hoping the new input pipeline would be build on top of queues, since they provide major performance boosts but make it quite hard to work with (e.g. having seperate input pipelines with queues to switch between training and validation datasets).",Solution Discussion
2781,This is quite easy with the new API but it seems there is no real performance boost.,Solution Discussion
2782,Anybody observed the same or opposite?,Solution Discussion
2783,"@kratzert I, too, have experienced issues with getting GPUs to 100% usage and keeping them there.",Solution Discussion
2784,"The Dataset API, it seems, is implemented less efficiently and though it is a welcome change regarding code clarity and simplicity as well as a more natural way of doing training and validation, it cannot (yet) substitute queues for high data rate usecases, such as computer vision.",Solution Discussion
2785,@kratzert You are right.,Social Conversation
2786,The new input pipeline do not have queues.,Solution Discussion
2787,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
2788,@snnn Yes I know and I do exactly this.,Social Conversation
2789,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
2790,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
2791,But with images this can be hardly done for the entire dataset in memory.,Workarounds
2792,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
2793,"@vvekic Thanks for your reply, so I know it's not only me having performance issues.",Social Conversation
2794,Of course the code clarity and simplicity of working with the new dataset class is a huge step forward and very welcome.,Social Conversation
2795,But it seems that for training computer vision networks queues are still the way to go (unfortunately) as the performance boost is immense.,Solution Discussion
2796,"@kratzert Using queues increases your performance by overlapping data loading latency, and this is independent of what you use to load your data.",Solution Discussion
2797,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
2798,@byronyi What I meant is to receive tensors from non-TF processes.,Solution Discussion
2799,"Because as @PatWie pointed out above, data processing doesn't really need to happen in the graph.",Solution Discussion
2800,@ppwwyyxx do you have any example code for combining queues and the new dataset api?,Solution Usage
2801,Sounds awesome and I will definitely try this out later.,Social Conversation
2802,"@snnn Well I'll look into it, but since my knowledge in C++ isn't so profound we'll see how successfully I'll be.",Social Conversation
2803,"Anyway, I think this could be a feature that more people than I might be interested in and should/could possibly be integrated into master.",Potential New Issues and Requests
2804,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
2805,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
2806,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
2807,I'm doing something like this:CODE,Workarounds
2808,@EdeMeijer That's smart.,Social Conversation
2809,Thank you very much.,Social Conversation
2810,I should have come to this on my own!,Social Conversation
2811,Here is a complete working code snippet for anybody interested: CODE,Workarounds
2812,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
2813,Currently the tutorial says that we can useCODEto get shuffled data.,Solution Usage
2814,The pattern is also used in [CODE](https://github.com/tensorflow/tensorflow/blob/1efd7f171ba30421b5d8369a93526395a721c0d9/tensorflow/contrib/data/python/ops/dataset_ops.py#L595),Solution Usage
2815,However calling CODE before CODE could lead to the shuffle across multiple epochs.,Solution Usage
2816,"For example, the following codeCODEgets 3 CODE before getting a CODE.",Solution Usage
2817,Are there any concerns about calling CODE before CODE?,Solution Usage
2818,"Just want to add something here, I implemented a **multiprocess-based** data feeding pipeline for multi-task learning.",Solution Discussion
2819,It can achieve avg. GPU utilization >90% and quad-core CPU utilization >95%.,Solution Discussion
2820,Less prone to memory leak and particularly good for days-long training.,Solution Discussion
2821,"Not saying it's perfect, but at least works much better than current TF queue API in my case.",Solution Discussion
2822,If anyone interested: https://hanxiao.github.io/2017/07/07/Get-10x-Speedup-in-Tensorflow-Multi-Task-Learning-using-Python-Multiprocessing/,Solution Discussion
2823,That was already done in [TensorPack] URL  for a while now by @ppwwyyxx.,Solution Discussion
2824,There you also get further speedup using ZMQ -- plus it has a nice interface using Python generators.,Solution Discussion
2825,"For me, the way tensorpack handles input data, is the most elegant way.",Solution Discussion
2826,I hope to see something like this in a future TF.,Social Conversation
2827,@PatWie thanks for pointing this out!,Social Conversation
2828,I just quickly checked @ppwwyyxx repo really awesome!,Social Conversation
2829,Thanks again,Social Conversation
2830,It would be great to have GPU resident queues.,Expected Behaviour
2831,@xieqihuiPG See [StagingArea] URL  and [MapStagingArea] URL ,Solution Discussion
2832,Would greatly appreciate:,Expected Behaviour
2833,1.         Efficient random sampling:,Expected Behaviour
2834,CODE,Expected Behaviour
2835,2.         Dynamical changing and resizing methods:,Expected Behaviour
2836,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
2837,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour
2838,4.         Closer integration with HDF5 anyway,Expected Behaviour
2839,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
2840,What about supporting custom ops to create a Dataset?,Expected Behaviour
2841,"For example, let's say I have a Python function which returns a new batch on each call (a generator).",Motivation
2842,I want to wrap this function using CODE and use it to build a CODE.,Motivation
2843,This doesn't seem to be supported?,Motivation
2844,"I currently use this method with CODE ops and it works nicely but I'd like to find a way to do this for evaluation as well (and figured maybe Dataset is a good way to do this with the ""reintializable"" iterator).",Motivation
2845,@mrry This is great work and definitely very useful for creating nice learning APIs on top of TensorFlow.,Social Conversation
2846,"Also, if my description is terribly unclear, please let me know and I'll try to clarify.",Social Conversation
2847,The new input pipelines are great!,Social Conversation
2848,Some workarounds are,Workarounds
2849,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
2850,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
2851,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
2852,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
2853,Looking forward to hear whether we've just not been using the datasets API right.,Solution Usage
2854,I think the queues are nice enough.,Social Conversation
2855,I'd like to see two things improved though:,Expected Behaviour
2856,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour
2857,Maybe a class CODE that takes a tensorflow queue delegate and a python function CODE.,Solution Discussion
2858,CODE returns a (possibly nested) tuple of np.array or lists.,Solution Discussion
2859,The InputQueue starts CODE that calls CODE and puts these on the CODE.,Solution Discussion
2860,The threads are daemons so shuts down when the main process does.,Solution Discussion
2861,"Anyway, that's just my thoughts.",Social Conversation
2862,It's probably a lot harder than this due to the static requirements of tensorflow.,Solution Discussion
2863,Maybe you just have to provide the sizes when you create the CODE.,Solution Discussion
2864,I am using the new api CODE now.,Social Conversation
2865,But still find the problem that how to dynamically feed data to the Dataset.,Solution Usage
2866,There are two similar questions in [here] URL  and [here] URL @albertz.,Solution Usage
2867,"As you can see, the real-world problems are more than just feeding into a series of images or texts.",Motivation
2868,So I would really appreciate if you could let me to feed the data **freely** in terms of **when** and **how**.,Expected Behaviour
2869,I can image two options.,Solution Discussion
2870,One is efficient distributed reading through CODE.,Solution Discussion
2871,"Although it is slow, but with multi-processing, it is just a matter of machine.",Solution Discussion
2872,The other one is to _wrap_ some mature and widely accepted implementation.,Solution Discussion
2873,use staging area you can even hide all preprocessing and input time.,Solution Usage
2874,I'm trying to test the example in the [doc](https://www.tensorflow.org/versions/r1.3/programmers_guide/datasets#preprocessing_data_with_datasetmap),Solution Usage
2875,But seems that this call is passing only 1 argument to the function:,Solution Usage
2876,@eaplatanios one relevant PR for zip/unzip is https://github.com/tensorflow/tensorflow/issues/10837,Solution Discussion
2877,@bhack I haven't been able to make it work with more than one parameter in return from the function given to py_func.,Solution Usage
2878,I'm using python3 and didn't tried with python2.,Solution Usage
2879,Is your problem similar ?,Solution Usage
2880,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
2881,"@bhack Thanks, will try that soon, I was using a workaround which I'm not proud of :-)",Social Conversation
2882,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
2883,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
2884,I'd like to re-raise an earlier performance-related question by @kratzert that seems to have fallen out of focus.,Social Conversation
2885,The performance gain of using the new Dataset API is negligible.,Solution Discussion
2886,"@ppwwyyxx stated that queues and StagingArea can still be used with the Dataset API, but I still haven't seen a working example of this.",Solution Usage
2887,Do we have one?,Solution Usage
2888,"@vvekic, I experimented a bit with queues and the Dataset API after realising in horror that of the 0.8s/step in my inference loop, 0.2s is data fetching (with GPU at 0% utilization), raising to almost 2 seconds if the HDD is being used by something else at the same time.",Solution Usage
2889,My pipeline looks as follows: CODE,Solution Usage
2890,"I still have to run this on a big dataset and check if there's any performance improvement, but at least it seems to execute correctly.",Solution Usage
2891,"The catch is, I couldn't find a way to iterate over the data more than once (which luckily enough is not my use-case), because the only iterator that won't raise an error when the CODEs spawn the threads is the CODE.",Solution Usage
2892,"I don't know if I'm right here, but I have a question about the dataset API.",Social Conversation
2893,"My dataset contains one column with sequences and one with sequence length which i want treat different, because i want to pad the sequences.",Solution Usage
2894,Is it possible to address a single column in the dataset so that it is treated different from the other column?,Solution Usage
2895,E.g.: CODE,Solution Usage
2896,"Edit: After writing this, i found it out: CODE",Solution Usage
2897,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
2898,In response to a few recent questions:,Solution Usage
2899,"*         @GPhilo ([link](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-325698349)) and @kratzert ([link](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308845375)): The Dataset API includes methods for prefetching, so it shouldn't be necessary to add a queue here, and you can retain the other advantages of Datasets (like reinitialization etc.).",Solution Usage
2900,"Passing CODE to the CODE call, and following that with CODE will run your CODE function in parallel and should decently increase the performance.",Solution Usage
2901,CODE,Solution Usage
2902,(You can try it by downloading the current nightly build.),Solution Usage
2903,"In reponse to @kratzert's [specific question](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308845375) about the implementation, the CODE and CODE classes don't use TensorFlow's previous producer/consumer queues (such as CODE or CODE), but they do include simpler (and more efficient) implementations of the core ideas.",Solution Discussion
2904,"For example, CODE will start a background thread to populate a ordered buffer that *acts like* a CODE, so that downstream pipeline stages need not block.",Solution Discussion
2905,"However, the [CODE implementation] URL  is much simpler, because it doesn't need to support as many different concurrent operations as a CODE.",Solution Discussion
2906,I answered @albertz's Stack Overflow question about doing this [here] URL .,Solution Usage
2907,"I think this will also work for @rasmusbergpalm's [request](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-322407451), because you can create concurrent generators, and for @tillahoffmann's [request](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-321976369) and @sirfz's [request](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-321091444) as well.",Solution Discussion
2908,"This API is very new though, so if you have any feedback, please let us know!",Social Conversation
2909,The programmers' guide has [more details](https://www.tensorflow.org/programmers_guide/datasets#creating_an_iterator) about how to use this feature.,Solution Usage
2910,"*         @guillaumekln ([link](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308789560)) If you want to batch sequences with different lengths, you can use the CODE transformation.",Solution Usage
2911,Have a look at [how this is used in the NMT model code](https://github.com/tensorflow/nmt/blob/04c8c04a8b4e805f3d0a9c42b4d17c85f1324c55/nmt/utils/iterator_utils.py#L194) for an example.,Solution Usage
2912,Thanks again to all of you for your continued interest in this part of TensorFlow!,Social Conversation
2913,Debian test failures (was test_preserve_trustworthiness_approximately fails on 32bit: AssertionError: 0.89166666666666661 not greater than 0.9),Observed Bug Behaviour
2914,building 0.19b2 on debian/ubuntus ...,Observed Bug Behaviour
2915,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
2916,in both cases python-numpy is CODE (i.e. 1.12.1 numpy) and passed ok with numpy 1.8.2 in Debian jessie.,Observed Bug Behaviour
2917,ping @ogrisel?,Contribution and Commitment
2918,"Interesting, it's a only on a combo of numpy 1.12.1 and 32 bit python...",Observed Bug Behaviour
2919,Those tests pass with 32 bit python and numpy 1.13.1 on our wheel building travis:,Bug Reproduction
2920,https://travis-ci.org/MacPython/scikit-learn-wheels,Bug Reproduction
2921,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
2922,@ogrisel I will give it a try :),Contribution and Commitment
2923,@yarikoptic I am unable to reproduce the failure on 32bit debian CODE on docker.,Bug Reproduction
2924,I tried installing python and scikit dependency using CODE and the test passed for both CODE and CODE.,Bug Reproduction
2925,Do you have a specific configuration that could explain the difference?,Bug Reproduction
2926,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction
2927,Which repo did you use to produce this failure?,Bug Reproduction
2928,"@ogrisel I installed the CODE package, which uses version 1.12.1 and used branch CODE for CODE.",Bug Reproduction
2929,EDIT: I used this docker image: CODE,Bug Reproduction
2930,Indeed I was using an older image (jessie).,Bug Reproduction
2931,I confirm I cannot reproduce the issue on stretch with the following 32 bit image: CODE.,Bug Reproduction
2932,"@yarikoptic, we would like to release.",Task Progress
2933,"We need a way to reproduce the error, or we will need to skip the tests / lower the condition on certain architectures.",Investigation and Exploration
2934,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress
2935,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
2936,Right.,Social Conversation
2937,I see in the logs there an alarming number of fails for a final release :(((,Potential New Issues and Requests
2938,And none of them are about CODE CODE,Potential New Issues and Requests
2939,The last is the most confusing to me tbh.,Social Conversation
2940,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
2941,I guess it is not fully deterministic...,Investigation and Exploration
2942,"will try to reproduce now ""locally""",Bug Reproduction
2943,and do we need to fix the other test failures for scikit-learn 0.19 to shipwith Debian?,Task Progress
2944,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
2945,It's a result of CODE being the same as CODE on a machine with 1 core.,Potential New Issues and Requests
2946,"@rth, do you mind looking into the CODE failure above?",Potential New Issues and Requests
2947,"@yarikoptic On this link I see ""No entry in i386 database, check Packages-arch-specific"" (with ""Suite: experimental"").",Bug Reproduction
2948,Is there another way of getting this i386 build for debian?,Bug Reproduction
2949,or did I miss something?,Bug Reproduction
2950,Thanks.,Social Conversation
2951,"yeah, i clicked the logs column after failing to work it out",Bug Reproduction
2952,Thank you very much for looking into those!,Social Conversation
2953,FWIW -- locally I had only the test_multi_output_classification_partial_fit_parallelism to popup and indeed it was due to inability to do multiprocessing in my case (absent bound to /dev/shm I guess):CODE,Potential New Issues and Requests
2954,it passes just fine when I have /dev/shm mounted and joblib does not complaint.,Potential New Issues and Requests
2955,well -- for unstable Debian -- no.,Task Progress
2956,"But if we want to have it propagate into testing and thus become a part of the next Debian stable release (Whenever that would be) -- yes, should get addressed one way (fixed) or another (disabled)",Task Progress
2957,re original CODE,Bug Reproduction
2958,-         specific to older versions of something (yet to figure out since numpy as nscipy are the same) since is not reproducible on current debian sid but reproducible on testing (from few days back) and other older releases.,Bug Reproduction
2959,before I spend more time -- is there specific meaning for the threshold to be 0.9?,Investigation and Exploration
2960,may be it could just be relaxed a little? ;),Investigation and Exploration
2961,"btw these are the values I see for t, init, methodCODE",Investigation and Exploration
2962,i think .9 is somewhat arbitrary but we'd like to be sure that thevariation isn't pointing to something more sinister,Investigation and Exploration
2963,@jnothman how could we discover? ;),Investigation and Exploration
2964,By pinpointing where this and other machines diverge in their calculation...,Investigation and Exploration
2965,Not that that's easy to do without at least a VM of the target machine.,Investigation and Exploration
2966,"@rth could the CODE failure be because of floating point error (i.e. a small number was in Xt.data instead of 0, and so was not removed)?",Potential New Issues and Requests
2967,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests
2968,The test is failing where the importances in a model are being asserted identical to the importance in a similar model trained with sample_weight=3*orig_weights.,Potential New Issues and Requests
2969,Any ideas how to fix here?,Potential New Issues and Requests
2970,@jnothman So far I am not able to reproduce the CODE failure above.,Potential New Issues and Requests
2971,"Tried to build scikit-learn 0.19.2 it in a Debian sid/unstable i386 VM, were scipy and numpy 1.2.1 were installed with apt-get.",Potential New Issues and Requests
2972,I consistently get the failure about CODE (that was resolved since as far as I understand) but not the one about hashing.,Potential New Issues and Requests
2973,I don't think it's due to floating point error.,Potential New Issues and Requests
2974,"So the test fails on [this line](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/tests/test_feature_hasher.py#L122), where the expected values are CODE and  CODE (and I get those in the 32bit VM as well).",Potential New Issues and Requests
2975,This test assumes that the hash value of the tested tokens always produces the same results (in which case two of those produce a collision).,Potential New Issues and Requests
2976,"And it looks like mumurhash3 [doesn't actually produce the same results in 64bit and 32bit](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/src/MurmurHash3.cpp#L5), which would explain why this test fail.",Potential New Issues and Requests
2977,This doesn't explain why I can't reproduce it though.,Potential New Issues and Requests
2978,"Since this basically tests that in CODE we can disable the CODE functionality (enabled by default) and it doesn't validate any new functionality, it might be OK to skip it on failure on 32 bit?",Potential New Issues and Requests
2979,What do you think?,Potential New Issues and Requests
2980,Ha!,Social Conversation
2981,I had no idea it worked differently on 64-bit and 32-bit...,Potential New Issues and Requests
2982,strangechoice of hash function :\,Social Conversation
2983,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests
2984,Not quite satisfying as we don'tunderstand what's going on...,Social Conversation
2985,Is this testing a collision where the sign alternates and hence the valuelands up at 0?,Potential New Issues and Requests
2986,Or just testing that values are stored in the same spot dueto collision?,Potential New Issues and Requests
2987,The former I think.,Potential New Issues and Requests
2988,"Despite that comment in murmurhash3, I'm not sure the hash value is actually platform dependent: after all this test passes on Appveyor 32bit and 64bit (and it works fine for me on i386) .",Potential New Issues and Requests
2989,But it does seem like a plausible suspect.,Potential New Issues and Requests
2990,"We could try to make this test more robust, by just taking a large number of tokens N, hashing them with a hash table size = 1 (or any small number), and checking that with CODE the sum of hashed values is equal to CODE, and that it's strictly lower than CODE if  CODE (since some +1 / -1 are bound to cancel out if N is large enough).",Potential New Issues and Requests
2991,That would be less dependent on the actual hashing implementation...,Potential New Issues and Requests
2992,"Still, for a Debian release of 0.19.0 I'm not sure how this could work: can you apply some patches on the original .tar.gz to skip tests/modify code when needed?",Potential New Issues and Requests
2993,we're going to release a bug-fix release in any case.,Potential New Issues and Requests
2994,i had wondered iffinding and data close to 0 would help here.,Potential New Issues and Requests
2995,"Right, I don't think the value of zero matters.",Potential New Issues and Requests
2996,"It could be a +1 - 1 = 0or a +3 - 2 = 1 (instead of 3+2=5) as long the value in the hash bucketis lower than the sum of the absolute value of hashed terms, it issufficient to determine whether CODE is used or not duringthe hash collisions, I think..",Potential New Issues and Requests
2997,"Yes, I think you're right.",Social Conversation
2998,We're not calling eliminate_zeros anywhere.,Potential New Issues and Requests
2999,I can confirm that test_preserve_trustworthiness_approximately also failed on a 64 bit Mac.,Bug Reproduction
3000,Error message: AssertionError: 0.89166666666666661 not greater than 0.9,Bug Reproduction
3001,"2,4 GHz Intel Core i58 GB 1600 MHz DDR3",Bug Reproduction
3002,"Python 3.6.1numpy 1.13.1scikit-learn master branch, last commit hash d6a42354145c92cf88093cbcc70b13f639319c38numpy was installed from pip, so this is with Accelerate.OSX version 10.12.4",Bug Reproduction
3003,"FYI, I can not reproduce on my OSX version with the same numpy version, Accelerate as well.",Bug Reproduction
3004,I also tried on macOS (El Capitan) with Accelerate and could not reproduce either.,Bug Reproduction
3005,We probably need to raise a CODE if CODE.,Potential New Issues and Requests
3006,The n_jobs=1 issue has been fixed.,Potential New Issues and Requests
3007,We appear to have the following issues:,Potential New Issues and Requests
3008,"*         [x] CODE: [mips] URL , [powerpc] URL , [hppa] URL , [ppc64] URL , [s390x] URL , [sparc64] URL  fixed in #9710",Potential New Issues and Requests
3009,"*         [x] CODE [arm64] URL ,  [ppc64] URL , [ppc64el] URL , [s390x] URL .",Potential New Issues and Requests
3010,PR in #9733,Potential New Issues and Requests
3011,*         [x] CODE PR in #9808,Action on Issue
3012,*         [ ] CODE (not listed above): [mips] URL .,Potential New Issues and Requests
3013,PR in ~#9734~ #9830,Potential New Issues and Requests
3014,*         [x] CODE (fixed in #9544),Potential New Issues and Requests
3015,"The original issue with CODE remains the most concerning, IMO.",Social Conversation
3016,"Hm none of the links at CODEtest_preserve_trustworthyness_approximatelyCODE above have failures for that, right?",Investigation and Exploration
3017,Or I'm blind.,Social Conversation
3018,have we seen this before:,Potential New Issues and Requests
3019,from [kfreebsd-amd64] URL ,Potential New Issues and Requests
3020,"@jnothman I just tried, but I'm not able to run e.g. a ppc64 Docker image on my amd64 system.",Potential New Issues and Requests
3021,"With the CODE below I get an error,CODE",Potential New Issues and Requests
3022,at the first CODE suggesting there is [a platform conflict] URL .,Potential New Issues and Requests
3023,Using CODE as the first line this works fine for amd64.,Potential New Issues and Requests
3024,So unless I missed something it doesn't look like this could be reproducible in Docker.,Potential New Issues and Requests
3025,Will need to find a VM image instead...,Potential New Issues and Requests
3026,**Dockerfile**CODEbuilt withCODE,Potential New Issues and Requests
3027,"Actually, the above Docker setup with conda wouldn't have worked anyway for other platforms, it should have been, something along the lines of, I think,CODE",Potential New Issues and Requests
3028,"but this still wouldn't help unless someone has access to non amd64 platforms and is able to run it there, using the [appropriate Docker Debian image](https://github.com/docker-library/official-images#architectures-other-than-amd64) ...",Potential New Issues and Requests
3029,"@rth, okay.",Social Conversation
3030,Thanks for trying.,Social Conversation
3031,"No, I must have sorted these things incorrectly.",Social Conversation
3032,"@yarikoptic, I can't find the CODE failure under 0.19.0-1 logs.",Investigation and Exploration
3033,"@yarikoptic, any suggestion of how we can reproduce these test environments?",Bug Reproduction
3034,@jnothman any ideas about the CODEtest_pairwise_parallelCODE failure?,Potential New Issues and Requests
3035,"test_pairwise_parallel I had missed, but I also suspect it's something we'll find impossible to debug...",Potential New Issues and Requests
3036,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
3037,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests
3038,I'll submit a PR to reduce precision of the test.,Potential New Issues and Requests
3039,@priidukull is your test failure reproducible?,Bug Reproduction
3040,Could you help us debug?,Contribution and Commitment
3041,Which CODE and CODE combination is the first to fail?,Investigation and Exploration
3042,What I've done is to reduce the size of X... with something like:,Investigation and Exploration
3043,And then I debugged through the code on both of my environments and the best I could tell was that the divergence happened in C-code.,Investigation and Exploration
3044,But I could not tell where exactly with full certainty because it is tough to debug.,Investigation and Exploration
3045,CODE,Investigation and Exploration
3046,What do you mean by the divergence?,Investigation and Exploration
3047,What were you comparing it against?,Investigation and Exploration
3048,The different methods and inits produce different trustworthiness scores on all platforms.,Investigation and Exploration
3049,"@priidukull, could you please provide the output of: CODE and of:CODE",Investigation and Exploration
3050,Thanks.,Social Conversation
3051,"For reference, I have:CODEandCODE",Investigation and Exploration
3052,CODE CODE,Investigation and Exploration
3053,So the error is reducing much more slowly...,Investigation and Exploration
3054,"@priidukull, What did you mean by telling that the divergence happened in C code?",Investigation and Exploration
3055,Do you have another system you're comparing against?,Investigation and Exploration
3056,"@tommoral, if we continue to not be able to reproduce this bug, what kind of debugging output do you think would help us understand what's going wrong?",Investigation and Exploration
3057,Or what kind of more low-level unit tests might help us hone in on it?,Investigation and Exploration
3058,I was putting print statements into the code and comparing the values of the variable X during different stages of execution...,Investigation and Exploration
3059,one environment my Mac desktop and another one that I had set up with docker running on my Mac.,Investigation and Exploration
3060,Great.,Social Conversation
3061,It's extremely helpful to have someone reporting the issue who isalso capable and willing to debug it.,Social Conversation
3062,If only I could reproduce it on mymac.,Bug Reproduction
3063,I've wasted lots of time failing to set up an appropriate debianvirtual machine.,Bug Reproduction
3064,Do you recall which C function was responsible for the divergence?,Investigation and Exploration
3065,Is theinput to TSNE._tsne identical on both platforms?,Investigation and Exploration
3066,I've just realised we have a higher level of verbosity available to us.,Investigation and Exploration
3067,Perhaps comparing outputs at verbose=20 will be more informative.,Investigation and Exploration
3068,"Might aswell limit n_iter to 250, as we know divergence precedes that.",Investigation and Exploration
3069,Let's use verbose=100 just to be sure (there are some things reported atverbose=20),Investigation and Exploration
3070,"Ping @tommoral, @ogrisel",Contribution and Commitment
3071,"Unfortunately, that's not the issue here (although it should be fixed):compute_gradient is only ever called with stop=-1.",Potential New Issues and Requests
3072,@priidukull your verbose=20 output would be welcome.,Investigation and Exploration
3073,I'm otherwise at a loss.,Social Conversation
3074,Where can I set verbose=20?,Investigation and Exploration
3075,Sorry,Social Conversation
3076,CODE,Investigation and Exploration
3077,Ran: CODE,Investigation and Exploration
3078,Output: https://gist.github.com/priidukull/1453adb7cf2bca2093b2dd9d6646f64e,Investigation and Exploration
3079,@priidukull thanks for that.,Social Conversation
3080,"But the verbose output you have sent had substantial discrepancy with what it should, and not just in the numbers.",Investigation and Exploration
3081,Are you certain that the library is correctly compiled?,Investigation and Exploration
3082,Do you get this error when running the test on the wheel version of scikit-learn 0.19?,Investigation and Exploration
3083,Or maybe that comment was wrong and I was just confused because your outputisn't complete: the beginning is cut off,Investigation and Exploration
3084,"Uups, I missed that.",Social Conversation
3085,"The output is more than 1Mb in size, so I did not find a pastebin for that.",Investigation and Exploration
3086,Can run the test again.,Investigation and Exploration
3087,How do you suggest that I send the output to you?,Investigation and Exploration
3088,"you can email my personal address for the, thanks",Investigation and Exploration
3089,or zip it,Investigation and Exploration
3090,[output.txt.zip] URL ,Investigation and Exploration
3091,Test code: CODE,Investigation and Exploration
3092,@priidukull Thanks for the log.,Social Conversation
3093,"I tried to read it but there is only the logs after iteration 200 (""QuadTree"" is way too verbose and I think we lose the beginning as the log growth too big).",Investigation and Exploration
3094,Could you please check it out and re-run the same code?,Investigation and Exploration
3095,It prints the squared norm of the gradient and the error at each iteration so we can see which part of the code is diverging.,Investigation and Exploration
3096,Here is the output for the first 100 iterations (it is still too big for the gist)[output.text] URL ,Investigation and Exploration
3097,Test code: CODE,Investigation and Exploration
3098,[output2.txt.zip] URL ,Investigation and Exploration
3099,Thanks again.,Social Conversation
3100,"Still all we can compare by is error, and not, say, gradients:",Investigation and Exploration
3101,The first 20:CODE,Investigation and Exploration
3102,"We see that the first error is a small numerical imprecision at line 5, but that this quite quickly blows out.",Investigation and Exploration
3103,"I'm not sure that this is quite sufficient to say that there is nothing fundamentally broken in the implementation (e.g. accessing randomly initialised memory), but that:",Investigation and Exploration
3104,"*         it is more susceptible to numerical imprecision than we would like, but perhaps we should (seek contributions that) investigate stability improvements",Investigation and Exploration
3105,*         the test is brittle and already provides only weak assurances in asserting t > 0.9,Investigation and Exploration
3106,"*         given this, we can probably get away with lowering the threshold, with a comment referencing this issue",Solution Discussion
3107,"However, we may also be able to improve stability by choosing a better random data production approach; this random seed produces data where the following are the smallest differences between any pairwise distances in X: CODE",Solution Discussion
3108,"That's very small differences for float32 data, and a large range in exponent from min to max.",Investigation and Exploration
3109,Is there a reason this test needs to use randn?,Investigation and Exploration
3110,Can it have a higher variance?,Solution Discussion
3111,"Multiplying X by 1000 will mean at least the pairwise distances are much more distinguished in a float32, which I *think* may help.",Solution Discussion
3112,So I guess that's a question to @priidukull too.,Solution Discussion
3113,Does the following CODE easily pass for you?,Solution Discussion
3114,CODE,Solution Discussion
3115,I think @albertcthomas's [fix] URL  in #9340 is the right fix:,Solution Discussion
3116,-         This test generates training data as 32 bit float,Solution Discussion
3117,-         The Barnes Hut Cython code works on 32 bit float,Solution Discussion
3118,-         The Python validation of the CODE code would therefore upcast 32-bit float data into 64 bit floats before casting down back to 32 bit float to call into the Cython code.,Solution Discussion
3119,Upcasting from 32 bit to 64 bit is platform specific (the new bits are not necessarily set to zero) and can explain the non deterministic behaviour with observed on some platforms / machines.,Solution Discussion
3120,We need to pass 32 bit to 32 bit cython code without upcasting (which also wastes memory for nothing).,Solution Discussion
3121,"Just to be sure we are on the same page, the fix I suggested in #9340 consists in having CODE in a CODE I added in this same PR.",Solution Discussion
3122,The CODE in master already has a CODE (see [here](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L659)) (#9340 is older than the tSNE memory usage fix that was merged in July).,Solution Discussion
3123,Ah then there is something I do not understand.,Social Conversation
3124,Will need to investigate further.,Social Conversation
3125,+1 for trying with larger variance or even a different distribution (e.g. uniform).,Solution Discussion
3126,"Actually, multiplying the data by 100 does not make the algorithm more stable with the PCA init, quite the opposite actually.",Investigation and Exploration
3127,"On the original machine, the exact method + PCA init was triggering the instability according to: https://github.com/scikit-learn/scikit-learn/issues/9393#issuecomment-322214890",Investigation and Exploration
3128,Changing the random seed can have a large impact on the outcome.,Solution Discussion
3129,So maybe the rounding errors can indeed also have a large impact.,Solution Discussion
3130,"By increasing the number of samples to 100 (instead of 50), the trustworthiness gets much better (and therefore much more stable) but the test is significantly slower (couple of seconds on my machine).",Solution Discussion
3131,Ok after playing extensively with different random seeds and platforms (mkl vs openblas PCA for the init) I think that 0.9 is just too strict.,Investigation and Exploration
3132,We could keep the 0.9 threshold and stabilize this test by:,Solution Discussion
3133,-         running TSNE on larger datasets (in which case the trustworthiness score gets more stable),Solution Discussion
3134,-         running the tests several times with different random seeds and make an assertion on the median score.,Solution Discussion
3135,However both approaches are too expensive in my opinion.,Solution Discussion
3136,While running my test with several hundred seeds on the original 50 samples random dataset I have never seen this score go below 0.87.,Solution Discussion
3137,So I think setting it to 0.85 should fix the issue.,Solution Discussion
3138,I will submit a PR.,Action on Issue
3139,"FWIW, this issue still happens on 32bit debian stretch with 0.19.1CODE",Observed Bug Behaviour
3140,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
3141,My fault.,Social Conversation
3142,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
3143,Feel free to patch for Debian.,Contribution and Commitment
3144,You can cherry-pick 6c99d797 if you wish.,Action on Issue
3145,"there was apparently also a 32bit failure on windows for 0.19.1, but I don't think it was this one.",Potential New Issues and Requests
3146,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
3147,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
3148,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
3149,<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x10210d5c0> with a different variable scope than its first use.,Observed Bug Behaviour
3150,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
3151,Please create a new instance of the cell if you would like it to use a different set of weights.,Observed Bug Behaviour
3152,"If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).",Observed Bug Behaviour
3153,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
3154,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour
3155,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
3156,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
3157,I am getting the same error when trying to run the translate example (even when doing the small self test) which can be found here: https://github.com/tensorflow/models/tree/master/tutorials/rnn/translate,Bug Reproduction
3158,I met the same issue.,Bug Reproduction
3159,"If you are all using compiled version on master branch, I believe that we are the same issue caused by the [recent commit] URL .",Investigation and Exploration
3160,As the commit message says:,Investigation and Exploration
3161,"
REFERENCE",Investigation and Exploration
3162,"
REFERENCE",Investigation and Exploration
3163,"
REFERENCE",Investigation and Exploration
3164,"
REFERENCE",Investigation and Exploration
3165,"From my case, which is running the [ptb tutorial] URL , the solution is just to add a parameter named with CODE like this at line 112:",Solution Discussion
3166,"From my case, which is running the [ptb tutorial] URL , the solution is just to add a parameter named with CODE like this at line 112: def lstm_cell():return tf.contrib.rnn.BasicLSTMCell(size, forget_bias=0.0, state_is_tuple=True, reuse=tf.get_variable_scope().reuse) Then it works.",Solution Discussion
3167,@ebrevdo Could you please take a look at this?,Contribution and Commitment
3168,The issue replicates for me when using the Windows/GPU build 105 on the [Shakespeare RNN Repo] URL .,Bug Reproduction
3169,"When running the code with the Win 1.0.0/GPU Release, there is no issue.",Bug Reproduction
3170,"That repo looks like it's targeted at tf 1.0, not intermediate releases.",Investigation and Exploration
3171,"@tongda , I am using the Release Version of Tensorflow 1.0, working on MacOS in cpu mode.",Bug Reproduction
3172,"I will switch to the master branch to see if it work by adding the ""reuse"" parameter, thanks.",Solution Discussion
3173,"doncat99: if you do, please ensure your code queries the tensorflow versionand raises a flag if the version is lower than the master branch version.",Solution Discussion
3174,you may need to check against: from tensorflow.core import versionsversions.GIT_VERSION,Solution Discussion
3175,@ebrevdo So what would be the suggested changes to the Shakepeare RNN to allow it to work with the intermediate stable release?,Solution Discussion
3176,"Here is the key architectural section of the code, which now fails with build#105:CODE",Solution Discussion
3177,I do not seem to find any documentation regarding a CODE flag?,Solution Discussion
3178,Thanks in advance.,Social Conversation
3179,"Use: multicell = rnn.MultiRNNCell([rnn.DropoutWrapper(rnn.GRUCell(INTERNALSIZE),input_keep_prob=pkeep) for _ in range(NLAYERS)], state_is_tuple=False)  Which creates a separate grucell object for each layer.",Solution Discussion
3180,I don't understand why I am getting this error with the [seq2seq tutorial model] URL :CODE,Bug Reproduction
3181,[Source](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L129) where the cell is created withCODE,Bug Reproduction
3182,@ebrevdo Thanks for getting back to this issue.,Social Conversation
3183,"Unfortunately, the suggested change leaves matters as they are, with the aforementioned error.",Solution Discussion
3184,"Given the above comment regarding the **seq2seq tutorial**, I suspect we are all in the same boat?",Social Conversation
3185,Are you sure it's the exact same error?,Solution Discussion
3186,Please copy and paste it here.,Solution Discussion
3187,"My bad, I just went through the change process to the relevant code again (from scratch) and re-ran it as proposed.",Solution Discussion
3188,The error has indeed been removed and the Old Bard is hallucinating just fine now ð,Solution Discussion
3189,"So, thx, not sure where I went wrong yesterday, but it was clearly on me.",Social Conversation
3190,I met the same problem when using the Release Version of Tensorflow 1.0 and working on MacOS in cpu mode.,Bug Reproduction
3191,"Even if add the ""reuse"" parameterCODE",Solution Discussion
3192,your multicell looks wrong...,Solution Discussion
3193,"you should be using ""cell() for _ inrange(...)""",Solution Discussion
3194,I was trying to run the translate example: python2.7 translate.py --data_dir data/ --train_dir train/ --size=256 --num_layers=2 --steps_per_checkpoint=50,Bug Reproduction
3195,It seems the way to use MultiRNNCell is correct:,Bug Reproduction
3196,cell = tf.contrib.rnn.MultiRNNCell([single_cell() for _ in range(num_layers)]),Bug Reproduction
3197,But I got the same error:,Bug Reproduction
3198,ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7fba0683de90> with a different variable scope than its first use.,Bug Reproduction
3199,"First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.",Bug Reproduction
3200,Please create a new instance of the cell if you would like it to use a different set of weights.,Bug Reproduction
3201,"If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).",Bug Reproduction
3202,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Bug Reproduction
3203,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
3204,@bowu - did you have any luck with this?,Task Progress
3205,"if you haven't tried it yet, reinstall tensorflow from the latest source.",Solution Discussion
3206,"there were some changes to some of the core_rnn files, among a few others.",Solution Discussion
3207,works for me now.,Solution Discussion
3208,"@robmsylvester I reinstall tensorflow from the latest source, still the same error.",Solution Discussion
3209,I was on branch master and the latest commit is CODE.,Solution Discussion
3210,What's the latest commit when you build your repo?,Solution Discussion
3211,"Hi, I am using Tensorflow r1.0 using GPU built using source.",Bug Reproduction
3212,"I am trying to follow the unmodified Seq2Seq translation tutorial, but I'm getting the same error.",Bug Reproduction
3213,"i.e. > ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7f0fb51ebb00> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.....",Bug Reproduction
3214,The relevant portion of the code in my seq2seq_model.py is:CODE,Bug Reproduction
3215,What can I do to solve the problem?,Solution Discussion
3216,"adding ""reuse=tf.get_variable_scope().reuse"" to the call where the GRUCell is created doesn't help.",Solution Discussion
3217,Thanks a ton!,Social Conversation
3218,"@prashantserai - see what happens if you remove the MultiRNNCell line from above, effectively making your network just one layer.",Investigation and Exploration
3219,Does it work then?,Investigation and Exploration
3220,It might be a bug somewhere in MultiRNNCell.,Investigation and Exploration
3221,"I've read about that somewhere recently, probably on stack overflow.",Social Conversation
3222,"If you implement the stacked lstm/gru yourself, you don't get this error, and you can implement the same functionality (actually more, because you're free to do whatever you want with bidirectional architectures, weird residual and skip connections, etc.)",Solution Discussion
3223,@robmsylvester The same error persisted even when I tried with num_layers=1 which should effectively skip that line.,Investigation and Exploration
3224,Any other ideas?,Contribution and Commitment
3225,Thanks for the input.,Social Conversation
3226,Hmmm.,Social Conversation
3227,One thing that stands out to me is in the referenced legacy seq2seq file: CODE,Investigation and Exploration
3228,This line appears to be used because the same architecture is used on both the encoder and decoder side.,Investigation and Exploration
3229,"They make a copy of the cell, then pass the cell argument along to the attention decoder embedding function, then to the attention decoder itself.",Investigation and Exploration
3230,@robmsylvester  shouldn't making changes in the scopes of the cells work?,Investigation and Exploration
3231,It's working for the other two examples as well.,Investigation and Exploration
3232,"In my opinion, this would be a very ugly workaround;",Workarounds
3233,a cleaner solution must exist; maybe we are missing something?,Workarounds
3234,I'll play with it in a few hours and see if I can track something down.,Social Conversation
3235,"In fact, the copy.deepcopy is there because these are legacy functions andwe don't have the resources to maintain/update them.",Investigation and Exploration
3236,Keep in mind it wouldhave to be a backwards compatible change.,Potential New Issues and Requests
3237,@ebrevdo - I'll think about it.,Social Conversation
3238,"I do have a translator that works pretty similar to this one but creates cells through a separate class that allows for inserting bidirectional layers where you want, residuals where you want, merging inputs with concat vs. sum, and a few other things.",Potential New Issues and Requests
3239,I think I could migrate my class over to this tutorial pretty easily by using static RNN's.,Potential New Issues and Requests
3240,I'll let you know.,Social Conversation
3241,@ebrevdo i am running Tensorflow r1.0 (tensorflow-1.0.1-cp36-cp36m-linux_x86_64) on Red Hat and have the latest version of the translation tutorial from Github..,Bug Reproduction
3242,is there a way you know to make this work currently?,Task Progress
3243,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
3244,We should fix that.,Task Progress
3245,@lukaszkaiser can you take a look?,Contribution and Commitment
3246,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress
3247,lukasz; it's hard for me to identify from the various comments which part of the tutorial is faulty in TF 1.0.,Social Conversation
3248,@ebrevdo  It's [this ] URL  tutorial.,Investigation and Exploration
3249,The error is in [this](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L122) cluster of lines.,Investigation and Exploration
3250,"The cells passed here are used for both the backward and forward phase of the legacy seq2seq model, which throws an error because of same cells being used with different scopes.",Investigation and Exploration
3251,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
3252,"That would be great, I currently don't have the cycles to do that myself.",Social Conversation
3253,Thanks!,Social Conversation
3254,"I noticed that the TF 1.0  works fine with the newest version of translation tutorial if compiled from the source on branch remotes/origin/r1.0CODEthen build and install TensorFlow, it works fine.",Bug Reproduction
3255,"On branch remotes/origin/r1.1 it has the ""different variable scope"" error.",Bug Reproduction
3256,"@prashantserai Don't exactly know, but what you met seems to be another issue.",Potential New Issues and Requests
3257,@bowu Same error here.,Bug Reproduction
3258,"Mac OX Sierra, TensorFlow 1.1.0-rc1, Python 2.7.10 & Python 3.6.1.",Bug Reproduction
3259,here's a full traceback..,Workarounds
3260,Thank you so much everyone...!!!!!,Social Conversation
3261,_Here's my thoughts at the end of this:_,Solution Discussion
3262,@oxwsds comment **that the tutorial (in it's current form) works without any need for modification when Tensorflow is compiled from the branch remotes/origin/r1.0 was TRUE**.,Solution Discussion
3263,"Although, the sad bit was that the version of Tensorflow I had for which modifications within Tensorflow code were needed, and the version in remotes/origin/r1.0 were both identically labelled.",Solution Discussion
3264,"It is slightly messy to implement, but I could do it, which is saying something :-P",Social Conversation
3265,The error in my last two comments before this was due to my mistake.,Social Conversation
3266,Thanks for the feedback!,Social Conversation
3267,Seems there's something different between the TFon pypi and at that tag?,Investigation and Exploration
3268,"Gunhan, is that possible?",Contribution and Commitment
3269,For information I had this issue while trying to stack LSTM cells:,Bug Reproduction
3270,My orginial code was:CODE,Bug Reproduction
3271,"Then, with the following code, creating the model was ok, but I couldn't share the variable with another model.",Solution Discussion
3272,"(for instance if you create a train_model and a valid_model supposed to share tensors, it will fail)",Solution Discussion
3273,CODE,Solution Discussion
3274,So finally I used CODE to be the function like CODE in [tensorflow/models/tutorials/rnn/ptb/ptb_word_lm.py#L112](https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py#L112).,Solution Discussion
3275,I now have:CODE,Solution Discussion
3276,It is now fully working,Solution Discussion
3277,"trying to get this thing running, which results in the same error: https://gist.github.com/danijar/c7ec9a30052127c7a1ad169eeb83f159#file-blog_tensorflow_sequence_classification-py-L38",Bug Reproduction
3278,@pltrdy 's solution didn't do it for me oddly.,Solution Discussion
3279,I'm getting CODE,Solution Discussion
3280,@aep did you use the function of https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py#L112 I mention at the end of my post (now edited to be more clear),Solution Discussion
3281,cells=[]for _ in range(15):cell = create_lstm_cell(config)cells.append(cell)lsmt_layers = rnn.MultiRNNCell(cells),Solution Discussion
3282,it solved my problem,Solution Discussion
3283,Managed to fix this issue by installing older version of Tensorflow:CODE,Solution Discussion
3284,I was receiving the error when executing the seq2seq tutorial,Bug Reproduction
3285,"In regards to what @ebrevdo said, I think the solution is not to fix the legacy seq2seq code, but to update the tutorial to use the CODE package instead, which is actively maintained.",Solution Discussion
3286,It is quite demoralizing when the first tensorflow program you ever run spits out a bunch of errors.,Social Conversation
3287,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
3288,We're working on a new seq2seq tutorial.,Task Progress
3289,We had hoped to release by end oflast month but are getting delayed.,Task Progress
3290,It will use the new API.,Solution Discussion
3291,@ebrevdo I meet the same error when running the sequence_to_sequence model on the tensorflow1.1 website.,Bug Reproduction
3292,And I have try to use 'reuse' parameter but failed.,Solution Discussion
3293,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
3294,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
3295,@ebrevdo I am as well facing the same issue and unable to progress with seq2seq.,Bug Reproduction
3296,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
3297,Thanks a lot for your help.,Social Conversation
3298,Installing using CODE (Tensorflow 1.0) is working for me (translate tutorial).,Solution Discussion
3299,I have version 1.1.0-rc2.,Bug Reproduction
3300,TF1.2 will solve this problem?,Task Progress
3301,Please help me how to continue training the model.,Solution Usage
3302,TF 1.0 works but doesn't have devicewrapper api for multiple GPUs.,Solution Usage
3303,Having the same problem with tensor flow 1.1.,Bug Reproduction
3304,Still working on a solution,Social Conversation
3305,"I tried several things, at the end I was able to use tensorflow 1.1 but had to make these changes: (based on Tshzzz above) Remove this:CODE And add this:cells=[]for _ in range(NLAYERS):cell = rnn.DropoutWrapper(tf.contrib.rnn.GRUCell(INTERNALSIZE), input_keep_prob=pkeep)cells.append(cell)multicell = rnn.MultiRNNCell(cells, state_is_tuple=False)",Solution Discussion
3306,"@ebrevdo Congratulations, TF 1.2 just got released - was the new tutorial also released somewhere or is it being released anytime soon?",Task Progress
3307,Thanks,Social Conversation
3308,We'll plan to have an announcement when it's released.,Task Progress
3309,Working on it.,Task Progress
3310,"For anyone using tensorflow-gpu==1.1.0  and getting this error, switching to 1.0.0 via pip install tensorflow-gpu==1.0.0 is not going to fix the problem, at least didn't work for me.",Solution Discussion
3311,I ran into this issue on both mac and ubuntu and compiling from source worked both times.,Solution Discussion
3312,So:pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.0-cp34-cp34m-linux_x86_64.whl,Solution Discussion
3313,@ajaanbaahu Still waiting for tf1.2 new seq2seq tutorial.,Social Conversation
3314,It worked for me using CODE.,Solution Discussion
3315,"As the rookie, I raise some of my opinion.",Social Conversation
3316,The following code will make this similar mistake occure:(Piece of my code)CODE,Bug Reproduction
3317,The error dump as the following:CODE,Bug Reproduction
3318,"But after I do the revision, It can work.",Solution Discussion
3319,CODE,Solution Discussion
3320,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
3321,I'm using CODE model with CODE cells.,Bug Reproduction
3322,I had to reverse back to 1.0.1: `pip3 install tensorflow==1.0,Solution Discussion
3323,Anyone have these issues when working with legacy_seq2seq.rnn_decoder()?,Bug Reproduction
3324,"@oxwsds As you said, I change input args cell of tf.contrib.legacy_seq2seq.embedding_attention_seq2seq to two different cell {encoder_cells, decoder_cells}.",Solution Discussion
3325,"Finally, I get seq2seq model worked.",Solution Discussion
3326,"After 73200 setps, I get perplexity 5.54.",Solution Discussion
3327,"Then I run decode part,>> Who is the president of the United States?Qui est le prÃ©sident des Ãtats-Unis ?",Solution Discussion
3328,Problem solved.,Solution Discussion
3329,Thanks.,Social Conversation
3330,So I change the related part in CODE to CODE,Solution Discussion
3331,"@supermeatboy82 , Could you share your code?",Solution Discussion
3332,Upgrading to Tensorflow 1.2.0 and generating the cells in a loop instead of list multiplication fixed this for me.,Solution Discussion
3333,I would like to update everyone that I downgraded the tensorflow to 1.0.0 (tensorflow-GPU) and it is working for me.,Solution Discussion
3334,The models are performing as expected.,Solution Discussion
3335,I assume that the CPU version of 1.0.0 should function as expected?,Solution Discussion
3336,Or?.,Social Conversation
3337,Thanks :),Social Conversation
3338,"Hi guys, I don't know if you're still interested on it, but I found that the problem is related to the operation of copying the cell passed as params to the CODE function.",Investigation and Exploration
3339,This is because the same cell definition is used both for encoder and decoder.,Investigation and Exploration
3340,I think the tutorial is deprecated since it uses a seq2seq model with bucketing in contrast to a dynamic seq2seq.,Investigation and Exploration
3341,"But, I'm pasting a modified function that works.",Solution Discussion
3342,The function is updated in the file CODE.,Solution Discussion
3343,"thanks,",Social Conversation
3344,Fabio,Social Conversation
3345,CODE,Solution Discussion
3346,@fabiofumarola Thank you for the function.,Social Conversation
3347,Looks really helpful.,Social Conversation
3348,I also saw that the tutorial is deprecated.,Investigation and Exploration
3349,I am still waiting for an official tutorial release.,Social Conversation
3350,Looks like you have used the new api.,Solution Discussion
3351,Do you have any code that can be looked up to start coding on the new api?,Solution Discussion
3352,Any help is well appreciated.,Social Conversation
3353,Thank you once again :),Social Conversation
3354,@syw2014 Did you fix your issue?,Task Progress
3355,it says CODEafter using the update that @fabiofumarola posted.,Solution Discussion
3356,Can you guys please help me?,Contribution and Commitment
3357,Yes because the update I have proposed require you to change theembedding_attention_seq2seq Function.,Solution Discussion
3358,If you go to the source file in youtensorflow release you can change the method definition you re self.,Solution Discussion
3359,Yes i did the same thing.,Social Conversation
3360,I changed the function in seq2seq.py file in the tensorflow release.,Solution Discussion
3361,Still i am getting the same error.,Solution Discussion
3362,Is there one more argument to the function?,Solution Discussion
3363,"Yes, now in you code you need to specify to rnn_cells.",Solution Discussion
3364,One for the encoderand another for the decoder.,Solution Discussion
3365,I am totally new to this.,Social Conversation
3366,Maybe this a pretty basic question but could you tell what argument to be passed as the decoder cell in this code?,Solution Discussion
3367,I am trying to develop the seq2seq as shown in the tensorflow tutorial using own dataset.,Solution Discussion
3368,CODE,Solution Discussion
3369,Okay!,Social Conversation
3370,thanks though!,Social Conversation
3371,:),Social Conversation
3372,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
3373,Thank you.,Social Conversation
3374,Amazing work!.,Social Conversation
3375,yeah waiting for the new tutorial...,Social Conversation
3376,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress
3377,"tried to take code in the kernel tests and retrofit the beam search with the legacy seq2seq, but it was challenging...",Solution Discussion
3378,We're hoping for this coming week!,Task Progress
3379,"Hi guys,",Social Conversation
3380,@tshi1983I got the same problem with tensorflow 1.1-gpu for ubuntu.,Bug Reproduction
3381,I upgrade to tf 1.2. It still doesn't work.,Solution Discussion
3382,Then I change the function embedding_attention_seq2seq in filetensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.pyto the one as @fabiofumarola suggested above.,Solution Discussion
3383,Now it starts training.,Solution Discussion
3384,I haven't tested decoding yet.,Solution Discussion
3385,"Move the code on cell definition into seq2seq_f: CODEThen ""python translate.py --data_dir data/ --train_dir checkpoint/ --size=256 --num_layers=2 --steps_per_checkpoint=50"" can work.",Solution Discussion
3386,@huxuanlai it works!,Social Conversation
3387,"At least it's training now, thx!",Social Conversation
3388,@huxuanlai Works for me as well.,Social Conversation
3389,I am receiving the same CODE but with CODE.,Potential New Issues and Requests
3390,I am running tf 1.2.1 (GPU)  on ubuntu 16.04 lts.,Potential New Issues and Requests
3391,This only seems to occur when I have more than 1 bucket.,Potential New Issues and Requests
3392,full traceback:CODE,Potential New Issues and Requests
3393,"@Tshzzz @jtubertthx, your solution worked for me.",Solution Discussion
3394,My tf verstion is 1.1.0.,Bug Reproduction
3395,I changed from:CODEto:CODE,Solution Discussion
3396,I'm facing this error:CODE,Potential New Issues and Requests
3397,The error points to this function in seq2seq_model.py which is line 142 in seq2seq_model.py: CODE,Potential New Issues and Requests
3398,"Anyone who came across with this error and managed  to solve this, please help me correct this issue.",Potential New Issues and Requests
3399,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x11d32cbd0> with a different variable scope than its first use. First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/gru_cell'. Please create a new instance of the cell if you would like it to use a different set of weights. If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]). If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse). In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
3400,"the origin code:from tensorflow.contrib import rnninputs = tf.placeholder(dtype=tf.int32, shape=[None, None], name=""inputs"")keep_prob = tf.placeholder(dtype=tf.float32, name=""keep_prob"")cell = rnn.GRUCell(10)cell = rnn.DropoutWrapper(cell=cell, input_keep_prob=keep_prob)cell = rnn.MultiRNNCell([cell for _ in range(5)], state_is_tuple=True) outs, states = tf.nn.dynamic_rnn(cell=cell, inputs=look_up, dtype=tf.float32)",Bug Reproduction
3401,"solution:inputs = tf.placeholder(dtype=tf.int32, shape=[None, None], name=""inputs"")keep_prob = tf.placeholder(dtype=tf.float32, name=""keep_prob"")cell = rnn.MultiRNNCell([rnn.DropoutWrapper(rnn.GRUCell(10), input_keep_prob=keep_prob) for _ in range(5)] , state_is_tuple=True)",Solution Discussion
3402,Do you have this issue with the tf nightlies?,Investigation and Exploration
3403,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
3404,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x117f7cbd0> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_1/gru_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
3405,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
3406,Please update the label and/or status accordingly.,Action on Issue
3407,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
3408,Please update the label and/or status accordingly.,Action on Issue
3409,The solution is to move to a newer version of TF.,Solution Discussion
3410,This thread has drastically diverged from its original issue.,Action on Issue
3411,Closing.,Action on Issue
3412,If you want instant solution you can try what i tried :,Solution Discussion
3413,CODE,Solution Discussion
3414,"The issue is with tenorflow 1.1 version , it worked for me.",Solution Discussion
3415,For spaCy to work out of the box with [Apache Spark] URL  the language modles need to be pickled so that they can be initialised on the master node and then sent to the workers.,Motivation
3416,"This currently doesn't work with plain pickle, failing as follows: CODE",Motivation
3417,"Apache Spark ships with a package called [cloudpickle] URL  which is meant to support a wider set of Python constructs, but serialisation with cloudpickle also fails resulting in a segmentation fault: CODE",Motivation
3418,"By default Apache Spark uses pickle, but can be told to use cloudpickle instead.",Motivation
3419,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
3420,The above works.,Workarounds
3421,"Nevertheless, I wonder if it would be possible to make the English() object pickleable?",Expected Behaviour
3422,"If not too difficult from your end, having the language models pickleable would provide a better out of box experience for Apache Spark users.",Motivation
3423,I've spent a little time looking into this now.,Social Conversation
3424,The workflow that's a little bit tricky to support is something like this:,Solution Discussion
3425,-         Create an CODE instance,Solution Discussion
3426,"-         Change the state of some binary data, e.g. modify the lexicon",Solution Discussion
3427,"-         Send it to workers, with new state preserved",Solution Discussion
3428,"Now, when I say ""a little bit tricky""...If this is a requirement, we can do it.",Solution Discussion
3429,"It'll mean writing out all the state to binary data strings, shipping ~1gb to each worker, and then loading from the strings.",Solution Discussion
3430,"The patch will touch every class, and it might be fiddly, especially to keep efficiency nice.",Solution Discussion
3431,But there's no real problem.,Solution Discussion
3432,The question is whether this work-flow is really important.,Solution Discussion
3433,"I would've thought that the better way to do things was to divide the documents in the master node, and then send a reference to a function like this: CODE",Solution Discussion
3434,Does PySpark not work this way?,Solution Discussion
3435,Yes the way you suggest is similar to what I am doing now with a lazy loaded CODE object.,Solution Discussion
3436,"I mainly created this issue in case someone else is running into similar problems when trying spaCy on Spark, as the error messages raised by Spark when failing to pickle the language models are not very helpful (workers just crash because of segmentation fault).",Motivation
3437,This issue can be closed from my end.,Action on Issue
3438,Thanks.,Social Conversation
3439,Let's leave it open for now and think about it a bit more.,Action on Issue
3440,"@honnibal When you say ""writing out all the state"", can you clarify what is involved here?",Solution Discussion
3441,Which objects inside of CODE's state are easy to serialize and which ones aren't?,Solution Discussion
3442,Good question.,Social Conversation
3443,A quick summary:,Solution Discussion
3444,"| Class | Instance | Changes if | Frequently changes? | Size | Description || --- | --- | --- | --- | --- | --- || CODE | CODE | Any unseen token is processed | Yes | 9mb | Mapping table of strings to integers. Serialized as list of strings. || CODE | CODE | User writes Lexeme properties | Maybe | 80mb | Pre-computed attributes for every lexical type in the vocabulary. || CODE | CODE | User updates word vectors | Maybe | 200mb to 1gb | Word vectors. || CODE | CODE | User adds to gazetteer | Yes | <1mb | User-custom entity recognition behaviour. || CODE | CODE | Shouldn't, but must check. | Think no? | Small | I think the serializer reads data off the vocab. But need to double check. || CODE | CODE | Training | No | 490mb | Parser's statistical model. Immutable in normal use. || CODE | CODE | Training | No | 38mb | NER statistical model. Immutable in normal use. || CODE | CODE | Training | No | 12mb | POS statistical model. Immutable in normal use. |",Solution Discussion
3445,"Really everything could be serialized, because everything knows how to write itself to disk and load itself back, usually in a binary format.",Solution Discussion
3446,"One super simple way to do the serialization would be to dump to a directory, tar it, send the bits, untar, load.",Solution Discussion
3447,"I'm sure we can do better than that, though, In standard use, the only things likely to change are within CODE.",Solution Discussion
3448,"If nothing is written to the NLP class, then serialization with Pickle is super simple: we can just tell it to load with the arguments originally passed to the constructor.",Solution Discussion
3449,"Just to chime in: Based on my experience with Spark, it sounds like loading English locally at each worker is best.",Solution Discussion
3450,Does this summary of pros/cons sound about right?,Solution Discussion
3451,Pros,Solution Discussion
3452,-         Less communication (so faster),Solution Discussion
3453,"-         If the English object will be used on workers multiple times, it'd be important to cache it to prevent re-loading.",Solution Discussion
3454,-         Simpler to implement,Solution Discussion
3455,-         This seems like the biggest argument---the cost of dev time.,Solution Discussion
3456,"Also, serialization might have to be updated if the English object gets updated.",Solution Discussion
3457,-         Less memory used on driver,Solution Discussion
3458,-         It's much better to do heavy work on workers than on the driver.,Solution Discussion
3459,"If an executor dies, things are often recoverable, but more may be lost when the driver dies.",Solution Discussion
3460,Cons,Solution Discussion
3461,-         Need to ensure configuration/setup of English is identical across workers,Solution Discussion
3462,"-         This was the part I was not sure about: Is there any setup required, or is it sufficient to just load the English object at each worker?",Solution Discussion
3463,"If there is some setup, then it'd be worth discussing what needs to be communicated for each worker to do the same setup.",Solution Discussion
3464,Thanks.,Social Conversation
3465,Okay so.,Social Conversation
3466,"To be clear, the **wrong** way to do this is to batch the texts into jobs yourself, and then map over the jobs, right?",Solution Discussion
3467,"Instead if the task is per text, we should let Spark map over the texts, and it's our/user's job to make that work.",Solution Discussion
3468,It's also wrong to let Spark see the English instance as a shared variable.,Solution Discussion
3469,"It needs to be private to the workers, because we really don't want the workers to transfer it back to the driver.",Solution Discussion
3470,"In terms of the trade-offs, my perspective is that we're happy to take on implementation complexity.",Solution Discussion
3471,The library is very willing to do work so that users don't have to.,Solution Discussion
3472,They key priority is that the library should make the right thing easy.,Solution Discussion
3473,"Whatever our recommended workflow is, it should be the obvious and least-effort thing to do.",Solution Discussion
3474,"But if there's an important trade-off to make, we don't want to have a silent default that just picks an option, and then the user gets a bad result and has to go back and figure out what went wrong.",Solution Discussion
3475,I worry that adding this pickling capability will lead users down the wrong track.,Solution Discussion
3476,"It seems to me that it makes the whole thing transparent, when actually there's a meaningful decision here, that maybe the user needs to make.",Solution Discussion
3477,Masking that decision isn't necessarily a good service to them.,Solution Discussion
3478,"If it's a pure map operation, then it is better to let Spark handle the map, if only because it can then handle distributing the work and providing some fault tolerance.",Solution Discussion
3479,"It's not wrong, but it is not ideal since 1GB is a fairly big object.",Solution Discussion
3480,It'd be nice to design an API which encouraged minimal communication: either (a) load it on the driver and broadcast it (transfer only once) or (b) load it on each worker (once).,Solution Discussion
3481,The API could potentially handle this under the hood.,Solution Discussion
3482,"If you're not worried about development effort, then actually serialization sounds like the best option.",Solution Discussion
3483,But you could hide it from the user.,Solution Discussion
3484,Here's what I'm thinking:,Solution Discussion
3485,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour
3486,"-         Implementation A: Simpler, but requires user to be aware of local vs. distributed operations",Solution Discussion
3487,"-         When the user wants to do a distributed operation, they call CODE on the driver, and English handles the map under the hood.",Solution Discussion
3488,"-         Under the hood, English could broadcast itself (requiring pickling), or just load itself locally on each worker.",Solution Discussion
3489,"-         Implementation B: More complex, but user can be oblivious",Solution Discussion
3490,"-         Within English, make the big objects transient (i.e., specify that via CODE for pickling).",Solution Discussion
3491,"-         Store those big objects in broadcast variables (initialized on the driver in the constructor), which are then read when needed on the workers.",Solution Discussion
3492,"Both of these options require pickling, but B requires somewhat more complex pickling.",Solution Discussion
3493,"After thinking more about it, I'd recommend broadcasting English (unless you think it will grow far beyond 1GB in the future).",Solution Discussion
3494,That will be easier for handling English's settings or parameters.,Solution Discussion
3495,I think it's OK to hide things from the user.,Solution Discussion
3496,"As far as I can tell, the main things the user needs to be aware of are (a) whether any options they set will be used both on the driver and on workers and (b) when a data object is local vs. distributed.",Solution Discussion
3497,"Okay, thanks.",Social Conversation
3498,Can I expect tempfiles and tempdirs to work?,Solution Discussion
3499,Is the file system shared between the driver and all children?,Solution Discussion
3500,Just pushed v0.95.,Task Progress
3501,Everything should now pickle.,Task Progress
3502,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
3503,"Please keep an eye out for other issues, and report them :)",Social Conversation
3504,"It seems like the pickler tries to pickle a Vocab, Tokenizer, Tagger, Parser, and Matcher object.",Solution Discussion
3505,"When it gets to the [Tokenizer](https://github.com/honnibal/spaCy/blob/master/spacy/tokenizer.pyx#L22), it doesn't seem to have a doesn't seem to have a CODE implemented.",Solution Discussion
3506,"I don't see Tokenizer in the above list of ""state objects that need pickling""; do we not expect the pickler to find the Tokenizer object?",Solution Discussion
3507,Thanks in advance for any hints.,Social Conversation
3508,This is odd â I definitely thought I'd done this.,Social Conversation
3509,"I'll figure this out, thanks.",Social Conversation
3510,FWIW: tests/test_pickle.py passes for me as well.,Solution Discussion
3511,There seems to be something different between CODE and CODE that I don't understand.,Solution Discussion
3512,Reopening this.,Action on Issue
3513,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
3514,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
3515,The root of the problem is that a number of spaCy classes carry large binary data structures.,Investigation and Exploration
3516,"Common usage is to load this data and consider it immutable, however you can write to these models, e.g. to change the word vectors, and pickle should not silently dump these changes.",Solution Discussion
3517,On the other hand it's harsh to assume we always need to write out the state.,Solution Discussion
3518,This would mean that users who follow the pattern of keeping the data immutable have to write out ~1gb of data to pickle the models.,Solution Discussion
3519,This makes average usage of Spark etc really problematic.,Solution Discussion
3520,"We could do this implicitly with copy-on-write semantics, but I don't think it's great to invoke some method where it may or may not write out 1gb of data to disk, depending on the entire execution history of the program.",Solution Discussion
3521,"We could have a more explicit version of copy-on-write, where all the classes track whether they've been changed, and then the models should refuse to be pickled if the state is unclean.",Solution Discussion
3522,Users would then explicitly save the state after they change it.,Solution Discussion
3523,"I think this is a recipe for having long-running processes suddenly die, though. Mostly Python is designed around the assumption that things can either be pickled or they can't.",Solution Discussion
3524,"It's surprising to find that your pickle works, sometimes, depending on state, but then your long-running process dies because you didn't meet the assumed invariant.",Solution Discussion
3525,"And then next time you run, you get an error in that other place in your code where the classes get pickled.",Solution Discussion
3526,I've been thinking for a while that context managers are the idiomatic standard for dealing with this problem.,Solution Discussion
3527,"The idea would be that if you want to write to any of this loaded data, you have to open it within a context manager, so that the changes are explicitly scoped, and you explicitly decide whether you want to save the changes or dump them.",Solution Discussion
3528,"Ignoring the naming of everything, this might look like: CODE",Solution Discussion
3529,"Having a bit of experience in spark, using Spacy with spark will always be tricky as the stringstore will evolve differently in all the workers so a string converted to an int will not necessarily be equivalent to the same int on another worker.",Solution Discussion
3530,So any shuffling of Spacy data across nodes will result in strange things.,Solution Discussion
3531,"Knowing this, serializing the English instance is of little interest.",Solution Discussion
3532,"To avoid dependency hell (making sure the same version of spacy and it's data is installed on each node), a much better approach would be to broadcast the library and the data models as broadcast objec (which takes less space and is sent as a torrent file)t, un-serialize them in a temp directory and lazy load them from there.",Solution Discussion
3533,"That's a problem for some usages, yes.",Solution Discussion
3534,"But the tokenizer is over 100x faster than the rest of the library, so you can simply tokenize all the text in a single process, to initialize the CODE before you send out the batches.",Solution Discussion
3535,There will also be use-cases where you only care that the activity on each shard is internally consistent.,Solution Discussion
3536,"For instance, if you want to just recognise entities and store them in textual form, you don't care that the CODE instances can diverge between your shards.",Motivation
3537,We think it's important to support Spark as best we can.,Solution Discussion
3538,We can at least pickle our data correctly :),Social Conversation
3539,"I agree with both things you said, you could indeed tokenize all texts in one process before sending them out, but if you need to use Spark (and I mean need not want to because it's cool), chances are that this would still be blocking as all the data would have to go through a single node.",Solution Discussion
3540,"And for your second use case, I still think that bundling the Spacy data and classes then lazy loading them would be easier than adding serialization to all your classes.",Solution Discussion
3541,"I'm saying that because before playing with Spacy on apache-storm, I painfully implemented a serializable nlp pipeline in scala on Spark.",Solution Discussion
3542,Extract from the [spark 1.6.0 manual] URL  CODE,Solution Discussion
3543,"**edit** Also, Spacy uses compiled C-libraries that need to be installed on all the nodes.",Solution Discussion
3544,So installing Spacy on all the machines and just packaging the data to be lazy-loaded seems the easiest solution to me.,Solution Discussion
3545,[confer] URL ,Solution Discussion
3546,Hmm.,Social Conversation
3547,I do see your argument.,Social Conversation
3548,"With the new improvements in loading time (down to 15s from about 100s), and the addition of multi-threading, I'm not nearly as keen on supporting in-memory pickling as I was before.",Solution Discussion
3549,"I think @aborsu is right: the problem of serializing such that pickle can work is basically the same as the problem of loading from disk, so there's no reason to believe unpickling the classes would be faster than just loading them as new objects.",Solution Discussion
3550,The important thing is to have a workflow for users that want to use spaCy with a map/reduce framework like Spark.,Solution Discussion
3551,I think supporting the pickle protocol is not necessarily the best way to do that.,Solution Discussion
3552,Thoughts?,Solution Discussion
3553,"I also had issues with pickling with [SFrame] URL , which behaves similarly to how Spark has been described to work here.",Motivation
3554,"To avoid pickling and unpickling data that could just be read from disk (on a single machine), I've been using the following CODE proxy object.",Solution Discussion
3555,CODE,Solution Discussion
3556,"I had originally implemented the proxy using thread-local storage, but this works just as well for my purposes.",Solution Discussion
3557,Just my 2Â¢...,Social Conversation
3558,"Hi guys,",Social Conversation
3559,Relative noob here looking for a recommendation.,Social Conversation
3560,"My goal: POS tag the English language Wikipedia dump (approx 23GB, maybe 3B words).",Motivation
3561,Can someone tell me either:,Solution Discussion
3562,"A)         DON'T DO IT, go for something smaller; or",Solution Discussion
3563,B)         A distillation of the above discussion into the current recommended workflow?,Solution Discussion
3564,"Unfortunately, I can't quite follow the conversation.",Social Conversation
3565,P.S. Thanks Matthew for spaCy!,Social Conversation
3566,"I'm using that and following your sense2vec implementation, with a few changes, to attempt the [word clustering that is mentioned on Google Code word2vec page] URL .",Motivation
3567,I was planning on doing that until... I ran out of memory.,Solution Discussion
3568,"I was using the scikit-learn word count module, so YMMV.",Solution Discussion
3569,"They also have a good implementation of word2vec, but it unfortunately the scikit pipeline does not always use iterators and would need quite a bit of memory (>24GB including paging when I tried a _much_ smaller dataset).",Solution Discussion
3570,"I recommend starting with something smaller, such as using only the Wikipedia page titles, to test out your pipeline.",Solution Discussion
3571,Debugging would go more quickly too :+1:,Solution Discussion
3572,"If you are on a Mac, you can enable multithreading per the instructions in #267 .",Solution Discussion
3573,This conversation is about distributing spacy over multiple machines.,Solution Discussion
3574,"The problem is not that it doesn't work, but that the distributed computing frameworks mentioned in this thread pickle and send over the spacy data models.",Solution Discussion
3575,That could amount to several GB of data.,Solution Discussion
3576,Hope this helps!,Social Conversation
3577,Cheers.,Social Conversation
3578,Tagging Wikipedia should be no problem.,Solution Discussion
3579,"I haven't benchmarked the tagger in a while, but I think it should be running at over 100k tokens a second per process, and it doesn't use much memory.",Solution Discussion
3580,On a high compute node you should be done in a couple of hours.,Solution Discussion
3581,"I've run the full pipeline on over ten times that much data, and I don't use Spark --- just simple multiprocessing, on a node with lots of cores.",Solution Discussion
3582,Example script: https://github.com/spacy-io/spaCy/blob/master/examples/parallel_parse.py,Solution Discussion
3583,Thanks both of you.,Social Conversation
3584,I was thinking Spark because of the benchmarking on this [blog post] URL  suggested I'd be at it for about half a year (although I also may have misinterpreted the results).,Solution Discussion
3585,Will continue onwards and let you know about my results when I get them!,Social Conversation
3586,Second what @honnibal said.,Social Conversation
3587,The issues I ran into were outside of spacy in doing the word count.,Solution Discussion
3588,"You could try the [HashingVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer) in sklearn, though I had issues with that too.",Solution Discussion
3589,"Hey @honnibal, before going onto AWS, I wanted to start small.",Solution Discussion
3590,I took your merge_text.py from the sense2vec implementation and trimmed it down.,Solution Discussion
3591,Running it on a pretty small input is taking a while.,Solution Discussion
3592,Can you see something that I'm doing wrong?,Solution Discussion
3593,Updated script and data file attached.,Solution Discussion
3594,"I'm on a 4 core 2011 MacBook Pro with 8GB RAM, so it shouldn't be the hardware.[Archive.zip] URL ",Solution Discussion
3595,Thanks!,Social Conversation
3596,Seems to me that Parallel is doing the pickle thing mentioned in this thread.,Solution Discussion
3597,This means that each worker process will take a while to load all the data models.,Solution Discussion
3598,"On my MacBook Pro, each Python worker process uses between 800MB and 1.5GB.",Solution Discussion
3599,"I have 16GB physical memory and an SSD, so I don't notice paging as much.",Solution Discussion
3600,"Apple didn't make SSD MBP in 2011, so it's probably going to be much slower for you.",Solution Discussion
3601,I stopped your script after spending a few minutes writing this post.,Solution Discussion
3602,The overhead of pickling and unpickling the spacy data models is significant.,Solution Discussion
3603,"As spacy itself is very fast, it would take huge batch sizes to make it worth it to use this multiprocessing model.",Solution Discussion
3604,"Instead, it would be significantly faster to use a single Python process and spacy's CODE multithreading API.",Solution Discussion
3605,"On Linux, this is supported natively.",Solution Discussion
3606,"On Mac, you'll need to do a little more work (#267).",Solution Discussion
3607,"I modified your script to not use Parallel and it ran to completion in seconds, single-threaded.",Solution Discussion
3608,Would a different serialization format help here?,Solution Discussion
3609,Pickle is heavyweight.,Solution Discussion
3610,There are many to choose from.,Solution Discussion
3611,"I maintain the Python port of FlatBuffers, which is a serialization formatoptimized for minimal memory usage.",Solution Discussion
3612,Happy to answer any questions.,Social Conversation
3613,I ran into this issue too.,Bug Reproduction
3614,I'm trying to do some work on the text from Wiki Dump.,Motivation
3615,Using a Spark map function do_work.,Solution Discussion
3616,As suggested here when I move English() inside the function it works but when it's outside it doesn't.,Solution Discussion
3617,Python crashes.,Solution Discussion
3618,But instantiating English() in every function call makes it super slow and practically useless.,Solution Discussion
3619,CODE,Solution Discussion
3620,I really need to write a blog post/tutorial on working with large jobs.,Social Conversation
3621,I think at the moment this is quite confusing.,Social Conversation
3622,"I'm grateful to @mikepb , @aborsu and others for their contributions to the discussion here.",Social Conversation
3623,"In future more of the pipeline will be multi-threaded, so I'd recommend using this construction even if you're just using the tokenizer and tagger, which are currently single-threaded (they're very fast though --- and load much quicker.)",Solution Discussion
3624,"A much better improvement will be gained if you can manage to reuse the same CODE object across more text, i.e. if you can increase the size of your batches of documents.",Solution Discussion
3625,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
3626,"Unfortunately, with spaCy (and probably with lots of other situations), the constants really matter.",Solution Discussion
3627,"Loading the spaCy models takes about as much time as processing 1,000 documents (at ~200 tokens each).",Solution Discussion
3628,This means you have to somehow manually manage the chunk size.,Solution Discussion
3629,You have to somehow help Spark schedule the work in larger increments.,Solution Discussion
3630,"If you have your data already split out into large files, e.g. by month, then it might be enough to have each process work on one month of data.",Solution Discussion
3631,"In this situation, we can make CODE work transparently, which is nice.",Solution Discussion
3632,"But if what you have is a collection of texts, not a collection of larger archives, you have to think about the details a bit more.",Solution Discussion
3633,"My main advice would be to not assume that Spark, Hadoop etc are automatically better than using a single machine and using multiple processes with spaCy's CODE method for multithreading.",Solution Discussion
3634,"In the worst case, if you had a chunk size of 1, you could use a thousand node cluster and have your job complete slower than it would on a Macbook Air.",Solution Discussion
3635,"So, if your process is slow, it might be worth taking a closer look and checking that you're at least doing around 10,000 tokens per thread per second.",Solution Discussion
3636,"If you're doing an order of magnitude less than that, then either the problem is outside of spaCy, or the work isn't being scheduled effectively.",Solution Discussion
3637,Thanks @honnibal for your advice.,Social Conversation
3638,I've been trying to do NLP with Spark with NLTK and Stanford and etc.,Motivation
3639,But their objects are big and not serializable.,Motivation
3640,I really like Spacy's simple and all in one approach.,Motivation
3641,It's close integration with Spark will be a great advantage for many researchers.,Motivation
3642,As you mentioned that would be heaven to see this code just work: CODE,Motivation
3643,So far it looks like using Spacy pipe without Spark is the fastest option to do the job.,Solution Discussion
3644,I will feed Spark with processed data for the rest of the work.,Social Conversation
3645,It might be off topic but @mikepb mentioned with CODE we can see a lot of improvement in speed.,Solution Discussion
3646,But I'm not gaining speed using pipe.,Solution Discussion
3647,I suspect that I have to enable multi-threading using OpenMP.,Solution Discussion
3648,But I couldn't find any instructions to do that on Windows.,Solution Discussion
3649,"Yes, you would need OpenMP to enable multithreading.",Solution Discussion
3650,It's tricky to get right:,Solution Discussion
3651,-         See #267 and #266 for info on using OpenMP on OS X.,Solution Discussion
3652,It's wonderful when it works though!,Social Conversation
3653,I believe Microsoft has implemented OpenMP in Visual Studio.,Solution Discussion
3654,I'm wholly unfamiliar with Windows development...,Social Conversation
3655,"@mikepb Normally, you don't have to do anything special on Windows, it's trickier on OS X because Apple's default clang doesn't support OpenMP, yet. MSVC does, though.",Solution Discussion
3656,@henningpeters I managed to compile and run pipe with OpenMP support.,Solution Discussion
3657,It looks beautiful when it utilizes all CPU cores.,Social Conversation
3658,OpenMP support is by default disabled for MSVC.,Solution Discussion
3659,I added the compiler option to the setup file and committed the changes to the master branch.,Solution Discussion
3660,I'm surprised nobody is using Windows it seems.,Social Conversation
3661,But with that switch enabled next releases will work properly on Windows,Task Progress
3662,@honnibal What you mentioned about some parts of the pipeline multi-threaded made a lot more sense after I managed to use pipe in multi-threaded scenario.,Solution Discussion
3663,But it also seems single-threaded parts of the pipeline take almost the same time as the multi-threaded parts.,Solution Discussion
3664,That would make it a lot faster if those single threads also support multithreaded.,Solution Discussion
3665,I attach my CPU usage here. It's clear the single threads play some role in the time it takes to finish the job.,Solution Discussion
3666,![pipe_performance] URL ,Solution Discussion
3667,Tricky,Social Conversation
3668,:+1:,Social Conversation
3669,"Oh, seems we overlooked msvc's openmp option.",Social Conversation
3670,Thanks,Social Conversation
3671,Thanks @sjjpo2002 for your PR!,Action on Issue
3672,Just merged it.,Action on Issue
3673,It seems the CODE option is not available for some(?) Visual Studio express editions.,Solution Discussion
3674,That means many/most(?) Windows users won't be able to install spaCy anymore from source for free.,Solution Discussion
3675,"There seems to exist a workaround  URL , but it's not something I'd like to put in our getting-started install guide.",Solution Discussion
3676,"Hence, I think we should make OpenMP support on Windows optional for now.",Solution Discussion
3677,Microsoft Visual C++ Compiler for Python is [free ] URL for eveyone and it supports openmp.,Solution Discussion
3678,"Thanks, do you know whether this also works for Python 3.4/3.5?",Solution Discussion
3679,We need to have a solution in place that works as seamless as possible across all environments.,Solution Discussion
3680,I never tried it on Python 3.x. But a quick check for /openmp [here] URL  it is supported on VS 2010 ans 2015. For Python 3.4 using VS 2010 and for 3.5 VS 2015 are [suggested] URL .,Solution Discussion
3681,"But, I agree that it should be tested on all platforms.",Social Conversation
3682,Maybe I do it over the weekend.,Social Conversation
3683,My reading about it so far is that MS only provides support for OpenMP in VS professional editions or higher.,Solution Discussion
3684,Here's the error output from VS 2010 express edition: https://ci.spacy.io/builders/spacy-win64-py34-64-install/builds/98/steps/shell_2/logs/stdio.,Solution Discussion
3685,"It might be possible to make it work as I suggested above, but so far I haven't seen a simple install instruction I would like to keep as default for spaCy all users.",Solution Discussion
3686,I think this is relevant: https://github.com/spacy-io/spaCy/issues/413,Potential New Issues and Requests
3687,Closing this and making #1045 the master issue.,Action on Issue
3688,Work in progress for spaCy v2.0!,Task Progress
3689,"Dears,Is this issue resolved with the release of spacy 2.0.",Task Progress
3690,How can I use spacy in Spark?,Solution Usage
3691,Thanks for your help.,Social Conversation
3692,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
3693,Please open a new issue for related bugs.,Action on Issue
3694,t-SNE fails with array must not contain infs or NaNs (OSX specific),Observed Bug Behaviour
3695,CODE,Observed Bug Behaviour
3696,When trying to run a t-SNE CODE,Observed Bug Behaviour
3697,However CODE,Observed Bug Behaviour
3698,Full Stack Trace: CODE,Observed Bug Behaviour
3699,"Same with ('Scikit-Learn', '0.18.dev0')",Bug Reproduction
3700,Do you mind sharing your data X with me?,Bug Reproduction
3701,"Sure, where and in what format would you like it?",Bug Reproduction
3702,My email is 370846270@qq.com,Bug Reproduction
3703,"As i know, there is a function numpy.save for saving an array to a binary file in .npy format~~",Bug Reproduction
3704,I test your data in ubuntu 14.04 LTS withPython==2.7.6scikit-learn==0.17.1numpy==1.8.2scipy==0.13.3,Bug Reproduction
3705,It is fine and doesn't raise the ValueError.,Bug Reproduction
3706,The test code is:CODE,Bug Reproduction
3707,"Then i upgrade numpy, scipy to 1.11.0, 0.17.0 and test with the same code and it also doesn't raise any error.",Bug Reproduction
3708,Reproduced for 3.5 with anaconda under OS X El Capitan.,Bug Reproduction
3709,CODE,Bug Reproduction
3710,Example run: CODE,Bug Reproduction
3711,"Thanks @ivan-krukov, but I'm failing to replicate in Python 3.3.",Bug Reproduction
3712,Will try 3.5,Bug Reproduction
3713,"This does not apply to CODE (4.4.0-21, Ubuntu 16.04) with the same packages under 3.5.",Bug Reproduction
3714,"I'm on El-Capitan, but I'm failing to get a Python 3.5 installation up and running.",Bug Reproduction
3715,Is there any update on this?,Task Progress
3716,"I have the issue on a dataset of mine, on Anaconda, Py 3.5, sklearn 0.17.1, OSX El Capitan.",Bug Reproduction
3717,I can reproduce the error with the example provided by @ivan-krukov .,Bug Reproduction
3718,Same issue.,Bug Reproduction
3719,Python 2.7.6 on OS X El Capitan on 0.17.,Bug Reproduction
3720,"Tried the same code on Linux using Python 2.7.6 and 0.17, and it works.",Bug Reproduction
3721,Same issue.,Bug Reproduction
3722,OSX El Capitan Python 3.5.1scikit-learn==0.17.1scipy==0.17.1,Bug Reproduction
3723,I have the same problem and would really appreciate a fix (or workaround?),Bug Reproduction
3724,System Version: OS X 10.11.5Python 3.5.1 :: Anaconda 4.0.0 (x86_64)numpy.version.version 1.11.0scipy.version 0.17.1sklearn.**version** 0.17.1,Bug Reproduction
3725,I can also reproduce the bug with the code sample from ivan-krukov,Bug Reproduction
3726,Same issue on OS X EI Capitan using Python 3.5,Bug Reproduction
3727,"System Version: OS X 10.11.5Python 3.5.1 :: Continuum Analytics, Inc.numpy.**version** 1.11.1scipy.**version** 0.16.0sklearn.**version** 0.17.1",Bug Reproduction
3728,Same problem.,Bug Reproduction
3729,Though I have noticed that **it only occurs for a subset of my dataset and not with the whole thing**.,Investigation and Exploration
3730,"That is, if I do TSNE on the whole data set it **works**, if I do it on a reduced set it does not.",Investigation and Exploration
3731,O_o;;,Social Conversation
3732,"This just in, if I repeat the same 'broken' subset that doesn't work(by means of list*10) then it works.",Investigation and Exploration
3733,"Multiplying each individual vector by 10 doesn't work, but duplicating the date does.",Investigation and Exploration
3734,just doubling the length of the list is insufficient.,Investigation and Exploration
3735,Maybe this is some kind of degrees of freedom check run amok?,Investigation and Exploration
3736,@ivan-krukov I bit the bullet today and installed an El Capitan VM.,Bug Reproduction
3737,Unfortunately I can not reproduce your problem.,Bug Reproduction
3738,@Concomitant can you reproduce the error on the stand-alone example given in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction
3739,@jnothman it doesn't seem to be happening only on Python 3.5 so if you could try to reproduce with Python 2.7 (snippet: https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) that would be great.,Bug Reproduction
3740,@lesteve I can reproduce the issue.,Bug Reproduction
3741,CODE,Bug Reproduction
3742,"Following the same code, however: CODE",Bug Reproduction
3743,Bizarre.,Social Conversation
3744,"I cannot reproduce either with python 3.5.1, numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1 from miniconda (with MKL) on a virtualbox with OSX El Capitan.",Bug Reproduction
3745,I will try on a real mac hardware later.,Bug Reproduction
3746,Also @joelkuiper and @Concomitant can you please check that you can reproduce the problem on the current state of the scikit-learn master branch?,Bug Reproduction
3747,@lesteve and others I cannot reproduce the error with the [snippet posted earlier](https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) on the latest master with python 2.7.,Bug Reproduction
3748,System info: CODE,Bug Reproduction
3749,"I tried again on a real mac running OSX El Capitan 10.11.3 (with anaconda's latest numpy scipy and scikit-learn, same setting as reported by @Concomitant in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-229703129) but could not reproduce the problem either (tried running the snippet several times).",Bug Reproduction
3750,What is weird though it that the despite the CODE line I get different results for the output of CODE.,Investigation and Exploration
3751,This might be a bug in itself.,Investigation and Exploration
3752,Actually I read @Concomitant's code snippet too quickly:,Bug Reproduction
3753,instead of CODE it should be CODE otherwise the numpy RNG is not reseeded appropriately and one cannot get deterministic results.,Bug Reproduction
3754,Also I now realized that I read the whole discussion too quickly and that the bug only happens with python 2.7.,Bug Reproduction
3755,Will try again.,Bug Reproduction
3756,I cannot reproduce either with python 2.7.12 from conda on OSX 10.11.3 either.,Bug Reproduction
3757,Actually @Ekliptor can reproduce the issue with python 3.5.1 from conda so it's probably not related to the version of Python either.,Investigation and Exploration
3758,Maybe it depends on the minor version of OSX.,Investigation and Exploration
3759,I cannot replicate either with OSX 10.11.5.,Bug Reproduction
3760,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
3761,I don't know what to do.,Social Conversation
3762,"If one of you can reproduce the problem, please try to find a numpy random seed that trigger the issue (using CODE instead of CODE in the above snippet) and communicate the value here (along with the version of OSX and you python packages).",Investigation and Exploration
3763,I can not reproduce it anymore as before.,Bug Reproduction
3764,I only updated numpy:numpy.version.version 1.11.1,Solution Discussion
3765,To all people working with Tensorflow I can add:,Solution Discussion
3766,When I try to plot a very small sample (< 200 points) I sometimes still run into this error.,Solution Discussion
3767,After increasing the sample size I pass into tsne.fit_transform() it always works.,Solution Discussion
3768,@joelkuiper and @Concomitant do you confirm that scikit-learn master also work for you?,Solution Discussion
3769,If so we can close this issue.,Action on Issue
3770,"I installed master, the code snippet runs cleanly now.",Solution Discussion
3771,seems to work for everybody now.,Task Progress
3772,closing.,Action on Issue
3773,"Sorry, but I still get this on Python 3.5.1, scikit 0.17, scikit-learn 0.18 (commit 9e913c04d748), and Numpy 1.11.1 on Mac OS 10.11.5.",Bug Reproduction
3774,@dmyersturnbull do you get the error when running the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction
3775,"@lesteve I did with that exact snippet, yes.",Bug Reproduction
3776,"However, I no longer get it after clearing my Anaconda installation and reinstalling from scratch with Python 3.5.2.",Solution Discussion
3777,"I get the same problem with Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3.",Bug Reproduction
3778,It works when I have more than 2100 points but fails for lower values.,Bug Reproduction
3779,Analogically **fails for low points' values**,Bug Reproduction
3780,"Reopen, please",Action on Issue
3781,"I am getting the same problem on OS X 10.11.6, python 3.5.1,  sklearn 0.17.1 and numpy 1.11.1 .On this dataset: https://dl.dropboxusercontent.com/u/103591/vals.out (with np.savetxt)",Bug Reproduction
3782,@Lucidyan I don't understand what you mean by that.,Investigation and Exploration
3783,@pbnsilva can you try this snippet posted below ?,Investigation and Exploration
3784,You may need to run it multiple times because unfortunately the seed is not set appropriately (you need to use CODE rather than CODE).,Investigation and Exploration
3785,CODE,Investigation and Exploration
3786,Alternatively some people reported that this bug was fixed in master.,Solution Discussion
3787,Could you try to build scikit-learn master to see whether the problem disappears ?,Solution Discussion
3788,"@lesteve I meant that I get the same error with a small number of instances, with the same system parameters (Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3)",Bug Reproduction
3789,"I tried it, and it fails with X_SIZE <= 1750 (Y_SIZE=20, n_components=2 became constants).",Investigation and Exploration
3790,"if I start to change the constants (increase) with fixed X_SIZE=1750, it fails too.",Investigation and Exploration
3791,@Lucidyan could you try the same snippet with scikit-learn master and see whether it fails too ?,Investigation and Exploration
3792,what did you guys change...?,Social Conversation
3793,@act65 we are more than keen to get to the bottom of this but we haven't been able to reproduce and it seems like we are getting mixed reports from users so far unfortunately.,Task Progress
3794,"So if you haven't already (unfortunately we are not mind readers and ""not working for me"" does not tell us what you tried) could you try to run the snippet mentioned above in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185.",Investigation and Exploration
3795,Try to run it multiple times just in case because the random seed is not set properly and there may be some randomness left in the snippet.,Investigation and Exploration
3796,Then what would be really great if you could try with the 0.18 release candidate which is straightforward to install (highly recommended to do it in a separate virtualenv or conda env): CODE **Edited: 0.18 has been released so you can just use (no need to use CODE):** CODE and re-run the snippet to see whether it is fixed in 0.18 as some users have reported in this thread already.,Solution Discussion
3797,"yea my bad, should have been clearer.",Social Conversation
3798,"(I had tried roughly the same thing others had, just on MNIST).",Solution Discussion
3799,"anyway, it works!",Social Conversation
3800,thanks :),Social Conversation
3801,This seems to match what other have reported when they say it was fixed in master.,Social Conversation
3802,"Just for completeness though, it is recommended to stick to released versions for production code, so you may need to wait a little bit more until the 0.18 release is out.",Solution Discussion
3803,Thanks @Lucidyan for giving it a try.,Social Conversation
3804,"Try uninstalling and reinstalling numpy, scipy and scikit-learn.",Solution Discussion
3805,"If that still fails, try in a different virtualenv (or conda environment if you are using conda) to make sure something is not wrong in your Python environment.",Solution Discussion
3806,Still get the same error (CODE) in sklearn 0.18  (CODE) via conda.,Solution Discussion
3807,The pip wheels seem to work fine though!,Solution Discussion
3808,Hmmm interesting ...,Social Conversation
3809,"could you try using conda packages without mkl, i.e. something like CODE so we can see whether that is a MKL vs openblas thing?",Investigation and Exploration
3810,Up until now the snippet we have is non-deterministic (CODE is used and has no influence of numpy.random seed).,Investigation and Exploration
3811,"Sure, no problem.",Social Conversation
3812,"This may be be a BLAS problem indeed, the CODE env works fine.",Investigation and Exploration
3813,"E.g., CODE reproduces the problem on my machine.",Investigation and Exploration
3814,"However, when I replace CODE by CODE it seems to be fine.",Investigation and Exploration
3815,"Would be good to find a more light-weight example maybe, to add this particular case to the travis tests.",Investigation and Exploration
3816,EDIT: Same is true for iris.,Investigation and Exploration
3817,"CODE works in fit_transform, a splitted dataset (CODE) does not.",Investigation and Exploration
3818,Maybe there's sth funny going on in CODE.,Investigation and Exploration
3819,"However, both CODE and CODE seem to be float 64 arrays ...",Investigation and Exploration
3820,"What about the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185, you didn't find a way to make it deterministic and still fail on your machine?",Investigation and Exploration
3821,The snippet CODE reproduces the error (but it works fine on the nomkl env),Investigation and Exploration
3822,"OK thanks a lot for this, at least we have a deterministic snippet now.",Social Conversation
3823,"For the record, can you post the output of this snippet: CODE",Investigation and Exploration
3824,"Also, just for the sake of sanity, can you make sure you can reproduce the problem in a fresh conda environment.",Investigation and Exploration
3825,"To be honest, I am not sure where we go from this.",Social Conversation
3826,"Sure, the machine that causes this problem: CODE (tested it in a fresh conda environment)",Investigation and Exploration
3827,I think you may be onto sth!,Social Conversation
3828,"I tried it on my other mac, and it works fine there.",Bug Reproduction
3829,The only difference is to the output above it is running on an older kernel (CODE).,Investigation and Exploration
3830,"Haven't updated the second mac to macOS Sierra yet, which is running on the former machine that has this problem.",Investigation and Exploration
3831,Could be OS-related.,Investigation and Exploration
3832,"Given that the problem has been reported on different OSX versions, I kind of doubt this is only a OSX version issue.",Investigation and Exploration
3833,IIRC @ogrisel's hunch was that it was CPU architecture related.,Investigation and Exploration
3834,Another (more time-intensive) way to debug this problem would be to track down where the NaNs appear in the code.,Investigation and Exploration
3835,"Hm, how would the conda scikit-learn version differ from the pip wheels?",Investigation and Exploration
3836,Because the latter seem to work on the same machine.,Investigation and Exploration
3837,Maybe it's somehow related to conda,Investigation and Exploration
3838,"I noticed that the gradient in https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L387 explodes, until it becomes CODE in one position after the 25th iteration in the https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L386 for-loop",Investigation and Exploration
3839,CODE,Investigation and Exploration
3840,"On the other machine (the one that works fine), the gradients are all < 0 after the same iteration.",Investigation and Exploration
3841,"So, somehow the CODE function doesn't work properly (maybe due to some BLAS thing).",Investigation and Exploration
3842,"The pip wheels are using OpenBLAS and you don't have the problem when using OpenBLAS with conda (through the CODE trick) so this does look like a MKL problem, which on top of that is likely CPU-specific.",Investigation and Exploration
3843,Great job debugging the issue by the way!,Social Conversation
3844,The problem arises very likely in some cython code in sklearn/manifold/_barnes_hut_tsne.pyx.,Investigation and Exploration
3845,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
3846,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
3847,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
3848,"You are right, reopening.",Action on Issue
3849,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
3850,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
3851,"However, even this can be further isolated, I am curious if there's a fix for such a hardware-specific problem.",Solution Discussion
3852,"Maybe, until this is fully resolved, it may be worthwhile to raise a more specific exception/warning if the gradient contains infs with a note about this problem?",Solution Discussion
3853,"I just created a new conda virtualenv and built a devp version of sklearn from the source code freshly forked from the sciki-learn master branch, the error disappeared.",Investigation and Exploration
3854,Is the devp sklearn built from source code using OpenBLAS instead of MKL?,Investigation and Exploration
3855,"Sounds great, thanks a lot !",Social Conversation
3856,"Not sure about a fix, one hope would be if we can change our cython code to work-around problem once we have isolated it.",Solution Discussion
3857,"Also it could well be an openblas issue and that would be great reporting it upstream, especially since wheels use openblas.",Solution Discussion
3858,"Adding some advice to the error message (only on OS X), sounds like a good idea, but I am not sure what it should say, maybe ""consider using conda and install scikit-learn with MKL"" or something like this.",Solution Discussion
3859,@zhongyuk depends which library you have installed.,Investigation and Exploration
3860,"One way to know once you have built scikit-learn from source is to run the equivalent of CODE (Google seems to say CODE) on CODE (name will be different if you are using Python 3, i.e. something like CODE).",Investigation and Exploration
3861,"On my Ubuntu machine for example, I get this: CODE",Investigation and Exploration
3862,"So you can see from the third line, that it is using MKL.",Investigation and Exploration
3863,I just wanted to write that I think you got it flipped: the wheels worked find and the issue only occured when I was using it via conda with MKL ...,Solution Discussion
3864,"Now, I think I have good news in some way: I just wanted to rerun the above example that previously caused this issue to confirm CODE and I am no longer getting this problem.",Investigation and Exploration
3865,I remember that I reininstalled miniconda the other week due to some other problems.,Investigation and Exploration
3866,Do you think it could be related to some issue in the old conda?,Investigation and Exploration
3867,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
3868,"Meanwhile, I will try to see if I can find an old backupstate to find out which conda version I had installed previously.",Investigation and Exploration
3869,"(right now, I have conda 4.2.12)",Investigation and Exploration
3870,"Just wanna say that I ran CODE on CODE (I assume this is the t_sne.py compiled file?), it seems like it's indeed using BLAS.",Investigation and Exploration
3871,And the one which threw error seems to use MKL..,Investigation and Exploration
3872,"The conda version I have is 4.2.13, both the env which throws the error and the env with source built sklearn (which does not throw error) are inside conda.",Investigation and Exploration
3873,"Hm, interesting, so it's not a conda issue after all then ...",Investigation and Exploration
3874,Curious why it works for me now :/,Investigation and Exploration
3875,all I can think that has changed (except for reinstalling conda) was rebooting :P,Investigation and Exploration
3876,"Yeah, sorry about that.",Social Conversation
3877,I'll edit the issue title to try to remember it right for next time.,Social Conversation
3878,"Hmmm, random guess maybe the mkl version, although if I believe the output of CODE the latest mkl version (11.3.3) is from 2016-05-13.",Investigation and Exploration
3879,"@zhongyuk try to build scikit-learn inside a conda env that uses mkl, I believe this should be enough for mkl to be picked up (probably a good idea in this case to do CODE and then CODE to rebuild from scratch).",Investigation and Exploration
3880,"@lesteve I built scikit-learn in two conda virtual environments from source code (branch 0.18 release), the one uses MKL indeed throws the error; the one uses libBLAS does not throw error.",Investigation and Exploration
3881,The output running CODE on CODE is here (in case MKL version gives you any clue?) CODE,Investigation and Exploration
3882,@zhongyuk great !,Social Conversation
3883,"For completeness, can you post the output of CODE (in your MKL conda environment)?",Investigation and Exploration
3884,While we are at it your CPU information (CODE according to Google) and your platform information (CODE) would be great.,Investigation and Exploration
3885,What would be really great is to continue where @rabst stopped and further isolate the problem:https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-258311980,Investigation and Exploration
3886,"Since this is related to BLAS, my hunch is that something goes wrong in this [line](https://github.com/scikit-learn/scikit-learn/blob/46fc1be145bf952a916ef5abd06efec105105c2e/sklearn/manifold/_barnes_hut_tsne.pyx#L660) causing the gradient to have some non-finite values.",Investigation and Exploration
3887,@lesteve Output of conda MKL environment info:CODE,Investigation and Exploration
3888,CPU info: CODEPlatform info: CODE,Investigation and Exploration
3889,"@zhongyuk If it helps, I have a very similar setup (can't reproduce the issue anymore since reinstalling miniconda), except that I have macOS Sierra instead of OS X El Capitan and that I have numpy 1.11.2 instead of 1.11.1.",Investigation and Exploration
3890,"@rasbt hmm, I wonder if the problem goes away in Sierra...",Investigation and Exploration
3891,I don't want to upgrade OS yet b/z I thought I read somewhere that TensorFlow doesn't support Sierra yet (could be mistaken or no longer be true anymore since I don't remember where or how long ago I read it)?,Investigation and Exploration
3892,And I don't wanna break my projects with TF dependency,Social Conversation
3893,"@zhongyuk Hm, I think it's unlikely that it is related.",Investigation and Exploration
3894,"Before I reinstalled miniconda, I also had the problem in macOS Sierra.",Investigation and Exploration
3895,"PS: Tensorflow works fine for me on Sierra, but I only do CPU and prototyping on my macs so I don't know about GPU issues related to Sierra",Investigation and Exploration
3896,"@rasbt hmm, that's good to know that TF works fine on Sierra.",Investigation and Exploration
3897,Do you wanna run CODE on the CODE file in your platform to see which math library sklearn using underneath?,Investigation and Exploration
3898,At least that way we might know if the problem went away after reinstalling miniconda is fundamentally linked to math library?,Investigation and Exploration
3899,I am getting the following on CODE: CODE,Investigation and Exploration
3900,"@rasbt Hmm, that's really interesting.",Social Conversation
3901,It's using MKL as well.,Investigation and Exploration
3902,I don't know enough about the math library to speculate what does this mean...,Social Conversation
3903,@lesteve probably will be able to infer more from this?,Contribution and Commitment
3904,I noticed that in my platform CODE is not loaded...,Investigation and Exploration
3905,Is it possible that caused the problem?,Investigation and Exploration
3906,"WOW, yes!",Social Conversation
3907,it is caused by CODE not loaded!!!,Investigation and Exploration
3908,"I found [this thread on stack overflow] URL  and then ran CODE, then ran CODE on the  CODE file, then CODE loaded up, and ran the code snippet, error went away!",Solution Discussion
3909,Have five team work! @rasbt,Social Conversation
3910,"@lesteve Since it does look like a lot of ppl has hit this problem, and it does look like it's related to (some version of ?) conda not extracting full MKL libraries (my understanding of the situation so far), even though it's not a scikit-learn bug, I do think either add some kind of remark or warning or error messages to (OS X) users would be nice?",Solution Discussion
3911,That way at least they can check if MKL lib is fully extracted in their platform and then fix it if it's not?,Solution Discussion
3912,"@zhongyuk awesome, glad to hear that you were able to narrow it down!",Social Conversation
3913,That would also explain why it works for me now after re-installing Miniconda ...,Solution Discussion
3914,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
3915,"If the aforementioned CODE really caused this issue, the remaining question would be how to deal with that in scikit-learn.",Solution Discussion
3916,"I mean, this ""bug"" is kind of hideous and it may be a bit tricky for folks to figure out that it's due to CODE.",Solution Discussion
3917,"I probably wouldn't inject an additional ""if gradient contains inf raise error + message"" in the code in scikit-learn since it could be quite annoying performance-wise.",Solution Discussion
3918,"However, i think that adding a note or comment in the installation and/or T-SNE docs would be a good idea.",Solution Discussion
3919,Just want to add a quick update: I had 2 virtual envs in conda both using MKL.,Investigation and Exploration
3920,One of them is equipped with CODE and the other is equipped with CODE.,Investigation and Exploration
3921,Running CODE indicated that both of them somehow didn't have CODE loaded.,Investigation and Exploration
3922,"After making sure CODE loaded up, the error disappeared in the virtual env with CODE.",Investigation and Exploration
3923,"However, the error remained appearing in the env with CODE.",Investigation and Exploration
3924,"After upgrading CODE to 1.11.2, I can no longer reproduce the error in either conda virtual environment.",Investigation and Exploration
3925,"As it sounds complicated and the exact cause of the error is still obscure, I speculate it's probably a complication interweaved by incomplete MKL library loading and scikit-learn dependent libraries (possibly numpy?).",Investigation and Exploration
3926,Although I haven't tried to create an virtualenv with MKL and CODE to see if this would reproduce the error.,Investigation and Exploration
3927,"And I second @rasbt suggestion on adding some kind of note, comment or docs!",Solution Discussion
3928,@zhongyuk glad you got it fixed !,Social Conversation
3929,It seems that reinstalling packages with conda may help but I am afraid there doesn't seem to be a very clear picture of the cause of the problem :(.,Investigation and Exploration
3930,"This is a conda bug, right?",Investigation and Exploration
3931,Or did anyone experience the bug not using conda?,Investigation and Exploration
3932,I managed to find a way to reproduce I think by installing the numpy wheel and then scikit-learn via conda on top of it (got the hint from the CODE output in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762 where two CODE are listed).,Bug Reproduction
3933,CODE,Bug Reproduction
3934,then execute the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762.,Bug Reproduction
3935,So it seems like this is happening when mixing numpy installed via pip and conda.,Investigation and Exploration
3936,"In my book this is never a good idea to mix pip and conda for a given package but I guess this can happen without realizing it quite easily (for example you install a project that depends on numpy via pip, and then scikit-learn via conda).",Solution Discussion
3937,Why this exactly happens I don't know ...,Social Conversation
3938,and it seems to happen only on OSX by the way (i.e. not on my Ubuntu box).,Investigation and Exploration
3939,"For anyone affected by this, this should fix it: CODE",Solution Discussion
3940,Let me know if that doesn't work for you.,Solution Discussion
3941,Thanks for the deep dive (again!) @lesteve,Social Conversation
3942,I thought we would never get to the bottom of this one to be honest :) !,Social Conversation
3943,OK it's not quite the bottom but it's low enough as far as I am concerned.,Social Conversation
3944,Hi,Social Conversation
3945,"I tried two setups, where",Bug Reproduction
3946,"-         TSNE works well with one setup (where Tensorflow is de-activated, Python-3.x), however,",Bug Reproduction
3947,"-         TSNE does not work with the other setup (where Tensorflow is activated, Python 2.x).",Bug Reproduction
3948,**The set up where TSNE works well:**,Bug Reproduction
3949,Terminal:CODE,Bug Reproduction
3950,Jupyer notebook:CODE>>CODE,Bug Reproduction
3951,Note: I triedCODEto make TSNE work well with Tensorflow deactivated.,Solution Discussion
3952,"However, with the new setup below (where I have to use Tensorflow), this does not work any more.",Solution Discussion
3953,**The set up where TSNE does not work:**,Bug Reproduction
3954,**Terminal:**CODE,Bug Reproduction
3955,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
3956,**Error**:CODE,Bug Reproduction
3957,Any suggestions ?,Solution Discussion
3958,Thanks a lot,Social Conversation
3959,Interesting.,Social Conversation
3960,I think it has nothing to do with tensorflow; my guess is that [GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] vs [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] is the culprit!?,Investigation and Exploration
3961,Thanks for response :),Social Conversation
3962,Any suggested solutions/to_do_list ?,Solution Discussion
3963,Need use bothTensorflow andTSNEin Jupyter notebook ....,Motivation
3964,"BTW: just tried ""from __future__ import division"" in Python 2.x and did not solve the problem.",Solution Discussion
3965,"Hm, not sure if that helps -- personally, I am not getting this mysterious issue anymore with  CODE",Solution Discussion
3966,"I am on Tf (now 1.0) as well, and I don't have this CODE issue anymorewhen I execute CODE which previously didn't work.",Solution Discussion
3967,Maybe try to create a new python 3.5 env and try the above-mentioned snippet to see if it works without error:,Solution Discussion
3968,CODE,Solution Discussion
3969,"Hi rasbt,Yes I made TSNE work on Python 3.5.",Solution Discussion
3970,"However, for some other reason I'd better use Python 2.7, so I have to continue to explore ...",Solution Discussion
3971,cross fingers,Social Conversation
3972,Thanks for your help.,Social Conversation
3973,Do you have an old(er) Miniconda/Anaconda 2.7 distro installed?,Investigation and Exploration
3974,"In this case, maybe consider installing one of the more recent ones, or update your conda root or default python and give it another try (or create a new py 27 env by substituting the 3.5 by 2.7 in CODE) ?",Solution Discussion
3975,"not sure if this is really the reason, but I think CODE may be an issue; since the error doesn't seem to occur via CODE",Investigation and Exploration
3976,"Update: TSNE(perplexity=30, n_components=2, init='pca', n_iter=1000, **method='exact'**) make it  worked ...",Solution Discussion
3977,**method='exact'** was the trick.,Solution Discussion
3978,Also been having this problem.,Bug Reproduction
3979,"Using method='exact' seems to works for me, but it is so painfully slow.",Solution Discussion
3980,Is there really no other solution that people have found?,Solution Discussion
3981,Have you read https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-264029983 and https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-264087057 ?,Solution Discussion
3982,The only way I managed to reproduce this problem was to install numpy with both pip and conda in the same conda environment.,Investigation and Exploration
3983,If you create a conda environment from scratch you should not have this problem.,Investigation and Exploration
3984,"In case your problem do not seem to match this description, please post the exact commands you ran to create your conda environment, so we can try to reproduce.",Bug Reproduction
3985,"Hi,",Social Conversation
3986,I read the above comments and can reproduce this.,Bug Reproduction
3987,I re-ran code from a few weeks ago and now this issue appears.,Bug Reproduction
3988,Here's a minimal example that now reproduces this issue:CODE,Bug Reproduction
3989,And the output ofCODEis CODE,Bug Reproduction
3990,"Again, changing the method to exact (CODE) gets rid of the error.",Solution Discussion
3991,"More generally, I have noticed wildly different results when using sklearn's TSNE (with identitical perplexity and other parameters) from the bh implementation published by Laurens van der Maaten and the MATLAB version.",Investigation and Exploration
3992,I wonder if there may be a connection?,Investigation and Exploration
3993,Did you refer to https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-264087057,Solution Discussion
3994,That fixed it.,Solution Discussion
3995,"I had the same problem as reported here, and I do not use conda.",Bug Reproduction
3996,My Python version is installed via brew on macOS Sierra 10.12.4,Bug Reproduction
3997,CODE,Bug Reproduction
3998,Adding CODE solved my problem.,Solution Discussion
3999,@lesteve: i had this error using the setup you describe (two versions of numpy installed).,Bug Reproduction
4000,simply updating the conda install of numpy to the same version as the pip install (1.12.1) did the trick for me.,Solution Discussion
4001,"i did remove the pip numpy install, though, as i didn't intend to have two versions :)",Solution Discussion
4002,@lesteve: Thank you for the solution!,Social Conversation
4003,I happened to have this error and then I found this discussion.,Social Conversation
4004,Fix it right away after remove the duplicated version of numpy.,Solution Discussion
4005,**Replicated**,Bug Reproduction
4006,I have removed pip installs of numpy and updated conda.,Solution Discussion
4007,"Darwin-16.7.0-x86_64-i386-64bit('Python', '2.7.13 |Anaconda custom (x86_64)| (default, Dec 20 2016, 23:05:08) \n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]')('NumPy', '1.13.1')('SciPy', '0.19.0')('Scikit-Learn', '0.18.1')",Solution Discussion
4008,It seems fine on my linux machine Linux:,Bug Reproduction
4009,"Linux-3.0.101-0.47.71-default-x86_64-with-SuSE-11-x86_64('Python', '2.7.12 |Anaconda 2.3.0 (64-bit)| (default, Jul  2 2016, 17:42:40) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.1')",Bug Reproduction
4010,@wolfiex so you didCODE,Solution Discussion
4011,Somewhat related I recommend you update to scikit-learn 0.19 which has some fixes in t-SNE,Solution Discussion
4012,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
4013,I installed tf-nightly build and I get the following error on import of tensorflow.,Observed Bug Behaviour
4014,CODE.,Observed Bug Behaviour
4015,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
4016,I that due to a name mismatch. CODE?,Investigation and Exploration
4017,And if so how can we overcome this?,Solution Discussion
4018,@Timonzimm I know and I think the whole issue is this f** naming libcublas.so.xxx that nvidia puts.,Investigation and Exploration
4019,"This inherently is mismatch on linux systems whenever that number changes, so since it can not find the exact matches then it thinks the file doesn't exist and throws the error.",Investigation and Exploration
4020,"I think you should use symbol link from ''cuda/''   to ''cuda/9.1"",or your cuda version is too new to tensorflow master branch",Solution Discussion
4021,@burui11087 I completely forgot about symlinking.,Social Conversation
4022,Thanks for reminding me.,Social Conversation
4023,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4024,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
4025,I also occur the exactly same problem with kirk86.,Bug Reproduction
4026,"For me, I installed cuda toolkit 8.0, and cudnn 5.1.",Bug Reproduction
4027,"Then I did what you guys said above, all of them does not work.",Solution Discussion
4028,"For using nightlies, you have to have CUDA 9.0 and cudnn 7 installed.",Solution Discussion
4029,@yangfengKAUST with the current version of cuda and cudnn installed TF is just complaining that it cannot find the versions it is expecting.,Investigation and Exploration
4030,@Timonzimm  I am facing the same issue.,Bug Reproduction
4031,Have you figured it out?,Task Progress
4032,"I have 8.0, 9.0, 9.1 installed + cudnn versions which seem specific to each.",Bug Reproduction
4033,The sym  linking didn't work from the 9.1 libs.,Solution Discussion
4034,I suspect that sometimes the symlink in the LD_LIBRARY_PATH doesn't work either when I switch versions on the /usr/local/cuda link.,Solution Discussion
4035,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
4036,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
4037,@asimshankar Would like to know that in your above comment you mean that we should downgrade cuda to 9.0 and tensorflow 1.5 doesn't work with cuda 9.1 ?,Solution Discussion
4038,Note: I also have cuda 9.1 installed instead of cuda 9.0.,Bug Reproduction
4039,"Just FYI, I have both installed.",Solution Discussion
4040,"Building from scratch will work w/ either, but the nightly binaries use 9.0.",Solution Discussion
4041,@AwasthiMaddy - Yes TensorFlow 1.5 release binaries are built for CUDA 9.,Solution Discussion
4042,Have you solved it ?,Task Progress
4043,And rember uninstall tensorflow-gpu-1.5.,Solution Discussion
4044,"Please use this""pip install --upgrade tensorflow-gpu==1.4""",Solution Discussion
4045,@aipeteryao  - Thank you.,Social Conversation
4046,"Then as soon as you're done, you get this error (it is looking for cublas 9.0, which, from what I can read here, would not have worked either, as CUDA 9.1 is the default you get from NVIDIA).",Bug Reproduction
4047,"Either the webpage instructions should work with the default latest of everything, or it should tell you explicitly to install tensorflow-gpu-1.4 (for example) and not tensorflow-gpu..",Solution Discussion
4048,Seconding bwesons's comment.,Social Conversation
4049,I have CUDA 8.0 and Tensorflow 1.3.,Bug Reproduction
4050,"I followed the current install instructions for TF 1.5 (GPU, ubuntu, virtualenv) and it breaks as described above.",Bug Reproduction
4051,Reverting to TF 1.3 until this is resolved.,Workarounds
4052,"I ended up uninstalling the latest version and installing 1.4, in my virtualenv.",Solution Discussion
4053,CODE,Solution Discussion
4054,The install page for Ubuntu should be updated:,Solution Discussion
4055,https://www.tensorflow.org/install/install_linux,Solution Discussion
4056,"Since TensorFlow 1.5 is expecting Cuda 9.0 ( NOT 9.1 ), as well as cuDNN 7",Solution Discussion
4057,"In fact, we should view the official document of tensorflow ,it give tensorflowâs envirment(include python,gcc,cuda,cudnn,an so on).",Solution Discussion
4058,"@bwesen yes,you were right .",Social Conversation
4059,"My computer installed CUDA 8.0,cudnn 6.0 ,tensorflow 1.4.",Bug Reproduction
4060,I think this issue should still be open.,Action on Issue
4061,@bwesen's [comment](https://github.com/tensorflow/tensorflow/issues/15604#issuecomment-362637994) is correct.,Social Conversation
4062,[The docs] URL  tell you to install Cuda 8.0 and use CODE.,Solution Discussion
4063,Right now that gives you tensorflow 1.5 which does not work with Cuda 8.0,Solution Discussion
4064,pinging @asimshankar,Contribution and Commitment
4065,I have the same issue (with cuda 9.1 + tensorflow 1.5).,Bug Reproduction
4066,"I think to resolve it, one option is that to downgrade cuda to 9.0.",Solution Discussion
4067,The other option would be to downgrade both cuda to 8.0 and tensorflow to 1.4.,Solution Discussion
4068,"If you have already installed cuda 8.0, you only need to modify CODE (and CODE) environment variable to point to cuda 8.0 directory (i.e. CODE).",Solution Discussion
4069,"I'm getting this issue (Cuda 9.1.85, cuDNN 7.05)",Bug Reproduction
4070,"Tried with tensorflow 1.5, it broke.",Solution Discussion
4071,"Uninstalled, installed 1.4 with CODE, still broke.",Solution Discussion
4072,"@DylanDmitri  1.5 expects Cuda 9.0, not 9.1",Solution Discussion
4073,Have you tried with Cuda 9.0 drivers?,Solution Discussion
4074,@DylanDmitri @mkaze You need Cuda 9.0.,Solution Discussion
4075,"Also, for anyone having trouble installing requirements, I suggest double checking your cuDNN installation.",Solution Discussion
4076,The .deb file didn't work for me because it did not copy files to the right place.,Solution Discussion
4077,I had to use the .tgz file and manually copy files according to nVidia's directions in order to get a working installation.,Solution Discussion
4078,Why not just install cuda-9-0?,Solution Discussion
4079,-         Go here: https://developer.nvidia.com/cuda-90-download-archive,Solution Discussion
4080,"-         Then, for me: Download deb (network)",Solution Discussion
4081,CODE,Solution Discussion
4082,@abrahamrhoffman That's easy for anyone who has sudo privileges but what about people on a shared system like a cluster environment with simple user privileges.,Solution Discussion
4083,In those cases even if you ask from the sys admin to install any libraries most probably the answer is gonna be NO!,Solution Discussion
4084,Since they are afraid that might interfere with other users' settings and environments.,Solution Discussion
4085,@abrahamrhoffman Would you also mind providing a justification on the down vote?,Solution Discussion
4086,I installed cuda-9.0 and still it does not work.,Solution Discussion
4087,This is really irritating.,Social Conversation
4088,"Please make sure to set your PATH variable appropriately, such as described here: https://stackoverflow.com/questions/39287744/ubuntu-16-04-nvidia-toolkit-8-0-rc-darknet-compilation-error-expected-a/41290056#41290056",Solution Discussion
4089,CODE,Solution Discussion
4090,cuda 9.1 is the current version.,Solution Discussion
4091,I want TF to use it. How to?,Solution Discussion
4092,Even tf-nightly-gpu is not looking for cuda 9.1.,Solution Discussion
4093,Meh,Social Conversation
4094,I tried symbolic links from all the 9.0 filenames to all the 9.1 filenames and it didn't work.,Solution Discussion
4095,"In the end, TF knows the true version.",Solution Discussion
4096,The repo doesn't even have 9.0 anymore so I'm afraid I'll break my nvidia stuff if I remove 9.1 and then manually install 9.0.,Solution Discussion
4097,I fix him for now by:,Workarounds
4098,Download deb (network) from:,Workarounds
4099,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
4100,Then: CODE,Workarounds
4101,Then: aptitude update,Workarounds
4102,Then: aptitude install cuda-9-0,Workarounds
4103,"First I've installed tensorflow 1.5, it broke, and I get the following error:CODE",Bug Reproduction
4104,"then I uninstalled,  installed 1.4 with pip install --upgrade tensorflow-gpu==1.4, it did't work,  and I get the following error:CODE",Solution Discussion
4105,@xiezhongzhao What version of Cuda are you using?,Solution Discussion
4106,For tensorflow 1.5 you must have installed the Cuda 9.0 and for tensorflow 1.4 you must use cuda 8.0.,Solution Discussion
4107,"If the the tensorflow version and cuda version are compatible, then check the environment variables i.e. CODEand CODE.",Solution Discussion
4108,@mkaze I used Cuda9.1,Solution Discussion
4109,@xiezhongzhao Install Cuda 9.0 and you should be fine.,Solution Discussion
4110,Tensorflow 1.5 does not work with Cuda 9.1.,Solution Discussion
4111,@mkaze Thank you very much,Social Conversation
4112,I am also getting this issue and struggling to resolve it.,Bug Reproduction
4113,CODE,Bug Reproduction
4114,I installed following these instructionshttps://www.tensorflow.org/install/install_linux#nvidia_requirements_to_run_tensorflow_with_gpu_support,Bug Reproduction
4115,I believe I installed the right versions from nvidia.,Bug Reproduction
4116,filenames wereCODEand CODE (version 7.0.5),Bug Reproduction
4117,I set the path as per those instructions on the tensorflow docs and also tried the instructions that CODE gave above.,Solution Discussion
4118,"When I run ldconfig -v I get some 9.0 libs, but do not see libcublas.so.9.0CODE",Solution Discussion
4119,"I did not install 9.1, at least not intentionally.",Bug Reproduction
4120,This is on a amazon ec2 instance with stock ubuntu 16.04.,Bug Reproduction
4121,"nvidia-smi also returns a gpu, this is a g3.4xlarge instance",Bug Reproduction
4122,any guidance is greatly appreciated.,Social Conversation
4123,Per the CUDNN guide at: http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html You need to copy the unpacked files (from the directory you ran CODE or similar) into CODE subdirectories: CODECODECODECODE,Solution Discussion
4124,Thank you for the reply @entropy43.,Social Conversation
4125,I should have been more specific.,Social Conversation
4126,I did those two CODE and the CODE commands after CODE.,Solution Discussion
4127,When I look in the folder cuda folder for where I ran the tar command like CODE I seeCODE,Solution Discussion
4128,I tried this section as well from the nvidia [doc] URL CODE and the tests pass here in CODE,Solution Discussion
4129,Any advice to get that lib is appreciated,Social Conversation
4130,Could someone please summarize where this currently stands?,Task Progress
4131,Advice?,Social Conversation
4132,Similar to what yazabazra is asking above:,Social Conversation
4133,"TF1.6 Ubuntu 16.04nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2017 NVIDIA CorporationBuilt on Fri_Nov__3_21:07:56_CDT_2017Cuda compilation tools, release 9.1, V9.1.85Which requited a Nvidia display driver 390+",Bug Reproduction
4134,Critical to see: https://devtalk.nvidia.com/default/topic/1000340/cuda-setup-and-installation/-quot-nvidia-smi-has-failed-because-it-couldn-t-communicate-with-the-nvidia-driver-quot-ubuntu-16-04/post/5243047/#5243047,Motivation
4135,"whelp to add to it all,, After a major amount of hassle I got the Nvidia updated to the newest release see above, as the TF doc indicated that there were bugs in an earlier release..",Bug Reproduction
4136,Now I'm getting the :,Bug Reproduction
4137,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction
4138,Failed to load the native TensorFlow runtime.,Bug Reproduction
4139,Which appears to be a mismatch between 9.0 (TF wants) vs 9.1 Which is most current Nvidia.,Investigation and Exploration
4140,It would seem better to run with 9.1 but I'd rather avoid building TF from source and it seems that may not fix it anyhow..,Solution Discussion
4141,Can this combo be made to work with a binary package?,Solution Discussion
4142,TF 1.6 Cuda 9.1 ??,Solution Discussion
4143,Further note and caution to those looking here..,Social Conversation
4144,after upgrading my Nvidia stuff my older versions of TF in separate conda env's no longer work as the older TF wants : ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,Bug Reproduction
4145,so 9.1 won't cut it..,Investigation and Exploration
4146,how about specifying greater than??,Solution Discussion
4147,vs specific versions?,Solution Discussion
4148,just a suggestion..,Social Conversation
4149,In the meantime I'm dead in the water..,Social Conversation
4150,And this is why availability of a binary that supports 9.1 would be nice: (from the TF1.6 release notes),Motivation
4151,Using XLA:GPU with CUDA 9 and CUDA 9.1 results in garbage results and/orCUDA_ILLEGAL_ADDRESS failures.,Motivation
4152,Google discovered in mid-December 2017 that the PTX-to-SASS compiler in CUDA 9and CUDA 9.1 sometimes does not properly compute the carry bit whendecomposing 64-bit address calculations with large offsets (e.g. load [x + large_constant]) into 32-bit arithmetic in SASS.,Motivation
4153,"As a result, these versions of ptxas miscompile most XLA programs which usemore than 4GB of temp memory.",Motivation
4154,This results in garbage results and/orCUDA_ERROR_ILLEGAL_ADDRESS failures.,Motivation
4155,A fix in CUDA 9.1.121 is expected in late February 2018.,Motivation
4156,We do not expect afix for CUDA 9.0.x.,Motivation
4157,"Until the fix is available, the only workaround is todowngrade to CUDA 8.0.xor disable XLA:GPU.",Motivation
4158,Maybe one of the nightlies does it?,Solution Discussion
4159,Another solution?,Solution Discussion
4160,can one install multiple revisions of Cuda since  TF seems to search for specific Rev's?,Solution Discussion
4161,"If so, any advice as to how to?",Solution Discussion
4162,So Ideally I'd be able to to run TF 1.4(which currently requires Cuda 8.0) in one conda environment and TF 1.6 (which currently requires Cuda 9.0) in another?,Solution Discussion
4163,So I  just added sudo apt-get -y install cuda-toolkit-9.0 and I'm up and running with TF1.6,Solution Discussion
4164,"@dartdog after installing cuda-toolkit-9.0, did you face the issue CODE ?",Solution Discussion
4165,@dartdogCODE,Solution Discussion
4166,"This is definitely supposed to be included in the tensorflow documentation, as said by @bwesen.",Solution Discussion
4167,It should also be included in the errors list.,Solution Discussion
4168,Is it possible for us do this in anyway?,Contribution and Commitment
4169,"Ok, guys.",Social Conversation
4170,I have now opened a new issue at https://github.com/tensorflow/tensorflow/issues/17629.,Potential New Issues and Requests
4171,I was handling with this issue as well.,Bug Reproduction
4172,What worked for me with tensorflow-gpu 1.6:,Solution Discussion
4173,-         I downloaded the toolkit from the [archive] URL  as 9.0 but it got installed as 9.1 (I do not know why...),Solution Discussion
4174,-         Still not found libcublas.so.9.0,Solution Discussion
4175,-         Run: CODE as suggested at the end of the installation instructions.,Solution Discussion
4176,-         The issue seems to have been solved.,Solution Discussion
4177,"If you want to have tensorflow work with your CUDA version, you need to first uninstall it then compile it from source and specify the CUDA version while running ./configure",Solution Discussion
4178,Detailed information can be found here:  URL ,Solution Discussion
4179,I am trying this (which builds tensorflow manually)[link] URL ,Solution Discussion
4180,Might take a while longer but you can define the minor versions this way.,Solution Discussion
4181,"@mldm4 actually, the command CODE probably installed 9.1 for you because you also had that in your system.",Solution Discussion
4182,"I had the same problem, and I did CODE to install a specific version (I had also downloaded from the archive).",Solution Discussion
4183,I think the commad you did (CODE) also downloads cuda 9.0.,Solution Discussion
4184,so no solution yet?,Task Progress
4185,@thread :,Social Conversation
4186,****Please read through the posts carefully! The answer is posted.****,Social Conversation
4187,"It is your job to read the thread, and discover the solution; not simply scroll to the end.",Social Conversation
4188,@abrahamrhoffman that's rude.,Social Conversation
4189,I just changed my batchrc from cuda-9.1 to just cuda.,Solution Discussion
4190,Then my tensorflow is able of finding the libcublas.so.9.0,Solution Discussion
4191,just fyi: nvidia website for downloading cuda-9.0 is actually downloading cuda-9.1.,Solution Discussion
4192,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=deblocal,Solution Discussion
4193,@DanlanChen That is probably because you also have 9.1 installed.,Solution Discussion
4194,"To install 9.0, in the steps to download, do CODE instead of CODE.",Solution Discussion
4195,"@DanlanChen but then, I guess it is preffered to use the latest version.",Social Conversation
4196,"So, if you ever want to upgrade, you now know what to do!",Social Conversation
4197,:smile:,Social Conversation
4198,"Im facing the same issue, but I am trying to run tensorflow using nvidia-docker.",Bug Reproduction
4199,"I have cuda-9-0 installed on the host, but when I try to run my docker container I get CODE",Bug Reproduction
4200,@magick93 and all that turn up here!,Social Conversation
4201,LISTEN!,Social Conversation
4202,Anything you need is downgrade your cuda 9.1 -> cuda 9.0.,Solution Discussion
4203,That's it!,Social Conversation
4204,Just do it (if you downloaded cuda 9.1 before that you can execute following command in your terminal): CODE and remove cuda 9.1 by rm -rf.,Solution Discussion
4205,"Btw, don't forget to change $PATH in your CODE (9.1 -> 9.0).",Solution Discussion
4206,@Oktai15 doesn't CODE delete your system?,Solution Discussion
4207,"Please be more clear here, because people might try it without going into the required directory, and end up emptying their home folder.",Solution Discussion
4208,"@magick93 your issue seems to be something else, not the CUDA version.",Potential New Issues and Requests
4209,If you install new cuda while you still have previous version please make sure to specify the path  like this CODE,Solution Discussion
4210,@Abduoit your Ubuntu version doesn't really matter.,Solution Discussion
4211,"The thing is, TensorFlow 1.6 expects CUDA to be version 9.0, and cuDNN to be version 7.0.4 (yes, the 0.4 _does_ matter)",Solution Discussion
4212,"Traceback (most recent call last):File ""utils.py"", line 15, in <module>import tensorflow as tfFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>from tensorflow.python import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>from tensorflow.python import pywrap_tensorflowFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>raise ImportError(msg)ImportError: Traceback (most recent call last):File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>from tensorflow.python.pywrap_tensorflow_internal import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>_pywrap_tensorflow_internal = swig_import_helper()File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory  Failed to load the native TensorFlow runtime.",Bug Reproduction
4213,See https://www.tensorflow.org/install/install_sources#common_installation_problemssudo apt-get install cuda-7-0vim ~/.bashrcexport PATH=/usr/local/cuda-7.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda7.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PAfor some common reasons and solutions.,Bug Reproduction
4214,Include the entire stack traceabove this error message when asking for help.,Solution Discussion
4215,"As @pascalwhoop mentioned, I followed the instructions in here  URL  to build Tensorflow from source.",Solution Discussion
4216,"Whenever it said cuda 9.0 I changed to 9.1, and cudnn 7.0 I put 7.1.2.",Solution Discussion
4217,"Worked fine, so far!",Social Conversation
4218,@SAGGSOC why are you installing cuda 7.0?,Solution Discussion
4219,You need CUDA 9.0 and CuDNN 7.0.4,Solution Discussion
4220,Rather do a 6gb image pull once that works than DLing 5 versions of CuDNN before stuff works..,Solution Discussion
4221,https://github.com/pascalwhoop/tf_openailab_gpu_docker,Solution Discussion
4222,I started a while back but stopped because of shifting project focuses.,Social Conversation
4223,But I think it's worth pursuing.,Social Conversation
4224,Keeps the whole trouble of finding a the right combination of 17 moving parts away from most ppl.,Solution Discussion
4225,Just to clarify a few things for anyone who might stumble on this post.,Social Conversation
4226,"I have in my system installed cuda-8.0, cuda-9.0, cuda-9.1.",Bug Reproduction
4227,You don't have to remove anything to make it work with tensorflow.,Solution Discussion
4228,"Instead if you are missing cuda-9.0 from your system, as other have already pointed then you'll need to install it that is a prerequisite for tensorflow to work properly.",Solution Discussion
4229,If you have cuda-9.0 installed on you system and tensorflow is complaining about CODE again as others have said expose that during runtime through your  CODE environment variable in your CODE make it point to CODE.,Solution Discussion
4230,This should be working even for tensorflow 1.7.,Solution Discussion
4231,What I have tried and failed to accomplish is build from source.,Solution Discussion
4232,For some reason bazel always exits with an error. If you try to build with cuda-9.0/cuda-9.1 and cudnn7 it complains about gcc7.,Solution Discussion
4233,Using gcc5 compilation seems to be working fine but then at the end I always get an error and the build is unsuccessful.,Solution Discussion
4234,My question is if anyone has managed to compile from source with cuda-9.1/cuda-9.0 without problems?,Solution Discussion
4235,This worked for me: Download CUDA Toolkit 9.0 from NVidia previous releases section.,Solution Discussion
4236,Then: CODE,Solution Discussion
4237,Notice 9.0 at the last line above.,Solution Discussion
4238,CODE,Solution Discussion
4239,My setupTensorflow 1.7cuDNN 7.1.2Ubuntu 16.04,Bug Reproduction
4240,Thank you for your post :),Social Conversation
4241,I had teh same situation.,Bug Reproduction
4242,"I had cuda 9.1, and tensorflow would not find libraries for cuda 9.0.",Bug Reproduction
4243,I have installed cuda 9.0 with command: sudo apt-get install cuda-libraries-9-0,Solution Discussion
4244,That solved my problem.,Solution Discussion
4245,"So, I setCODE in pycharm Environment variable field and it works.",Solution Discussion
4246,the above worked for installing on Ubuntu Server 17.,Solution Discussion
4247,"namely, -         installing cuda-9.0 (NOT 9.1)-         cuDNN v7.1.2 (Mar 21, 2018) for CUDA 9.0-         everything else according to the official tf installation instructions",Solution Discussion
4248,much easier than compiling.,Solution Discussion
4249,be careful conda users.,Social Conversation
4250,"i hit the same problem and was scratching my head for two days, until finally i discovered that local copy of libcudnn.so was used by conda, under:/miniconda3/lib/libcudnn.so which pointed to libcudnn.so.7 which pointed to libcudnn.so.7.0.5",Investigation and Exploration
4251,i don't remember who and how placed it there but pretty much it overloaded the system default libcudnn.so.7.1.2 !!!,Investigation and Exploration
4252,"once removed, everything works like a charm:tensorflow 1.7 or 1.8-nightly, cuda-9.1, cudnn-7.1.2 on ubuntu 16.04",Solution Discussion
4253,"Somehow, I solved this by installing:cuda 9.1 (from package manager),cudnn 7.1 for 9.1and from anaconda:by using this default command 'conda install -c anaconda tensorflow-gpu'cudatoolkit 9.0,tensorflow 1.7,tensorflow-gpu 1.7",Solution Discussion
4254,"I used Antergos linux, GTX 1060 in my PC.",Solution Discussion
4255,"It worked as well in my notebook (Xubuntu 18.04, GT 840m).",Solution Discussion
4256,"In my notebook i used :cuda 9.1 (from nvidia ppa), cudnn 7.1 for 9.1 (from nvidia web), and the rest was the same",Solution Discussion
4257,Thanks @Suananda!,Social Conversation
4258,It works like magic.,Solution Discussion
4259,"If you have old version of CUDA, the library link may point to the old library even you install the newer CUDA especially if you install it manually.",Investigation and Exploration
4260,"Try delete your old installation, and then sudo ldconfig to update the dynamic links.",Solution Discussion
4261,No solution yet!?,Task Progress
4262,For anyone that might stumble on this I have released a community wheel of latest tensorflow 1.8.0-rc1 built with cuda 9.1.,Solution Discussion
4263,You can find it [here] URL !,Solution Discussion
4264,"I have find the reason is ldconf,  ldconfig is a dynamic link library management command whose purpose is to allow the dynamic link library to be usedby the system.",Investigation and Exploration
4265,"The default ldconf only search /lib and /usr/lib, as well as the library file under the directory listed in the configuration file /etc/ld. so. conf.",Investigation and Exploration
4266,so all of this is caused by the  dynamic library of CUDA in the installed CUDA path such as : /path/cuda-9.0/lib64  or /path/cuda-9.0/lib. (for eample my CUDA is installed in /usr/local/cuda-9.0),Investigation and Exploration
4267,"1.         if you install the CUDA manual,  then after install, you should add the  path of cuda/lib64 to /etc/ld.so.conf fileCODEthenCODE",Solution Discussion
4268,"of course , you can add the path manual, like:CODEthen add the path  '/usr/local/cuda-9.0/lib64' at the end.",Solution Discussion
4269,"CODEafter the operation, reopen the ipython or pycharm ,import tensorflow as  tf",Solution Discussion
4270,"wow, you will enjoy it!",Social Conversation
4271,"2.         if you install the CUDA by command such as 'dpkg -i cuda-repo-ubuntu1604_9.0.176-1_amd64.deb' or others, it may add the cuda lib path to the /etc/ld.so.conf  automatically .",Solution Discussion
4272,"but to be on the safe side, check the /etc/ld.so.conf and see if the path add to it .",Solution Discussion
4273,"@NYcleanerOn Ubuntu, there is a CODE file containing :CODE",Solution Discussion
4274,Is this enough or do I need to add the directory CODE to it ?,Solution Discussion
4275,@sebmayou  should add  the CODE path  to itï¼ the ***.so files  are in the  lib64,Solution Discussion
4276,CODE,Solution Discussion
4277,from https://gist.github.com/zhanwenchen/e520767a409325d9961072f666815bb8,Solution Discussion
4278,@mashu Well the other option is that the community provides pre-built [wheels] URL .,Solution Discussion
4279,If you read 2-3 threads above you'll also see that mentioned again.,Solution Discussion
4280,"@Suananda  Thanks, it works for me in a tensorflow conda environment.",Solution Discussion
4281,"Suggest the official guys to modify the installation guide ""https://www.tensorflow.org/install/install_linux#InstallingAnaconda"", step 4 of Anaconda installing, from ""pip install --ignore-installed --upgrade tfBinaryURL"" to ""conda install -c anaconda tensorflow-gpu""",Solution Discussion
4282,Softlink seems not solve this issue: CODE,Solution Discussion
4283,Still got: CODE,Solution Discussion
4284,"when I run my code on the linux environment directly, everything is OK.",Bug Reproduction
4285,"But when I run on the local pycharm through the remote interpreter, I encounter the problem: CODE",Bug Reproduction
4286,export PATH=${PATH}:/usr/local/cuda-9.0/binexport CUDA_HOME=${CUDA_HOME}:/usr/local/cuda:/usr/local/cuda-9.0export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda-9.0/lib64export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64,Solution Discussion
4287,if use pycharm - add it to interpreter,Solution Discussion
4288,what about f** I just only want to use tensorflow1.8 and cuda9.1?,Motivation
4289,@dongzhuoyao So what's the problem?,Solution Discussion
4290,look at my comment 6 threads above and you'll find your solution there!,Solution Discussion
4291,I guess the problem has cropped up again with CODE and CODE.,Bug Reproduction
4292,"In a virtualenv, I get:CODE",Bug Reproduction
4293,My CODE folder has the following libcublas:CODE,Bug Reproduction
4294,Versions:CODE,Bug Reproduction
4295,We'll need an update to tensorflow-gpu to use cuda 9.2.,Solution Discussion
4296,"Also, if I were to downgrade to cuda 9.0, would I have to first remove cuda 9.2 or just install 9.0 straight away?",Solution Discussion
4297,Would I have conflicting installations?,Solution Discussion
4298,@mebble Here you go: [link] URL .,Solution Discussion
4299,That's tf 1.8 wheel for cuda 9.2.,Solution Discussion
4300,Don't downgrade.,Solution Discussion
4301,Install whatever other version you want they'll get installed at CODE,Solution Discussion
4302,Thanks!,Social Conversation
4303,I forgot to mention that im using CODE and pip CODE.,Solution Discussion
4304,I think the wheel is for python 3.6 so the install doesn't work.,Solution Discussion
4305,Do you have one for 3.5 as well?,Solution Discussion
4306,@kirk86 after installing the whl you gave it throws a similar error for libmpi.so.40,Solution Discussion
4307,"I'm on CentOS and K80 GPU, cuda 9.2 and cudnn v7.1",Solution Discussion
4308,### Suggestion,Solution Discussion
4309,"As far as I know you can have sub-packages xxx,yyy,zzz etc.. and install them as followCODE",Solution Discussion
4310,This way different co-existing back-ends can be provided.,Solution Discussion
4311,"Tensorflow can be build with different options, so at least a couple of cuda-toolkit builds could be provided this way.",Solution Discussion
4312,"The whole point of package is to save time of building, but package build for very specific set of libraries that installs fine, but does not work is counter-productive.",Solution Discussion
4313,It would be better off not to have such package in the first place.,Solution Discussion
4314,@mebble just make a conda virtual environment for python 3.6.,Solution Discussion
4315,Make sure that you also have installed on your system openmpi.,Solution Discussion
4316,@pavan-08 Install openmpi on your system also nccl 2.x whatever is the latest from nvidia.,Solution Discussion
4317,"I've compiled tf with most of the packages and libraries, so it can be used hdfs, kafta, aws, etc.",Solution Discussion
4318,That's why is asking libmpi.so because it's from openmpi library.,Solution Discussion
4319,With cuda 9.2 and tensorflow-gpu 1.8 I cannot build tensorflow,Solution Discussion
4320,declared output 'external/local_config_cuda/cuda/cuda/lib/libcudnn.so.7' is a dangling symbolic link,Solution Discussion
4321,The symlink exists,Solution Discussion
4322,Versions: Ubuntu 17.10cuda 9.2cudnn 7.1.4tensorflow-gpu 1.8.0,Solution Discussion
4323,Cuda is only compatible with Nvidia graphics card.,Solution Discussion
4324,If you still have the error after downgrading to tf-gpu 1.4; maybe you don't have a Nvidia !,Solution Discussion
4325,You can check your graphic card with the command :,Solution Discussion
4326,CODE,Solution Discussion
4327,"This works for me (tensorflow-gpu==1.8.0 and cuda version is 9.0, install in anaconda)",Solution Discussion
4328,CODE,Solution Discussion
4329,suggestion from: https://stackoverflow.com/questions/48428415/importerror-libcublas-so-9-0-cannot-open-shared-object-file,Solution Discussion
4330,However we cannot merge GPL code into TensorFlow.,Action on Issue
4331,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4332,This issue can be closed from my end.,Action on Issue
4333,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4334,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4335,Let's leave it open for now and think about it a bit more.,Action on Issue
4336,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
4337,I think this issue should still be open.,Action on Issue
4338,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4339,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4340,I'll close this (broad) bug now.,Action on Issue
4341,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4342,Let's leave it open for now and think about it a bit more.,Action on Issue
4343,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4344,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4345,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4346,If so we can close this issue.,Action on Issue
4347,I will submit a PR.,Action on Issue
4348,Please open a new issue for related bugs.,Action on Issue
4349,I think this issue should still be open.,Action on Issue
4350,Please update the label and/or status accordingly.,Action on Issue
4351,This thread has drastically diverged from its original issue.,Action on Issue
4352,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4353,If so we can close this issue.,Action on Issue
4354,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4355,Closing.,Action on Issue
4356,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4357,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4358,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
4359,This issue can be closed from my end.,Action on Issue
4360,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4361,Please update the label and/or status accordingly.,Action on Issue
4362,You can cherry-pick 6c99d797 if you wish.,Action on Issue
4363,Please open a new issue for related bugs.,Action on Issue
4364,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4365,Closing for now.,Action on Issue
4366,"Otherwise, remove the CODE label.",Action on Issue
4367,closing.,Action on Issue
4368,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4369,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4370,I think this issue should still be open.,Action on Issue
4371,I think this issue should still be open.,Action on Issue
4372,You can cherry-pick 6c99d797 if you wish.,Action on Issue
4373,Just merged it.,Action on Issue
4374,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4375,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4376,I will submit a PR.,Action on Issue
4377,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
4378,"Otherwise, remove the CODE label.",Action on Issue
4379,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4380,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4381,I will submit a PR.,Action on Issue
4382,Closing.,Action on Issue
4383,Please open a new issue for related bugs.,Action on Issue
4384,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4385,This thread has drastically diverged from its original issue.,Action on Issue
4386,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4387,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4388,Let's leave it open for now and think about it a bit more.,Action on Issue
4389,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
4390,@ry sure I can change the license surely :),Action on Issue
4391,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4392,I'll close this (broad) bug now.,Action on Issue
4393,Reopening this.,Action on Issue
4394,I think this issue should still be open.,Action on Issue
4395,I will close this issue.,Action on Issue
4396,I will close this issue.,Action on Issue
4397,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4398,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
4399,Please open a new issue for related bugs.,Action on Issue
4400,I will close this issue.,Action on Issue
4401,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4402,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4403,I will submit a PR.,Action on Issue
4404,If so we can close this issue.,Action on Issue
4405,"If so, the issue can be considered fixed, IMHO.",Action on Issue
4406,"You are right, reopening.",Action on Issue
4407,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4408,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4409,Closing for now.,Action on Issue
4410,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4411,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4412,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4413,"Otherwise, remove the CODE label.",Action on Issue
4414,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4415,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4416,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4417,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4418,Thanks @sjjpo2002 for your PR!,Action on Issue
4419,This thread has drastically diverged from its original issue.,Action on Issue
4420,Reopening this.,Action on Issue
4421,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4422,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4423,Reopening for visibility of the documentation issues.,Action on Issue
4424,If so we can close this issue.,Action on Issue
4425,Let's leave it open for now and think about it a bit more.,Action on Issue
4426,I think this issue should still be open.,Action on Issue
4427,Closing for now.,Action on Issue
4428,If so we can close this issue.,Action on Issue
4429,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4430,However we cannot merge GPL code into TensorFlow.,Action on Issue
4431,I will submit a PR.,Action on Issue
4432,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4433,Closing.,Action on Issue
4434,Please reopen if it reoccurs.,Action on Issue
4435,"If so, the issue can be considered fixed, IMHO.",Action on Issue
4436,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4437,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4438,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
4439,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4440,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4441,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4442,Closing this and making #1045 the master issue.,Action on Issue
4443,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4444,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4445,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4446,I think this issue should still be open.,Action on Issue
4447,I will close this issue.,Action on Issue
4448,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4449,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4450,Just merged it.,Action on Issue
4451,Please open a new issue for related bugs.,Action on Issue
4452,Let's leave it open for now and think about it a bit more.,Action on Issue
4453,I'll close this (broad) bug now.,Action on Issue
4454,Please open a new issue for related bugs.,Action on Issue
4455,Let's leave it open for now and think about it a bit more.,Action on Issue
4456,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4457,However we cannot merge GPL code into TensorFlow.,Action on Issue
4458,Just merged it.,Action on Issue
4459,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4460,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
4461,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4462,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
4463,Reopening for visibility of the documentation issues.,Action on Issue
4464,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4465,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4466,Please open a new issue for related bugs.,Action on Issue
4467,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4468,*         [x] CODE PR in #9808,Action on Issue
4469,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4470,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4471,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
4472,I'll close this (broad) bug now.,Action on Issue
4473,Reopening for visibility of the documentation issues.,Action on Issue
4474,Just merged it.,Action on Issue
4475,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4476,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4477,"You are right, reopening.",Action on Issue
4478,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4479,Please open a new issue for related bugs.,Action on Issue
4480,Please open a new issue for related bugs.,Action on Issue
4481,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4482,Just merged it.,Action on Issue
4483,Let's leave it open for now and think about it a bit more.,Action on Issue
4484,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4485,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4486,Please open a new issue for related bugs.,Action on Issue
4487,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
4488,Please reopen if it reoccurs.,Action on Issue
4489,Thanks @sjjpo2002 for your PR!,Action on Issue
4490,Please open a new issue for related bugs.,Action on Issue
4491,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4492,This thread has drastically diverged from its original issue.,Action on Issue
4493,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4494,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4495,*         [x] CODE PR in #9808,Action on Issue
4496,Closing.,Action on Issue
4497,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4498,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4499,This thread has drastically diverged from its original issue.,Action on Issue
4500,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4501,Thanks @sjjpo2002 for your PR!,Action on Issue
4502,Please reopen if it reoccurs.,Action on Issue
4503,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4504,Please open a new issue for related bugs.,Action on Issue
4505,*         [x] CODE PR in #9808,Action on Issue
4506,Just merged it.,Action on Issue
4507,Please open a new issue for related bugs.,Action on Issue
4508,Please update the label and/or status accordingly.,Action on Issue
4509,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4510,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4511,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
4512,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4513,This issue can be closed from my end.,Action on Issue
4514,Please update the label and/or status accordingly.,Action on Issue
4515,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4516,Please open a new issue for related bugs.,Action on Issue
4517,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4518,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
4519,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4520,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4521,Reopening this.,Action on Issue
4522,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4523,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4524,Closing for now.,Action on Issue
4525,Please open a new issue for related bugs.,Action on Issue
4526,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4527,Please update the label and/or status accordingly.,Action on Issue
4528,"If so, the issue can be considered fixed, IMHO.",Action on Issue
4529,Please reopen if it reoccurs.,Action on Issue
4530,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4531,Please open a new issue for related bugs.,Action on Issue
4532,closing.,Action on Issue
4533,Reopening this.,Action on Issue
4534,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4535,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4536,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4537,I'll close this (broad) bug now.,Action on Issue
4538,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
4539,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4540,Closing.,Action on Issue
4541,Closing for now.,Action on Issue
4542,@ry sure I can change the license surely :),Action on Issue
4543,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4544,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4545,closing.,Action on Issue
4546,"Reopen, please",Action on Issue
4547,*         [x] CODE PR in #9808,Action on Issue
4548,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4549,Reopening for visibility of the documentation issues.,Action on Issue
4550,Please open a new issue for related bugs.,Action on Issue
4551,"Otherwise, remove the CODE label.",Action on Issue
4552,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4553,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
4554,@ry sure I can change the license surely :),Action on Issue
4555,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4556,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4557,Please open a new issue for related bugs.,Action on Issue
4558,Closing this and making #1045 the master issue.,Action on Issue
4559,"You are right, reopening.",Action on Issue
4560,Closing.,Action on Issue
4561,This issue can be closed from my end.,Action on Issue
4562,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4563,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4564,Reopening this.,Action on Issue
4565,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4566,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4567,Thanks @sjjpo2002 for your PR!,Action on Issue
4568,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4569,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4570,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4571,Closing.,Action on Issue
4572,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4573,You can cherry-pick 6c99d797 if you wish.,Action on Issue
4574,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4575,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4576,You can cherry-pick 6c99d797 if you wish.,Action on Issue
4577,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4578,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4579,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4580,Please open a new issue for related bugs.,Action on Issue
4581,Please open a new issue for related bugs.,Action on Issue
4582,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4583,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4584,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
4585,"Otherwise, remove the CODE label.",Action on Issue
4586,*         [x] CODE PR in #9808,Action on Issue
4587,Closing for now.,Action on Issue
4588,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
4589,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4590,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
4591,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4592,Closing for now.,Action on Issue
4593,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4594,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4595,Reopening this.,Action on Issue
4596,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4597,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4598,"Otherwise, remove the CODE label.",Action on Issue
4599,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
4600,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4601,Let's leave it open for now and think about it a bit more.,Action on Issue
4602,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4603,I will close this issue.,Action on Issue
4604,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4605,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4606,Please open a new issue for related bugs.,Action on Issue
4607,Reopening for visibility of the documentation issues.,Action on Issue
4608,However we cannot merge GPL code into TensorFlow.,Action on Issue
4609,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4610,Please open a new issue for related bugs.,Action on Issue
4611,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4612,This thread has drastically diverged from its original issue.,Action on Issue
4613,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4614,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4615,Closing this and making #1045 the master issue.,Action on Issue
4616,@ry sure I can change the license surely :),Action on Issue
4617,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4618,Please update the label and/or status accordingly.,Action on Issue
4619,Closing for now.,Action on Issue
4620,"Reopen, please",Action on Issue
4621,"If so, the issue can be considered fixed, IMHO.",Action on Issue
4622,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4623,"You are right, reopening.",Action on Issue
4624,Reopening this.,Action on Issue
4625,If so we can close this issue.,Action on Issue
4626,If so we can close this issue.,Action on Issue
4627,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4628,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4629,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4630,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4631,You can cherry-pick 6c99d797 if you wish.,Action on Issue
4632,I will close this issue.,Action on Issue
4633,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4634,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
4635,Please open a new issue for related bugs.,Action on Issue
4636,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
4637,Please update the label and/or status accordingly.,Action on Issue
4638,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
4639,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4640,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4641,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4642,Please open a new issue for related bugs.,Action on Issue
4643,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
4644,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4645,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4646,Let's leave it open for now and think about it a bit more.,Action on Issue
4647,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4648,Reopening for visibility of the documentation issues.,Action on Issue
4649,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4650,Let's leave it open for now and think about it a bit more.,Action on Issue
4651,"If so, the issue can be considered fixed, IMHO.",Action on Issue
4652,This thread has drastically diverged from its original issue.,Action on Issue
4653,Please open a new issue for related bugs.,Action on Issue
4654,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4655,Please update the label and/or status accordingly.,Action on Issue
4656,Please open a new issue for related bugs.,Action on Issue
4657,Please open a new issue for related bugs.,Action on Issue
4658,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4659,closing.,Action on Issue
4660,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4661,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4662,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
4663,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4664,Please open a new issue for related bugs.,Action on Issue
4665,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4666,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4667,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4668,If so we can close this issue.,Action on Issue
4669,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4670,Please open a new issue for related bugs.,Action on Issue
4671,Please update the label and/or status accordingly.,Action on Issue
4672,I'll close this (broad) bug now.,Action on Issue
4673,Closing.,Action on Issue
4674,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4675,Please open a new issue for related bugs.,Action on Issue
4676,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4677,However we cannot merge GPL code into TensorFlow.,Action on Issue
4678,Closing this and making #1045 the master issue.,Action on Issue
4679,Just merged it.,Action on Issue
4680,I'll close this (broad) bug now.,Action on Issue
4681,Reopening this.,Action on Issue
4682,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4683,Please open a new issue for related bugs.,Action on Issue
4684,closing.,Action on Issue
4685,I will submit a PR.,Action on Issue
4686,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
4687,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4688,This issue can be closed from my end.,Action on Issue
4689,Please open a new issue for related bugs.,Action on Issue
4690,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4691,Please update the label and/or status accordingly.,Action on Issue
4692,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4693,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4694,Please open a new issue for related bugs.,Action on Issue
4695,I think this issue should still be open.,Action on Issue
4696,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4697,I think this issue should still be open.,Action on Issue
4698,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4699,Please open a new issue for related bugs.,Action on Issue
4700,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4701,Just merged it.,Action on Issue
4702,You can cherry-pick 6c99d797 if you wish.,Action on Issue
4703,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4704,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4705,Closing for now.,Action on Issue
4706,You can cherry-pick 6c99d797 if you wish.,Action on Issue
4707,Thanks @sjjpo2002 for your PR!,Action on Issue
4708,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4709,Please open a new issue for related bugs.,Action on Issue
4710,"If so, the issue can be considered fixed, IMHO.",Action on Issue
4711,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
4712,"Otherwise, remove the CODE label.",Action on Issue
4713,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4714,Please open a new issue for related bugs.,Action on Issue
4715,Please open a new issue for related bugs.,Action on Issue
4716,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4717,"Reopen, please",Action on Issue
4718,@ry sure I can change the license surely :),Action on Issue
4719,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4720,Reopening this.,Action on Issue
4721,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4722,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4723,closing.,Action on Issue
4724,Please update the label and/or status accordingly.,Action on Issue
4725,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4726,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4727,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4728,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4729,This issue can be closed from my end.,Action on Issue
4730,Please reopen if it reoccurs.,Action on Issue
4731,@ry sure I can change the license surely :),Action on Issue
4732,"Reopen, please",Action on Issue
4733,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4734,"Reopen, please",Action on Issue
4735,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4736,@ry sure I can change the license surely :),Action on Issue
4737,Please open a new issue for related bugs.,Action on Issue
4738,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4739,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4740,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4741,I think this issue should still be open.,Action on Issue
4742,"Otherwise, remove the CODE label.",Action on Issue
4743,closing.,Action on Issue
4744,Let's leave it open for now and think about it a bit more.,Action on Issue
4745,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4746,"If so, the issue can be considered fixed, IMHO.",Action on Issue
4747,Please open a new issue for related bugs.,Action on Issue
4748,Please reopen if it reoccurs.,Action on Issue
4749,Closing for now.,Action on Issue
4750,Reopening this.,Action on Issue
4751,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4752,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4753,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4754,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4755,Please open a new issue for related bugs.,Action on Issue
4756,Please update the label and/or status accordingly.,Action on Issue
4757,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4758,Please open a new issue for related bugs.,Action on Issue
4759,Please open a new issue for related bugs.,Action on Issue
4760,I will close this issue.,Action on Issue
4761,Reopening for visibility of the documentation issues.,Action on Issue
4762,I will submit a PR.,Action on Issue
4763,Closing this and making #1045 the master issue.,Action on Issue
4764,I think this issue should still be open.,Action on Issue
4765,Let's leave it open for now and think about it a bit more.,Action on Issue
4766,Please open a new issue for related bugs.,Action on Issue
4767,I think this issue should still be open.,Action on Issue
4768,Just merged it.,Action on Issue
4769,closing.,Action on Issue
4770,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
4771,I think this issue should still be open.,Action on Issue
4772,Please open a new issue for related bugs.,Action on Issue
4773,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4774,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4775,Thanks @sjjpo2002 for your PR!,Action on Issue
4776,This thread has drastically diverged from its original issue.,Action on Issue
4777,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4778,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4779,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4780,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4781,Please update the label and/or status accordingly.,Action on Issue
4782,However we cannot merge GPL code into TensorFlow.,Action on Issue
4783,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
4784,You can cherry-pick 6c99d797 if you wish.,Action on Issue
4785,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4786,"If so, the issue can be considered fixed, IMHO.",Action on Issue
4787,This thread has drastically diverged from its original issue.,Action on Issue
4788,This thread has drastically diverged from its original issue.,Action on Issue
4789,I will submit a PR.,Action on Issue
4790,Closing this and making #1045 the master issue.,Action on Issue
4791,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4792,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4793,Closing for now.,Action on Issue
4794,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4795,*         [x] CODE PR in #9808,Action on Issue
4796,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4797,Closing for now.,Action on Issue
4798,I will close this issue.,Action on Issue
4799,You can cherry-pick 6c99d797 if you wish.,Action on Issue
4800,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4801,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4802,Reopening for visibility of the documentation issues.,Action on Issue
4803,I think this issue should still be open.,Action on Issue
4804,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4805,Please open a new issue for related bugs.,Action on Issue
4806,Closing for now.,Action on Issue
4807,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4808,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4809,"Otherwise, remove the CODE label.",Action on Issue
4810,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4811,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
4812,Reopening for visibility of the documentation issues.,Action on Issue
4813,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
4814,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4815,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4816,Please open a new issue for related bugs.,Action on Issue
4817,*         [x] CODE PR in #9808,Action on Issue
4818,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
4819,Reopening this.,Action on Issue
4820,Please open a new issue for related bugs.,Action on Issue
4821,I'll close this (broad) bug now.,Action on Issue
4822,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
4823,I will close this issue.,Action on Issue
4824,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4825,This thread has drastically diverged from its original issue.,Action on Issue
4826,I'll close this (broad) bug now.,Action on Issue
4827,Please open a new issue for related bugs.,Action on Issue
4828,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4829,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4830,Please update the label and/or status accordingly.,Action on Issue
4831,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4832,Thanks @sjjpo2002 for your PR!,Action on Issue
4833,Please open a new issue for related bugs.,Action on Issue
4834,Thanks @sjjpo2002 for your PR!,Action on Issue
4835,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4836,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4837,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
4838,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4839,"If so, the issue can be considered fixed, IMHO.",Action on Issue
4840,This thread has drastically diverged from its original issue.,Action on Issue
4841,Thanks @sjjpo2002 for your PR!,Action on Issue
4842,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4843,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4844,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4845,This thread has drastically diverged from its original issue.,Action on Issue
4846,Closing this and making #1045 the master issue.,Action on Issue
4847,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4848,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4849,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4850,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4851,@ry sure I can change the license surely :),Action on Issue
4852,Please open a new issue for related bugs.,Action on Issue
4853,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4854,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4855,Please open a new issue for related bugs.,Action on Issue
4856,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4857,This issue can be closed from my end.,Action on Issue
4858,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4859,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4860,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
4861,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4862,"You are right, reopening.",Action on Issue
4863,Please open a new issue for related bugs.,Action on Issue
4864,Thanks @sjjpo2002 for your PR!,Action on Issue
4865,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
4866,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4867,If so we can close this issue.,Action on Issue
4868,Please open a new issue for related bugs.,Action on Issue
4869,I think this issue should still be open.,Action on Issue
4870,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4871,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4872,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4873,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4874,Closing this and making #1045 the master issue.,Action on Issue
4875,Closing for now.,Action on Issue
4876,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4877,closing.,Action on Issue
4878,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
4879,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4880,This thread has drastically diverged from its original issue.,Action on Issue
4881,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4882,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4883,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4884,Closing.,Action on Issue
4885,"Otherwise, remove the CODE label.",Action on Issue
4886,*         [x] CODE PR in #9808,Action on Issue
4887,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4888,Please update the label and/or status accordingly.,Action on Issue
4889,Please update the label and/or status accordingly.,Action on Issue
4890,Thanks @sjjpo2002 for your PR!,Action on Issue
4891,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4892,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4893,Please update the label and/or status accordingly.,Action on Issue
4894,I will close this issue.,Action on Issue
4895,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4896,"Otherwise, remove the CODE label.",Action on Issue
4897,Please update the label and/or status accordingly.,Action on Issue
4898,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
4899,*         [x] CODE PR in #9808,Action on Issue
4900,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4901,"Otherwise, remove the CODE label.",Action on Issue
4902,Please update the label and/or status accordingly.,Action on Issue
4903,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4904,Just merged it.,Action on Issue
4905,Reopening this.,Action on Issue
4906,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4907,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4908,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4909,Please open a new issue for related bugs.,Action on Issue
4910,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4911,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4912,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4913,Just merged it.,Action on Issue
4914,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4915,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4916,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4917,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4918,Let's leave it open for now and think about it a bit more.,Action on Issue
4919,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4920,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4921,*         [x] CODE PR in #9808,Action on Issue
4922,Please update the label and/or status accordingly.,Action on Issue
4923,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4924,Please open a new issue for related bugs.,Action on Issue
4925,Let's leave it open for now and think about it a bit more.,Action on Issue
4926,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4927,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4928,Thanks @sjjpo2002 for your PR!,Action on Issue
4929,Please open a new issue for related bugs.,Action on Issue
4930,If so we can close this issue.,Action on Issue
4931,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4932,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4933,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4934,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4935,This issue can be closed from my end.,Action on Issue
4936,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4937,"Otherwise, remove the CODE label.",Action on Issue
4938,@ry sure I can change the license surely :),Action on Issue
4939,"Otherwise, remove the CODE label.",Action on Issue
4940,I'll close this (broad) bug now.,Action on Issue
4941,Please open a new issue for related bugs.,Action on Issue
4942,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4943,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4944,I'll close this (broad) bug now.,Action on Issue
4945,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
4946,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
4947,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
4948,*         [x] CODE PR in #9808,Action on Issue
4949,"You are right, reopening.",Action on Issue
4950,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
4951,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4952,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
4953,Please open a new issue for related bugs.,Action on Issue
4954,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4955,I think this issue should still be open.,Action on Issue
4956,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
4957,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
4958,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4959,Closing for now.,Action on Issue
4960,Please update the label and/or status accordingly.,Action on Issue
4961,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
4962,Please update the label and/or status accordingly.,Action on Issue
4963,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4964,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
4965,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4966,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4967,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4968,Reopening for visibility of the documentation issues.,Action on Issue
4969,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
4970,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
4971,Let's leave it open for now and think about it a bit more.,Action on Issue
4972,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
4973,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
4974,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4975,I will close this issue.,Action on Issue
4976,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4977,"You are right, reopening.",Action on Issue
4978,Closing.,Action on Issue
4979,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4980,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
4981,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
4982,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
4983,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
4984,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4985,Closing.,Action on Issue
4986,"Otherwise, remove the CODE label.",Action on Issue
4987,Let's leave it open for now and think about it a bit more.,Action on Issue
4988,Please update the label and/or status accordingly.,Action on Issue
4989,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
4990,Please open a new issue for related bugs.,Action on Issue
4991,Let's leave it open for now and think about it a bit more.,Action on Issue
4992,Let's leave it open for now and think about it a bit more.,Action on Issue
4993,Closing this and making #1045 the master issue.,Action on Issue
4994,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
4995,Just merged it.,Action on Issue
4996,Let's leave it open for now and think about it a bit more.,Action on Issue
4997,Please update the label and/or status accordingly.,Action on Issue
4998,I will close this issue.,Action on Issue
4999,Let's leave it open for now and think about it a bit more.,Action on Issue
5000,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5001,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5002,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5003,*         [x] CODE PR in #9808,Action on Issue
5004,This issue can be closed from my end.,Action on Issue
5005,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5006,@ry sure I can change the license surely :),Action on Issue
5007,Please open a new issue for related bugs.,Action on Issue
5008,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5009,Closing.,Action on Issue
5010,Reopening for visibility of the documentation issues.,Action on Issue
5011,I will submit a PR.,Action on Issue
5012,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5013,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5014,However we cannot merge GPL code into TensorFlow.,Action on Issue
5015,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5016,closing.,Action on Issue
5017,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5018,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5019,Please open a new issue for related bugs.,Action on Issue
5020,"Otherwise, remove the CODE label.",Action on Issue
5021,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5022,Please open a new issue for related bugs.,Action on Issue
5023,Let's leave it open for now and think about it a bit more.,Action on Issue
5024,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5025,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5026,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5027,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5028,Let's leave it open for now and think about it a bit more.,Action on Issue
5029,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5030,I think this issue should still be open.,Action on Issue
5031,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5032,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5033,Please reopen if it reoccurs.,Action on Issue
5034,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5035,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5036,Thanks @sjjpo2002 for your PR!,Action on Issue
5037,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5038,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
5039,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
5040,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5041,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5042,"Otherwise, remove the CODE label.",Action on Issue
5043,Please update the label and/or status accordingly.,Action on Issue
5044,If so we can close this issue.,Action on Issue
5045,Please update the label and/or status accordingly.,Action on Issue
5046,I will submit a PR.,Action on Issue
5047,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5048,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5049,I will close this issue.,Action on Issue
5050,Thanks @sjjpo2002 for your PR!,Action on Issue
5051,Reopening this.,Action on Issue
5052,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5053,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5054,"Otherwise, remove the CODE label.",Action on Issue
5055,Closing this and making #1045 the master issue.,Action on Issue
5056,Please open a new issue for related bugs.,Action on Issue
5057,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5058,Please open a new issue for related bugs.,Action on Issue
5059,*         [x] CODE PR in #9808,Action on Issue
5060,"You are right, reopening.",Action on Issue
5061,Please open a new issue for related bugs.,Action on Issue
5062,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5063,Closing this and making #1045 the master issue.,Action on Issue
5064,I will close this issue.,Action on Issue
5065,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5066,Just merged it.,Action on Issue
5067,Please update the label and/or status accordingly.,Action on Issue
5068,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5069,@ry sure I can change the license surely :),Action on Issue
5070,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5071,I will close this issue.,Action on Issue
5072,Please update the label and/or status accordingly.,Action on Issue
5073,closing.,Action on Issue
5074,Please open a new issue for related bugs.,Action on Issue
5075,If so we can close this issue.,Action on Issue
5076,*         [x] CODE PR in #9808,Action on Issue
5077,"If so, the issue can be considered fixed, IMHO.",Action on Issue
5078,Let's leave it open for now and think about it a bit more.,Action on Issue
5079,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
5080,I will submit a PR.,Action on Issue
5081,closing.,Action on Issue
5082,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
5083,Closing for now.,Action on Issue
5084,Please open a new issue for related bugs.,Action on Issue
5085,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5086,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5087,I'll close this (broad) bug now.,Action on Issue
5088,Please open a new issue for related bugs.,Action on Issue
5089,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5090,"Otherwise, remove the CODE label.",Action on Issue
5091,Reopening this.,Action on Issue
5092,Closing for now.,Action on Issue
5093,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
5094,Closing for now.,Action on Issue
5095,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5096,"Otherwise, remove the CODE label.",Action on Issue
5097,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5098,Let's leave it open for now and think about it a bit more.,Action on Issue
5099,Closing for now.,Action on Issue
5100,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5101,However we cannot merge GPL code into TensorFlow.,Action on Issue
5102,This thread has drastically diverged from its original issue.,Action on Issue
5103,Please open a new issue for related bugs.,Action on Issue
5104,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5105,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5106,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5107,I will submit a PR.,Action on Issue
5108,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5109,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5110,Closing for now.,Action on Issue
5111,Closing for now.,Action on Issue
5112,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5113,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5114,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5115,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5116,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5117,Please open a new issue for related bugs.,Action on Issue
5118,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5119,If so we can close this issue.,Action on Issue
5120,Reopening this.,Action on Issue
5121,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5122,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5123,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5124,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5125,Please open a new issue for related bugs.,Action on Issue
5126,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5127,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5128,"Otherwise, remove the CODE label.",Action on Issue
5129,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5130,Thanks @sjjpo2002 for your PR!,Action on Issue
5131,If so we can close this issue.,Action on Issue
5132,Please reopen if it reoccurs.,Action on Issue
5133,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5134,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5135,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5136,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5137,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5138,I'll close this (broad) bug now.,Action on Issue
5139,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5140,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5141,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5142,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5143,I'll close this (broad) bug now.,Action on Issue
5144,Please open a new issue for related bugs.,Action on Issue
5145,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5146,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5147,Please update the label and/or status accordingly.,Action on Issue
5148,This thread has drastically diverged from its original issue.,Action on Issue
5149,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5150,This thread has drastically diverged from its original issue.,Action on Issue
5151,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
5152,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
5153,This thread has drastically diverged from its original issue.,Action on Issue
5154,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5155,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5156,I'll close this (broad) bug now.,Action on Issue
5157,Reopening for visibility of the documentation issues.,Action on Issue
5158,However we cannot merge GPL code into TensorFlow.,Action on Issue
5159,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
5160,Thanks @sjjpo2002 for your PR!,Action on Issue
5161,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5162,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5163,Please update the label and/or status accordingly.,Action on Issue
5164,I'll close this (broad) bug now.,Action on Issue
5165,However we cannot merge GPL code into TensorFlow.,Action on Issue
5166,Please open a new issue for related bugs.,Action on Issue
5167,Please update the label and/or status accordingly.,Action on Issue
5168,I'll close this (broad) bug now.,Action on Issue
5169,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
5170,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5171,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5172,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5173,This issue can be closed from my end.,Action on Issue
5174,Just merged it.,Action on Issue
5175,"If so, the issue can be considered fixed, IMHO.",Action on Issue
5176,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5177,Please open a new issue for related bugs.,Action on Issue
5178,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5179,"Otherwise, remove the CODE label.",Action on Issue
5180,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5181,I think this issue should still be open.,Action on Issue
5182,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5183,Please open a new issue for related bugs.,Action on Issue
5184,Reopening for visibility of the documentation issues.,Action on Issue
5185,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5186,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5187,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
5188,Please open a new issue for related bugs.,Action on Issue
5189,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5190,I'll close this (broad) bug now.,Action on Issue
5191,Please open a new issue for related bugs.,Action on Issue
5192,I think this issue should still be open.,Action on Issue
5193,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
5194,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
5195,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5196,"If so, the issue can be considered fixed, IMHO.",Action on Issue
5197,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5198,Please open a new issue for related bugs.,Action on Issue
5199,I think this issue should still be open.,Action on Issue
5200,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
5201,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5202,Closing this and making #1045 the master issue.,Action on Issue
5203,Please update the label and/or status accordingly.,Action on Issue
5204,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
5205,This thread has drastically diverged from its original issue.,Action on Issue
5206,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5207,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5208,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5209,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5210,closing.,Action on Issue
5211,If so we can close this issue.,Action on Issue
5212,"Otherwise, remove the CODE label.",Action on Issue
5213,Please update the label and/or status accordingly.,Action on Issue
5214,This issue can be closed from my end.,Action on Issue
5215,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5216,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5217,Please open a new issue for related bugs.,Action on Issue
5218,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5219,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5220,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5221,Please reopen if it reoccurs.,Action on Issue
5222,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5223,Please open a new issue for related bugs.,Action on Issue
5224,Let's leave it open for now and think about it a bit more.,Action on Issue
5225,*         [x] CODE PR in #9808,Action on Issue
5226,"Otherwise, remove the CODE label.",Action on Issue
5227,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5228,If so we can close this issue.,Action on Issue
5229,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5230,I'll close this (broad) bug now.,Action on Issue
5231,Reopening for visibility of the documentation issues.,Action on Issue
5232,I will close this issue.,Action on Issue
5233,I'll close this (broad) bug now.,Action on Issue
5234,I will submit a PR.,Action on Issue
5235,Please open a new issue for related bugs.,Action on Issue
5236,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5237,Please open a new issue for related bugs.,Action on Issue
5238,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5239,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5240,Please open a new issue for related bugs.,Action on Issue
5241,"Otherwise, remove the CODE label.",Action on Issue
5242,This thread has drastically diverged from its original issue.,Action on Issue
5243,Please open a new issue for related bugs.,Action on Issue
5244,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5245,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
5246,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5247,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5248,This thread has drastically diverged from its original issue.,Action on Issue
5249,Please open a new issue for related bugs.,Action on Issue
5250,Please reopen if it reoccurs.,Action on Issue
5251,Just merged it.,Action on Issue
5252,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5253,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5254,I think this issue should still be open.,Action on Issue
5255,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5256,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5257,Please open a new issue for related bugs.,Action on Issue
5258,closing.,Action on Issue
5259,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
5260,Please open a new issue for related bugs.,Action on Issue
5261,Let's leave it open for now and think about it a bit more.,Action on Issue
5262,Reopening for visibility of the documentation issues.,Action on Issue
5263,I'll close this (broad) bug now.,Action on Issue
5264,Thanks @sjjpo2002 for your PR!,Action on Issue
5265,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5266,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5267,*         [x] CODE PR in #9808,Action on Issue
5268,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5269,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5270,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5271,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5272,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5273,Reopening this.,Action on Issue
5274,Please open a new issue for related bugs.,Action on Issue
5275,*         [x] CODE PR in #9808,Action on Issue
5276,This issue can be closed from my end.,Action on Issue
5277,I think this issue should still be open.,Action on Issue
5278,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5279,@ry sure I can change the license surely :),Action on Issue
5280,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5281,Closing this and making #1045 the master issue.,Action on Issue
5282,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5283,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5284,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5285,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
5286,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5287,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5288,If so we can close this issue.,Action on Issue
5289,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5290,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5291,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
5292,Please update the label and/or status accordingly.,Action on Issue
5293,Please reopen if it reoccurs.,Action on Issue
5294,Please open a new issue for related bugs.,Action on Issue
5295,I'll close this (broad) bug now.,Action on Issue
5296,Please update the label and/or status accordingly.,Action on Issue
5297,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5298,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
5299,I'll close this (broad) bug now.,Action on Issue
5300,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5301,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
5302,Just merged it.,Action on Issue
5303,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5304,Reopening for visibility of the documentation issues.,Action on Issue
5305,Please open a new issue for related bugs.,Action on Issue
5306,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5307,If so we can close this issue.,Action on Issue
5308,"You are right, reopening.",Action on Issue
5309,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5310,closing.,Action on Issue
5311,Please open a new issue for related bugs.,Action on Issue
5312,@ry sure I can change the license surely :),Action on Issue
5313,Please update the label and/or status accordingly.,Action on Issue
5314,Please update the label and/or status accordingly.,Action on Issue
5315,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5316,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5317,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5318,I'll close this (broad) bug now.,Action on Issue
5319,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5320,Please open a new issue for related bugs.,Action on Issue
5321,I will submit a PR.,Action on Issue
5322,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5323,@ry sure I can change the license surely :),Action on Issue
5324,Please open a new issue for related bugs.,Action on Issue
5325,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5326,Let's leave it open for now and think about it a bit more.,Action on Issue
5327,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5328,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5329,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5330,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5331,Reopening this.,Action on Issue
5332,closing.,Action on Issue
5333,closing.,Action on Issue
5334,"Otherwise, remove the CODE label.",Action on Issue
5335,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5336,I will close this issue.,Action on Issue
5337,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5338,Please open a new issue for related bugs.,Action on Issue
5339,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5340,*         [x] CODE PR in #9808,Action on Issue
5341,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5342,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5343,"Otherwise, remove the CODE label.",Action on Issue
5344,Reopening this.,Action on Issue
5345,"Otherwise, remove the CODE label.",Action on Issue
5346,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5347,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5348,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5349,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
5350,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5351,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5352,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5353,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5354,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5355,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5356,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5357,However we cannot merge GPL code into TensorFlow.,Action on Issue
5358,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5359,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5360,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5361,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5362,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5363,I will close this issue.,Action on Issue
5364,closing.,Action on Issue
5365,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5366,Reopening this.,Action on Issue
5367,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
5368,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5369,"You are right, reopening.",Action on Issue
5370,Please reopen if it reoccurs.,Action on Issue
5371,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
5372,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5373,Please update the label and/or status accordingly.,Action on Issue
5374,Please open a new issue for related bugs.,Action on Issue
5375,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5376,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5377,Please open a new issue for related bugs.,Action on Issue
5378,This issue can be closed from my end.,Action on Issue
5379,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5380,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5381,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5382,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5383,@ry sure I can change the license surely :),Action on Issue
5384,Closing this and making #1045 the master issue.,Action on Issue
5385,@ry sure I can change the license surely :),Action on Issue
5386,However we cannot merge GPL code into TensorFlow.,Action on Issue
5387,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5388,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
5389,This issue can be closed from my end.,Action on Issue
5390,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5391,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5392,Reopening this.,Action on Issue
5393,Please update the label and/or status accordingly.,Action on Issue
5394,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5395,@ry sure I can change the license surely :),Action on Issue
5396,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
5397,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5398,This issue can be closed from my end.,Action on Issue
5399,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5400,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5401,closing.,Action on Issue
5402,Please open a new issue for related bugs.,Action on Issue
5403,"You are right, reopening.",Action on Issue
5404,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5405,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5406,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5407,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5408,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5409,"If so, the issue can be considered fixed, IMHO.",Action on Issue
5410,Please open a new issue for related bugs.,Action on Issue
5411,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
5412,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5413,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5414,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5415,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
5416,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5417,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue
5418,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
5419,This issue can be closed from my end.,Action on Issue
5420,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5421,Thanks @sjjpo2002 for your PR!,Action on Issue
5422,Please open a new issue for related bugs.,Action on Issue
5423,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5424,Reopening this.,Action on Issue
5425,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
5426,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5427,Please reopen if it reoccurs.,Action on Issue
5428,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5429,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5430,Please open a new issue for related bugs.,Action on Issue
5431,Reopening for visibility of the documentation issues.,Action on Issue
5432,Reopening this.,Action on Issue
5433,"Reopen, please",Action on Issue
5434,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5435,Please reopen if it reoccurs.,Action on Issue
5436,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5437,"Otherwise, remove the CODE label.",Action on Issue
5438,"Reopen, please",Action on Issue
5439,@ry sure I can change the license surely :),Action on Issue
5440,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5441,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5442,Please open a new issue for related bugs.,Action on Issue
5443,Closing.,Action on Issue
5444,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5445,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue
5446,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5447,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5448,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5449,Please open a new issue for related bugs.,Action on Issue
5450,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5451,Please open a new issue for related bugs.,Action on Issue
5452,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5453,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5454,Closing.,Action on Issue
5455,However we cannot merge GPL code into TensorFlow.,Action on Issue
5456,I think this issue should still be open.,Action on Issue
5457,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5458,Please update the label and/or status accordingly.,Action on Issue
5459,Please open a new issue for related bugs.,Action on Issue
5460,"Otherwise, remove the CODE label.",Action on Issue
5461,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5462,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5463,I will submit a PR.,Action on Issue
5464,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5465,Please reopen if it reoccurs.,Action on Issue
5466,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5467,Please open a new issue for related bugs.,Action on Issue
5468,closing.,Action on Issue
5469,Please open a new issue for related bugs.,Action on Issue
5470,Closing for now.,Action on Issue
5471,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5472,"Otherwise, remove the CODE label.",Action on Issue
5473,Closing this and making #1045 the master issue.,Action on Issue
5474,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5475,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5476,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5477,*         [x] CODE PR in #9808,Action on Issue
5478,Closing this and making #1045 the master issue.,Action on Issue
5479,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5480,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5481,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5482,Closing for now.,Action on Issue
5483,This thread has drastically diverged from its original issue.,Action on Issue
5484,I will close this issue.,Action on Issue
5485,I will close this issue.,Action on Issue
5486,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5487,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5488,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5489,"You are right, reopening.",Action on Issue
5490,Just merged it.,Action on Issue
5491,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
5492,Please open a new issue for related bugs.,Action on Issue
5493,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5494,I will close this issue.,Action on Issue
5495,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5496,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5497,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5498,"Reopen, please",Action on Issue
5499,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5500,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5501,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
5502,Reopening for visibility of the documentation issues.,Action on Issue
5503,Please open a new issue for related bugs.,Action on Issue
5504,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5505,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5506,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5507,Please update the label and/or status accordingly.,Action on Issue
5508,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5509,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5510,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5511,Please open a new issue for related bugs.,Action on Issue
5512,If so we can close this issue.,Action on Issue
5513,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5514,Reopening for visibility of the documentation issues.,Action on Issue
5515,Reopening for visibility of the documentation issues.,Action on Issue
5516,Please open a new issue for related bugs.,Action on Issue
5517,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5518,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5519,"You are right, reopening.",Action on Issue
5520,"If so, the issue can be considered fixed, IMHO.",Action on Issue
5521,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5522,I will submit a PR.,Action on Issue
5523,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5524,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5525,Closing this and making #1045 the master issue.,Action on Issue
5526,You can cherry-pick 6c99d797 if you wish.,Action on Issue
5527,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5528,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
5529,Please open a new issue for related bugs.,Action on Issue
5530,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5531,This issue can be closed from my end.,Action on Issue
5532,Thanks @sjjpo2002 for your PR!,Action on Issue
5533,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5534,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5535,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5536,Let's leave it open for now and think about it a bit more.,Action on Issue
5537,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue
5538,Reopening for visibility of the documentation issues.,Action on Issue
5539,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5540,"If so, the issue can be considered fixed, IMHO.",Action on Issue
5541,Reopening for visibility of the documentation issues.,Action on Issue
5542,Please open a new issue for related bugs.,Action on Issue
5543,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5544,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue
5545,*         [x] CODE PR in #9808,Action on Issue
5546,I think this issue should still be open.,Action on Issue
5547,I think this issue should still be open.,Action on Issue
5548,Reopening for visibility of the documentation issues.,Action on Issue
5549,I will submit a PR.,Action on Issue
5550,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5551,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5552,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
5553,If so we can close this issue.,Action on Issue
5554,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5555,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5556,Let's leave it open for now and think about it a bit more.,Action on Issue
5557,"Reopen, please",Action on Issue
5558,Let's leave it open for now and think about it a bit more.,Action on Issue
5559,I think this issue should still be open.,Action on Issue
5560,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5561,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5562,I will close this issue.,Action on Issue
5563,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5564,I will close this issue.,Action on Issue
5565,This thread has drastically diverged from its original issue.,Action on Issue
5566,@ry sure I can change the license surely :),Action on Issue
5567,Reopening this.,Action on Issue
5568,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5569,Please reopen if it reoccurs.,Action on Issue
5570,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5571,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5572,Please update the label and/or status accordingly.,Action on Issue
5573,*         [x] CODE PR in #9808,Action on Issue
5574,I think this issue should still be open.,Action on Issue
5575,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5576,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5577,Thanks @sjjpo2002 for your PR!,Action on Issue
5578,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5579,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
5580,Please reopen if it reoccurs.,Action on Issue
5581,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5582,Please update the label and/or status accordingly.,Action on Issue
5583,Please update the label and/or status accordingly.,Action on Issue
5584,Shouldn't this issue be re-opened given the latest findings?,Action on Issue
5585,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5586,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5587,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5588,I will submit a PR.,Action on Issue
5589,Please update the label and/or status accordingly.,Action on Issue
5590,If so we can close this issue.,Action on Issue
5591,This thread has drastically diverged from its original issue.,Action on Issue
5592,"Otherwise, remove the CODE label.",Action on Issue
5593,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5594,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
5595,This thread has drastically diverged from its original issue.,Action on Issue
5596,This issue can be closed from my end.,Action on Issue
5597,Reopening for visibility of the documentation issues.,Action on Issue
5598,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5599,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5600,Just merged it.,Action on Issue
5601,"Otherwise, remove the CODE label.",Action on Issue
5602,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5603,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5604,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue
5605,Closing this and making #1045 the master issue.,Action on Issue
5606,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5607,"Reopen, please",Action on Issue
5608,Let's leave it open for now and think about it a bit more.,Action on Issue
5609,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue
5610,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5611,Just merged it.,Action on Issue
5612,I think this issue should still be open.,Action on Issue
5613,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue
5614,Reopening this.,Action on Issue
5615,@ry sure I can change the license surely :),Action on Issue
5616,Please open a new issue for related bugs.,Action on Issue
5617,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue
5618,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5619,closing.,Action on Issue
5620,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5621,Just merged it.,Action on Issue
5622,closing.,Action on Issue
5623,Please open a new issue for related bugs.,Action on Issue
5624,"Otherwise, remove the CODE label.",Action on Issue
5625,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5626,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5627,"Otherwise, remove the CODE label.",Action on Issue
5628,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5629,"Reopen, please",Action on Issue
5630,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5631,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue
5632,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue
5633,*         [x] CODE PR in #9808,Action on Issue
5634,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5635,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue
5636,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue
5637,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5638,Please open a new issue for related bugs.,Action on Issue
5639,Let's leave it open for now and think about it a bit more.,Action on Issue
5640,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5641,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue
5642,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue
5643,Please open a new issue for related bugs.,Action on Issue
5644,However we cannot merge GPL code into TensorFlow.,Action on Issue
5645,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5646,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5647,Reopening this.,Action on Issue
5648,I think this issue should still be open.,Action on Issue
5649,Please open a new issue for related bugs.,Action on Issue
5650,closing.,Action on Issue
5651,"If so, the issue can be considered fixed, IMHO.",Action on Issue
5652,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue
5653,Thanks @sjjpo2002 for your PR!,Action on Issue
5654,Please open a new issue for related bugs.,Action on Issue
5655,Please open a new issue for related bugs.,Action on Issue
5656,Please update the label and/or status accordingly.,Action on Issue
5657,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue
5658,I'll close this (broad) bug now.,Action on Issue
5659,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5660,"Otherwise, remove the CODE label.",Action on Issue
5661,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5662,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5663,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue
5664,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue
5665,I think this issue should still be open.,Action on Issue
5666,Please open a new issue for related bugs.,Action on Issue
5667,Please open a new issue for related bugs.,Action on Issue
5668,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue
5669,Closing for now.,Action on Issue
5670,@ry sure I can change the license surely :),Action on Issue
5671,"Otherwise, remove the CODE label.",Action on Issue
5672,"If so, the issue can be considered fixed, IMHO.",Action on Issue
5673,Please update the label and/or status accordingly.,Action on Issue
5674,Let's leave it open for now and think about it a bit more.,Action on Issue
5675,*         [x] CODE PR in #9808,Action on Issue
5676,closing.,Action on Issue
5677,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue
5678,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue
5679,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue
5680,"@ogrisel I installed the CODE package, which uses version 1.12.1 and used branch CODE for CODE.",Bug Reproduction
5681,For information I had this issue while trying to stack LSTM cells:,Bug Reproduction
5682,It works when I have more than 2100 points but fails for lower values.,Bug Reproduction
5683,CODE,Bug Reproduction
5684,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
5685,Steps to reproduce: CODE,Bug Reproduction
5686,"First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.",Bug Reproduction
5687,"the origin code:from tensorflow.contrib import rnninputs = tf.placeholder(dtype=tf.int32, shape=[None, None], name=""inputs"")keep_prob = tf.placeholder(dtype=tf.float32, name=""keep_prob"")cell = rnn.GRUCell(10)cell = rnn.DropoutWrapper(cell=cell, input_keep_prob=keep_prob)cell = rnn.MultiRNNCell([cell for _ in range(5)], state_is_tuple=True) outs, states = tf.nn.dynamic_rnn(cell=cell, inputs=look_up, dtype=tf.float32)",Bug Reproduction
5688,See https://www.tensorflow.org/install/install_sources#common_installation_problemssudo apt-get install cuda-7-0vim ~/.bashrcexport PATH=/usr/local/cuda-7.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda7.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PAfor some common reasons and solutions.,Bug Reproduction
5689,Jupyer notebook:CODE>>CODE,Bug Reproduction
5690,"@yarikoptic, any suggestion of how we can reproduce these test environments?",Bug Reproduction
5691,"First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.",Bug Reproduction
5692,I've wasted lots of time failing to set up an appropriate debianvirtual machine.,Bug Reproduction
5693,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
5694,"Same problem here, working on Windows 10 with German text.",Bug Reproduction
5695,"Traceback (most recent call last):File ""utils.py"", line 15, in <module>import tensorflow as tfFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>from tensorflow.python import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>from tensorflow.python import pywrap_tensorflowFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>raise ImportError(msg)ImportError: Traceback (most recent call last):File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>from tensorflow.python.pywrap_tensorflow_internal import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>_pywrap_tensorflow_internal = swig_import_helper()File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory  Failed to load the native TensorFlow runtime.",Bug Reproduction
5696,OSX El Capitan Python 3.5.1scikit-learn==0.17.1scipy==0.17.1,Bug Reproduction
5697,"-         TSNE does not work with the other setup (where Tensorflow is activated, Python 2.x).",Bug Reproduction
5698,Versions:CODE,Bug Reproduction
5699,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Bug Reproduction
5700,"@tongda , I am using the Release Version of Tensorflow 1.0, working on MacOS in cpu mode.",Bug Reproduction
5701,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
5702,OS: Windows 10 x64 10.0.16299.309Python package: WinPython-64bit-3.6.1numpy (1.14.2)scikit-learn (0.19.1)scipy (1.0.0),Bug Reproduction
5703,"I have in my system installed cuda-8.0, cuda-9.0, cuda-9.1.",Bug Reproduction
5704,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
5705,"@lesteve I meant that I get the same error with a small number of instances, with the same system parameters (Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3)",Bug Reproduction
5706,I tried installing python and scikit dependency using CODE and the test passed for both CODE and CODE.,Bug Reproduction
5707,I met the same issue.,Bug Reproduction
5708,Here's a minimal example that now reproduces this issue:CODE,Bug Reproduction
5709,@ebrevdo i am running Tensorflow r1.0 (tensorflow-1.0.1-cp36-cp36m-linux_x86_64) on Red Hat and have the latest version of the translation tutorial from Github..,Bug Reproduction
5710,I'll get back to this if I'll be able to reproduce it with specific steps.,Bug Reproduction
5711,I have the same issue (with cuda 9.1 + tensorflow 1.5).,Bug Reproduction
5712,re original CODE,Bug Reproduction
5713,I believe I installed the right versions from nvidia.,Bug Reproduction
5714,or did I miss something?,Bug Reproduction
5715,Anyone have these issues when working with legacy_seq2seq.rnn_decoder()?,Bug Reproduction
5716,"This does not apply to CODE (4.4.0-21, Ubuntu 16.04) with the same packages under 3.5.",Bug Reproduction
5717,I tried this same code on a Linux and it runs well.,Bug Reproduction
5718,I can also reproduce the bug with the code sample from ivan-krukov,Bug Reproduction
5719,"i.e. > ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7f0fb51ebb00> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.....",Bug Reproduction
5720,*         post a fully stand-alone snippet (for your next issue).,Bug Reproduction
5721,"Thanks @ivan-krukov, but I'm failing to replicate in Python 3.3.",Bug Reproduction
5722,I cannot replicate either with OSX 10.11.5.,Bug Reproduction
5723,"Im facing the same issue, but I am trying to run tensorflow using nvidia-docker.",Bug Reproduction
5724,I cannot replicate either with OSX 10.11.5.,Bug Reproduction
5725,I met the same issue.,Bug Reproduction
5726,@jnothman it doesn't seem to be happening only on Python 3.5 so if you could try to reproduce with Python 2.7 (snippet: https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) that would be great.,Bug Reproduction
5727,@lesteve: i had this error using the setup you describe (two versions of numpy installed).,Bug Reproduction
5728,**The set up where TSNE works well:**,Bug Reproduction
5729,"More info: Darwin-16.6.0-x86_64-i386-64bit('Python', '2.7.13 (default, Apr  4 2017, 08:47:57) \n[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.2')",Bug Reproduction
5730,Indeed I was using an older image (jessie).,Bug Reproduction
5731,I met the same problem when using the Release Version of Tensorflow 1.0 and working on MacOS in cpu mode.,Bug Reproduction
5732,Terminal:CODE,Bug Reproduction
5733,And the output ofCODEis CODE,Bug Reproduction
5734,Jupyer notebook:CODE>>CODE,Bug Reproduction
5735,"i.e. > ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7f0fb51ebb00> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.....",Bug Reproduction
5736,I am also getting this issue and struggling to resolve it.,Bug Reproduction
5737,**Replicated**,Bug Reproduction
5738,@Concomitant can you reproduce the error on the stand-alone example given in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction
5739,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
5740,"If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).",Bug Reproduction
5741,My tf verstion is 1.1.0.,Bug Reproduction
5742,"The script ends correctly, showing the results as follows (sorry, I meant 50k not 500k): ![captura de pantalla de 2018-05-26 13-09-00] URL  ![captura de pantalla de 2018-05-26 13-09-51] URL ",Bug Reproduction
5743,I can also reproduce the bug with the code sample from ivan-krukov,Bug Reproduction
5744,Actually I read @Concomitant's code snippet too quickly:,Bug Reproduction
5745,I met the same issue.,Bug Reproduction
5746,It is fine and doesn't raise the ValueError.,Bug Reproduction
5747,"@lesteve I did with that exact snippet, yes.",Bug Reproduction
5748,@KaisJM I think it is more useful if you start from your freezing script and manage to simplify and post a fully stand-alone that freezes for you.,Bug Reproduction
5749,"I am getting the same problem on OS X 10.11.6, python 3.5.1,  sklearn 0.17.1 and numpy 1.11.1 .On this dataset: https://dl.dropboxusercontent.com/u/103591/vals.out (with np.savetxt)",Bug Reproduction
5750,Please give a reproducible code snippet.,Bug Reproduction
5751,"Python 3.6.1numpy 1.13.1scikit-learn master branch, last commit hash d6a42354145c92cf88093cbcc70b13f639319c38numpy was installed from pip, so this is with Accelerate.OSX version 10.12.4",Bug Reproduction
5752,"Traceback (most recent call last):File ""utils.py"", line 15, in <module>import tensorflow as tfFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>from tensorflow.python import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>from tensorflow.python import pywrap_tensorflowFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>raise ImportError(msg)ImportError: Traceback (most recent call last):File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>from tensorflow.python.pywrap_tensorflow_internal import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>_pywrap_tensorflow_internal = swig_import_helper()File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory  Failed to load the native TensorFlow runtime.",Bug Reproduction
5753,"My computer installed CUDA 8.0,cudnn 6.0 ,tensorflow 1.4.",Bug Reproduction
5754,I managed to find a way to reproduce I think by installing the numpy wheel and then scikit-learn via conda on top of it (got the hint from the CODE output in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762 where two CODE are listed).,Bug Reproduction
5755,CODE,Bug Reproduction
5756,"Following the same code, however: CODE",Bug Reproduction
5757,Versions:CODE,Bug Reproduction
5758,Same issue.,Bug Reproduction
5759,CODE,Bug Reproduction
5760,re original CODE,Bug Reproduction
5761,"the origin code:from tensorflow.contrib import rnninputs = tf.placeholder(dtype=tf.int32, shape=[None, None], name=""inputs"")keep_prob = tf.placeholder(dtype=tf.float32, name=""keep_prob"")cell = rnn.GRUCell(10)cell = rnn.DropoutWrapper(cell=cell, input_keep_prob=keep_prob)cell = rnn.MultiRNNCell([cell for _ in range(5)], state_is_tuple=True) outs, states = tf.nn.dynamic_rnn(cell=cell, inputs=look_up, dtype=tf.float32)",Bug Reproduction
5762,It seems fine on my linux machine Linux:,Bug Reproduction
5763,Terminal:CODE,Bug Reproduction
5764,My tf verstion is 1.1.0.,Bug Reproduction
5765,Reproduced for 3.5 with anaconda under OS X El Capitan.,Bug Reproduction
5766,The test code is:CODE,Bug Reproduction
5767,I confirm I cannot reproduce the issue on stretch with the following 32 bit image: CODE.,Bug Reproduction
5768,My CODE folder has the following libcublas:CODE,Bug Reproduction
5769,My orginial code was:CODE,Bug Reproduction
5770,"This does not apply to CODE (4.4.0-21, Ubuntu 16.04) with the same packages under 3.5.",Bug Reproduction
5771,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
5772,@bowu Same error here.,Bug Reproduction
5773,I re-ran code from a few weeks ago and now this issue appears.,Bug Reproduction
5774,"On branch remotes/origin/r1.1 it has the ""different variable scope"" error.",Bug Reproduction
5775,"As i know, there is a function numpy.save for saving an array to a binary file in .npy format~~",Bug Reproduction
5776,Error message: AssertionError: 0.89166666666666661 not greater than 0.9,Bug Reproduction
5777,"Mac OX Sierra, TensorFlow 1.1.0-rc1, Python 2.7.10 & Python 3.6.1.",Bug Reproduction
5778,"Same problem here, working on Windows 10 with German text.",Bug Reproduction
5779,The test code is:CODE,Bug Reproduction
5780,I had teh same situation.,Bug Reproduction
5781,System info: CODE,Bug Reproduction
5782,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
5783,@ebrevdo i am running Tensorflow r1.0 (tensorflow-1.0.1-cp36-cp36m-linux_x86_64) on Red Hat and have the latest version of the translation tutorial from Github..,Bug Reproduction
5784,It seems fine on my linux machine Linux:,Bug Reproduction
5785,"-         TSNE does not work with the other setup (where Tensorflow is activated, Python 2.x).",Bug Reproduction
5786,But I got the same error:,Bug Reproduction
5787,"On branch remotes/origin/r1.1 it has the ""different variable scope"" error.",Bug Reproduction
5788,Do you have a specific configuration that could explain the difference?,Bug Reproduction
5789,Actually I read @Concomitant's code snippet too quickly:,Bug Reproduction
5790,"@amueller Ok, I will run it again with 500k rows and will post the results.",Bug Reproduction
5791,@lesteve I can reproduce the issue.,Bug Reproduction
5792,Now I'm getting the :,Bug Reproduction
5793,OS: Windows 10 x64 10.0.16299.309Python package: WinPython-64bit-3.6.1numpy (1.14.2)scikit-learn (0.19.1)scipy (1.0.0),Bug Reproduction
5794,"System Version: OS X 10.11.5Python 3.5.1 :: Continuum Analytics, Inc.numpy.**version** 1.11.1scipy.**version** 0.16.0sklearn.**version** 0.17.1",Bug Reproduction
5795,System info: CODE,Bug Reproduction
5796,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Bug Reproduction
5797,I guess the problem has cropped up again with CODE and CODE.,Bug Reproduction
5798,I tested the code in thomberg1's https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-337985212.,Bug Reproduction
5799,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction
5800,Steps to reproduce: CODE,Bug Reproduction
5801,@lesteve I can reproduce the issue.,Bug Reproduction
5802,I've wasted lots of time failing to set up an appropriate debianvirtual machine.,Bug Reproduction
5803,OS: Windows 10 x64 10.0.16299.309Python package: WinPython-64bit-3.6.1numpy (1.14.2)scikit-learn (0.19.1)scipy (1.0.0),Bug Reproduction
5804,Will try again.,Bug Reproduction
5805,This is on a amazon ec2 instance with stock ubuntu 16.04.,Bug Reproduction
5806,Still facing this problem with the same sample  code.,Bug Reproduction
5807,This will give you the best chance of getting good feed-back.,Bug Reproduction
5808,Here is an updated snippet: CODE,Bug Reproduction
5809,or did I miss something?,Bug Reproduction
5810,"As i know, there is a function numpy.save for saving an array to a binary file in .npy format~~",Bug Reproduction
5811,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
5812,I managed to find a way to reproduce I think by installing the numpy wheel and then scikit-learn via conda on top of it (got the hint from the CODE output in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762 where two CODE are listed).,Bug Reproduction
5813,Also @joelkuiper and @Concomitant can you please check that you can reproduce the problem on the current state of the scikit-learn master branch?,Bug Reproduction
5814,"Same with ('Scikit-Learn', '0.18.dev0')",Bug Reproduction
5815,Please give a reproducible code snippet.,Bug Reproduction
5816,I can confirm that test_preserve_trustworthiness_approximately also failed on a 64 bit Mac.,Bug Reproduction
5817,System info: CODE,Bug Reproduction
5818,"I followed the current install instructions for TF 1.5 (GPU, ubuntu, virtualenv) and it breaks as described above.",Bug Reproduction
5819,"Hi, I am using Tensorflow r1.0 using GPU built using source.",Bug Reproduction
5820,Same here.OSX 10.12.5,Bug Reproduction
5821,"I have cuda-9-0 installed on the host, but when I try to run my docker container I get CODE",Bug Reproduction
5822,I was receiving the error when executing the seq2seq tutorial,Bug Reproduction
5823,I test your data in ubuntu 14.04 LTS withPython==2.7.6scikit-learn==0.17.1numpy==1.8.2scipy==0.13.3,Bug Reproduction
5824,Error message: AssertionError: 0.89166666666666661 not greater than 0.9,Bug Reproduction
5825,I was handling with this issue as well.,Bug Reproduction
5826,"FWIW, my machine has no problem fitting iris with this snippet on the development version of sklearn.",Bug Reproduction
5827,I test your data in ubuntu 14.04 LTS withPython==2.7.6scikit-learn==0.17.1numpy==1.8.2scipy==0.13.3,Bug Reproduction
5828,"trying to get this thing running, which results in the same error: https://gist.github.com/danijar/c7ec9a30052127c7a1ad169eeb83f159#file-blog_tensorflow_sequence_classification-py-L38",Bug Reproduction
5829,I have CUDA 8.0 and Tensorflow 1.3.,Bug Reproduction
5830,"Linux-3.0.101-0.47.71-default-x86_64-with-SuSE-11-x86_64('Python', '2.7.12 |Anaconda 2.3.0 (64-bit)| (default, Jul  2 2016, 17:42:40) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.1')",Bug Reproduction
5831,@ebrevdo I am as well facing the same issue and unable to progress with seq2seq.,Bug Reproduction
5832,My orginial code was:CODE,Bug Reproduction
5833,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
5834,"2,4 GHz Intel Core i58 GB 1600 MHz DDR3",Bug Reproduction
5835,Which repo did you use to produce this failure?,Bug Reproduction
5836,"@amueller Ok, I will run it again with 500k rows and will post the results.",Bug Reproduction
5837,Failed to load the native TensorFlow runtime.,Bug Reproduction
5838,See https://www.tensorflow.org/install/install_sources#common_installation_problemssudo apt-get install cuda-7-0vim ~/.bashrcexport PATH=/usr/local/cuda-7.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda7.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PAfor some common reasons and solutions.,Bug Reproduction
5839,Just run these lines in a python shell CODE,Bug Reproduction
5840,"First I've installed tensorflow 1.5, it broke, and I get the following error:CODE",Bug Reproduction
5841,Same problem.,Bug Reproduction
5842,See https://www.tensorflow.org/install/install_sources#common_installation_problemssudo apt-get install cuda-7-0vim ~/.bashrcexport PATH=/usr/local/cuda-7.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda7.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PAfor some common reasons and solutions.,Bug Reproduction
5843,I installed following these instructionshttps://www.tensorflow.org/install/install_linux#nvidia_requirements_to_run_tensorflow_with_gpu_support,Bug Reproduction
5844,The relevant portion of the code in my seq2seq_model.py is:CODE,Bug Reproduction
5845,I ran into this issue too.,Bug Reproduction
5846,"I followed the current install instructions for TF 1.5 (GPU, ubuntu, virtualenv) and it breaks as described above.",Bug Reproduction
5847,I'll get back to this if I'll be able to reproduce it with specific steps.,Bug Reproduction
5848,@Concomitant can you reproduce the error on the stand-alone example given in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction
5849,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Bug Reproduction
5850,after upgrading my Nvidia stuff my older versions of TF in separate conda env's no longer work as the older TF wants : ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,Bug Reproduction
5851,System info: CODE,Bug Reproduction
5852,"When running the code with the Win 1.0.0/GPU Release, there is no issue.",Bug Reproduction
5853,I read the above comments and can reproduce this.,Bug Reproduction
5854,If only I could reproduce it on mymac.,Bug Reproduction
5855,"I am getting the same problem on OS X 10.11.6, python 3.5.1,  sklearn 0.17.1 and numpy 1.11.1 .On this dataset: https://dl.dropboxusercontent.com/u/103591/vals.out (with np.savetxt)",Bug Reproduction
5856,"yeah, i clicked the logs column after failing to work it out",Bug Reproduction
5857,CODE,Bug Reproduction
5858,"If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).",Bug Reproduction
5859,"When running the code with the Win 1.0.0/GPU Release, there is no issue.",Bug Reproduction
5860,Reproduced for 3.5 with anaconda under OS X El Capitan.,Bug Reproduction
5861,"whelp to add to it all,, After a major amount of hassle I got the Nvidia updated to the newest release see above, as the TF doc indicated that there were bugs in an earlier release..",Bug Reproduction
5862,The error dump as the following:CODE,Bug Reproduction
5863,"I have 8.0, 9.0, 9.1 installed + cudnn versions which seem specific to each.",Bug Reproduction
5864,I re-ran code from a few weeks ago and now this issue appears.,Bug Reproduction
5865,after upgrading my Nvidia stuff my older versions of TF in separate conda env's no longer work as the older TF wants : ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,Bug Reproduction
5866,"Hi, I am using Tensorflow r1.0 using GPU built using source.",Bug Reproduction
5867,I will try on a real mac hardware later.,Bug Reproduction
5868,cell = tf.contrib.rnn.MultiRNNCell([single_cell() for _ in range(num_layers)]),Bug Reproduction
5869,"@tongda , I am using the Release Version of Tensorflow 1.0, working on MacOS in cpu mode.",Bug Reproduction
5870,"If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).",Bug Reproduction
5871,Analogically **fails for low points' values**,Bug Reproduction
5872,"Mac OX Sierra, TensorFlow 1.1.0-rc1, Python 2.7.10 & Python 3.6.1.",Bug Reproduction
5873,Same issue.,Bug Reproduction
5874,"I followed the current install instructions for TF 1.5 (GPU, ubuntu, virtualenv) and it breaks as described above.",Bug Reproduction
5875,I will try on a real mac hardware later.,Bug Reproduction
5876,"Then as soon as you're done, you get this error (it is looking for cublas 9.0, which, from what I can read here, would not have worked either, as CUDA 9.1 is the default you get from NVIDIA).",Bug Reproduction
5877,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
5878,The relevant portion of the code in my seq2seq_model.py is:CODE,Bug Reproduction
5879,This will give you the best chance of getting good feed-back.,Bug Reproduction
5880,The error dump as the following:CODE,Bug Reproduction
5881,https://travis-ci.org/MacPython/scikit-learn-wheels,Bug Reproduction
5882,Please give a reproducible code snippet.,Bug Reproduction
5883,Any advice?,Bug Reproduction
5884,will try to reproduce with minimal code. CODE,Bug Reproduction
5885,It is fine and doesn't raise the ValueError.,Bug Reproduction
5886,@lesteve I can reproduce the issue.,Bug Reproduction
5887,"First I've installed tensorflow 1.5, it broke, and I get the following error:CODE",Bug Reproduction
5888,EDIT: I used this docker image: CODE,Bug Reproduction
5889,"I have the issue on a dataset of mine, on Anaconda, Py 3.5, sklearn 0.17.1, OSX El Capitan.",Bug Reproduction
5890,@KaisJM I think it is more useful if you start from your freezing script and manage to simplify and post a fully stand-alone that freezes for you.,Bug Reproduction
5891,"I followed the current install instructions for TF 1.5 (GPU, ubuntu, virtualenv) and it breaks as described above.",Bug Reproduction
5892,@lesteve and others I cannot reproduce the error with the [snippet posted earlier](https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) on the latest master with python 2.7.,Bug Reproduction
5893,This is on a amazon ec2 instance with stock ubuntu 16.04.,Bug Reproduction
5894,Please give a reproducible code snippet.,Bug Reproduction
5895,I tried to mimic as close as possible @boazsh's versions: CODE,Bug Reproduction
5896,then execute the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762.,Bug Reproduction
5897,@priidukull is your test failure reproducible?,Bug Reproduction
5898,System Version: OS X 10.11.5Python 3.5.1 :: Anaconda 4.0.0 (x86_64)numpy.version.version 1.11.0scipy.version 0.17.1sklearn.**version** 0.17.1,Bug Reproduction
5899,"I noticed that the TF 1.0  works fine with the newest version of translation tutorial if compiled from the source on branch remotes/origin/r1.0CODEthen build and install TensorFlow, it works fine.",Bug Reproduction
5900,The relevant portion of the code in my seq2seq_model.py is:CODE,Bug Reproduction
5901,@dmyersturnbull do you get the error when running the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction
5902,I read the above comments and can reproduce this.,Bug Reproduction
5903,"I have the issue on a dataset of mine, on Anaconda, Py 3.5, sklearn 0.17.1, OSX El Capitan.",Bug Reproduction
5904,Hmm actually I can reproduce but your snippet was not a complete reproducer.,Bug Reproduction
5905,I also occur the exactly same problem with kirk86.,Bug Reproduction
5906,Note: I also have cuda 9.1 installed instead of cuda 9.0.,Bug Reproduction
5907,"@amueller, running the script with 50k rows works as expected.",Bug Reproduction
5908,"I had the same problem as reported here, and I do not use conda.",Bug Reproduction
5909,My Python version is installed via brew on macOS Sierra 10.12.4,Bug Reproduction
5910,"I'm getting this issue (Cuda 9.1.85, cuDNN 7.05)",Bug Reproduction
5911,I will try on a real mac hardware later.,Bug Reproduction
5912,I met the same problem when using the Release Version of Tensorflow 1.0 and working on MacOS in cpu mode.,Bug Reproduction
5913,FWIW I can not reproduce the problem on my OS X VM.,Bug Reproduction
5914,Same issue here with the german model and CODE on Amazon Linux (also on Ubuntu Server 14.04 LTS) using python 3.5.,Bug Reproduction
5915,@bowu Same error here.,Bug Reproduction
5916,OS: Windows 10 x64 10.0.16299.309Python package: WinPython-64bit-3.6.1numpy (1.14.2)scikit-learn (0.19.1)scipy (1.0.0),Bug Reproduction
5917,re original CODE,Bug Reproduction
5918,I can reproduce the error with the example provided by @ivan-krukov .,Bug Reproduction
5919,It is fine and doesn't raise the ValueError.,Bug Reproduction
5920,"I have in my system installed cuda-8.0, cuda-9.0, cuda-9.1.",Bug Reproduction
5921,Same issue.,Bug Reproduction
5922,"However, blang's minimal example works on my Macbook (OSX 10.11.3) where I don't have OpenMP support in place (obviously only in single-thread).",Bug Reproduction
5923,@bowu Same error here.,Bug Reproduction
5924,"@tongda , I am using the Release Version of Tensorflow 1.0, working on MacOS in cpu mode.",Bug Reproduction
5925,I have the same issue (with cuda 9.1 + tensorflow 1.5).,Bug Reproduction
5926,Versions:CODE,Bug Reproduction
5927,I'll get back to this if I'll be able to reproduce it with specific steps.,Bug Reproduction
5928,"when I run my code on the linux environment directly, everything is OK.",Bug Reproduction
5929,Same issue.,Bug Reproduction
5930,I cannot replicate either with OSX 10.11.5.,Bug Reproduction
5931,I can confirm that test_preserve_trustworthiness_approximately also failed on a 64 bit Mac.,Bug Reproduction
5932,I read the above comments and can reproduce this.,Bug Reproduction
5933,"My computer installed CUDA 8.0,cudnn 6.0 ,tensorflow 1.4.",Bug Reproduction
5934,"My computer installed CUDA 8.0,cudnn 6.0 ,tensorflow 1.4.",Bug Reproduction
5935,I met the same problem when using the Release Version of Tensorflow 1.0 and working on MacOS in cpu mode.,Bug Reproduction
5936,"Same with ('Scikit-Learn', '0.18.dev0')",Bug Reproduction
5937,I am getting the same error when trying to run the translate example (even when doing the small self test) which can be found here: https://github.com/tensorflow/models/tree/master/tutorials/rnn/translate,Bug Reproduction
5938,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
5939,"i.e. > ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7f0fb51ebb00> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.....",Bug Reproduction
5940,Same here.OSX 10.12.5,Bug Reproduction
5941,"@jnothman in case you want to reproduce the problem, IIRC you can create an environment with Accelerate on OSX  with something like:CODE",Bug Reproduction
5942,*         post a fully stand-alone snippet (for your next issue).,Bug Reproduction
5943,"I tried two setups, where",Bug Reproduction
5944,@ebrevdo I meet the same error when running the sequence_to_sequence model on the tensorflow1.1 website.,Bug Reproduction
5945,Failed to load the native TensorFlow runtime.,Bug Reproduction
5946,**Terminal:**CODE,Bug Reproduction
5947,This is on a amazon ec2 instance with stock ubuntu 16.04.,Bug Reproduction
5948,I was trying to run the translate example: python2.7 translate.py --data_dir data/ --train_dir train/ --size=256 --num_layers=2 --steps_per_checkpoint=50,Bug Reproduction
5949,My Python version is installed via brew on macOS Sierra 10.12.4,Bug Reproduction
5950,Actually I read @Concomitant's code snippet too quickly:,Bug Reproduction
5951,"The only way we can investigate, is that you post a fully standalone snippet which we can just copy and paste in an IPython sesion and see if we can reproduce the problem.",Bug Reproduction
5952,"@lesteve I did with that exact snippet, yes.",Bug Reproduction
5953,My tf verstion is 1.1.0.,Bug Reproduction
5954,Steps to reproduce: CODE,Bug Reproduction
5955,"The best way of turning these 5 hours into something useful for the project, would be to provide us with a stand-alone example reproducing the problem.",Bug Reproduction
5956,Anyone have these issues when working with legacy_seq2seq.rnn_decoder()?,Bug Reproduction
5957,@lesteve and others I cannot reproduce the error with the [snippet posted earlier](https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) on the latest master with python 2.7.,Bug Reproduction
5958,My orginial code was:CODE,Bug Reproduction
5959,"Thanks @ivan-krukov, but I'm failing to replicate in Python 3.3.",Bug Reproduction
5960,I ran into this issue too.,Bug Reproduction
5961,I can not reproduce it anymore as before.,Bug Reproduction
5962,will try to reproduce with minimal code. CODE,Bug Reproduction
5963,Is there another way of getting this i386 build for debian?,Bug Reproduction
5964,Hmm actually I can reproduce but your snippet was not a complete reproducer.,Bug Reproduction
5965,The following code will make this similar mistake occure:(Piece of my code)CODE,Bug Reproduction
5966,It worked fine in Jupyter Notebook and command-line.,Bug Reproduction
5967,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x117f7cbd0> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_1/gru_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
5968,"I tried it on my other mac, and it works fine there.",Bug Reproduction
5969,@jnothman it doesn't seem to be happening only on Python 3.5 so if you could try to reproduce with Python 2.7 (snippet: https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) that would be great.,Bug Reproduction
5970,"Python 3.6.1numpy 1.13.1scikit-learn master branch, last commit hash d6a42354145c92cf88093cbcc70b13f639319c38numpy was installed from pip, so this is with Accelerate.OSX version 10.12.4",Bug Reproduction
5971,@dmyersturnbull do you get the error when running the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction
5972,The test code is:CODE,Bug Reproduction
5973,@priidukull is your test failure reproducible?,Bug Reproduction
5974,"Then as soon as you're done, you get this error (it is looking for cublas 9.0, which, from what I can read here, would not have worked either, as CUDA 9.1 is the default you get from NVIDIA).",Bug Reproduction
5975,"I have in my system installed cuda-8.0, cuda-9.0, cuda-9.1.",Bug Reproduction
5976,"I tried two setups, where",Bug Reproduction
5977,"I have in my system installed cuda-8.0, cuda-9.0, cuda-9.1.",Bug Reproduction
5978,Same issue on OS X EI Capitan using Python 3.5,Bug Reproduction
5979,"I have 8.0, 9.0, 9.1 installed + cudnn versions which seem specific to each.",Bug Reproduction
5980,"When running the code with the Win 1.0.0/GPU Release, there is no issue.",Bug Reproduction
5981,@ivan-krukov I bit the bullet today and installed an El Capitan VM.,Bug Reproduction
5982,Having the same problem with tensor flow 1.1.,Bug Reproduction
5983,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
5984,Still facing this problem with the same sample  code.,Bug Reproduction
5985,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x117f7cbd0> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_1/gru_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
5986,Failed to load the native TensorFlow runtime.,Bug Reproduction
5987,"I have the issue on a dataset of mine, on Anaconda, Py 3.5, sklearn 0.17.1, OSX El Capitan.",Bug Reproduction
5988,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction
5989,I don't understand why I am getting this error with the [seq2seq tutorial model] URL :CODE,Bug Reproduction
5990,I tested the code in thomberg1's https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-337985212.,Bug Reproduction
5991,"I did not install 9.1, at least not intentionally.",Bug Reproduction
5992,"Python 3.6.1numpy 1.13.1scikit-learn master branch, last commit hash d6a42354145c92cf88093cbcc70b13f639319c38numpy was installed from pip, so this is with Accelerate.OSX version 10.12.4",Bug Reproduction
5993,I will try on a real mac hardware later.,Bug Reproduction
5994,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
5995,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
5996,I can not reproduce it anymore as before.,Bug Reproduction
5997,cell = tf.contrib.rnn.MultiRNNCell([single_cell() for _ in range(num_layers)]),Bug Reproduction
5998,@ebrevdo i am running Tensorflow r1.0 (tensorflow-1.0.1-cp36-cp36m-linux_x86_64) on Red Hat and have the latest version of the translation tutorial from Github..,Bug Reproduction
5999,"@yarikoptic, any suggestion of how we can reproduce these test environments?",Bug Reproduction
6000,@KaisJM I think it is more useful if you start from your freezing script and manage to simplify and post a fully stand-alone that freezes for you.,Bug Reproduction
6001,"@ogrisel I installed the CODE package, which uses version 1.12.1 and used branch CODE for CODE.",Bug Reproduction
6002,Same issue on OS X EI Capitan using Python 3.5,Bug Reproduction
6003,It worked fine in Jupyter Notebook and command-line.,Bug Reproduction
6004,"I cannot reproduce either with python 3.5.1, numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1 from miniconda (with MKL) on a virtualbox with OSX El Capitan.",Bug Reproduction
6005,"I'm getting this issue (Cuda 9.1.85, cuDNN 7.05)",Bug Reproduction
6006,Steps to reproduce: CODE,Bug Reproduction
6007,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
6008,CODE,Bug Reproduction
6009,Reproduced for 3.5 with anaconda under OS X El Capitan.,Bug Reproduction
6010,Anyone have these issues when working with legacy_seq2seq.rnn_decoder()?,Bug Reproduction
6011,"i.e. > ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7f0fb51ebb00> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.....",Bug Reproduction
6012,@ivan-krukov I bit the bullet today and installed an El Capitan VM.,Bug Reproduction
6013,"FWIW, I have no problem running that snippet with: >>> import platform; print(platform.platform())Darwin-16.7.0-x86_64-i386-64bit>>> import sys; print(""Python"", sys.version)Python 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]>>> import numpy; print(""NumPy"", numpy.__version__)NumPy 1.13.1>>> import scipy; print(""SciPy"", scipy.__version__)SciPy 0.19.1>>> import sklearn; print(""Scikit-Learn"", sklearn.__version__)Scikit-Learn 0.18.2",Bug Reproduction
6014,**Replicated**,Bug Reproduction
6015,Versions:CODE,Bug Reproduction
6016,I was handling with this issue as well.,Bug Reproduction
6017,OSX El Capitan Python 3.5.1scikit-learn==0.17.1scipy==0.17.1,Bug Reproduction
6018,I was handling with this issue as well.,Bug Reproduction
6019,Same issue on OS X EI Capitan using Python 3.5,Bug Reproduction
6020,This will give you the best chance of getting good feed-back.,Bug Reproduction
6021,**The set up where TSNE works well:**,Bug Reproduction
6022,@ebrevdo I meet the same error when running the sequence_to_sequence model on the tensorflow1.1 website.,Bug Reproduction
6023,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6024,Same issue on OS X EI Capitan using Python 3.5,Bug Reproduction
6025,I have CUDA 8.0 and Tensorflow 1.3.,Bug Reproduction
6026,"i.e. > ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7f0fb51ebb00> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.....",Bug Reproduction
6027,"I am trying to follow the unmodified Seq2Seq translation tutorial, but I'm getting the same error.",Bug Reproduction
6028,"Same problem here, working on Windows 10 with German text.",Bug Reproduction
6029,"nvidia-smi also returns a gpu, this is a g3.4xlarge instance",Bug Reproduction
6030,"Same with ('Scikit-Learn', '0.18.dev0')",Bug Reproduction
6031,Example run: CODE,Bug Reproduction
6032,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
6033,Unfortunately I can not reproduce your problem.,Bug Reproduction
6034,I will try on a real mac hardware later.,Bug Reproduction
6035,It worked fine in Jupyter Notebook and command-line.,Bug Reproduction
6036,My orginial code was:CODE,Bug Reproduction
6037,after upgrading my Nvidia stuff my older versions of TF in separate conda env's no longer work as the older TF wants : ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,Bug Reproduction
6038,@priidukull is your test failure reproducible?,Bug Reproduction
6039,@ivan-krukov I bit the bullet today and installed an El Capitan VM.,Bug Reproduction
6040,I confirm I cannot reproduce the issue on stretch with the following 32 bit image: CODE.,Bug Reproduction
6041,That means anyone can copy and paste it in a IPython session and easily try to reproduce.,Bug Reproduction
6042,"I get the same problem with Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3.",Bug Reproduction
6043,"@amueller, running the script with 50k rows works as expected.",Bug Reproduction
6044,"FWIW, my machine has no problem fitting iris with this snippet on the development version of sklearn.",Bug Reproduction
6045,@jnothman it doesn't seem to be happening only on Python 3.5 so if you could try to reproduce with Python 2.7 (snippet: https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) that would be great.,Bug Reproduction
6046,"@lesteve I did with that exact snippet, yes.",Bug Reproduction
6047,Same issue here with the german model and CODE on Amazon Linux (also on Ubuntu Server 14.04 LTS) using python 3.5.,Bug Reproduction
6048,My CODE folder has the following libcublas:CODE,Bug Reproduction
6049,"However, blang's minimal example works on my Macbook (OSX 10.11.3) where I don't have OpenMP support in place (obviously only in single-thread).",Bug Reproduction
6050,"However, blang's minimal example works on my Macbook (OSX 10.11.3) where I don't have OpenMP support in place (obviously only in single-thread).",Bug Reproduction
6051,"@boazsh thanks a lot for the snippet, it is not deterministic though, can you edit it and use a CODE to make sure the random numbers are always the same on each run.",Bug Reproduction
6052,"Sorry, but I still get this on Python 3.5.1, scikit 0.17, scikit-learn 0.18 (commit 9e913c04d748), and Numpy 1.11.1 on Mac OS 10.11.5.",Bug Reproduction
6053,"I have the issue on a dataset of mine, on Anaconda, Py 3.5, sklearn 0.17.1, OSX El Capitan.",Bug Reproduction
6054,I also occur the exactly same problem with kirk86.,Bug Reproduction
6055,I have the exact same problem on OSX 10.10.5,Bug Reproduction
6056,"nvidia-smi also returns a gpu, this is a g3.4xlarge instance",Bug Reproduction
6057,"Mac OX Sierra, TensorFlow 1.1.0-rc1, Python 2.7.10 & Python 3.6.1.",Bug Reproduction
6058,"@boazsh thanks a lot for the snippet, it is not deterministic though, can you edit it and use a CODE to make sure the random numbers are always the same on each run.",Bug Reproduction
6059,"More info: Darwin-16.6.0-x86_64-i386-64bit('Python', '2.7.13 (default, Apr  4 2017, 08:47:57) \n[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.2')",Bug Reproduction
6060,Do you mind sharing your data X with me?,Bug Reproduction
6061,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
6062,Same issue.,Bug Reproduction
6063,"Mac OX Sierra, TensorFlow 1.1.0-rc1, Python 2.7.10 & Python 3.6.1.",Bug Reproduction
6064,@lesteve: i had this error using the setup you describe (two versions of numpy installed).,Bug Reproduction
6065,OS: Windows 10 x64 10.0.16299.309Python package: WinPython-64bit-3.6.1numpy (1.14.2)scikit-learn (0.19.1)scipy (1.0.0),Bug Reproduction
6066,I cannot reproduce either with python 2.7.12 from conda on OSX 10.11.3 either.,Bug Reproduction
6067,Still facing this problem with the same sample  code.,Bug Reproduction
6068,"For me, I installed cuda toolkit 8.0, and cudnn 5.1.",Bug Reproduction
6069,"Windows-10-10.0.15063-SP0Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]NumPy 1.14.1SciPy 1.0.0Scikit-Learn 0.19.1",Bug Reproduction
6070,I just tried this again and it seems to work now (reinstalled spaCy and the german model).,Bug Reproduction
6071,My orginial code was:CODE,Bug Reproduction
6072,**Error**:CODE,Bug Reproduction
6073,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
6074,"Sorry, but I still get this on Python 3.5.1, scikit 0.17, scikit-learn 0.18 (commit 9e913c04d748), and Numpy 1.11.1 on Mac OS 10.11.5.",Bug Reproduction
6075,I've wasted lots of time failing to set up an appropriate debianvirtual machine.,Bug Reproduction
6076,"Hi, I am using Tensorflow r1.0 using GPU built using source.",Bug Reproduction
6077,Same here.OSX 10.12.5,Bug Reproduction
6078,Do you mind sharing your data X with me?,Bug Reproduction
6079,after upgrading my Nvidia stuff my older versions of TF in separate conda env's no longer work as the older TF wants : ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,Bug Reproduction
6080,"-         TSNE works well with one setup (where Tensorflow is de-activated, Python-3.x), however,",Bug Reproduction
6081,instead of CODE it should be CODE otherwise the numpy RNG is not reseeded appropriately and one cannot get deterministic results.,Bug Reproduction
6082,Error message: AssertionError: 0.89166666666666661 not greater than 0.9,Bug Reproduction
6083,Analogically **fails for low points' values**,Bug Reproduction
6084,"On branch remotes/origin/r1.1 it has the ""different variable scope"" error.",Bug Reproduction
6085,Same problem.,Bug Reproduction
6086,"Following the same code, however: CODE",Bug Reproduction
6087,It seems fine on my linux machine Linux:,Bug Reproduction
6088,"FWIW, my machine has no problem fitting iris with this snippet on the development version of sklearn.",Bug Reproduction
6089,"FWIW, I have no problem running that snippet with: >>> import platform; print(platform.platform())Darwin-16.7.0-x86_64-i386-64bit>>> import sys; print(""Python"", sys.version)Python 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]>>> import numpy; print(""NumPy"", numpy.__version__)NumPy 1.13.1>>> import scipy; print(""SciPy"", scipy.__version__)SciPy 0.19.1>>> import sklearn; print(""Scikit-Learn"", sklearn.__version__)Scikit-Learn 0.18.2",Bug Reproduction
6090,Failed to load the native TensorFlow runtime.,Bug Reproduction
6091,or did I miss something?,Bug Reproduction
6092,My setupTensorflow 1.7cuDNN 7.1.2Ubuntu 16.04,Bug Reproduction
6093,"Windows-10-10.0.15063-SP0Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]NumPy 1.14.1SciPy 1.0.0Scikit-Learn 0.19.1",Bug Reproduction
6094,"I had the same problem as reported here, and I do not use conda.",Bug Reproduction
6095,It is fine and doesn't raise the ValueError.,Bug Reproduction
6096,My Python version is installed via brew on macOS Sierra 10.12.4,Bug Reproduction
6097,"@boazsh thanks a lot for the snippet, it is not deterministic though, can you edit it and use a CODE to make sure the random numbers are always the same on each run.",Bug Reproduction
6098,CODE,Bug Reproduction
6099,@ebrevdo i am running Tensorflow r1.0 (tensorflow-1.0.1-cp36-cp36m-linux_x86_64) on Red Hat and have the latest version of the translation tutorial from Github..,Bug Reproduction
6100,I had teh same situation.,Bug Reproduction
6101,I have the same problem and would really appreciate a fix (or workaround?),Bug Reproduction
6102,I was trying to run the translate example: python2.7 translate.py --data_dir data/ --train_dir train/ --size=256 --num_layers=2 --steps_per_checkpoint=50,Bug Reproduction
6103,@lesteve I can reproduce the issue.,Bug Reproduction
6104,I am getting the same error when trying to run the translate example (even when doing the small self test) which can be found here: https://github.com/tensorflow/models/tree/master/tutorials/rnn/translate,Bug Reproduction
6105,"I am trying to follow the unmodified Seq2Seq translation tutorial, but I'm getting the same error.",Bug Reproduction
6106,I tried to mimic as close as possible @boazsh's versions: CODE,Bug Reproduction
6107,"I get the same problem with Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3.",Bug Reproduction
6108,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
6109,Same issue.,Bug Reproduction
6110,Same problem.,Bug Reproduction
6111,@lesteve I can reproduce the issue.,Bug Reproduction
6112,@tshi1983I got the same problem with tensorflow 1.1-gpu for ubuntu.,Bug Reproduction
6113,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction
6114,I'm using CODE model with CODE cells.,Bug Reproduction
6115,"@amueller, running the script with 50k rows works as expected.",Bug Reproduction
6116,Steps to reproduce: CODE,Bug Reproduction
6117,Here's a minimal example that now reproduces this issue:CODE,Bug Reproduction
6118,OS: Windows 10 x64 10.0.16299.309Python package: WinPython-64bit-3.6.1numpy (1.14.2)scikit-learn (0.19.1)scipy (1.0.0),Bug Reproduction
6119,Also been having this problem.,Bug Reproduction
6120,Versions:CODE,Bug Reproduction
6121,"As i know, there is a function numpy.save for saving an array to a binary file in .npy format~~",Bug Reproduction
6122,I met the same issue.,Bug Reproduction
6123,Having the same problem with tensor flow 1.1.,Bug Reproduction
6124,My email is 370846270@qq.com,Bug Reproduction
6125,"2,4 GHz Intel Core i58 GB 1600 MHz DDR3",Bug Reproduction
6126,filenames wereCODEand CODE (version 7.0.5),Bug Reproduction
6127,"FWIW, I have no problem running that snippet with: >>> import platform; print(platform.platform())Darwin-16.7.0-x86_64-i386-64bit>>> import sys; print(""Python"", sys.version)Python 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]>>> import numpy; print(""NumPy"", numpy.__version__)NumPy 1.13.1>>> import scipy; print(""SciPy"", scipy.__version__)SciPy 0.19.1>>> import sklearn; print(""Scikit-Learn"", sklearn.__version__)Scikit-Learn 0.18.2",Bug Reproduction
6128,"Sorry, but I still get this on Python 3.5.1, scikit 0.17, scikit-learn 0.18 (commit 9e913c04d748), and Numpy 1.11.1 on Mac OS 10.11.5.",Bug Reproduction
6129,Note: I also have cuda 9.1 installed instead of cuda 9.0.,Bug Reproduction
6130,cell = tf.contrib.rnn.MultiRNNCell([single_cell() for _ in range(num_layers)]),Bug Reproduction
6131,"Python 3.6.1numpy 1.13.1scikit-learn master branch, last commit hash d6a42354145c92cf88093cbcc70b13f639319c38numpy was installed from pip, so this is with Accelerate.OSX version 10.12.4",Bug Reproduction
6132,Hmm actually I can reproduce but your snippet was not a complete reproducer.,Bug Reproduction
6133,Do you have a specific configuration that could explain the difference?,Bug Reproduction
6134,Also @joelkuiper and @Concomitant can you please check that you can reproduce the problem on the current state of the scikit-learn master branch?,Bug Reproduction
6135,I read the above comments and can reproduce this.,Bug Reproduction
6136,"I had the same problem as reported here, and I do not use conda.",Bug Reproduction
6137,"More info: Darwin-16.6.0-x86_64-i386-64bit('Python', '2.7.13 (default, Apr  4 2017, 08:47:57) \n[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.2')",Bug Reproduction
6138,"I cannot reproduce either with python 3.5.1, numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1 from miniconda (with MKL) on a virtualbox with OSX El Capitan.",Bug Reproduction
6139,"Hi, I am using Tensorflow r1.0 using GPU built using source.",Bug Reproduction
6140,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction
6141,@ebrevdo i am running Tensorflow r1.0 (tensorflow-1.0.1-cp36-cp36m-linux_x86_64) on Red Hat and have the latest version of the translation tutorial from Github..,Bug Reproduction
6142,It works when I have more than 2100 points but fails for lower values.,Bug Reproduction
6143,OS: Windows 10 x64 10.0.16299.309Python package: WinPython-64bit-3.6.1numpy (1.14.2)scikit-learn (0.19.1)scipy (1.0.0),Bug Reproduction
6144,Is there another way of getting this i386 build for debian?,Bug Reproduction
6145,That means anyone can copy and paste it in a IPython session and easily try to reproduce.,Bug Reproduction
6146,"@lesteve I did with that exact snippet, yes.",Bug Reproduction
6147,From a maintainer's point of view what we need is a fully stand-alone python snippet to see if we can reproduce.,Bug Reproduction
6148,-         specific to older versions of something (yet to figure out since numpy as nscipy are the same) since is not reproducible on current debian sid but reproducible on testing (from few days back) and other older releases.,Bug Reproduction
6149,@lesteve and others I cannot reproduce the error with the [snippet posted earlier](https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) on the latest master with python 2.7.,Bug Reproduction
6150,My Python version is installed via brew on macOS Sierra 10.12.4,Bug Reproduction
6151,Actually I read @Concomitant's code snippet too quickly:,Bug Reproduction
6152,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6153,I am also getting this issue and struggling to resolve it.,Bug Reproduction
6154,I have CUDA 8.0 and Tensorflow 1.3.,Bug Reproduction
6155,It is fine and doesn't raise the ValueError.,Bug Reproduction
6156,CODE,Bug Reproduction
6157,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Bug Reproduction
6158,Unfortunately I can not reproduce your problem.,Bug Reproduction
6159,**Replicated**,Bug Reproduction
6160,It is fine and doesn't raise the ValueError.,Bug Reproduction
6161,"Im facing the same issue, but I am trying to run tensorflow using nvidia-docker.",Bug Reproduction
6162,"First I've installed tensorflow 1.5, it broke, and I get the following error:CODE",Bug Reproduction
6163,"I had the same problem as reported here, and I do not use conda.",Bug Reproduction
6164,I was handling with this issue as well.,Bug Reproduction
6165,"Sure, where and in what format would you like it?",Bug Reproduction
6166,Do you mind sharing your data X with me?,Bug Reproduction
6167,I also occur the exactly same problem with kirk86.,Bug Reproduction
6168,Terminal:CODE,Bug Reproduction
6169,"More info: Darwin-16.6.0-x86_64-i386-64bit('Python', '2.7.13 (default, Apr  4 2017, 08:47:57) \n[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.2')",Bug Reproduction
6170,System Version: OS X 10.11.5Python 3.5.1 :: Anaconda 4.0.0 (x86_64)numpy.version.version 1.11.0scipy.version 0.17.1sklearn.**version** 0.17.1,Bug Reproduction
6171,"trying to get this thing running, which results in the same error: https://gist.github.com/danijar/c7ec9a30052127c7a1ad169eeb83f159#file-blog_tensorflow_sequence_classification-py-L38",Bug Reproduction
6172,@KaisJM I think it is more useful if you start from your freezing script and manage to simplify and post a fully stand-alone that freezes for you.,Bug Reproduction
6173,Reproduced for 3.5 with anaconda under OS X El Capitan.,Bug Reproduction
6174,It seems the way to use MultiRNNCell is correct:,Bug Reproduction
6175,I'll get back to this if I'll be able to reproduce it with specific steps.,Bug Reproduction
6176,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x11d32cbd0> with a different variable scope than its first use. First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/gru_cell'. Please create a new instance of the cell if you would like it to use a different set of weights. If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]). If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse). In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
6177,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
6178,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
6179,@ebrevdo i am running Tensorflow r1.0 (tensorflow-1.0.1-cp36-cp36m-linux_x86_64) on Red Hat and have the latest version of the translation tutorial from Github..,Bug Reproduction
6180,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
6181,Will try again.,Bug Reproduction
6182,CODE,Bug Reproduction
6183,"I have in my system installed cuda-8.0, cuda-9.0, cuda-9.1.",Bug Reproduction
6184,"I have cuda-9-0 installed on the host, but when I try to run my docker container I get CODE",Bug Reproduction
6185,"I tried again on a real mac running OSX El Capitan 10.11.3 (with anaconda's latest numpy scipy and scikit-learn, same setting as reported by @Concomitant in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-229703129) but could not reproduce the problem either (tried running the snippet several times).",Bug Reproduction
6186,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Bug Reproduction
6187,Same issue here with the german model and CODE on Amazon Linux (also on Ubuntu Server 14.04 LTS) using python 3.5.,Bug Reproduction
6188,Versions:CODE,Bug Reproduction
6189,@yarikoptic I am unable to reproduce the failure on 32bit debian CODE on docker.,Bug Reproduction
6190,I have the exact same problem on OSX 10.10.5,Bug Reproduction
6191,I have the exact same problem on OSX 10.10.5,Bug Reproduction
6192,OSX El Capitan Python 3.5.1scikit-learn==0.17.1scipy==0.17.1,Bug Reproduction
6193,"@yarikoptic On this link I see ""No entry in i386 database, check Packages-arch-specific"" (with ""Suite: experimental"").",Bug Reproduction
6194,CODE,Bug Reproduction
6195,I read the above comments and can reproduce this.,Bug Reproduction
6196,*         post a fully stand-alone snippet (for your next issue).,Bug Reproduction
6197,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6198,"When running the code with the Win 1.0.0/GPU Release, there is no issue.",Bug Reproduction
6199,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
6200,Analogically **fails for low points' values**,Bug Reproduction
6201,then execute the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762.,Bug Reproduction
6202,Hmm actually I can reproduce but your snippet was not a complete reproducer.,Bug Reproduction
6203,"I had cuda 9.1, and tensorflow would not find libraries for cuda 9.0.",Bug Reproduction
6204,I have the exact same problem on OSX 10.10.5,Bug Reproduction
6205,re original CODE,Bug Reproduction
6206,Same issue.,Bug Reproduction
6207,@ebrevdo I meet the same error when running the sequence_to_sequence model on the tensorflow1.1 website.,Bug Reproduction
6208,And the output ofCODEis CODE,Bug Reproduction
6209,Note: I also have cuda 9.1 installed instead of cuda 9.0.,Bug Reproduction
6210,Same issue here with the german model and CODE on Amazon Linux (also on Ubuntu Server 14.04 LTS) using python 3.5.,Bug Reproduction
6211,Unfortunately I can not reproduce your problem.,Bug Reproduction
6212,"@lesteve I meant that I get the same error with a small number of instances, with the same system parameters (Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3)",Bug Reproduction
6213,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
6214,Will try 3.5,Bug Reproduction
6215,The following code will make this similar mistake occure:(Piece of my code)CODE,Bug Reproduction
6216,The relevant portion of the code in my seq2seq_model.py is:CODE,Bug Reproduction
6217,But I got the same error:,Bug Reproduction
6218,"Windows-10-10.0.15063-SP0Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]NumPy 1.14.1SciPy 1.0.0Scikit-Learn 0.19.1",Bug Reproduction
6219,Jupyer notebook:CODE>>CODE,Bug Reproduction
6220,Anyone have these issues when working with legacy_seq2seq.rnn_decoder()?,Bug Reproduction
6221,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
6222,"FWIW, I have no problem running that snippet with: >>> import platform; print(platform.platform())Darwin-16.7.0-x86_64-i386-64bit>>> import sys; print(""Python"", sys.version)Python 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]>>> import numpy; print(""NumPy"", numpy.__version__)NumPy 1.13.1>>> import scipy; print(""SciPy"", scipy.__version__)SciPy 0.19.1>>> import sklearn; print(""Scikit-Learn"", sklearn.__version__)Scikit-Learn 0.18.2",Bug Reproduction
6223,"@boazsh thanks a lot for the snippet, it is not deterministic though, can you edit it and use a CODE to make sure the random numbers are always the same on each run.",Bug Reproduction
6224,My setupTensorflow 1.7cuDNN 7.1.2Ubuntu 16.04,Bug Reproduction
6225,CODE,Bug Reproduction
6226,The issue replicates for me when using the Windows/GPU build 105 on the [Shakespeare RNN Repo] URL .,Bug Reproduction
6227,I had teh same situation.,Bug Reproduction
6228,"I'm getting this issue (Cuda 9.1.85, cuDNN 7.05)",Bug Reproduction
6229,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
6230,"I'm on El-Capitan, but I'm failing to get a Python 3.5 installation up and running.",Bug Reproduction
6231,"@yarikoptic, any suggestion of how we can reproduce these test environments?",Bug Reproduction
6232,CODE,Bug Reproduction
6233,I tried to mimic as close as possible @boazsh's versions: CODE,Bug Reproduction
6234,Analogically **fails for low points' values**,Bug Reproduction
6235,Please give a reproducible code snippet.,Bug Reproduction
6236,I was receiving the error when executing the seq2seq tutorial,Bug Reproduction
6237,@lesteve I can reproduce the issue.,Bug Reproduction
6238,Error message: AssertionError: 0.89166666666666661 not greater than 0.9,Bug Reproduction
6239,I can not reproduce it anymore as before.,Bug Reproduction
6240,I'm using CODE model with CODE cells.,Bug Reproduction
6241,Anyone have these issues when working with legacy_seq2seq.rnn_decoder()?,Bug Reproduction
6242,And the output ofCODEis CODE,Bug Reproduction
6243,Just run these lines in a python shell CODE,Bug Reproduction
6244,Do you mind sharing your data X with me?,Bug Reproduction
6245,"But when I run on the local pycharm through the remote interpreter, I encounter the problem: CODE",Bug Reproduction
6246,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
6247,The problem is that I don't know if these results are going to be the best for my whole dataset.,Bug Reproduction
6248,"The only way we can investigate, is that you post a fully standalone snippet which we can just copy and paste in an IPython sesion and see if we can reproduce the problem.",Bug Reproduction
6249,I also tried on macOS (El Capitan) with Accelerate and could not reproduce either.,Bug Reproduction
6250,Same issue.,Bug Reproduction
6251,I will try on a real mac hardware later.,Bug Reproduction
6252,"I followed the current install instructions for TF 1.5 (GPU, ubuntu, virtualenv) and it breaks as described above.",Bug Reproduction
6253,"On branch remotes/origin/r1.1 it has the ""different variable scope"" error.",Bug Reproduction
6254,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
6255,I managed to find a way to reproduce I think by installing the numpy wheel and then scikit-learn via conda on top of it (got the hint from the CODE output in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762 where two CODE are listed).,Bug Reproduction
6256,"I have 8.0, 9.0, 9.1 installed + cudnn versions which seem specific to each.",Bug Reproduction
6257,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction
6258,"However, blang's minimal example works on my Macbook (OSX 10.11.3) where I don't have OpenMP support in place (obviously only in single-thread).",Bug Reproduction
6259,Will try 3.5,Bug Reproduction
6260,@priidukull is your test failure reproducible?,Bug Reproduction
6261,Same issue.,Bug Reproduction
6262,I don't understand why I am getting this error with the [seq2seq tutorial model] URL :CODE,Bug Reproduction
6263,Hmm actually I can reproduce but your snippet was not a complete reproducer.,Bug Reproduction
6264,"I am trying to follow the unmodified Seq2Seq translation tutorial, but I'm getting the same error.",Bug Reproduction
6265,"Mac OX Sierra, TensorFlow 1.1.0-rc1, Python 2.7.10 & Python 3.6.1.",Bug Reproduction
6266,CODE,Bug Reproduction
6267,"FYI, I can not reproduce on my OSX version with the same numpy version, Accelerate as well.",Bug Reproduction
6268,"@lesteve I meant that I get the same error with a small number of instances, with the same system parameters (Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3)",Bug Reproduction
6269,"Python 3.6.1numpy 1.13.1scikit-learn master branch, last commit hash d6a42354145c92cf88093cbcc70b13f639319c38numpy was installed from pip, so this is with Accelerate.OSX version 10.12.4",Bug Reproduction
6270,"@yarikoptic, any suggestion of how we can reproduce these test environments?",Bug Reproduction
6271,I test your data in ubuntu 14.04 LTS withPython==2.7.6scikit-learn==0.17.1numpy==1.8.2scipy==0.13.3,Bug Reproduction
6272,Note: I also have cuda 9.1 installed instead of cuda 9.0.,Bug Reproduction
6273,I met the same issue.,Bug Reproduction
6274,@dmyersturnbull do you get the error when running the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction
6275,-         specific to older versions of something (yet to figure out since numpy as nscipy are the same) since is not reproducible on current debian sid but reproducible on testing (from few days back) and other older releases.,Bug Reproduction
6276,"yeah, i clicked the logs column after failing to work it out",Bug Reproduction
6277,"I followed the current install instructions for TF 1.5 (GPU, ubuntu, virtualenv) and it breaks as described above.",Bug Reproduction
6278,re original CODE,Bug Reproduction
6279,@byrony can you provide code to reproduce?,Bug Reproduction
6280,"TF1.6 Ubuntu 16.04nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2017 NVIDIA CorporationBuilt on Fri_Nov__3_21:07:56_CDT_2017Cuda compilation tools, release 9.1, V9.1.85Which requited a Nvidia display driver 390+",Bug Reproduction
6281,I was handling with this issue as well.,Bug Reproduction
6282,@Timonzimm  I am facing the same issue.,Bug Reproduction
6283,And the output ofCODEis CODE,Bug Reproduction
6284,Will try again.,Bug Reproduction
6285,"Traceback (most recent call last):File ""utils.py"", line 15, in <module>import tensorflow as tfFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>from tensorflow.python import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>from tensorflow.python import pywrap_tensorflowFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>raise ImportError(msg)ImportError: Traceback (most recent call last):File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>from tensorflow.python.pywrap_tensorflow_internal import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>_pywrap_tensorflow_internal = swig_import_helper()File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory  Failed to load the native TensorFlow runtime.",Bug Reproduction
6286,"nvidia-smi also returns a gpu, this is a g3.4xlarge instance",Bug Reproduction
6287,"TF1.6 Ubuntu 16.04nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2017 NVIDIA CorporationBuilt on Fri_Nov__3_21:07:56_CDT_2017Cuda compilation tools, release 9.1, V9.1.85Which requited a Nvidia display driver 390+",Bug Reproduction
6288,"trying to get this thing running, which results in the same error: https://gist.github.com/danijar/c7ec9a30052127c7a1ad169eeb83f159#file-blog_tensorflow_sequence_classification-py-L38",Bug Reproduction
6289,CODE,Bug Reproduction
6290,**Replicated**,Bug Reproduction
6291,I managed to find a way to reproduce I think by installing the numpy wheel and then scikit-learn via conda on top of it (got the hint from the CODE output in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762 where two CODE are listed).,Bug Reproduction
6292,I cannot reproduce either with python 2.7.12 from conda on OSX 10.11.3 either.,Bug Reproduction
6293,Also I now realized that I read the whole discussion too quickly and that the bug only happens with python 2.7.,Bug Reproduction
6294,"I tried two setups, where",Bug Reproduction
6295,Same issue on OS X EI Capitan using Python 3.5,Bug Reproduction
6296,"I tried it on my other mac, and it works fine there.",Bug Reproduction
6297,"First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.",Bug Reproduction
6298,@byrony can you provide code to reproduce?,Bug Reproduction
6299,See https://www.tensorflow.org/install/install_sources#common_installation_problemssudo apt-get install cuda-7-0vim ~/.bashrcexport PATH=/usr/local/cuda-7.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda7.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PAfor some common reasons and solutions.,Bug Reproduction
6300,EDIT: I used this docker image: CODE,Bug Reproduction
6301,"Thanks @ivan-krukov, but I'm failing to replicate in Python 3.3.",Bug Reproduction
6302,I test your data in ubuntu 14.04 LTS withPython==2.7.6scikit-learn==0.17.1numpy==1.8.2scipy==0.13.3,Bug Reproduction
6303,"I have the issue on a dataset of mine, on Anaconda, Py 3.5, sklearn 0.17.1, OSX El Capitan.",Bug Reproduction
6304,Please create a new instance of the cell if you would like it to use a different set of weights.,Bug Reproduction
6305,My setupTensorflow 1.7cuDNN 7.1.2Ubuntu 16.04,Bug Reproduction
6306,"Following the same code, however: CODE",Bug Reproduction
6307,@jnothman it doesn't seem to be happening only on Python 3.5 so if you could try to reproduce with Python 2.7 (snippet: https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) that would be great.,Bug Reproduction
6308,I test your data in ubuntu 14.04 LTS withPython==2.7.6scikit-learn==0.17.1numpy==1.8.2scipy==0.13.3,Bug Reproduction
6309,The error dump as the following:CODE,Bug Reproduction
6310,Is there another way of getting this i386 build for debian?,Bug Reproduction
6311,"Linux-3.0.101-0.47.71-default-x86_64-with-SuSE-11-x86_64('Python', '2.7.12 |Anaconda 2.3.0 (64-bit)| (default, Jul  2 2016, 17:42:40) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.1')",Bug Reproduction
6312,"I'm getting this issue (Cuda 9.1.85, cuDNN 7.05)",Bug Reproduction
6313,"I did not install 9.1, at least not intentionally.",Bug Reproduction
6314,@KaisJM I think it is more useful if you start from your freezing script and manage to simplify and post a fully stand-alone that freezes for you.,Bug Reproduction
6315,I can also reproduce the bug with the code sample from ivan-krukov,Bug Reproduction
6316,I'm using CODE model with CODE cells.,Bug Reproduction
6317,"For me, I installed cuda toolkit 8.0, and cudnn 5.1.",Bug Reproduction
6318,Those tests pass with 32 bit python and numpy 1.13.1 on our wheel building travis:,Bug Reproduction
6319,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
6320,From a maintainer's point of view what we need is a fully stand-alone python snippet to see if we can reproduce.,Bug Reproduction
6321,"nvidia-smi also returns a gpu, this is a g3.4xlarge instance",Bug Reproduction
6322,I tried this same code on a Linux and it runs well.,Bug Reproduction
6323,Python 2.7.6 on OS X El Capitan on 0.17.,Bug Reproduction
6324,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x11d32cbd0> with a different variable scope than its first use. First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/gru_cell'. Please create a new instance of the cell if you would like it to use a different set of weights. If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]). If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse). In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
6325,I've wasted lots of time failing to set up an appropriate debianvirtual machine.,Bug Reproduction
6326,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6327,"I am trying to follow the unmodified Seq2Seq translation tutorial, but I'm getting the same error.",Bug Reproduction
6328,Error message: AssertionError: 0.89166666666666661 not greater than 0.9,Bug Reproduction
6329,This is on a amazon ec2 instance with stock ubuntu 16.04.,Bug Reproduction
6330,ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7fba0683de90> with a different variable scope than its first use.,Bug Reproduction
6331,I have version 1.1.0-rc2.,Bug Reproduction
6332,@yarikoptic I am unable to reproduce the failure on 32bit debian CODE on docker.,Bug Reproduction
6333,@ivan-krukov I bit the bullet today and installed an El Capitan VM.,Bug Reproduction
6334,Now I'm getting the :,Bug Reproduction
6335,Do you mind sharing your data X with me?,Bug Reproduction
6336,@Concomitant can you reproduce the error on the stand-alone example given in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction
6337,I re-ran code from a few weeks ago and now this issue appears.,Bug Reproduction
6338,"FWIW, my machine has no problem fitting iris with this snippet on the development version of sklearn.",Bug Reproduction
6339,"i.e. > ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7f0fb51ebb00> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.....",Bug Reproduction
6340,"@boazsh thanks a lot for the snippet, it is not deterministic though, can you edit it and use a CODE to make sure the random numbers are always the same on each run.",Bug Reproduction
6341,I re-ran code from a few weeks ago and now this issue appears.,Bug Reproduction
6342,"I am getting the same problem on OS X 10.11.6, python 3.5.1,  sklearn 0.17.1 and numpy 1.11.1 .On this dataset: https://dl.dropboxusercontent.com/u/103591/vals.out (with np.savetxt)",Bug Reproduction
6343,"@jnothman in case you want to reproduce the problem, IIRC you can create an environment with Accelerate on OSX  with something like:CODE",Bug Reproduction
6344,I can not reproduce it anymore as before.,Bug Reproduction
6345,"yeah, i clicked the logs column after failing to work it out",Bug Reproduction
6346,I tried this same code on a Linux and it runs well.,Bug Reproduction
6347,I am also getting this issue and struggling to resolve it.,Bug Reproduction
6348,I met the same issue.,Bug Reproduction
6349,"On branch remotes/origin/r1.1 it has the ""different variable scope"" error.",Bug Reproduction
6350,Just run these lines in a python shell CODE,Bug Reproduction
6351,filenames wereCODEand CODE (version 7.0.5),Bug Reproduction
6352,"Windows-10-10.0.15063-SP0Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]NumPy 1.14.1SciPy 1.0.0Scikit-Learn 0.19.1",Bug Reproduction
6353,Python 2.7.6 on OS X El Capitan on 0.17.,Bug Reproduction
6354,It is fine and doesn't raise the ValueError.,Bug Reproduction
6355,@ebrevdo I meet the same error when running the sequence_to_sequence model on the tensorflow1.1 website.,Bug Reproduction
6356,re original CODE,Bug Reproduction
6357,"More info: Darwin-16.6.0-x86_64-i386-64bit('Python', '2.7.13 (default, Apr  4 2017, 08:47:57) \n[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.2')",Bug Reproduction
6358,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
6359,Failed to load the native TensorFlow runtime.,Bug Reproduction
6360,"I have the issue on a dataset of mine, on Anaconda, Py 3.5, sklearn 0.17.1, OSX El Capitan.",Bug Reproduction
6361,"The best way of turning these 5 hours into something useful for the project, would be to provide us with a stand-alone example reproducing the problem.",Bug Reproduction
6362,"Sure, where and in what format would you like it?",Bug Reproduction
6363,FWIW I can not reproduce the problem on my OS X VM.,Bug Reproduction
6364,"My computer installed CUDA 8.0,cudnn 6.0 ,tensorflow 1.4.",Bug Reproduction
6365,I'm using CODE model with CODE cells.,Bug Reproduction
6366,"Then as soon as you're done, you get this error (it is looking for cublas 9.0, which, from what I can read here, would not have worked either, as CUDA 9.1 is the default you get from NVIDIA).",Bug Reproduction
6367,I am getting the same error when trying to run the translate example (even when doing the small self test) which can be found here: https://github.com/tensorflow/models/tree/master/tutorials/rnn/translate,Bug Reproduction
6368,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6369,"Sorry, but I still get this on Python 3.5.1, scikit 0.17, scikit-learn 0.18 (commit 9e913c04d748), and Numpy 1.11.1 on Mac OS 10.11.5.",Bug Reproduction
6370,Also been having this problem.,Bug Reproduction
6371,CODE,Bug Reproduction
6372,"FWIW, my machine has no problem fitting iris with this snippet on the development version of sklearn.",Bug Reproduction
6373,Example run: CODE,Bug Reproduction
6374,I guess the problem has cropped up again with CODE and CODE.,Bug Reproduction
6375,"TF1.6 Ubuntu 16.04nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2017 NVIDIA CorporationBuilt on Fri_Nov__3_21:07:56_CDT_2017Cuda compilation tools, release 9.1, V9.1.85Which requited a Nvidia display driver 390+",Bug Reproduction
6376,Steps to reproduce: CODE,Bug Reproduction
6377,It seems fine on my linux machine Linux:,Bug Reproduction
6378,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction
6379,@bowu Same error here.,Bug Reproduction
6380,then execute the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762.,Bug Reproduction
6381,"@amueller, running the script with 50k rows works as expected.",Bug Reproduction
6382,"If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).",Bug Reproduction
6383,"I have 8.0, 9.0, 9.1 installed + cudnn versions which seem specific to each.",Bug Reproduction
6384,"I cannot reproduce either with python 3.5.1, numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1 from miniconda (with MKL) on a virtualbox with OSX El Capitan.",Bug Reproduction
6385,"Sorry, but I still get this on Python 3.5.1, scikit 0.17, scikit-learn 0.18 (commit 9e913c04d748), and Numpy 1.11.1 on Mac OS 10.11.5.",Bug Reproduction
6386,"nvidia-smi also returns a gpu, this is a g3.4xlarge instance",Bug Reproduction
6387,Actually I read @Concomitant's code snippet too quickly:,Bug Reproduction
6388,I'll get back to this if I'll be able to reproduce it with specific steps.,Bug Reproduction
6389,will try to reproduce with minimal code. CODE,Bug Reproduction
6390,will try to create a minimal example that reproduces the problem.,Bug Reproduction
6391,I tried this same code on a Linux and it runs well.,Bug Reproduction
6392,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
6393,Same issue here with the german model and CODE on Amazon Linux (also on Ubuntu Server 14.04 LTS) using python 3.5.,Bug Reproduction
6394,I can also reproduce the bug with the code sample from ivan-krukov,Bug Reproduction
6395,I installed following these instructionshttps://www.tensorflow.org/install/install_linux#nvidia_requirements_to_run_tensorflow_with_gpu_support,Bug Reproduction
6396,Unfortunately I can not reproduce your problem.,Bug Reproduction
6397,"If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).",Bug Reproduction
6398,That means anyone can copy and paste it in a IPython session and easily try to reproduce.,Bug Reproduction
6399,CODE,Bug Reproduction
6400,"I am getting the same problem on OS X 10.11.6, python 3.5.1,  sklearn 0.17.1 and numpy 1.11.1 .On this dataset: https://dl.dropboxusercontent.com/u/103591/vals.out (with np.savetxt)",Bug Reproduction
6401,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
6402,"If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).",Bug Reproduction
6403,"In a virtualenv, I get:CODE",Bug Reproduction
6404,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction
6405,@yarikoptic I am unable to reproduce the failure on 32bit debian CODE on docker.,Bug Reproduction
6406,"My computer installed CUDA 8.0,cudnn 6.0 ,tensorflow 1.4.",Bug Reproduction
6407,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
6408,Steps to reproduce: CODE,Bug Reproduction
6409,"I did not install 9.1, at least not intentionally.",Bug Reproduction
6410,Will try again.,Bug Reproduction
6411,"Tried the same code on Linux using Python 2.7.6 and 0.17, and it works.",Bug Reproduction
6412,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
6413,**Replicated**,Bug Reproduction
6414,@byrony can you provide code to reproduce?,Bug Reproduction
6415,Reproduced for 3.5 with anaconda under OS X El Capitan.,Bug Reproduction
6416,CODE,Bug Reproduction
6417,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
6418,"Thanks @ivan-krukov, but I'm failing to replicate in Python 3.3.",Bug Reproduction
6419,"Then as soon as you're done, you get this error (it is looking for cublas 9.0, which, from what I can read here, would not have worked either, as CUDA 9.1 is the default you get from NVIDIA).",Bug Reproduction
6420,Here is an updated snippet: CODE,Bug Reproduction
6421,"Windows-10-10.0.15063-SP0Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]NumPy 1.14.1SciPy 1.0.0Scikit-Learn 0.19.1",Bug Reproduction
6422,Steps to reproduce: CODE,Bug Reproduction
6423,I just tried this again and it seems to work now (reinstalled spaCy and the german model).,Bug Reproduction
6424,Will try 3.5,Bug Reproduction
6425,"On branch remotes/origin/r1.1 it has the ""different variable scope"" error.",Bug Reproduction
6426,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction
6427,Error message: AssertionError: 0.89166666666666661 not greater than 0.9,Bug Reproduction
6428,"Following the same code, however: CODE",Bug Reproduction
6429,@byrony can you provide code to reproduce?,Bug Reproduction
6430,"I tried it on my other mac, and it works fine there.",Bug Reproduction
6431,@priidukull is your test failure reproducible?,Bug Reproduction
6432,@ebrevdo I am as well facing the same issue and unable to progress with seq2seq.,Bug Reproduction
6433,Please give a reproducible code snippet.,Bug Reproduction
6434,[Source](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L129) where the cell is created withCODE,Bug Reproduction
6435,The relevant portion of the code in my seq2seq_model.py is:CODE,Bug Reproduction
6436,"@tongda , I am using the Release Version of Tensorflow 1.0, working on MacOS in cpu mode.",Bug Reproduction
6437,"when I run my code on the linux environment directly, everything is OK.",Bug Reproduction
6438,I managed to find a way to reproduce I think by installing the numpy wheel and then scikit-learn via conda on top of it (got the hint from the CODE output in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762 where two CODE are listed).,Bug Reproduction
6439,"The best way of turning these 5 hours into something useful for the project, would be to provide us with a stand-alone example reproducing the problem.",Bug Reproduction
6440,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction
6441,"For me, I installed cuda toolkit 8.0, and cudnn 5.1.",Bug Reproduction
6442,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
6443,[Source](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L129) where the cell is created withCODE,Bug Reproduction
6444,"My computer installed CUDA 8.0,cudnn 6.0 ,tensorflow 1.4.",Bug Reproduction
6445,"I did not install 9.1, at least not intentionally.",Bug Reproduction
6446,OSX El Capitan Python 3.5.1scikit-learn==0.17.1scipy==0.17.1,Bug Reproduction
6447,"This does not apply to CODE (4.4.0-21, Ubuntu 16.04) with the same packages under 3.5.",Bug Reproduction
6448,Having the same problem with tensor flow 1.1.,Bug Reproduction
6449,"I have cuda-9-0 installed on the host, but when I try to run my docker container I get CODE",Bug Reproduction
6450,Error message: AssertionError: 0.89166666666666661 not greater than 0.9,Bug Reproduction
6451,The test code is:CODE,Bug Reproduction
6452,My email is 370846270@qq.com,Bug Reproduction
6453,Same problem.,Bug Reproduction
6454,Please give a reproducible code snippet.,Bug Reproduction
6455,@ivan-krukov I bit the bullet today and installed an El Capitan VM.,Bug Reproduction
6456,Same here.OSX 10.12.5,Bug Reproduction
6457,"whelp to add to it all,, After a major amount of hassle I got the Nvidia updated to the newest release see above, as the TF doc indicated that there were bugs in an earlier release..",Bug Reproduction
6458,@ebrevdo I meet the same error when running the sequence_to_sequence model on the tensorflow1.1 website.,Bug Reproduction
6459,"Same problem here, working on Windows 10 with German text.",Bug Reproduction
6460,"yeah, i clicked the logs column after failing to work it out",Bug Reproduction
6461,This will give you the best chance of getting good feed-back.,Bug Reproduction
6462,"@lesteve I did with that exact snippet, yes.",Bug Reproduction
6463,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction
6464,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
6465,I just tried this again and it seems to work now (reinstalled spaCy and the german model).,Bug Reproduction
6466,Here's a minimal example that now reproduces this issue:CODE,Bug Reproduction
6467,It is fine and doesn't raise the ValueError.,Bug Reproduction
6468,"@lesteve I did with that exact snippet, yes.",Bug Reproduction
6469,"when I run my code on the linux environment directly, everything is OK.",Bug Reproduction
6470,"Mac OX Sierra, TensorFlow 1.1.0-rc1, Python 2.7.10 & Python 3.6.1.",Bug Reproduction
6471,https://travis-ci.org/MacPython/scikit-learn-wheels,Bug Reproduction
6472,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
6473,CODE,Bug Reproduction
6474,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
6475,https://travis-ci.org/MacPython/scikit-learn-wheels,Bug Reproduction
6476,This will give you the best chance of getting good feed-back.,Bug Reproduction
6477,Still facing this problem with the same sample  code.,Bug Reproduction
6478,It seems fine on my linux machine Linux:,Bug Reproduction
6479,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6480,The issue replicates for me when using the Windows/GPU build 105 on the [Shakespeare RNN Repo] URL .,Bug Reproduction
6481,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
6482,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
6483,I will try on a real mac hardware later.,Bug Reproduction
6484,I tried this same code on a Linux and it runs well.,Bug Reproduction
6485,It is fine and doesn't raise the ValueError.,Bug Reproduction
6486,Error message: AssertionError: 0.89166666666666661 not greater than 0.9,Bug Reproduction
6487,I have the exact same problem on OSX 10.10.5,Bug Reproduction
6488,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
6489,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
6490,"2,4 GHz Intel Core i58 GB 1600 MHz DDR3",Bug Reproduction
6491,@tshi1983I got the same problem with tensorflow 1.1-gpu for ubuntu.,Bug Reproduction
6492,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x117f7cbd0> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_1/gru_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
6493,"The script ends correctly, showing the results as follows (sorry, I meant 50k not 500k): ![captura de pantalla de 2018-05-26 13-09-00] URL  ![captura de pantalla de 2018-05-26 13-09-51] URL ",Bug Reproduction
6494,Terminal:CODE,Bug Reproduction
6495,"Then i upgrade numpy, scipy to 1.11.0, 0.17.0 and test with the same code and it also doesn't raise any error.",Bug Reproduction
6496,I also occur the exactly same problem with kirk86.,Bug Reproduction
6497,"the origin code:from tensorflow.contrib import rnninputs = tf.placeholder(dtype=tf.int32, shape=[None, None], name=""inputs"")keep_prob = tf.placeholder(dtype=tf.float32, name=""keep_prob"")cell = rnn.GRUCell(10)cell = rnn.DropoutWrapper(cell=cell, input_keep_prob=keep_prob)cell = rnn.MultiRNNCell([cell for _ in range(5)], state_is_tuple=True) outs, states = tf.nn.dynamic_rnn(cell=cell, inputs=look_up, dtype=tf.float32)",Bug Reproduction
6498,I re-ran code from a few weeks ago and now this issue appears.,Bug Reproduction
6499,"However, blang's minimal example works on my Macbook (OSX 10.11.3) where I don't have OpenMP support in place (obviously only in single-thread).",Bug Reproduction
6500,Also been having this problem.,Bug Reproduction
6501,"I had cuda 9.1, and tensorflow would not find libraries for cuda 9.0.",Bug Reproduction
6502,@ebrevdo I am as well facing the same issue and unable to progress with seq2seq.,Bug Reproduction
6503,"@lesteve I did with that exact snippet, yes.",Bug Reproduction
6504,cell = tf.contrib.rnn.MultiRNNCell([single_cell() for _ in range(num_layers)]),Bug Reproduction
6505,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction
6506,I tested the code in thomberg1's https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-337985212.,Bug Reproduction
6507,[Source](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L129) where the cell is created withCODE,Bug Reproduction
6508,Same here.OSX 10.12.5,Bug Reproduction
6509,Failed to load the native TensorFlow runtime.,Bug Reproduction
6510,My tf verstion is 1.1.0.,Bug Reproduction
6511,I installed following these instructionshttps://www.tensorflow.org/install/install_linux#nvidia_requirements_to_run_tensorflow_with_gpu_support,Bug Reproduction
6512,System info: CODE,Bug Reproduction
6513,"I get the same problem with Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3.",Bug Reproduction
6514,I cannot reproduce either with python 2.7.12 from conda on OSX 10.11.3 either.,Bug Reproduction
6515,Failed to load the native TensorFlow runtime.,Bug Reproduction
6516,"My computer installed CUDA 8.0,cudnn 6.0 ,tensorflow 1.4.",Bug Reproduction
6517,I met the same issue.,Bug Reproduction
6518,"Hi, I am using Tensorflow r1.0 using GPU built using source.",Bug Reproduction
6519,Just run these lines in a python shell CODE,Bug Reproduction
6520,Here is an updated snippet: CODE,Bug Reproduction
6521,I'll get back to this if I'll be able to reproduce it with specific steps.,Bug Reproduction
6522,"FYI, I can not reproduce on my OSX version with the same numpy version, Accelerate as well.",Bug Reproduction
6523,But I got the same error:,Bug Reproduction
6524,CODE,Bug Reproduction
6525,Here is an updated snippet: CODE,Bug Reproduction
6526,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6527,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6528,"Traceback (most recent call last):File ""utils.py"", line 15, in <module>import tensorflow as tfFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>from tensorflow.python import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>from tensorflow.python import pywrap_tensorflowFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>raise ImportError(msg)ImportError: Traceback (most recent call last):File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>from tensorflow.python.pywrap_tensorflow_internal import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>_pywrap_tensorflow_internal = swig_import_helper()File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory  Failed to load the native TensorFlow runtime.",Bug Reproduction
6529,I can also reproduce the bug with the code sample from ivan-krukov,Bug Reproduction
6530,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Bug Reproduction
6531,My Python version is installed via brew on macOS Sierra 10.12.4,Bug Reproduction
6532,CODE,Bug Reproduction
6533,I tried this same code on a Linux and it runs well.,Bug Reproduction
6534,Here is an updated snippet: CODE,Bug Reproduction
6535,"For me, I installed cuda toolkit 8.0, and cudnn 5.1.",Bug Reproduction
6536,Having the same problem with tensor flow 1.1.,Bug Reproduction
6537,Here's a minimal example that now reproduces this issue:CODE,Bug Reproduction
6538,"In a virtualenv, I get:CODE",Bug Reproduction
6539,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6540,It works when I have more than 2100 points but fails for lower values.,Bug Reproduction
6541,after upgrading my Nvidia stuff my older versions of TF in separate conda env's no longer work as the older TF wants : ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,Bug Reproduction
6542,**The set up where TSNE works well:**,Bug Reproduction
6543,From a maintainer's point of view what we need is a fully stand-alone python snippet to see if we can reproduce.,Bug Reproduction
6544,"@amueller Ok, I will run it again with 500k rows and will post the results.",Bug Reproduction
6545,@lesteve and others I cannot reproduce the error with the [snippet posted earlier](https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) on the latest master with python 2.7.,Bug Reproduction
6546,This will give you the best chance of getting good feed-back.,Bug Reproduction
6547,I was receiving the error when executing the seq2seq tutorial,Bug Reproduction
6548,See https://www.tensorflow.org/install/install_sources#common_installation_problemssudo apt-get install cuda-7-0vim ~/.bashrcexport PATH=/usr/local/cuda-7.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda7.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PAfor some common reasons and solutions.,Bug Reproduction
6549,That means anyone can copy and paste it in a IPython session and easily try to reproduce.,Bug Reproduction
6550,"My computer installed CUDA 8.0,cudnn 6.0 ,tensorflow 1.4.",Bug Reproduction
6551,Do you mind sharing your data X with me?,Bug Reproduction
6552,@byrony can you provide code to reproduce?,Bug Reproduction
6553,It worked fine in Jupyter Notebook and command-line.,Bug Reproduction
6554,It worked fine in Jupyter Notebook and command-line.,Bug Reproduction
6555,I was receiving the error when executing the seq2seq tutorial,Bug Reproduction
6556,"yeah, i clicked the logs column after failing to work it out",Bug Reproduction
6557,@lesteve I can reproduce the issue.,Bug Reproduction
6558,My CODE folder has the following libcublas:CODE,Bug Reproduction
6559,Python 2.7.6 on OS X El Capitan on 0.17.,Bug Reproduction
6560,The error dump as the following:CODE,Bug Reproduction
6561,Still facing this problem with the same sample  code.,Bug Reproduction
6562,"The script ends correctly, showing the results as follows (sorry, I meant 50k not 500k): ![captura de pantalla de 2018-05-26 13-09-00] URL  ![captura de pantalla de 2018-05-26 13-09-51] URL ",Bug Reproduction
6563,The relevant portion of the code in my seq2seq_model.py is:CODE,Bug Reproduction
6564,OS: Windows 10 x64 10.0.16299.309Python package: WinPython-64bit-3.6.1numpy (1.14.2)scikit-learn (0.19.1)scipy (1.0.0),Bug Reproduction
6565,instead of CODE it should be CODE otherwise the numpy RNG is not reseeded appropriately and one cannot get deterministic results.,Bug Reproduction
6566,"Then as soon as you're done, you get this error (it is looking for cublas 9.0, which, from what I can read here, would not have worked either, as CUDA 9.1 is the default you get from NVIDIA).",Bug Reproduction
6567,System Version: OS X 10.11.5Python 3.5.1 :: Anaconda 4.0.0 (x86_64)numpy.version.version 1.11.0scipy.version 0.17.1sklearn.**version** 0.17.1,Bug Reproduction
6568,re original CODE,Bug Reproduction
6569,See https://www.tensorflow.org/install/install_sources#common_installation_problemssudo apt-get install cuda-7-0vim ~/.bashrcexport PATH=/usr/local/cuda-7.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda7.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PAfor some common reasons and solutions.,Bug Reproduction
6570,I can reproduce the error with the example provided by @ivan-krukov .,Bug Reproduction
6571,"In a virtualenv, I get:CODE",Bug Reproduction
6572,"the origin code:from tensorflow.contrib import rnninputs = tf.placeholder(dtype=tf.int32, shape=[None, None], name=""inputs"")keep_prob = tf.placeholder(dtype=tf.float32, name=""keep_prob"")cell = rnn.GRUCell(10)cell = rnn.DropoutWrapper(cell=cell, input_keep_prob=keep_prob)cell = rnn.MultiRNNCell([cell for _ in range(5)], state_is_tuple=True) outs, states = tf.nn.dynamic_rnn(cell=cell, inputs=look_up, dtype=tf.float32)",Bug Reproduction
6573,For information I had this issue while trying to stack LSTM cells:,Bug Reproduction
6574,"I have cuda-9-0 installed on the host, but when I try to run my docker container I get CODE",Bug Reproduction
6575,ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7fba0683de90> with a different variable scope than its first use.,Bug Reproduction
6576,"@yarikoptic On this link I see ""No entry in i386 database, check Packages-arch-specific"" (with ""Suite: experimental"").",Bug Reproduction
6577,I tried installing python and scikit dependency using CODE and the test passed for both CODE and CODE.,Bug Reproduction
6578,@ebrevdo I am as well facing the same issue and unable to progress with seq2seq.,Bug Reproduction
6579,Please create a new instance of the cell if you would like it to use a different set of weights.,Bug Reproduction
6580,I also occur the exactly same problem with kirk86.,Bug Reproduction
6581,CODE,Bug Reproduction
6582,My orginial code was:CODE,Bug Reproduction
6583,**Error**:CODE,Bug Reproduction
6584,This will give you the best chance of getting good feed-back.,Bug Reproduction
6585,I met the same problem when using the Release Version of Tensorflow 1.0 and working on MacOS in cpu mode.,Bug Reproduction
6586,This will give you the best chance of getting good feed-back.,Bug Reproduction
6587,"@yarikoptic On this link I see ""No entry in i386 database, check Packages-arch-specific"" (with ""Suite: experimental"").",Bug Reproduction
6588,My setupTensorflow 1.7cuDNN 7.1.2Ubuntu 16.04,Bug Reproduction
6589,Any advice?,Bug Reproduction
6590,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
6591,"Following the same code, however: CODE",Bug Reproduction
6592,after upgrading my Nvidia stuff my older versions of TF in separate conda env's no longer work as the older TF wants : ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,Bug Reproduction
6593,-         specific to older versions of something (yet to figure out since numpy as nscipy are the same) since is not reproducible on current debian sid but reproducible on testing (from few days back) and other older releases.,Bug Reproduction
6594,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
6595,"yeah, i clicked the logs column after failing to work it out",Bug Reproduction
6596,Which repo did you use to produce this failure?,Bug Reproduction
6597,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
6598,"@lesteve I meant that I get the same error with a small number of instances, with the same system parameters (Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3)",Bug Reproduction
6599,@lesteve and others I cannot reproduce the error with the [snippet posted earlier](https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) on the latest master with python 2.7.,Bug Reproduction
6600,"I am getting the same problem on OS X 10.11.6, python 3.5.1,  sklearn 0.17.1 and numpy 1.11.1 .On this dataset: https://dl.dropboxusercontent.com/u/103591/vals.out (with np.savetxt)",Bug Reproduction
6601,@bowu Same error here.,Bug Reproduction
6602,Indeed I was using an older image (jessie).,Bug Reproduction
6603,Will try again.,Bug Reproduction
6604,It works when I have more than 2100 points but fails for lower values.,Bug Reproduction
6605,It works when I have more than 2100 points but fails for lower values.,Bug Reproduction
6606,Example run: CODE,Bug Reproduction
6607,"In case your problem do not seem to match this description, please post the exact commands you ran to create your conda environment, so we can try to reproduce.",Bug Reproduction
6608,"Linux-3.0.101-0.47.71-default-x86_64-with-SuSE-11-x86_64('Python', '2.7.12 |Anaconda 2.3.0 (64-bit)| (default, Jul  2 2016, 17:42:40) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.1')",Bug Reproduction
6609,This will give you the best chance of getting good feed-back.,Bug Reproduction
6610,I have the same problem and would really appreciate a fix (or workaround?),Bug Reproduction
6611,I can reproduce the error with the example provided by @ivan-krukov .,Bug Reproduction
6612,"FWIW, I have no problem running that snippet with: >>> import platform; print(platform.platform())Darwin-16.7.0-x86_64-i386-64bit>>> import sys; print(""Python"", sys.version)Python 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]>>> import numpy; print(""NumPy"", numpy.__version__)NumPy 1.13.1>>> import scipy; print(""SciPy"", scipy.__version__)SciPy 0.19.1>>> import sklearn; print(""Scikit-Learn"", sklearn.__version__)Scikit-Learn 0.18.2",Bug Reproduction
6613,"I noticed that the TF 1.0  works fine with the newest version of translation tutorial if compiled from the source on branch remotes/origin/r1.0CODEthen build and install TensorFlow, it works fine.",Bug Reproduction
6614,Here is an updated snippet: CODE,Bug Reproduction
6615,"But when I run on the local pycharm through the remote interpreter, I encounter the problem: CODE",Bug Reproduction
6616,Still facing this problem with the same sample  code.,Bug Reproduction
6617,I ran into this issue too.,Bug Reproduction
6618,"I noticed that the TF 1.0  works fine with the newest version of translation tutorial if compiled from the source on branch remotes/origin/r1.0CODEthen build and install TensorFlow, it works fine.",Bug Reproduction
6619,"nvidia-smi also returns a gpu, this is a g3.4xlarge instance",Bug Reproduction
6620,"@boazsh thanks a lot for the snippet, it is not deterministic though, can you edit it and use a CODE to make sure the random numbers are always the same on each run.",Bug Reproduction
6621,"The best way of turning these 5 hours into something useful for the project, would be to provide us with a stand-alone example reproducing the problem.",Bug Reproduction
6622,Example run: CODE,Bug Reproduction
6623,Will try 3.5,Bug Reproduction
6624,Terminal:CODE,Bug Reproduction
6625,I tried installing python and scikit dependency using CODE and the test passed for both CODE and CODE.,Bug Reproduction
6626,"Then i upgrade numpy, scipy to 1.11.0, 0.17.0 and test with the same code and it also doesn't raise any error.",Bug Reproduction
6627,@lesteve and others I cannot reproduce the error with the [snippet posted earlier](https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) on the latest master with python 2.7.,Bug Reproduction
6628,"On branch remotes/origin/r1.1 it has the ""different variable scope"" error.",Bug Reproduction
6629,It works when I have more than 2100 points but fails for lower values.,Bug Reproduction
6630,Also @joelkuiper and @Concomitant can you please check that you can reproduce the problem on the current state of the scikit-learn master branch?,Bug Reproduction
6631,Also been having this problem.,Bug Reproduction
6632,Anyone have these issues when working with legacy_seq2seq.rnn_decoder()?,Bug Reproduction
6633,The error dump as the following:CODE,Bug Reproduction
6634,"I am getting the same problem on OS X 10.11.6, python 3.5.1,  sklearn 0.17.1 and numpy 1.11.1 .On this dataset: https://dl.dropboxusercontent.com/u/103591/vals.out (with np.savetxt)",Bug Reproduction
6635,"I am trying to follow the unmodified Seq2Seq translation tutorial, but I'm getting the same error.",Bug Reproduction
6636,@dmyersturnbull do you get the error when running the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction
6637,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
6638,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction
6639,But I got the same error:,Bug Reproduction
6640,I'm using CODE model with CODE cells.,Bug Reproduction
6641,Also been having this problem.,Bug Reproduction
6642,"Mac OX Sierra, TensorFlow 1.1.0-rc1, Python 2.7.10 & Python 3.6.1.",Bug Reproduction
6643,"The only way we can investigate, is that you post a fully standalone snippet which we can just copy and paste in an IPython sesion and see if we can reproduce the problem.",Bug Reproduction
6644,"2,4 GHz Intel Core i58 GB 1600 MHz DDR3",Bug Reproduction
6645,"This does not apply to CODE (4.4.0-21, Ubuntu 16.04) with the same packages under 3.5.",Bug Reproduction
6646,Also been having this problem.,Bug Reproduction
6647,Failed to load the native TensorFlow runtime.,Bug Reproduction
6648,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x117f7cbd0> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_1/gru_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
6649,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
6650,Please give a reproducible code snippet.,Bug Reproduction
6651,@lesteve and others I cannot reproduce the error with the [snippet posted earlier](https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) on the latest master with python 2.7.,Bug Reproduction
6652,"On branch remotes/origin/r1.1 it has the ""different variable scope"" error.",Bug Reproduction
6653,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction
6654,FWIW I can not reproduce the problem on my OS X VM.,Bug Reproduction
6655,will try to create a minimal example that reproduces the problem.,Bug Reproduction
6656,https://travis-ci.org/MacPython/scikit-learn-wheels,Bug Reproduction
6657,@lesteve and others I cannot reproduce the error with the [snippet posted earlier](https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) on the latest master with python 2.7.,Bug Reproduction
6658,I guess the problem has cropped up again with CODE and CODE.,Bug Reproduction
6659,Failed to load the native TensorFlow runtime.,Bug Reproduction
6660,Actually I read @Concomitant's code snippet too quickly:,Bug Reproduction
6661,"I did not install 9.1, at least not intentionally.",Bug Reproduction
6662,"Same with ('Scikit-Learn', '0.18.dev0')",Bug Reproduction
6663,This will give you the best chance of getting good feed-back.,Bug Reproduction
6664,Here is an updated snippet: CODE,Bug Reproduction
6665,"For me, I installed cuda toolkit 8.0, and cudnn 5.1.",Bug Reproduction
6666,Actually I read @Concomitant's code snippet too quickly:,Bug Reproduction
6667,@KaisJM I think it is more useful if you start from your freezing script and manage to simplify and post a fully stand-alone that freezes for you.,Bug Reproduction
6668,It works when I have more than 2100 points but fails for lower values.,Bug Reproduction
6669,The relevant portion of the code in my seq2seq_model.py is:CODE,Bug Reproduction
6670,"nvidia-smi also returns a gpu, this is a g3.4xlarge instance",Bug Reproduction
6671,@yarikoptic I am unable to reproduce the failure on 32bit debian CODE on docker.,Bug Reproduction
6672,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction
6673,"But when I run on the local pycharm through the remote interpreter, I encounter the problem: CODE",Bug Reproduction
6674,"Then i upgrade numpy, scipy to 1.11.0, 0.17.0 and test with the same code and it also doesn't raise any error.",Bug Reproduction
6675,I can reproduce the error with the example provided by @ivan-krukov .,Bug Reproduction
6676,Unfortunately I can not reproduce your problem.,Bug Reproduction
6677,I re-ran code from a few weeks ago and now this issue appears.,Bug Reproduction
6678,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction
6679,**Replicated**,Bug Reproduction
6680,I managed to find a way to reproduce I think by installing the numpy wheel and then scikit-learn via conda on top of it (got the hint from the CODE output in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762 where two CODE are listed).,Bug Reproduction
6681,EDIT: I used this docker image: CODE,Bug Reproduction
6682,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6683,*         post a fully stand-alone snippet (for your next issue).,Bug Reproduction
6684,"I had the same problem as reported here, and I do not use conda.",Bug Reproduction
6685,"Same problem here, working on Windows 10 with German text.",Bug Reproduction
6686,I'm using CODE model with CODE cells.,Bug Reproduction
6687,Please create a new instance of the cell if you would like it to use a different set of weights.,Bug Reproduction
6688,@lesteve: i had this error using the setup you describe (two versions of numpy installed).,Bug Reproduction
6689,The test code is:CODE,Bug Reproduction
6690,Steps to reproduce: CODE,Bug Reproduction
6691,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
6692,"System Version: OS X 10.11.5Python 3.5.1 :: Continuum Analytics, Inc.numpy.**version** 1.11.1scipy.**version** 0.16.0sklearn.**version** 0.17.1",Bug Reproduction
6693,"The only way we can investigate, is that you post a fully standalone snippet which we can just copy and paste in an IPython sesion and see if we can reproduce the problem.",Bug Reproduction
6694,"2,4 GHz Intel Core i58 GB 1600 MHz DDR3",Bug Reproduction
6695,EDIT: I used this docker image: CODE,Bug Reproduction
6696,"@yarikoptic On this link I see ""No entry in i386 database, check Packages-arch-specific"" (with ""Suite: experimental"").",Bug Reproduction
6697,Jupyer notebook:CODE>>CODE,Bug Reproduction
6698,Also I now realized that I read the whole discussion too quickly and that the bug only happens with python 2.7.,Bug Reproduction
6699,"@lesteve I did with that exact snippet, yes.",Bug Reproduction
6700,**Error**:CODE,Bug Reproduction
6701,"The script ends correctly, showing the results as follows (sorry, I meant 50k not 500k): ![captura de pantalla de 2018-05-26 13-09-00] URL  ![captura de pantalla de 2018-05-26 13-09-51] URL ",Bug Reproduction
6702,The test code is:CODE,Bug Reproduction
6703,I was handling with this issue as well.,Bug Reproduction
6704,Please give a reproducible code snippet.,Bug Reproduction
6705,I cannot replicate either with OSX 10.11.5.,Bug Reproduction
6706,Having the same problem with tensor flow 1.1.,Bug Reproduction
6707,will try to create a minimal example that reproduces the problem.,Bug Reproduction
6708,"I followed the current install instructions for TF 1.5 (GPU, ubuntu, virtualenv) and it breaks as described above.",Bug Reproduction
6709,I have CUDA 8.0 and Tensorflow 1.3.,Bug Reproduction
6710,Now I'm getting the :,Bug Reproduction
6711,System Version: OS X 10.11.5Python 3.5.1 :: Anaconda 4.0.0 (x86_64)numpy.version.version 1.11.0scipy.version 0.17.1sklearn.**version** 0.17.1,Bug Reproduction
6712,"More info: Darwin-16.6.0-x86_64-i386-64bit('Python', '2.7.13 (default, Apr  4 2017, 08:47:57) \n[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.2')",Bug Reproduction
6713,"In a virtualenv, I get:CODE",Bug Reproduction
6714,@tshi1983I got the same problem with tensorflow 1.1-gpu for ubuntu.,Bug Reproduction
6715,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Bug Reproduction
6716,Do you have a specific configuration that could explain the difference?,Bug Reproduction
6717,*         post a fully stand-alone snippet (for your next issue).,Bug Reproduction
6718,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
6719,I was trying to run the translate example: python2.7 translate.py --data_dir data/ --train_dir train/ --size=256 --num_layers=2 --steps_per_checkpoint=50,Bug Reproduction
6720,I have version 1.1.0-rc2.,Bug Reproduction
6721,"I have 8.0, 9.0, 9.1 installed + cudnn versions which seem specific to each.",Bug Reproduction
6722,OSX El Capitan Python 3.5.1scikit-learn==0.17.1scipy==0.17.1,Bug Reproduction
6723,I believe I installed the right versions from nvidia.,Bug Reproduction
6724,"FWIW, my machine has no problem fitting iris with this snippet on the development version of sklearn.",Bug Reproduction
6725,I was trying to run the translate example: python2.7 translate.py --data_dir data/ --train_dir train/ --size=256 --num_layers=2 --steps_per_checkpoint=50,Bug Reproduction
6726,"More info: Darwin-16.6.0-x86_64-i386-64bit('Python', '2.7.13 (default, Apr  4 2017, 08:47:57) \n[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.2')",Bug Reproduction
6727,"@tongda , I am using the Release Version of Tensorflow 1.0, working on MacOS in cpu mode.",Bug Reproduction
6728,"I had cuda 9.1, and tensorflow would not find libraries for cuda 9.0.",Bug Reproduction
6729,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x11d32cbd0> with a different variable scope than its first use. First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/gru_cell'. Please create a new instance of the cell if you would like it to use a different set of weights. If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]). If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse). In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
6730,"As i know, there is a function numpy.save for saving an array to a binary file in .npy format~~",Bug Reproduction
6731,Same issue on OS X EI Capitan using Python 3.5,Bug Reproduction
6732,"First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.",Bug Reproduction
6733,I was handling with this issue as well.,Bug Reproduction
6734,"@amueller, running the script with 50k rows works as expected.",Bug Reproduction
6735,"whelp to add to it all,, After a major amount of hassle I got the Nvidia updated to the newest release see above, as the TF doc indicated that there were bugs in an earlier release..",Bug Reproduction
6736,"Traceback (most recent call last):File ""utils.py"", line 15, in <module>import tensorflow as tfFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>from tensorflow.python import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>from tensorflow.python import pywrap_tensorflowFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>raise ImportError(msg)ImportError: Traceback (most recent call last):File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>from tensorflow.python.pywrap_tensorflow_internal import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>_pywrap_tensorflow_internal = swig_import_helper()File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory  Failed to load the native TensorFlow runtime.",Bug Reproduction
6737,CODE,Bug Reproduction
6738,"In a virtualenv, I get:CODE",Bug Reproduction
6739,I will try on a real mac hardware later.,Bug Reproduction
6740,@jnothman it doesn't seem to be happening only on Python 3.5 so if you could try to reproduce with Python 2.7 (snippet: https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) that would be great.,Bug Reproduction
6741,"Linux-3.0.101-0.47.71-default-x86_64-with-SuSE-11-x86_64('Python', '2.7.12 |Anaconda 2.3.0 (64-bit)| (default, Jul  2 2016, 17:42:40) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.1')",Bug Reproduction
6742,"But when I run on the local pycharm through the remote interpreter, I encounter the problem: CODE",Bug Reproduction
6743,Python 2.7.6 on OS X El Capitan on 0.17.,Bug Reproduction
6744,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction
6745,CODE,Bug Reproduction
6746,I met the same issue.,Bug Reproduction
6747,Also @joelkuiper and @Concomitant can you please check that you can reproduce the problem on the current state of the scikit-learn master branch?,Bug Reproduction
6748,@priidukull is your test failure reproducible?,Bug Reproduction
6749,"-         TSNE does not work with the other setup (where Tensorflow is activated, Python 2.x).",Bug Reproduction
6750,"Traceback (most recent call last):File ""utils.py"", line 15, in <module>import tensorflow as tfFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>from tensorflow.python import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>from tensorflow.python import pywrap_tensorflowFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>raise ImportError(msg)ImportError: Traceback (most recent call last):File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>from tensorflow.python.pywrap_tensorflow_internal import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>_pywrap_tensorflow_internal = swig_import_helper()File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory  Failed to load the native TensorFlow runtime.",Bug Reproduction
6751,But I got the same error:,Bug Reproduction
6752,See https://www.tensorflow.org/install/install_sources#common_installation_problemssudo apt-get install cuda-7-0vim ~/.bashrcexport PATH=/usr/local/cuda-7.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda7.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PAfor some common reasons and solutions.,Bug Reproduction
6753,CODE,Bug Reproduction
6754,Terminal:CODE,Bug Reproduction
6755,"Thanks @ivan-krukov, but I'm failing to replicate in Python 3.3.",Bug Reproduction
6756,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6757,This is on a amazon ec2 instance with stock ubuntu 16.04.,Bug Reproduction
6758,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction
6759,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
6760,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction
6761,"Python 3.6.1numpy 1.13.1scikit-learn master branch, last commit hash d6a42354145c92cf88093cbcc70b13f639319c38numpy was installed from pip, so this is with Accelerate.OSX version 10.12.4",Bug Reproduction
6762,I managed to find a way to reproduce I think by installing the numpy wheel and then scikit-learn via conda on top of it (got the hint from the CODE output in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762 where two CODE are listed).,Bug Reproduction
6763,"I get the same problem with Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3.",Bug Reproduction
6764,Also been having this problem.,Bug Reproduction
6765,"I'm getting this issue (Cuda 9.1.85, cuDNN 7.05)",Bug Reproduction
6766,"I tried it on my other mac, and it works fine there.",Bug Reproduction
6767,"I tried again on a real mac running OSX El Capitan 10.11.3 (with anaconda's latest numpy scipy and scikit-learn, same setting as reported by @Concomitant in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-229703129) but could not reproduce the problem either (tried running the snippet several times).",Bug Reproduction
6768,That means anyone can copy and paste it in a IPython session and easily try to reproduce.,Bug Reproduction
6769,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6770,"when I run my code on the linux environment directly, everything is OK.",Bug Reproduction
6771,"Python 3.6.1numpy 1.13.1scikit-learn master branch, last commit hash d6a42354145c92cf88093cbcc70b13f639319c38numpy was installed from pip, so this is with Accelerate.OSX version 10.12.4",Bug Reproduction
6772,@ebrevdo i am running Tensorflow r1.0 (tensorflow-1.0.1-cp36-cp36m-linux_x86_64) on Red Hat and have the latest version of the translation tutorial from Github..,Bug Reproduction
6773,That means anyone can copy and paste it in a IPython session and easily try to reproduce.,Bug Reproduction
6774,This is on a amazon ec2 instance with stock ubuntu 16.04.,Bug Reproduction
6775,"When running the code with the Win 1.0.0/GPU Release, there is no issue.",Bug Reproduction
6776,Also I now realized that I read the whole discussion too quickly and that the bug only happens with python 2.7.,Bug Reproduction
6777,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
6778,OSX El Capitan Python 3.5.1scikit-learn==0.17.1scipy==0.17.1,Bug Reproduction
6779,"First I've installed tensorflow 1.5, it broke, and I get the following error:CODE",Bug Reproduction
6780,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction
6781,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
6782,*         post a fully stand-alone snippet (for your next issue).,Bug Reproduction
6783,I was handling with this issue as well.,Bug Reproduction
6784,will try to reproduce with minimal code. CODE,Bug Reproduction
6785,CODE,Bug Reproduction
6786,I managed to find a way to reproduce I think by installing the numpy wheel and then scikit-learn via conda on top of it (got the hint from the CODE output in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762 where two CODE are listed).,Bug Reproduction
6787,"Thanks @ivan-krukov, but I'm failing to replicate in Python 3.3.",Bug Reproduction
6788,I have the same issue (with cuda 9.1 + tensorflow 1.5).,Bug Reproduction
6789,I cannot reproduce either with python 2.7.12 from conda on OSX 10.11.3 either.,Bug Reproduction
6790,"If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).",Bug Reproduction
6791,"I have the issue on a dataset of mine, on Anaconda, Py 3.5, sklearn 0.17.1, OSX El Capitan.",Bug Reproduction
6792,"-         TSNE does not work with the other setup (where Tensorflow is activated, Python 2.x).",Bug Reproduction
6793,I guess the problem has cropped up again with CODE and CODE.,Bug Reproduction
6794,I tried installing python and scikit dependency using CODE and the test passed for both CODE and CODE.,Bug Reproduction
6795,"I am getting the same problem on OS X 10.11.6, python 3.5.1,  sklearn 0.17.1 and numpy 1.11.1 .On this dataset: https://dl.dropboxusercontent.com/u/103591/vals.out (with np.savetxt)",Bug Reproduction
6796,"@lesteve I meant that I get the same error with a small number of instances, with the same system parameters (Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3)",Bug Reproduction
6797,I test your data in ubuntu 14.04 LTS withPython==2.7.6scikit-learn==0.17.1numpy==1.8.2scipy==0.13.3,Bug Reproduction
6798,Reproduced for 3.5 with anaconda under OS X El Capitan.,Bug Reproduction
6799,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x11d32cbd0> with a different variable scope than its first use. First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/gru_cell'. Please create a new instance of the cell if you would like it to use a different set of weights. If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]). If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse). In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction
6800,Steps to reproduce: CODE,Bug Reproduction
6801,after upgrading my Nvidia stuff my older versions of TF in separate conda env's no longer work as the older TF wants : ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,Bug Reproduction
6802,"I have 8.0, 9.0, 9.1 installed + cudnn versions which seem specific to each.",Bug Reproduction
6803,after upgrading my Nvidia stuff my older versions of TF in separate conda env's no longer work as the older TF wants : ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,Bug Reproduction
6804,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction
6805,@tshi1983I got the same problem with tensorflow 1.1-gpu for ubuntu.,Bug Reproduction
6806,"@boazsh thanks a lot for the snippet, it is not deterministic though, can you edit it and use a CODE to make sure the random numbers are always the same on each run.",Bug Reproduction
6807,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction
6808,I'll get back to this if I'll be able to reproduce it with specific steps.,Bug Reproduction
6809,"Same problem here, working on Windows 10 with German text.",Bug Reproduction
6810,This is on a amazon ec2 instance with stock ubuntu 16.04.,Bug Reproduction
6811,Having the same problem with tensor flow 1.1.,Bug Reproduction
6812,I guess the problem has cropped up again with CODE and CODE.,Bug Reproduction
6813,FWIW I can not reproduce the problem on my OS X VM.,Bug Reproduction
6814,@KaisJM I think it is more useful if you start from your freezing script and manage to simplify and post a fully stand-alone that freezes for you.,Bug Reproduction
6815,"FWIW, I have no problem running that snippet with: >>> import platform; print(platform.platform())Darwin-16.7.0-x86_64-i386-64bit>>> import sys; print(""Python"", sys.version)Python 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]>>> import numpy; print(""NumPy"", numpy.__version__)NumPy 1.13.1>>> import scipy; print(""SciPy"", scipy.__version__)SciPy 0.19.1>>> import sklearn; print(""Scikit-Learn"", sklearn.__version__)Scikit-Learn 0.18.2",Bug Reproduction
6816,I am also getting this issue and struggling to resolve it.,Bug Reproduction
6817,CODE,Bug Reproduction
6818,**Jupyer notebook:**CODE>> CODE,Bug Reproduction
6819,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction
6820,-         specific to older versions of something (yet to figure out since numpy as nscipy are the same) since is not reproducible on current debian sid but reproducible on testing (from few days back) and other older releases.,Bug Reproduction
6821,Just run these lines in a python shell CODE,Bug Reproduction
6822,Example run: CODE,Bug Reproduction
6823,[Source](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L129) where the cell is created withCODE,Bug Reproduction
6824,Reproduced for 3.5 with anaconda under OS X El Capitan.,Bug Reproduction
6825,Terminal:CODE,Bug Reproduction
6826,"when I run my code on the linux environment directly, everything is OK.",Bug Reproduction
6827,I'm using CODE model with CODE cells.,Bug Reproduction
6828,Will try again.,Bug Reproduction
6829,Steps to reproduce: CODE,Bug Reproduction
6830,@bowu Same error here.,Bug Reproduction
6831,This will give you the best chance of getting good feed-back.,Bug Reproduction
6832,"FWIW, I have no problem running that snippet with: >>> import platform; print(platform.platform())Darwin-16.7.0-x86_64-i386-64bit>>> import sys; print(""Python"", sys.version)Python 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]>>> import numpy; print(""NumPy"", numpy.__version__)NumPy 1.13.1>>> import scipy; print(""SciPy"", scipy.__version__)SciPy 0.19.1>>> import sklearn; print(""Scikit-Learn"", sklearn.__version__)Scikit-Learn 0.18.2",Bug Reproduction
6833,@tshi1983I got the same problem with tensorflow 1.1-gpu for ubuntu.,Bug Reproduction
6834,"Then i upgrade numpy, scipy to 1.11.0, 0.17.0 and test with the same code and it also doesn't raise any error.",Bug Reproduction
6835,I confirm I cannot reproduce the issue on stretch with the following 32 bit image: CODE.,Bug Reproduction
6836,See https://www.tensorflow.org/install/install_sources#common_installation_problemssudo apt-get install cuda-7-0vim ~/.bashrcexport PATH=/usr/local/cuda-7.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda7.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PAfor some common reasons and solutions.,Bug Reproduction
6837,@priidukull is your test failure reproducible?,Bug Reproduction
6838,Example run: CODE,Bug Reproduction
6839,Also I now realized that I read the whole discussion too quickly and that the bug only happens with python 2.7.,Bug Reproduction
6840,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction
6841,**The set up where TSNE does not work:**,Bug Reproduction
6842,"Then i upgrade numpy, scipy to 1.11.0, 0.17.0 and test with the same code and it also doesn't raise any error.",Bug Reproduction
6843,"For me, I installed cuda toolkit 8.0, and cudnn 5.1.",Bug Reproduction
6844,"Same problem here, working on Windows 10 with German text.",Bug Reproduction
6845,Unfortunately I can not reproduce your problem.,Bug Reproduction
6846,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
6847,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
6848,"I would be happy to help, of course.",Contribution and Commitment
6849,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
6850,Can you guys please help me?,Contribution and Commitment
6851,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
6852,I'm working on some parts of that.,Contribution and Commitment
6853,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
6854,Can you guys please help me?,Contribution and Commitment
6855,Please note I'm not going to do this.,Contribution and Commitment
6856,"Gunhan, is that possible?",Contribution and Commitment
6857,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
6858,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
6859,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
6860,@sguada assigning to you for triaging.,Contribution and Commitment
6861,@lukaszkaiser can you take a look?,Contribution and Commitment
6862,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
6863,We hope more developers to discuss and contribute.,Contribution and Commitment
6864,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
6865,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
6866,Is it possible for us do this in anyway?,Contribution and Commitment
6867,"Ping @tommoral, @ogrisel",Contribution and Commitment
6868,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
6869,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
6870,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
6871,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
6872,"Ping @tommoral, @ogrisel",Contribution and Commitment
6873,@sguada assigning to you for triaging.,Contribution and Commitment
6874,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
6875,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
6876,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
6877,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
6878,(cc @martinwicke ? ),Contribution and Commitment
6879,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
6880,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
6881,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
6882,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
6883,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
6884,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
6885,@sguada assigning to you for triaging.,Contribution and Commitment
6886,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
6887,Would also be glad to help.,Contribution and Commitment
6888,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
6889,ping @ogrisel?,Contribution and Commitment
6890,"Gunhan, is that possible?",Contribution and Commitment
6891,Would also be glad to help.,Contribution and Commitment
6892,@sguada assigning to you for triaging.,Contribution and Commitment
6893,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
6894,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
6895,After that I should also have time again to work on it.,Contribution and Commitment
6896,Is it possible for us do this in anyway?,Contribution and Commitment
6897,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
6898,ping @ogrisel?,Contribution and Commitment
6899,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
6900,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
6901,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
6902,I have a Windows VM.,Contribution and Commitment
6903,Is it possible for us do this in anyway?,Contribution and Commitment
6904,pinging @asimshankar,Contribution and Commitment
6905,@ogrisel I will give it a try :),Contribution and Commitment
6906,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
6907,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
6908,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
6909,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
6910,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
6911,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
6912,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
6913,We hope more developers to discuss and contribute.,Contribution and Commitment
6914,I am willing to contribute.,Contribution and Commitment
6915,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
6916,I am willing to contribute.,Contribution and Commitment
6917,@lesteve probably will be able to infer more from this?,Contribution and Commitment
6918,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
6919,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
6920,Might be worth getting a tech writer on the case.,Contribution and Commitment
6921,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
6922,I am willing to contribute.,Contribution and Commitment
6923,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
6924,I can check.,Contribution and Commitment
6925,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
6926,Any other ideas?,Contribution and Commitment
6927,After that I should also have time again to work on it.,Contribution and Commitment
6928,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
6929,"Sorry, but I really don't do Windows :)",Contribution and Commitment
6930,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
6931,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
6932,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
6933,Any other ideas?,Contribution and Commitment
6934,I would gladly lend a hand.,Contribution and Commitment
6935,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
6936,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
6937,pinging @asimshankar,Contribution and Commitment
6938,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
6939,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
6940,Could you help us debug?,Contribution and Commitment
6941,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
6942,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
6943,I am very willing to contribute.,Contribution and Commitment
6944,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
6945,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
6946,"(I will do this when I'm available, aha)",Contribution and Commitment
6947,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
6948,I can check.,Contribution and Commitment
6949,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
6950,After that I should also have time again to work on it.,Contribution and Commitment
6951,@ebrevdo Could you please take a look at this?,Contribution and Commitment
6952,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
6953,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
6954,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
6955,Could you help us debug?,Contribution and Commitment
6956,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
6957,I am very willing to contribute.,Contribution and Commitment
6958,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
6959,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
6960,ping @ogrisel?,Contribution and Commitment
6961,We hope more developers to discuss and contribute.,Contribution and Commitment
6962,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
6963,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
6964,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
6965,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
6966,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
6967,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
6968,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
6969,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
6970,@ogrisel I will give it a try :),Contribution and Commitment
6971,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
6972,@ebrevdo Could you please take a look at this?,Contribution and Commitment
6973,I really need to fix this issue.,Contribution and Commitment
6974,(cc @martinwicke ? ),Contribution and Commitment
6975,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
6976,We hope more developers to discuss and contribute.,Contribution and Commitment
6977,Would also be glad to help.,Contribution and Commitment
6978,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
6979,(cc @martinwicke ? ),Contribution and Commitment
6980,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
6981,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
6982,Would also be glad to help.,Contribution and Commitment
6983,"Sorry, but I really don't do Windows :)",Contribution and Commitment
6984,I'm working on some parts of that.,Contribution and Commitment
6985,After that I should also have time again to work on it.,Contribution and Commitment
6986,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
6987,"Sorry, but I really don't do Windows :)",Contribution and Commitment
6988,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
6989,I am very willing to contribute.,Contribution and Commitment
6990,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
6991,@ebrevdo Could you please take a look at this?,Contribution and Commitment
6992,"Gunhan, is that possible?",Contribution and Commitment
6993,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
6994,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
6995,We hope more developers to discuss and contribute.,Contribution and Commitment
6996,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
6997,Would be glad to lend a hand...,Contribution and Commitment
6998,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
6999,"Gunhan, is that possible?",Contribution and Commitment
7000,@sguada assigning to you for triaging.,Contribution and Commitment
7001,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7002,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7003,After that I should also have time again to work on it.,Contribution and Commitment
7004,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7005,Is it possible for us do this in anyway?,Contribution and Commitment
7006,Would also be glad to help.,Contribution and Commitment
7007,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7008,"I would be happy to help, of course.",Contribution and Commitment
7009,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7010,I will try to get the first part in soon.,Contribution and Commitment
7011,Any other ideas?,Contribution and Commitment
7012,Would be glad to lend a hand...,Contribution and Commitment
7013,I am very willing to contribute.,Contribution and Commitment
7014,"(I will do this when I'm available, aha)",Contribution and Commitment
7015,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
7016,"Gunhan, is that possible?",Contribution and Commitment
7017,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7018,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
7019,ping @ogrisel?,Contribution and Commitment
7020,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7021,I really need to fix this issue.,Contribution and Commitment
7022,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
7023,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7024,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7025,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7026,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7027,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7028,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
7029,Might be worth getting a tech writer on the case.,Contribution and Commitment
7030,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7031,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7032,ping @ogrisel?,Contribution and Commitment
7033,Might be worth getting a tech writer on the case.,Contribution and Commitment
7034,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7035,@lukaszkaiser can you take a look?,Contribution and Commitment
7036,I have a Windows VM.,Contribution and Commitment
7037,@ogrisel I will give it a try :),Contribution and Commitment
7038,@Foorack I am willing to contribute it if some people are interested as well.,Contribution and Commitment
7039,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7040,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
7041,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7042,@sguada assigning to you for triaging.,Contribution and Commitment
7043,I have a Windows VM.,Contribution and Commitment
7044,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7045,Anyone up to write a NodeJS library?,Contribution and Commitment
7046,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7047,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7048,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7049,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7050,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
7051,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7052,Feel free to patch for Debian.,Contribution and Commitment
7053,Could you help us debug?,Contribution and Commitment
7054,I am very willing to contribute.,Contribution and Commitment
7055,ping @ogrisel?,Contribution and Commitment
7056,Anyone up to write a NodeJS library?,Contribution and Commitment
7057,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7058,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7059,Any other ideas?,Contribution and Commitment
7060,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7061,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7062,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7063,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
7064,Might be worth getting a tech writer on the case.,Contribution and Commitment
7065,Please note I'm not going to do this.,Contribution and Commitment
7066,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7067,pinging @asimshankar,Contribution and Commitment
7068,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7069,@sguada assigning to you for triaging.,Contribution and Commitment
7070,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7071,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
7072,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7073,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7074,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7075,I really need to fix this issue.,Contribution and Commitment
7076,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7077,Could you help us debug?,Contribution and Commitment
7078,"(I will do this when I'm available, aha)",Contribution and Commitment
7079,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7080,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
7081,So if you could give this a look that would be welcome.,Contribution and Commitment
7082,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7083,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7084,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
7085,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7086,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7087,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7088,Any other ideas?,Contribution and Commitment
7089,"But, I am now planning to look at this again.",Contribution and Commitment
7090,We hope more developers to discuss and contribute.,Contribution and Commitment
7091,Any other ideas?,Contribution and Commitment
7092,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7093,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
7094,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7095,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
7096,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7097,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7098,I am willing to contribute.,Contribution and Commitment
7099,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7100,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7101,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7102,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7103,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7104,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7105,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7106,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7107,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
7108,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7109,"(I will do this when I'm available, aha)",Contribution and Commitment
7110,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
7111,I really need to fix this issue.,Contribution and Commitment
7112,I would gladly lend a hand.,Contribution and Commitment
7113,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
7114,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7115,"Gunhan, is that possible?",Contribution and Commitment
7116,Might be worth getting a tech writer on the case.,Contribution and Commitment
7117,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7118,I am very willing to contribute.,Contribution and Commitment
7119,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7120,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7121,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
7122,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7123,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7124,Might be worth getting a tech writer on the case.,Contribution and Commitment
7125,I really need to fix this issue.,Contribution and Commitment
7126,pinging @asimshankar,Contribution and Commitment
7127,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7128,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7129,"But, I am now planning to look at this again.",Contribution and Commitment
7130,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7131,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
7132,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7133,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
7134,Might be worth getting a tech writer on the case.,Contribution and Commitment
7135,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7136,"But, I am now planning to look at this again.",Contribution and Commitment
7137,pinging @asimshankar,Contribution and Commitment
7138,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
7139,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7140,Would be glad to lend a hand...,Contribution and Commitment
7141,"I would be happy to help, of course.",Contribution and Commitment
7142,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
7143,I really need to fix this issue.,Contribution and Commitment
7144,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
7145,@lukaszkaiser can you take a look?,Contribution and Commitment
7146,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7147,Anyone up to write a NodeJS library?,Contribution and Commitment
7148,I would gladly lend a hand.,Contribution and Commitment
7149,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7150,I am very willing to contribute.,Contribution and Commitment
7151,Might be worth getting a tech writer on the case.,Contribution and Commitment
7152,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7153,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7154,I have a Windows VM.,Contribution and Commitment
7155,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7156,"Gunhan, is that possible?",Contribution and Commitment
7157,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7158,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7159,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7160,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7161,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7162,I'm working on some parts of that.,Contribution and Commitment
7163,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7164,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7165,Anyone up to write a NodeJS library?,Contribution and Commitment
7166,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7167,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
7168,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7169,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
7170,@sguada assigning to you for triaging.,Contribution and Commitment
7171,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7172,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7173,"Gunhan, is that possible?",Contribution and Commitment
7174,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
7175,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7176,I really need to fix this issue.,Contribution and Commitment
7177,@Foorack I am willing to contribute it if some people are interested as well.,Contribution and Commitment
7178,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7179,Would be glad to lend a hand...,Contribution and Commitment
7180,I am very willing to contribute.,Contribution and Commitment
7181,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
7182,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7183,I am very willing to contribute.,Contribution and Commitment
7184,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7185,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7186,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7187,"I would be happy to help, of course.",Contribution and Commitment
7188,After that I should also have time again to work on it.,Contribution and Commitment
7189,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7190,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7191,I would gladly lend a hand.,Contribution and Commitment
7192,I can check.,Contribution and Commitment
7193,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7194,I'm working on some parts of that.,Contribution and Commitment
7195,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7196,"Gunhan, is that possible?",Contribution and Commitment
7197,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7198,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7199,Can you guys please help me?,Contribution and Commitment
7200,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7201,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
7202,We hope more developers to discuss and contribute.,Contribution and Commitment
7203,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7204,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7205,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
7206,I am very willing to contribute.,Contribution and Commitment
7207,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7208,We hope more developers to discuss and contribute.,Contribution and Commitment
7209,Please note I'm not going to do this.,Contribution and Commitment
7210,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7211,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7212,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7213,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7214,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7215,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7216,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
7217,I am willing to contribute.,Contribution and Commitment
7218,So if you could give this a look that would be welcome.,Contribution and Commitment
7219,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7220,Is it possible for us do this in anyway?,Contribution and Commitment
7221,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7222,Would be glad to lend a hand...,Contribution and Commitment
7223,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7224,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7225,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7226,I can check.,Contribution and Commitment
7227,Can you guys please help me?,Contribution and Commitment
7228,"Gunhan, is that possible?",Contribution and Commitment
7229,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7230,Anyone up to write a NodeJS library?,Contribution and Commitment
7231,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7232,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
7233,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
7234,Would be glad to lend a hand...,Contribution and Commitment
7235,After that I should also have time again to work on it.,Contribution and Commitment
7236,I would gladly lend a hand.,Contribution and Commitment
7237,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7238,Feel free to patch for Debian.,Contribution and Commitment
7239,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7240,Can you guys please help me?,Contribution and Commitment
7241,Would also be glad to help.,Contribution and Commitment
7242,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
7243,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
7244,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7245,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7246,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
7247,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7248,"I would be happy to help, of course.",Contribution and Commitment
7249,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7250,We hope more developers to discuss and contribute.,Contribution and Commitment
7251,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7252,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7253,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7254,I have a Windows VM.,Contribution and Commitment
7255,"I would be happy to help, of course.",Contribution and Commitment
7256,We hope more developers to discuss and contribute.,Contribution and Commitment
7257,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
7258,ping @ogrisel?,Contribution and Commitment
7259,Feel free to patch for Debian.,Contribution and Commitment
7260,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7261,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7262,I can check.,Contribution and Commitment
7263,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
7264,After that I should also have time again to work on it.,Contribution and Commitment
7265,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7266,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7267,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7268,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7269,Can you guys please help me?,Contribution and Commitment
7270,Please note I'm not going to do this.,Contribution and Commitment
7271,@Foorack I am willing to contribute it if some people are interested as well.,Contribution and Commitment
7272,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7273,We hope more developers to discuss and contribute.,Contribution and Commitment
7274,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
7275,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7276,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7277,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7278,@ogrisel I will give it a try :),Contribution and Commitment
7279,@ogrisel I will give it a try :),Contribution and Commitment
7280,@lukaszkaiser can you take a look?,Contribution and Commitment
7281,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7282,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7283,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
7284,@sguada assigning to you for triaging.,Contribution and Commitment
7285,Anyone up to write a NodeJS library?,Contribution and Commitment
7286,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7287,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7288,(cc @martinwicke ? ),Contribution and Commitment
7289,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7290,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7291,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7292,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
7293,"(I will do this when I'm available, aha)",Contribution and Commitment
7294,"(I will do this when I'm available, aha)",Contribution and Commitment
7295,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7296,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7297,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7298,I would gladly lend a hand.,Contribution and Commitment
7299,"Gunhan, is that possible?",Contribution and Commitment
7300,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
7301,So if you could give this a look that would be welcome.,Contribution and Commitment
7302,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7303,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7304,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7305,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7306,Would be glad to lend a hand...,Contribution and Commitment
7307,Any other ideas?,Contribution and Commitment
7308,Please note I'm not going to do this.,Contribution and Commitment
7309,"But, I am now planning to look at this again.",Contribution and Commitment
7310,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
7311,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7312,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7313,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7314,Any other ideas?,Contribution and Commitment
7315,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7316,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7317,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
7318,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
7319,pinging @asimshankar,Contribution and Commitment
7320,So if you could give this a look that would be welcome.,Contribution and Commitment
7321,Feel free to patch for Debian.,Contribution and Commitment
7322,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7323,@ogrisel I will give it a try :),Contribution and Commitment
7324,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7325,pinging @asimshankar,Contribution and Commitment
7326,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment
7327,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7328,Could you help us debug?,Contribution and Commitment
7329,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7330,@ogrisel I will give it a try :),Contribution and Commitment
7331,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7332,I can check.,Contribution and Commitment
7333,Would be glad to lend a hand...,Contribution and Commitment
7334,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7335,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7336,"I would be happy to help, of course.",Contribution and Commitment
7337,Might be worth getting a tech writer on the case.,Contribution and Commitment
7338,"(I will do this when I'm available, aha)",Contribution and Commitment
7339,Could you help us debug?,Contribution and Commitment
7340,I'm working on some parts of that.,Contribution and Commitment
7341,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
7342,Any other ideas?,Contribution and Commitment
7343,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7344,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7345,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7346,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7347,ping @ogrisel?,Contribution and Commitment
7348,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7349,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7350,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
7351,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7352,I can check.,Contribution and Commitment
7353,I can check.,Contribution and Commitment
7354,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7355,I will try to get the first part in soon.,Contribution and Commitment
7356,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7357,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7358,Would be glad to lend a hand...,Contribution and Commitment
7359,So if you could give this a look that would be welcome.,Contribution and Commitment
7360,I would gladly lend a hand.,Contribution and Commitment
7361,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7362,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7363,"Ping @tommoral, @ogrisel",Contribution and Commitment
7364,After that I should also have time again to work on it.,Contribution and Commitment
7365,Any other ideas?,Contribution and Commitment
7366,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
7367,"I would be happy to help, of course.",Contribution and Commitment
7368,Feel free to patch for Debian.,Contribution and Commitment
7369,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7370,Would also be glad to help.,Contribution and Commitment
7371,I would gladly lend a hand.,Contribution and Commitment
7372,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7373,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7374,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7375,"I would be happy to help, of course.",Contribution and Commitment
7376,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7377,@Foorack I am willing to contribute it if some people are interested as well.,Contribution and Commitment
7378,We hope more developers to discuss and contribute.,Contribution and Commitment
7379,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7380,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7381,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7382,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7383,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7384,Is it possible for us do this in anyway?,Contribution and Commitment
7385,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7386,We hope more developers to discuss and contribute.,Contribution and Commitment
7387,Could you help us debug?,Contribution and Commitment
7388,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
7389,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7390,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7391,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7392,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
7393,Please note I'm not going to do this.,Contribution and Commitment
7394,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7395,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
7396,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7397,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
7398,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7399,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7400,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7401,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7402,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7403,I am very willing to contribute.,Contribution and Commitment
7404,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7405,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7406,pinging @asimshankar,Contribution and Commitment
7407,Please note I'm not going to do this.,Contribution and Commitment
7408,Would be glad to lend a hand...,Contribution and Commitment
7409,Feel free to patch for Debian.,Contribution and Commitment
7410,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7411,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7412,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
7413,I can check.,Contribution and Commitment
7414,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
7415,I can check.,Contribution and Commitment
7416,I would gladly lend a hand.,Contribution and Commitment
7417,"I would be happy to help, of course.",Contribution and Commitment
7418,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7419,@ogrisel I will give it a try :),Contribution and Commitment
7420,Is it possible for us do this in anyway?,Contribution and Commitment
7421,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7422,Can you guys please help me?,Contribution and Commitment
7423,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7424,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7425,I would gladly lend a hand.,Contribution and Commitment
7426,I am very willing to contribute.,Contribution and Commitment
7427,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7428,"(I will do this when I'm available, aha)",Contribution and Commitment
7429,Anyone up to write a NodeJS library?,Contribution and Commitment
7430,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
7431,Is it possible for us do this in anyway?,Contribution and Commitment
7432,I am very willing to contribute.,Contribution and Commitment
7433,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7434,I am willing to contribute.,Contribution and Commitment
7435,We hope more developers to discuss and contribute.,Contribution and Commitment
7436,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7437,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7438,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7439,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7440,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7441,Please note I'm not going to do this.,Contribution and Commitment
7442,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7443,I will try to get the first part in soon.,Contribution and Commitment
7444,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7445,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7446,I can check.,Contribution and Commitment
7447,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7448,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7449,"Ping @tommoral, @ogrisel",Contribution and Commitment
7450,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
7451,Anyone up to write a NodeJS library?,Contribution and Commitment
7452,Would be glad to lend a hand...,Contribution and Commitment
7453,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7454,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7455,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
7456,I really need to fix this issue.,Contribution and Commitment
7457,Any other ideas?,Contribution and Commitment
7458,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7459,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7460,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7461,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7462,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7463,After that I should also have time again to work on it.,Contribution and Commitment
7464,I am very willing to contribute.,Contribution and Commitment
7465,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7466,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7467,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7468,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
7469,Can you guys please help me?,Contribution and Commitment
7470,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7471,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment
7472,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7473,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7474,I can check.,Contribution and Commitment
7475,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7476,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7477,"(I will do this when I'm available, aha)",Contribution and Commitment
7478,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
7479,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7480,pinging @asimshankar,Contribution and Commitment
7481,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7482,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7483,"I would be happy to help, of course.",Contribution and Commitment
7484,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7485,I would gladly lend a hand.,Contribution and Commitment
7486,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
7487,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
7488,pinging @asimshankar,Contribution and Commitment
7489,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7490,@ogrisel I will give it a try :),Contribution and Commitment
7491,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
7492,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7493,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7494,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7495,We hope more developers to discuss and contribute.,Contribution and Commitment
7496,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7497,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7498,Would be glad to lend a hand...,Contribution and Commitment
7499,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7500,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7501,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7502,@sguada assigning to you for triaging.,Contribution and Commitment
7503,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7504,Feel free to patch for Debian.,Contribution and Commitment
7505,So if you could give this a look that would be welcome.,Contribution and Commitment
7506,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
7507,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7508,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7509,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
7510,We hope more developers to discuss and contribute.,Contribution and Commitment
7511,pinging @asimshankar,Contribution and Commitment
7512,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7513,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
7514,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7515,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7516,Feel free to patch for Debian.,Contribution and Commitment
7517,"I would be happy to help, of course.",Contribution and Commitment
7518,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7519,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7520,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7521,I would gladly lend a hand.,Contribution and Commitment
7522,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7523,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
7524,We hope more developers to discuss and contribute.,Contribution and Commitment
7525,Would also be glad to help.,Contribution and Commitment
7526,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7527,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7528,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7529,Is it possible for us do this in anyway?,Contribution and Commitment
7530,@ogrisel I will give it a try :),Contribution and Commitment
7531,"(I will do this when I'm available, aha)",Contribution and Commitment
7532,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7533,We hope more developers to discuss and contribute.,Contribution and Commitment
7534,So if you could give this a look that would be welcome.,Contribution and Commitment
7535,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
7536,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7537,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
7538,Can you guys please help me?,Contribution and Commitment
7539,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7540,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7541,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7542,"Ping @tommoral, @ogrisel",Contribution and Commitment
7543,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7544,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
7545,"I would be happy to help, of course.",Contribution and Commitment
7546,I have a Windows VM.,Contribution and Commitment
7547,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
7548,I really need to fix this issue.,Contribution and Commitment
7549,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
7550,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7551,@lukaszkaiser can you take a look?,Contribution and Commitment
7552,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
7553,I will try to get the first part in soon.,Contribution and Commitment
7554,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7555,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
7556,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7557,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7558,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
7559,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
7560,"Ping @tommoral, @ogrisel",Contribution and Commitment
7561,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7562,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7563,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7564,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7565,Anyone up to write a NodeJS library?,Contribution and Commitment
7566,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7567,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7568,I have a Windows VM.,Contribution and Commitment
7569,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7570,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7571,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment
7572,@lukaszkaiser can you take a look?,Contribution and Commitment
7573,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
7574,I will try to get the first part in soon.,Contribution and Commitment
7575,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
7576,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
7577,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7578,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7579,@lukaszkaiser can you take a look?,Contribution and Commitment
7580,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7581,"(I will do this when I'm available, aha)",Contribution and Commitment
7582,pinging @asimshankar,Contribution and Commitment
7583,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
7584,I am very willing to contribute.,Contribution and Commitment
7585,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7586,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7587,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7588,I will try to get the first part in soon.,Contribution and Commitment
7589,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment
7590,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7591,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7592,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7593,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
7594,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
7595,Would also be glad to help.,Contribution and Commitment
7596,@Foorack I am willing to contribute it if some people are interested as well.,Contribution and Commitment
7597,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7598,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment
7599,After that I should also have time again to work on it.,Contribution and Commitment
7600,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7601,After that I should also have time again to work on it.,Contribution and Commitment
7602,@lukaszkaiser can you take a look?,Contribution and Commitment
7603,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7604,After that I should also have time again to work on it.,Contribution and Commitment
7605,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7606,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7607,"(I will do this when I'm available, aha)",Contribution and Commitment
7608,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7609,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7610,I will try to get the first part in soon.,Contribution and Commitment
7611,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7612,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7613,"Ping @tommoral, @ogrisel",Contribution and Commitment
7614,Would be glad to lend a hand...,Contribution and Commitment
7615,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7616,We hope more developers to discuss and contribute.,Contribution and Commitment
7617,I really need to fix this issue.,Contribution and Commitment
7618,@ogrisel I will give it a try :),Contribution and Commitment
7619,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7620,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7621,Feel free to patch for Debian.,Contribution and Commitment
7622,(cc @martinwicke ? ),Contribution and Commitment
7623,@lukaszkaiser can you take a look?,Contribution and Commitment
7624,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
7625,Feel free to patch for Debian.,Contribution and Commitment
7626,@lukaszkaiser can you take a look?,Contribution and Commitment
7627,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
7628,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7629,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
7630,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7631,"I would be happy to help, of course.",Contribution and Commitment
7632,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7633,@ogrisel I will give it a try :),Contribution and Commitment
7634,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7635,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7636,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7637,Might be worth getting a tech writer on the case.,Contribution and Commitment
7638,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7639,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7640,@ogrisel I will give it a try :),Contribution and Commitment
7641,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7642,Anyone up to write a NodeJS library?,Contribution and Commitment
7643,Might be worth getting a tech writer on the case.,Contribution and Commitment
7644,"(I will do this when I'm available, aha)",Contribution and Commitment
7645,"(I will do this when I'm available, aha)",Contribution and Commitment
7646,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7647,@ogrisel I will give it a try :),Contribution and Commitment
7648,"Gunhan, is that possible?",Contribution and Commitment
7649,I am willing to contribute.,Contribution and Commitment
7650,Could you help us debug?,Contribution and Commitment
7651,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7652,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
7653,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
7654,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7655,I am willing to contribute.,Contribution and Commitment
7656,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
7657,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
7658,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7659,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7660,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7661,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment
7662,(cc @martinwicke ? ),Contribution and Commitment
7663,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
7664,I would gladly lend a hand.,Contribution and Commitment
7665,"Gunhan, is that possible?",Contribution and Commitment
7666,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7667,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7668,Anyone up to write a NodeJS library?,Contribution and Commitment
7669,I would gladly lend a hand.,Contribution and Commitment
7670,"I would be happy to help, of course.",Contribution and Commitment
7671,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7672,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7673,I will try to get the first part in soon.,Contribution and Commitment
7674,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7675,After that I should also have time again to work on it.,Contribution and Commitment
7676,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7677,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7678,I am very willing to contribute.,Contribution and Commitment
7679,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7680,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7681,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7682,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
7683,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7684,I have a Windows VM.,Contribution and Commitment
7685,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
7686,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7687,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7688,Would be glad to lend a hand...,Contribution and Commitment
7689,Would also be glad to help.,Contribution and Commitment
7690,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7691,"(I will do this when I'm available, aha)",Contribution and Commitment
7692,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7693,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7694,Feel free to patch for Debian.,Contribution and Commitment
7695,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7696,"Gunhan, is that possible?",Contribution and Commitment
7697,"Ping @tommoral, @ogrisel",Contribution and Commitment
7698,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7699,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7700,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7701,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
7702,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
7703,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
7704,Could you help us debug?,Contribution and Commitment
7705,"But, I am now planning to look at this again.",Contribution and Commitment
7706,@sguada assigning to you for triaging.,Contribution and Commitment
7707,ping @ogrisel?,Contribution and Commitment
7708,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7709,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
7710,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7711,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7712,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7713,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7714,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7715,Would also be glad to help.,Contribution and Commitment
7716,ping @ogrisel?,Contribution and Commitment
7717,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7718,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7719,Would be glad to lend a hand...,Contribution and Commitment
7720,Please note I'm not going to do this.,Contribution and Commitment
7721,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7722,I have a Windows VM.,Contribution and Commitment
7723,Would be glad to lend a hand...,Contribution and Commitment
7724,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7725,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7726,Feel free to patch for Debian.,Contribution and Commitment
7727,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7728,ping @ogrisel?,Contribution and Commitment
7729,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7730,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7731,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment
7732,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7733,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7734,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
7735,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment
7736,Would also be glad to help.,Contribution and Commitment
7737,"Gunhan, is that possible?",Contribution and Commitment
7738,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
7739,I would gladly lend a hand.,Contribution and Commitment
7740,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
7741,Please note I'm not going to do this.,Contribution and Commitment
7742,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
7743,Anyone up to write a NodeJS library?,Contribution and Commitment
7744,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
7745,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
7746,Can you guys please help me?,Contribution and Commitment
7747,Could you help us debug?,Contribution and Commitment
7748,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7749,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7750,Please note I'm not going to do this.,Contribution and Commitment
7751,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7752,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
7753,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
7754,ping @ogrisel?,Contribution and Commitment
7755,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
7756,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7757,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7758,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7759,"I would be happy to help, of course.",Contribution and Commitment
7760,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7761,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
7762,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7763,@ogrisel I will give it a try :),Contribution and Commitment
7764,@lukaszkaiser can you take a look?,Contribution and Commitment
7765,(cc @martinwicke ? ),Contribution and Commitment
7766,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7767,I'm working on some parts of that.,Contribution and Commitment
7768,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7769,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7770,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7771,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7772,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7773,Would be glad to lend a hand...,Contribution and Commitment
7774,We hope more developers to discuss and contribute.,Contribution and Commitment
7775,"Gunhan, is that possible?",Contribution and Commitment
7776,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7777,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7778,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7779,Feel free to patch for Debian.,Contribution and Commitment
7780,"(I will do this when I'm available, aha)",Contribution and Commitment
7781,Would be glad to lend a hand...,Contribution and Commitment
7782,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
7783,Is it possible for us do this in anyway?,Contribution and Commitment
7784,pinging @asimshankar,Contribution and Commitment
7785,I have a Windows VM.,Contribution and Commitment
7786,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7787,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7788,Would also be glad to help.,Contribution and Commitment
7789,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7790,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7791,I have a Windows VM.,Contribution and Commitment
7792,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
7793,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7794,ping @ogrisel?,Contribution and Commitment
7795,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
7796,ping @ogrisel?,Contribution and Commitment
7797,Would be glad to lend a hand...,Contribution and Commitment
7798,I am very willing to contribute.,Contribution and Commitment
7799,"Gunhan, is that possible?",Contribution and Commitment
7800,I am willing to contribute.,Contribution and Commitment
7801,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7802,So if you could give this a look that would be welcome.,Contribution and Commitment
7803,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7804,I am willing to contribute.,Contribution and Commitment
7805,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7806,@lukaszkaiser can you take a look?,Contribution and Commitment
7807,Anyone up to write a NodeJS library?,Contribution and Commitment
7808,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7809,We hope more developers to discuss and contribute.,Contribution and Commitment
7810,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7811,I can check.,Contribution and Commitment
7812,Would be glad to lend a hand...,Contribution and Commitment
7813,@sguada assigning to you for triaging.,Contribution and Commitment
7814,"Ping @tommoral, @ogrisel",Contribution and Commitment
7815,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
7816,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7817,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
7818,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
7819,Is it possible for us do this in anyway?,Contribution and Commitment
7820,Might be worth getting a tech writer on the case.,Contribution and Commitment
7821,Might be worth getting a tech writer on the case.,Contribution and Commitment
7822,Would be glad to lend a hand...,Contribution and Commitment
7823,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
7824,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7825,We hope more developers to discuss and contribute.,Contribution and Commitment
7826,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7827,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment
7828,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7829,I can check.,Contribution and Commitment
7830,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
7831,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7832,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7833,I'm working on some parts of that.,Contribution and Commitment
7834,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7835,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7836,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7837,So if you could give this a look that would be welcome.,Contribution and Commitment
7838,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
7839,"But, I am now planning to look at this again.",Contribution and Commitment
7840,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7841,So if you could give this a look that would be welcome.,Contribution and Commitment
7842,Feel free to patch for Debian.,Contribution and Commitment
7843,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7844,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7845,@lukaszkaiser can you take a look?,Contribution and Commitment
7846,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7847,"Gunhan, is that possible?",Contribution and Commitment
7848,I have a Windows VM.,Contribution and Commitment
7849,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7850,@lukaszkaiser can you take a look?,Contribution and Commitment
7851,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7852,@lukaszkaiser can you take a look?,Contribution and Commitment
7853,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7854,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7855,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7856,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7857,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7858,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7859,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
7860,So if you could give this a look that would be welcome.,Contribution and Commitment
7861,I really need to fix this issue.,Contribution and Commitment
7862,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7863,Is it possible for us do this in anyway?,Contribution and Commitment
7864,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7865,I would gladly lend a hand.,Contribution and Commitment
7866,I am very willing to contribute.,Contribution and Commitment
7867,@lukaszkaiser can you take a look?,Contribution and Commitment
7868,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
7869,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7870,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7871,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
7872,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
7873,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
7874,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7875,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
7876,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7877,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7878,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
7879,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7880,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
7881,So if you could give this a look that would be welcome.,Contribution and Commitment
7882,@sguada assigning to you for triaging.,Contribution and Commitment
7883,I'm working on some parts of that.,Contribution and Commitment
7884,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
7885,"I would be happy to help, of course.",Contribution and Commitment
7886,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7887,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
7888,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7889,"I would be happy to help, of course.",Contribution and Commitment
7890,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
7891,I can check.,Contribution and Commitment
7892,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7893,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7894,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7895,I have a Windows VM.,Contribution and Commitment
7896,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7897,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment
7898,Might be worth getting a tech writer on the case.,Contribution and Commitment
7899,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7900,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7901,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7902,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7903,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
7904,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
7905,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7906,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7907,@sguada assigning to you for triaging.,Contribution and Commitment
7908,Would also be glad to help.,Contribution and Commitment
7909,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7910,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
7911,I have a Windows VM.,Contribution and Commitment
7912,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
7913,@sguada assigning to you for triaging.,Contribution and Commitment
7914,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7915,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7916,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7917,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
7918,I would gladly lend a hand.,Contribution and Commitment
7919,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7920,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7921,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7922,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7923,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7924,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7925,Anyone up to write a NodeJS library?,Contribution and Commitment
7926,I really need to fix this issue.,Contribution and Commitment
7927,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7928,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7929,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment
7930,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7931,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7932,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
7933,I'm working on some parts of that.,Contribution and Commitment
7934,I will try to get the first part in soon.,Contribution and Commitment
7935,@lukaszkaiser can you take a look?,Contribution and Commitment
7936,Please note I'm not going to do this.,Contribution and Commitment
7937,After that I should also have time again to work on it.,Contribution and Commitment
7938,Feel free to patch for Debian.,Contribution and Commitment
7939,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
7940,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7941,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7942,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
7943,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment
7944,"Sorry, but I really don't do Windows :)",Contribution and Commitment
7945,@Foorack I am willing to contribute it if some people are interested as well.,Contribution and Commitment
7946,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7947,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7948,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
7949,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
7950,Any other ideas?,Contribution and Commitment
7951,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
7952,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
7953,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment
7954,I would gladly lend a hand.,Contribution and Commitment
7955,I really need to fix this issue.,Contribution and Commitment
7956,@lukaszkaiser can you take a look?,Contribution and Commitment
7957,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
7958,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7959,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7960,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7961,Can you guys please help me?,Contribution and Commitment
7962,"Gunhan, is that possible?",Contribution and Commitment
7963,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
7964,I have a Windows VM.,Contribution and Commitment
7965,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
7966,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
7967,@lesteve probably will be able to infer more from this?,Contribution and Commitment
7968,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
7969,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
7970,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
7971,Is it possible for us do this in anyway?,Contribution and Commitment
7972,(cc @martinwicke ? ),Contribution and Commitment
7973,I'm working on some parts of that.,Contribution and Commitment
7974,@ogrisel I will give it a try :),Contribution and Commitment
7975,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7976,@ebrevdo Could you please take a look at this?,Contribution and Commitment
7977,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
7978,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
7979,pinging @asimshankar,Contribution and Commitment
7980,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
7981,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7982,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
7983,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment
7984,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
7985,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
7986,Is it possible for us do this in anyway?,Contribution and Commitment
7987,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment
7988,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
7989,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment
7990,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
7991,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7992,@ogrisel I will give it a try :),Contribution and Commitment
7993,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
7994,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
7995,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
7996,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
7997,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
7998,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment
7999,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
8000,"If I have some time this week, I'll submit a PR.",Contribution and Commitment
8001,So if you could give this a look that would be welcome.,Contribution and Commitment
8002,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
8003,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
8004,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
8005,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
8006,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
8007,"Ping @tommoral, @ogrisel",Contribution and Commitment
8008,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
8009,I have a Windows VM.,Contribution and Commitment
8010,Would be glad to lend a hand...,Contribution and Commitment
8011,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
8012,pinging @asimshankar,Contribution and Commitment
8013,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
8014,"But, I am now planning to look at this again.",Contribution and Commitment
8015,Would be glad to lend a hand...,Contribution and Commitment
8016,I would gladly lend a hand.,Contribution and Commitment
8017,@lukaszkaiser can you take a look?,Contribution and Commitment
8018,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
8019,@ebrevdo Could you please take a look at this?,Contribution and Commitment
8020,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
8021,I am very willing to contribute.,Contribution and Commitment
8022,"I would be happy to help, of course.",Contribution and Commitment
8023,"Sorry, but I really don't do Windows :)",Contribution and Commitment
8024,Would also be glad to help.,Contribution and Commitment
8025,I would gladly lend a hand.,Contribution and Commitment
8026,I am willing to contribute.,Contribution and Commitment
8027,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
8028,"Gunhan, is that possible?",Contribution and Commitment
8029,I would gladly lend a hand.,Contribution and Commitment
8030,Can you guys please help me?,Contribution and Commitment
8031,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
8032,pinging @asimshankar,Contribution and Commitment
8033,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
8034,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
8035,Feel free to patch for Debian.,Contribution and Commitment
8036,@Foorack I am willing to contribute it if some people are interested as well.,Contribution and Commitment
8037,@Foorack I am willing to contribute it if some people are interested as well.,Contribution and Commitment
8038,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment
8039,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
8040,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
8041,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
8042,"Sorry, but I really don't do Windows :)",Contribution and Commitment
8043,@ogrisel I will give it a try :),Contribution and Commitment
8044,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
8045,pinging @asimshankar,Contribution and Commitment
8046,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
8047,(cc @martinwicke ? ),Contribution and Commitment
8048,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
8049,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
8050,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
8051,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
8052,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
8053,"(I will do this when I'm available, aha)",Contribution and Commitment
8054,@lukaszkaiser can you take a look?,Contribution and Commitment
8055,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
8056,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment
8057,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
8058,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
8059,Anyone up to write a NodeJS library?,Contribution and Commitment
8060,"Gunhan, is that possible?",Contribution and Commitment
8061,Please note I'm not going to do this.,Contribution and Commitment
8062,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
8063,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
8064,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
8065,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
8066,I really need to fix this issue.,Contribution and Commitment
8067,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment
8068,ping @ogrisel?,Contribution and Commitment
8069,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
8070,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
8071,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
8072,@sguada assigning to you for triaging.,Contribution and Commitment
8073,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
8074,I have a Windows VM.,Contribution and Commitment
8075,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
8076,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
8077,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
8078,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
8079,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
8080,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
8081,Is it possible for us do this in anyway?,Contribution and Commitment
8082,Would also be glad to help.,Contribution and Commitment
8083,ping @ogrisel?,Contribution and Commitment
8084,"Sorry, but I really don't do Windows :)",Contribution and Commitment
8085,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
8086,"(I will do this when I'm available, aha)",Contribution and Commitment
8087,I have a Windows VM.,Contribution and Commitment
8088,"But, I am now planning to look at this again.",Contribution and Commitment
8089,I am willing to contribute.,Contribution and Commitment
8090,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
8091,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
8092,We hope more developers to discuss and contribute.,Contribution and Commitment
8093,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment
8094,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment
8095,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
8096,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment
8097,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment
8098,I would gladly lend a hand.,Contribution and Commitment
8099,Might be worth getting a tech writer on the case.,Contribution and Commitment
8100,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
8101,I can check.,Contribution and Commitment
8102,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment
8103,"Would be great if someone else could try the ""fix.""",Contribution and Commitment
8104,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
8105,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment
8106,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment
8107,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment
8108,Would also be glad to help.,Contribution and Commitment
8109,Any other ideas?,Contribution and Commitment
8110,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
8111,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment
8112,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
8113,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment
8114,Would also be glad to help.,Contribution and Commitment
8115,"Sorry, but I really don't do Windows :)",Contribution and Commitment
8116,I can check.,Contribution and Commitment
8117,We hope more developers to discuss and contribute.,Contribution and Commitment
8118,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
8119,@ogrisel I will give it a try :),Contribution and Commitment
8120,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
8121,"Ping @tommoral, @ogrisel",Contribution and Commitment
8122,I would gladly lend a hand.,Contribution and Commitment
8123,Any other ideas?,Contribution and Commitment
8124,I am willing to contribute.,Contribution and Commitment
8125,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
8126,We hope more developers to discuss and contribute.,Contribution and Commitment
8127,I can check.,Contribution and Commitment
8128,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment
8129,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment
8130,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
8131,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
8132,Anyone up to write a NodeJS library?,Contribution and Commitment
8133,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
8134,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment
8135,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment
8136,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment
8137,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment
8138,"I would be happy to help, of course.",Contribution and Commitment
8139,@ogrisel I will give it a try :),Contribution and Commitment
8140,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
8141,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment
8142,"(I will do this when I'm available, aha)",Contribution and Commitment
8143,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
8144,"Gunhan, is that possible?",Contribution and Commitment
8145,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment
8146,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
8147,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
8148,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment
8149,"Gunhan, is that possible?",Contribution and Commitment
8150,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment
8151,I'm working on some parts of that.,Contribution and Commitment
8152,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment
8153,Please note I'm not going to do this.,Contribution and Commitment
8154,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
8155,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
8156,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment
8157,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment
8158,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment
8159,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment
8160,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment
8161,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment
8162,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment
8163,Might be worth getting a tech writer on the case.,Contribution and Commitment
8164,Anyone up to write a NodeJS library?,Contribution and Commitment
8165,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment
8166,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment
8167,I can check.,Contribution and Commitment
8168,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment
8169,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment
8170,Would be glad to lend a hand...,Contribution and Commitment
8171,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment
8172,(cc @martinwicke ? ),Contribution and Commitment
8173,I really need to fix this issue.,Contribution and Commitment
8174,What about supporting custom ops to create a Dataset?,Expected Behaviour
8175,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
8176,Node.js (JavaScript) Wrapper API,Expected Behaviour
8177,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
8178,My suggestion/request in the near term would be to have an option to make the vocabulary read only so that users who want to be able to leave spacy alone to do streaming data processing don't need to worry about changing memory requirements.,Expected Behaviour
8179,*         [iter_shuffle_batch_tensors] URL ,Expected Behaviour
8180,4.         Closer integration with HDF5 anyway,Expected Behaviour
8181,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
8182,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
8183,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8184,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
8185,"Whether anybody actually *wants* this ""max value""-based method, or whether we are fine with (in the future, after deprecation) only having the ""unique values""-based method.",Expected Behaviour
8186,"To be more precise, we need support for pipelines where learning is done in an online fashion, and training data is generated by a system responding to actions of a TensorFlow network (learning Atari simulator, robotics simulator, robot interacting with real world, etc).",Expected Behaviour
8187,Fitting additional estimators for ensemble methods,Expected Behaviour
8188,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
8189,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
8190,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
8191,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
8192,This gives: CODE,Expected Behaviour
8193,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
8194,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
8195,Node.js (JavaScript) Wrapper API,Expected Behaviour
8196,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
8197,What about supporting custom ops to create a Dataset?,Expected Behaviour
8198,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
8199,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
8200,"In the long term, I think that an optimal solution would be to add some functionality for a timeout on vocabulary entries that aren't loaded at initialization.",Expected Behaviour
8201,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
8202,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
8203,My suggestion/request in the near term would be to have an option to make the vocabulary read only so that users who want to be able to leave spacy alone to do streaming data processing don't need to worry about changing memory requirements.,Expected Behaviour
8204,This gives: CODE,Expected Behaviour
8205,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
8206,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
8207,"Feature Request: Vector ""File"" interface",Expected Behaviour
8208,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
8209,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
8210,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8211,Additional Language Support,Expected Behaviour
8212,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8213,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
8214,"One function that still seems to be missing, but would be essential for one of our primary use cases (see comment above: https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283186552) is a CODEused as inCODE function, where one element of CODE is mapped to one **or more** elements for CODE; i.e. #CODE >= #CODE.",Expected Behaviour
8215,I don't think fit_extend is a particularly great name so I'd welcome other suggestions.,Expected Behaviour
8216,input_fn has to return features and labels only.,Expected Behaviour
8217,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
8218,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
8219,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
8220,*         More iterators!,Expected Behaviour
8221,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
8222,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour
8223,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
8224,-         Support for SparseTensors.,Expected Behaviour
8225,I would be interested in a pipeline where:,Expected Behaviour
8226,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
8227,"For my use case it seems like CODE could represent a collection of time series, and the CODE would behave like a python iterator/generator and could handle any preprocessing to form batches of examples?",Expected Behaviour
8228,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
8229,4.         Closer integration with HDF5 anyway,Expected Behaviour
8230,I would be interested in a pipeline where:,Expected Behaviour
8231,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
8232,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
8233,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
8234,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
8235,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
8236,I'd like:,Expected Behaviour
8237,CODE,Expected Behaviour
8238,*         More iterators!,Expected Behaviour
8239,Really waiting for a machine library in JavaScript.,Expected Behaviour
8240,input_fn has to return features and labels only.,Expected Behaviour
8241,Consider the dataframe CODE which equals: CODE,Expected Behaviour
8242,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
8243,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
8244,"One function that still seems to be missing, but would be essential for one of our primary use cases (see comment above: https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283186552) is a CODEused as inCODE function, where one element of CODE is mapped to one **or more** elements for CODE; i.e. #CODE >= #CODE.",Expected Behaviour
8245,Please support reading hdf5 file directly.,Expected Behaviour
8246,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
8247,-         Most importantly we need to address the dequeueing overhead.,Expected Behaviour
8248,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
8249,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
8250,Please support reading hdf5 file directly.,Expected Behaviour
8251,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
8252,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
8253,*         [cycle_range] URL ,Expected Behaviour
8254,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8255,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
8256,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
8257,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour
8258,-         The dataset class (and not the model) should probably the one to have batch_size passed to it.,Expected Behaviour
8259,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
8260,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8261,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
8262,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
8263,I would like to propose an additional instance method to the ensemble estimators to fit additional sub-estimators.,Expected Behaviour
8264,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
8265,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour
8266,"For my use case it seems like CODE could represent a collection of time series, and the CODE would behave like a python iterator/generator and could handle any preprocessing to form batches of examples?",Expected Behaviour
8267,I'd like:,Expected Behaviour
8268,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
8269,*         [shuffle_iter] URL ,Expected Behaviour
8270,4.         Closer integration with HDF5 anyway,Expected Behaviour
8271,It would be nice so see something in this flavor: CODE,Expected Behaviour
8272,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
8273,What about supporting custom ops to create a Dataset?,Expected Behaviour
8274,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
8275,"Having some bundles, predefined ""easy-starter"" wrappers should be welcomed.",Expected Behaviour
8276,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8277,-         The dataset class (and not the model) should probably the one to have batch_size passed to it.,Expected Behaviour
8278,"To be more precise, we need support for pipelines where learning is done in an online fashion, and training data is generated by a system responding to actions of a TensorFlow network (learning Atari simulator, robotics simulator, robot interacting with real world, etc).",Expected Behaviour
8279,"Additionally, would be great to get some clarity from the tensorflow team on what API's would be good to initially cover as I'm sure their roadmap has many changes on the way, and I wouldn't want to conflict.",Expected Behaviour
8280,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
8281,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
8282,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8283,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
8284,CODE,Expected Behaviour
8285,Some other ideas I jotted down while brainstorming my own class:,Expected Behaviour
8286,"Then a solution I really like to see, is to be able to receive(similar to dequeue) tensors from a different process.",Expected Behaviour
8287,Like:CODE,Expected Behaviour
8288,Really waiting for a machine library in JavaScript.,Expected Behaviour
8289,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour
8290,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
8291,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
8292,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
8293,CODE,Expected Behaviour
8294,4.         Closer integration with HDF5 anyway,Expected Behaviour
8295,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour
8296,It would be nice so see something in this flavor: CODE,Expected Behaviour
8297,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
8298,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
8299,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
8300,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
8301,input_fn has to return features and labels only.,Expected Behaviour
8302,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour
8303,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8304,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
8305,"To be more precise, we need support for pipelines where learning is done in an online fashion, and training data is generated by a system responding to actions of a TensorFlow network (learning Atari simulator, robotics simulator, robot interacting with real world, etc).",Expected Behaviour
8306,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
8307,We can see the features names of the columns with: CODE,Expected Behaviour
8308,"Having some bundles, predefined ""easy-starter"" wrappers should be welcomed.",Expected Behaviour
8309,I would be interested in a pipeline where:,Expected Behaviour
8310,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
8311,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
8312,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
8313,The following iterators would be great:,Expected Behaviour
8314,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
8315,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
8316,1.         Efficient random sampling:,Expected Behaviour
8317,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
8318,CODE,Expected Behaviour
8319,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
8320,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
8321,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour
8322,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
8323,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
8324,CODE,Expected Behaviour
8325,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
8326,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
8327,*         More iterators!,Expected Behaviour
8328,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
8329,Streaming Data Memory Growth,Expected Behaviour
8330,input_fn has to return features and labels only.,Expected Behaviour
8331,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
8332,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
8333,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
8334,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
8335,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
8336,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
8337,So I would really appreciate if you could let me to feed the data **freely** in terms of **when** and **how**.,Expected Behaviour
8338,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
8339,"I would say that aside from the steep learning curve of input pipeline which can be overcome with documentation too, the key missing points are:",Expected Behaviour
8340,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
8341,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
8342,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
8343,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
8344,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
8345,"Whether anybody actually *wants* this ""max value""-based method, or whether we are fine with (in the future, after deprecation) only having the ""unique values""-based method.",Expected Behaviour
8346,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
8347,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8348,What about supporting custom ops to create a Dataset?,Expected Behaviour
8349,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
8350,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
8351,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8352,-         [product](https://docs.python.org/2/library/itertools.html#itertools.product),Expected Behaviour
8353,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8354,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour
8355,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
8356,*         [batch_iter] URL ,Expected Behaviour
8357,I'd like to see two things improved though:,Expected Behaviour
8358,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
8359,Consider the dataframe CODE which equals: CODE,Expected Behaviour
8360,What about supporting custom ops to create a Dataset?,Expected Behaviour
8361,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
8362,CODE,Expected Behaviour
8363,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
8364,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour
8365,"In the long term, I think that an optimal solution would be to add some functionality for a timeout on vocabulary entries that aren't loaded at initialization.",Expected Behaviour
8366,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
8367,CODE,Expected Behaviour
8368,My suggestion/request in the near term would be to have an option to make the vocabulary read only so that users who want to be able to leave spacy alone to do streaming data processing don't need to worry about changing memory requirements.,Expected Behaviour
8369,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
8370,1.         Efficient random sampling:,Expected Behaviour
8371,"So some concept of ""sample age"" would be nice.",Expected Behaviour
8372,"I would say that aside from the steep learning curve of input pipeline which can be overcome with documentation too, the key missing points are:",Expected Behaviour
8373,Additional Language Support,Expected Behaviour
8374,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
8375,*         multiprocessing rather than threading,Expected Behaviour
8376,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
8377,It would be nice so see something in this flavor: CODE,Expected Behaviour
8378,"Feature Request: Vector ""File"" interface",Expected Behaviour
8379,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
8380,Some other ideas I jotted down while brainstorming my own class:,Expected Behaviour
8381,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8382,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour
8383,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
8384,*         [cycle_range] URL ,Expected Behaviour
8385,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
8386,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
8387,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
8388,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
8389,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour
8390,"The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings).",Expected Behaviour
8391,Additional Language Support,Expected Behaviour
8392,I would like to propose an additional instance method to the ensemble estimators to fit additional sub-estimators.,Expected Behaviour
8393,Consider the dataframe CODE which equals: CODE,Expected Behaviour
8394,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8395,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
8396,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
8397,*         [cycle_range] URL ,Expected Behaviour
8398,Would greatly appreciate:,Expected Behaviour
8399,"To be more precise, we need support for pipelines where learning is done in an online fashion, and training data is generated by a system responding to actions of a TensorFlow network (learning Atari simulator, robotics simulator, robot interacting with real world, etc).",Expected Behaviour
8400,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
8401,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour
8402,It would be great to have GPU resident queues.,Expected Behaviour
8403,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
8404,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour
8405,*         [iter_tensors_slice] URL ,Expected Behaviour
8406,"What I'd like is for CODE and CODE there to output elements in the same order (because they share the CODE step), but with different functions (CODE/CODE) applied.",Expected Behaviour
8407,input_fn has to return features and labels only.,Expected Behaviour
8408,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
8409,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
8410,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
8411,2.         Dynamical changing and resizing methods:,Expected Behaviour
8412,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour
8413,And _n_ would be user configurable.,Expected Behaviour
8414,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
8415,So I would really appreciate if you could let me to feed the data **freely** in terms of **when** and **how**.,Expected Behaviour
8416,"Would love to replace standard vector file and in-memory loading with my own Redis (or any other ""shared-memory-system"") interface to allow a distributed cluster of spacy nodes to share the same ""file"".",Expected Behaviour
8417,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
8418,"In the long term, I think that an optimal solution would be to add some functionality for a timeout on vocabulary entries that aren't loaded at initialization.",Expected Behaviour
8419,"The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings).",Expected Behaviour
8420,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
8421,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
8422,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8423,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour
8424,-         Most importantly we need to address the dequeueing overhead.,Expected Behaviour
8425,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
8426,I would be interested in a pipeline where:,Expected Behaviour
8427,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
8428,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
8429,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
8430,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
8431,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
8432,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour
8433,*         [iter_tensors_slice] URL ,Expected Behaviour
8434,-         The dataset class (and not the model) should probably the one to have batch_size passed to it.,Expected Behaviour
8435,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
8436,It would be great to have GPU resident queues.,Expected Behaviour
8437,I'd like:,Expected Behaviour
8438,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
8439,4.         Closer integration with HDF5 anyway,Expected Behaviour
8440,Consider the dataframe CODE which equals: CODE,Expected Behaviour
8441,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
8442,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
8443,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour
8444,*         [iter_tensors_slice] URL ,Expected Behaviour
8445,Like:CODE,Expected Behaviour
8446,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
8447,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
8448,It would be nice so see something in this flavor: CODE,Expected Behaviour
8449,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
8450,*         [iter_shuffle_batch_tensors] URL ,Expected Behaviour
8451,Would greatly appreciate:,Expected Behaviour
8452,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
8453,CODE,Expected Behaviour
8454,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
8455,*         [cycle_range] URL ,Expected Behaviour
8456,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
8457,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
8458,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8459,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
8460,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour
8461,We can see the features names of the columns with: CODE,Expected Behaviour
8462,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
8463,CODE,Expected Behaviour
8464,"For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful.",Expected Behaviour
8465,Would greatly appreciate:,Expected Behaviour
8466,-         [product](https://docs.python.org/2/library/itertools.html#itertools.product),Expected Behaviour
8467,1.         Efficient random sampling:,Expected Behaviour
8468,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
8469,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
8470,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
8471,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
8472,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
8473,So I would really appreciate if you could let me to feed the data **freely** in terms of **when** and **how**.,Expected Behaviour
8474,input_fn has to return features and labels only.,Expected Behaviour
8475,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8476,Would greatly appreciate:,Expected Behaviour
8477,Some other ideas I jotted down while brainstorming my own class:,Expected Behaviour
8478,CODE,Expected Behaviour
8479,So I would really appreciate if you could let me to feed the data **freely** in terms of **when** and **how**.,Expected Behaviour
8480,1.         Efficient random sampling:,Expected Behaviour
8481,2.         Dynamical changing and resizing methods:,Expected Behaviour
8482,Node.js (JavaScript) Wrapper API,Expected Behaviour
8483,*         [cycle_range] URL ,Expected Behaviour
8484,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
8485,2.         Dynamical changing and resizing methods:,Expected Behaviour
8486,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour
8487,"Feature Request: Vector ""File"" interface",Expected Behaviour
8488,We can see the features names of the columns with: CODE,Expected Behaviour
8489,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
8490,We can see the features names of the columns with: CODE,Expected Behaviour
8491,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour
8492,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
8493,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
8494,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
8495,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
8496,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
8497,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
8498,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour
8499,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8500,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
8501,"For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful.",Expected Behaviour
8502,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
8503,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8504,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
8505,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour
8506,Please support reading hdf5 file directly.,Expected Behaviour
8507,"Then a solution I really like to see, is to be able to receive(similar to dequeue) tensors from a different process.",Expected Behaviour
8508,"For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful.",Expected Behaviour
8509,-         Most importantly we need to address the dequeueing overhead.,Expected Behaviour
8510,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
8511,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
8512,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
8513,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8514,*         multiprocessing rather than threading,Expected Behaviour
8515,-         [product](https://docs.python.org/2/library/itertools.html#itertools.product),Expected Behaviour
8516,And _n_ would be user configurable.,Expected Behaviour
8517,I'd like:,Expected Behaviour
8518,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8519,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
8520,Easy to use batch norm layer.,Expected Behaviour
8521,"Having some bundles, predefined ""easy-starter"" wrappers should be welcomed.",Expected Behaviour
8522,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
8523,CODE,Expected Behaviour
8524,*         [iter_tensors_slice] URL ,Expected Behaviour
8525,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
8526,(Like #4836),Expected Behaviour
8527,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
8528,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
8529,"What I'd like is for CODE and CODE there to output elements in the same order (because they share the CODE step), but with different functions (CODE/CODE) applied.",Expected Behaviour
8530,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
8531,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
8532,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour
8533,And _n_ would be user configurable.,Expected Behaviour
8534,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
8535,input_fn has to return features and labels only.,Expected Behaviour
8536,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
8537,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
8538,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
8539,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
8540,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
8541,So I would really appreciate if you could let me to feed the data **freely** in terms of **when** and **how**.,Expected Behaviour
8542,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
8543,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
8544,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
8545,And _n_ would be user configurable.,Expected Behaviour
8546,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
8547,CODE,Expected Behaviour
8548,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
8549,*         [iter_shuffle_batch_tensors] URL ,Expected Behaviour
8550,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour
8551,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
8552,-         The dataset class (and not the model) should probably the one to have batch_size passed to it.,Expected Behaviour
8553,It would be nice so see something in this flavor: CODE,Expected Behaviour
8554,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
8555,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
8556,*         [batch_iter] URL ,Expected Behaviour
8557,"One function that still seems to be missing, but would be essential for one of our primary use cases (see comment above: https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283186552) is a CODEused as inCODE function, where one element of CODE is mapped to one **or more** elements for CODE; i.e. #CODE >= #CODE.",Expected Behaviour
8558,-         Support for SparseTensors.,Expected Behaviour
8559,"To be more precise, we need support for pipelines where learning is done in an online fashion, and training data is generated by a system responding to actions of a TensorFlow network (learning Atari simulator, robotics simulator, robot interacting with real world, etc).",Expected Behaviour
8560,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
8561,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
8562,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
8563,*         [iter_shuffle_batch_tensors] URL ,Expected Behaviour
8564,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8565,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
8566,I'd like to see two things improved though:,Expected Behaviour
8567,*         More iterators!,Expected Behaviour
8568,Please support reading hdf5 file directly.,Expected Behaviour
8569,+1 to something like feed_dict.,Expected Behaviour
8570,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour
8571,Would greatly appreciate:,Expected Behaviour
8572,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
8573,Unfortunately the documentation is still lacking further explanations.,Expected Behaviour
8574,Please support reading hdf5 file directly.,Expected Behaviour
8575,Consider the dataframe CODE which equals: CODE,Expected Behaviour
8576,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
8577,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
8578,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
8579,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
8580,"Feature Request: Vector ""File"" interface",Expected Behaviour
8581,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
8582,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
8583,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
8584,input_fn has to return features and labels only.,Expected Behaviour
8585,"For my use case it seems like CODE could represent a collection of time series, and the CODE would behave like a python iterator/generator and could handle any preprocessing to form batches of examples?",Expected Behaviour
8586,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
8587,Would greatly appreciate:,Expected Behaviour
8588,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour
8589,I'd like:,Expected Behaviour
8590,I'd like to see two things improved though:,Expected Behaviour
8591,Please support reading hdf5 file directly.,Expected Behaviour
8592,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8593,I don't think fit_extend is a particularly great name so I'd welcome other suggestions.,Expected Behaviour
8594,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8595,It would be nice so see something in this flavor: CODE,Expected Behaviour
8596,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
8597,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
8598,Consider the dataframe CODE which equals: CODE,Expected Behaviour
8599,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
8600,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
8601,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour
8602,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
8603,Here my attempt to translate to small in-memory dataset some of the routines available in the TF's input pipeline for large dataset.,Expected Behaviour
8604,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
8605,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
8606,What about extra params which can be used while training progress to customise loss for given input?,Expected Behaviour
8607,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour
8608,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
8609,And _n_ would be user configurable.,Expected Behaviour
8610,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
8611,This gives: CODE,Expected Behaviour
8612,1.         Efficient random sampling:,Expected Behaviour
8613,*         More iterators!,Expected Behaviour
8614,Would greatly appreciate:,Expected Behaviour
8615,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour
8616,"So some concept of ""sample age"" would be nice.",Expected Behaviour
8617,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
8618,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour
8619,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour
8620,*         [batch_iter] URL ,Expected Behaviour
8621,I would be interested in a pipeline where:,Expected Behaviour
8622,What about supporting custom ops to create a Dataset?,Expected Behaviour
8623,4.         Closer integration with HDF5 anyway,Expected Behaviour
8624,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
8625,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8626,Unfortunately the documentation is still lacking further explanations.,Expected Behaviour
8627,Please support reading hdf5 file directly.,Expected Behaviour
8628,-         Most importantly we need to address the dequeueing overhead.,Expected Behaviour
8629,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour
8630,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
8631,-         Most importantly we need to address the dequeueing overhead.,Expected Behaviour
8632,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
8633,Additional Language Support,Expected Behaviour
8634,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
8635,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour
8636,Unfortunately the documentation is still lacking further explanations.,Expected Behaviour
8637,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
8638,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
8639,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
8640,Fitting additional estimators for ensemble methods,Expected Behaviour
8641,"Additionally, would be great to get some clarity from the tensorflow team on what API's would be good to initially cover as I'm sure their roadmap has many changes on the way, and I wouldn't want to conflict.",Expected Behaviour
8642,I would like to propose an additional instance method to the ensemble estimators to fit additional sub-estimators.,Expected Behaviour
8643,*         [cycle_range] URL ,Expected Behaviour
8644,input_fn has to return features and labels only.,Expected Behaviour
8645,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
8646,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
8647,This gives: CODE,Expected Behaviour
8648,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
8649,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
8650,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour
8651,My suggestion/request in the near term would be to have an option to make the vocabulary read only so that users who want to be able to leave spacy alone to do streaming data processing don't need to worry about changing memory requirements.,Expected Behaviour
8652,Some other ideas I jotted down while brainstorming my own class:,Expected Behaviour
8653,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
8654,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour
8655,"Would love to replace standard vector file and in-memory loading with my own Redis (or any other ""shared-memory-system"") interface to allow a distributed cluster of spacy nodes to share the same ""file"".",Expected Behaviour
8656,It would be great to have GPU resident queues.,Expected Behaviour
8657,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
8658,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
8659,It would be great to have GPU resident queues.,Expected Behaviour
8660,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
8661,"In the long term, I think that an optimal solution would be to add some functionality for a timeout on vocabulary entries that aren't loaded at initialization.",Expected Behaviour
8662,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour
8663,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour
8664,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
8665,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
8666,(Like #4836),Expected Behaviour
8667,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8668,Here my attempt to translate to small in-memory dataset some of the routines available in the TF's input pipeline for large dataset.,Expected Behaviour
8669,"The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings).",Expected Behaviour
8670,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
8671,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
8672,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
8673,(Like #4836),Expected Behaviour
8674,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
8675,Some other ideas I jotted down while brainstorming my own class:,Expected Behaviour
8676,So I would really appreciate if you could let me to feed the data **freely** in terms of **when** and **how**.,Expected Behaviour
8677,*         More iterators!,Expected Behaviour
8678,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
8679,"For my use case it seems like CODE could represent a collection of time series, and the CODE would behave like a python iterator/generator and could handle any preprocessing to form batches of examples?",Expected Behaviour
8680,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
8681,CODE,Expected Behaviour
8682,Fitting additional estimators for ensemble methods,Expected Behaviour
8683,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour
8684,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour
8685,*         [iter_tensors_slice] URL ,Expected Behaviour
8686,2.         Dynamical changing and resizing methods:,Expected Behaviour
8687,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
8688,Easy to use batch norm layer.,Expected Behaviour
8689,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
8690,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour
8691,What about supporting custom ops to create a Dataset?,Expected Behaviour
8692,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
8693,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour
8694,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
8695,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour
8696,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
8697,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour
8698,We can see the features names of the columns with: CODE,Expected Behaviour
8699,I don't think fit_extend is a particularly great name so I'd welcome other suggestions.,Expected Behaviour
8700,*         [iter_shuffle_batch_tensors] URL ,Expected Behaviour
8701,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour
8702,"What I'd like is for CODE and CODE there to output elements in the same order (because they share the CODE step), but with different functions (CODE/CODE) applied.",Expected Behaviour
8703,"Feature Request: Vector ""File"" interface",Expected Behaviour
8704,"So some concept of ""sample age"" would be nice.",Expected Behaviour
8705,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
8706,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
8707,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
8708,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
8709,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
8710,2.         Dynamical changing and resizing methods:,Expected Behaviour
8711,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
8712,Would greatly appreciate:,Expected Behaviour
8713,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
8714,It would be great to have GPU resident queues.,Expected Behaviour
8715,"What I'd like is for CODE and CODE there to output elements in the same order (because they share the CODE step), but with different functions (CODE/CODE) applied.",Expected Behaviour
8716,Streaming Data Memory Growth,Expected Behaviour
8717,I don't think fit_extend is a particularly great name so I'd welcome other suggestions.,Expected Behaviour
8718,"For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful.",Expected Behaviour
8719,*         [shuffle_iter] URL ,Expected Behaviour
8720,We can see the features names of the columns with: CODE,Expected Behaviour
8721,*         multiprocessing rather than threading,Expected Behaviour
8722,1.         Efficient random sampling:,Expected Behaviour
8723,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
8724,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8725,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
8726,Node.js (JavaScript) Wrapper API,Expected Behaviour
8727,"Nevertheless, I wonder if it would be possible to make the English() object pickleable?",Expected Behaviour
8728,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
8729,2.         Dynamical changing and resizing methods:,Expected Behaviour
8730,Really waiting for a machine library in JavaScript.,Expected Behaviour
8731,CODE,Expected Behaviour
8732,"Having some bundles, predefined ""easy-starter"" wrappers should be welcomed.",Expected Behaviour
8733,1.         Efficient random sampling:,Expected Behaviour
8734,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour
8735,"So some concept of ""sample age"" would be nice.",Expected Behaviour
8736,-         The dataset class (and not the model) should probably the one to have batch_size passed to it.,Expected Behaviour
8737,And _n_ would be user configurable.,Expected Behaviour
8738,And _n_ would be user configurable.,Expected Behaviour
8739,Unfortunately the documentation is still lacking further explanations.,Expected Behaviour
8740,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
8741,Easy to use batch norm layer.,Expected Behaviour
8742,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour
8743,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
8744,*         multiprocessing rather than threading,Expected Behaviour
8745,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour
8746,"Then a solution I really like to see, is to be able to receive(similar to dequeue) tensors from a different process.",Expected Behaviour
8747,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
8748,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
8749,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
8750,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
8751,+1 to something like feed_dict.,Expected Behaviour
8752,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
8753,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
8754,*         [shuffle_iter] URL ,Expected Behaviour
8755,+1 to something like feed_dict.,Expected Behaviour
8756,"For my use case it seems like CODE could represent a collection of time series, and the CODE would behave like a python iterator/generator and could handle any preprocessing to form batches of examples?",Expected Behaviour
8757,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
8758,I'd like:,Expected Behaviour
8759,4.         Closer integration with HDF5 anyway,Expected Behaviour
8760,2.         Dynamical changing and resizing methods:,Expected Behaviour
8761,This gives: CODE,Expected Behaviour
8762,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour
8763,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8764,*         [cycle_range] URL ,Expected Behaviour
8765,4.         Closer integration with HDF5 anyway,Expected Behaviour
8766,Easy to use batch norm layer.,Expected Behaviour
8767,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8768,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
8769,"Having some bundles, predefined ""easy-starter"" wrappers should be welcomed.",Expected Behaviour
8770,4.         Closer integration with HDF5 anyway,Expected Behaviour
8771,Really waiting for a machine library in JavaScript.,Expected Behaviour
8772,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
8773,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
8774,4.         Closer integration with HDF5 anyway,Expected Behaviour
8775,Easy to use batch norm layer.,Expected Behaviour
8776,(Like #4836),Expected Behaviour
8777,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour
8778,CODE,Expected Behaviour
8779,Really waiting for a machine library in JavaScript.,Expected Behaviour
8780,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
8781,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8782,CODE,Expected Behaviour
8783,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
8784,Fitting additional estimators for ensemble methods,Expected Behaviour
8785,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
8786,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
8787,+1 to something like feed_dict.,Expected Behaviour
8788,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
8789,"Would love to replace standard vector file and in-memory loading with my own Redis (or any other ""shared-memory-system"") interface to allow a distributed cluster of spacy nodes to share the same ""file"".",Expected Behaviour
8790,(Like #4836),Expected Behaviour
8791,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
8792,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour
8793,*         [cycle_range] URL ,Expected Behaviour
8794,Additional Language Support,Expected Behaviour
8795,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
8796,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
8797,Please support reading hdf5 file directly.,Expected Behaviour
8798,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8799,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
8800,And _n_ would be user configurable.,Expected Behaviour
8801,Here my attempt to translate to small in-memory dataset some of the routines available in the TF's input pipeline for large dataset.,Expected Behaviour
8802,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
8803,1.         Efficient random sampling:,Expected Behaviour
8804,-         Support for SparseTensors.,Expected Behaviour
8805,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8806,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour
8807,Please support reading hdf5 file directly.,Expected Behaviour
8808,CODE,Expected Behaviour
8809,"The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings).",Expected Behaviour
8810,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
8811,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour
8812,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
8813,Additional Language Support,Expected Behaviour
8814,This gives: CODE,Expected Behaviour
8815,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
8816,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
8817,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
8818,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
8819,-         [product](https://docs.python.org/2/library/itertools.html#itertools.product),Expected Behaviour
8820,Really waiting for a machine library in JavaScript.,Expected Behaviour
8821,*         [iter_shuffle_batch_tensors] URL ,Expected Behaviour
8822,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
8823,Fitting additional estimators for ensemble methods,Expected Behaviour
8824,Additional Language Support,Expected Behaviour
8825,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
8826,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
8827,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
8828,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
8829,-         Support for SparseTensors.,Expected Behaviour
8830,What about extra params which can be used while training progress to customise loss for given input?,Expected Behaviour
8831,"Nevertheless, I wonder if it would be possible to make the English() object pickleable?",Expected Behaviour
8832,"For my use case it seems like CODE could represent a collection of time series, and the CODE would behave like a python iterator/generator and could handle any preprocessing to form batches of examples?",Expected Behaviour
8833,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour
8834,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
8835,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour
8836,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
8837,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
8838,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
8839,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour
8840,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8841,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
8842,Streaming Data Memory Growth,Expected Behaviour
8843,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour
8844,We can see the features names of the columns with: CODE,Expected Behaviour
8845,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
8846,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
8847,We can see the features names of the columns with: CODE,Expected Behaviour
8848,I'd like:,Expected Behaviour
8849,+1 to something like feed_dict.,Expected Behaviour
8850,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
8851,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
8852,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
8853,Some other ideas I jotted down while brainstorming my own class:,Expected Behaviour
8854,Easy to use batch norm layer.,Expected Behaviour
8855,This gives: CODE,Expected Behaviour
8856,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
8857,Really waiting for a machine library in JavaScript.,Expected Behaviour
8858,-         Support for SparseTensors.,Expected Behaviour
8859,*         [cycle_range] URL ,Expected Behaviour
8860,+1 to something like feed_dict.,Expected Behaviour
8861,Unfortunately the documentation is still lacking further explanations.,Expected Behaviour
8862,I would be interested in a pipeline where:,Expected Behaviour
8863,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8864,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
8865,Node.js (JavaScript) Wrapper API,Expected Behaviour
8866,+1 to something like feed_dict.,Expected Behaviour
8867,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8868,Additional Language Support,Expected Behaviour
8869,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour
8870,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
8871,Please support reading hdf5 file directly.,Expected Behaviour
8872,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
8873,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
8874,-         [product](https://docs.python.org/2/library/itertools.html#itertools.product),Expected Behaviour
8875,*         More iterators!,Expected Behaviour
8876,What about supporting custom ops to create a Dataset?,Expected Behaviour
8877,"The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings).",Expected Behaviour
8878,Fitting additional estimators for ensemble methods,Expected Behaviour
8879,Node.js (JavaScript) Wrapper API,Expected Behaviour
8880,I would like to propose an additional instance method to the ensemble estimators to fit additional sub-estimators.,Expected Behaviour
8881,*         [cycle_range] URL ,Expected Behaviour
8882,Streaming Data Memory Growth,Expected Behaviour
8883,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
8884,-         [product](https://docs.python.org/2/library/itertools.html#itertools.product),Expected Behaviour
8885,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
8886,Like:CODE,Expected Behaviour
8887,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
8888,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
8889,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
8890,Please support reading hdf5 file directly.,Expected Behaviour
8891,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
8892,CODE,Expected Behaviour
8893,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
8894,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
8895,And _n_ would be user configurable.,Expected Behaviour
8896,Streaming Data Memory Growth,Expected Behaviour
8897,*         multiprocessing rather than threading,Expected Behaviour
8898,I'd like to see two things improved though:,Expected Behaviour
8899,I'd like to see two things improved though:,Expected Behaviour
8900,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
8901,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
8902,"Nevertheless, I wonder if it would be possible to make the English() object pickleable?",Expected Behaviour
8903,I would be interested in a pipeline where:,Expected Behaviour
8904,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
8905,CODE,Expected Behaviour
8906,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
8907,It would be nice so see something in this flavor: CODE,Expected Behaviour
8908,*         [batch_iter] URL ,Expected Behaviour
8909,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
8910,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour
8911,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
8912,Additional Language Support,Expected Behaviour
8913,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
8914,I would be interested in a pipeline where:,Expected Behaviour
8915,Easy to use batch norm layer.,Expected Behaviour
8916,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
8917,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
8918,"Additionally, would be great to get some clarity from the tensorflow team on what API's would be good to initially cover as I'm sure their roadmap has many changes on the way, and I wouldn't want to conflict.",Expected Behaviour
8919,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
8920,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
8921,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
8922,This gives: CODE,Expected Behaviour
8923,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
8924,"Having some bundles, predefined ""easy-starter"" wrappers should be welcomed.",Expected Behaviour
8925,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
8926,"Whether anybody actually *wants* this ""max value""-based method, or whether we are fine with (in the future, after deprecation) only having the ""unique values""-based method.",Expected Behaviour
8927,"So some concept of ""sample age"" would be nice.",Expected Behaviour
8928,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
8929,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
8930,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
8931,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
8932,What about supporting custom ops to create a Dataset?,Expected Behaviour
8933,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
8934,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
8935,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
8936,Here my attempt to translate to small in-memory dataset some of the routines available in the TF's input pipeline for large dataset.,Expected Behaviour
8937,input_fn has to return features and labels only.,Expected Behaviour
8938,*         [shuffle_iter] URL ,Expected Behaviour
8939,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
8940,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8941,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
8942,We can see the features names of the columns with: CODE,Expected Behaviour
8943,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
8944,Node.js (JavaScript) Wrapper API,Expected Behaviour
8945,2.         Dynamical changing and resizing methods:,Expected Behaviour
8946,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
8947,"I would say that aside from the steep learning curve of input pipeline which can be overcome with documentation too, the key missing points are:",Expected Behaviour
8948,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
8949,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
8950,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
8951,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
8952,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour
8953,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
8954,It would be great to have GPU resident queues.,Expected Behaviour
8955,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
8956,What about supporting custom ops to create a Dataset?,Expected Behaviour
8957,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
8958,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
8959,*         More iterators!,Expected Behaviour
8960,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
8961,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
8962,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
8963,It would be great to have GPU resident queues.,Expected Behaviour
8964,What about supporting custom ops to create a Dataset?,Expected Behaviour
8965,This gives: CODE,Expected Behaviour
8966,Node.js (JavaScript) Wrapper API,Expected Behaviour
8967,4.         Closer integration with HDF5 anyway,Expected Behaviour
8968,And _n_ would be user configurable.,Expected Behaviour
8969,*         [iter_tensors_slice] URL ,Expected Behaviour
8970,This gives: CODE,Expected Behaviour
8971,*         [iter_tensors_slice] URL ,Expected Behaviour
8972,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
8973,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
8974,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
8975,"Would love to replace standard vector file and in-memory loading with my own Redis (or any other ""shared-memory-system"") interface to allow a distributed cluster of spacy nodes to share the same ""file"".",Expected Behaviour
8976,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
8977,Like:CODE,Expected Behaviour
8978,-         Support for SparseTensors.,Expected Behaviour
8979,Node.js (JavaScript) Wrapper API,Expected Behaviour
8980,"In the long term, I think that an optimal solution would be to add some functionality for a timeout on vocabulary entries that aren't loaded at initialization.",Expected Behaviour
8981,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
8982,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
8983,I don't think fit_extend is a particularly great name so I'd welcome other suggestions.,Expected Behaviour
8984,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
8985,CODE,Expected Behaviour
8986,"So some concept of ""sample age"" would be nice.",Expected Behaviour
8987,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour
8988,"So some concept of ""sample age"" would be nice.",Expected Behaviour
8989,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
8990,*         [iter_tensors_slice] URL ,Expected Behaviour
8991,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
8992,"The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings).",Expected Behaviour
8993,*         multiprocessing rather than threading,Expected Behaviour
8994,What about extra params which can be used while training progress to customise loss for given input?,Expected Behaviour
8995,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour
8996,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
8997,Streaming Data Memory Growth,Expected Behaviour
8998,"Whether anybody actually *wants* this ""max value""-based method, or whether we are fine with (in the future, after deprecation) only having the ""unique values""-based method.",Expected Behaviour
8999,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
9000,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
9001,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
9002,Like:CODE,Expected Behaviour
9003,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour
9004,(Like #4836),Expected Behaviour
9005,I would be interested in a pipeline where:,Expected Behaviour
9006,"Additionally, would be great to get some clarity from the tensorflow team on what API's would be good to initially cover as I'm sure their roadmap has many changes on the way, and I wouldn't want to conflict.",Expected Behaviour
9007,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour
9008,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour
9009,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
9010,Consider the dataframe CODE which equals: CODE,Expected Behaviour
9011,Would greatly appreciate:,Expected Behaviour
9012,Like:CODE,Expected Behaviour
9013,Unfortunately the documentation is still lacking further explanations.,Expected Behaviour
9014,It would be nice so see something in this flavor: CODE,Expected Behaviour
9015,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
9016,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
9017,Additional Language Support,Expected Behaviour
9018,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
9019,"I would say that aside from the steep learning curve of input pipeline which can be overcome with documentation too, the key missing points are:",Expected Behaviour
9020,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour
9021,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
9022,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
9023,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour
9024,-         Most importantly we need to address the dequeueing overhead.,Expected Behaviour
9025,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
9026,"What I'd like is for CODE and CODE there to output elements in the same order (because they share the CODE step), but with different functions (CODE/CODE) applied.",Expected Behaviour
9027,"The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings).",Expected Behaviour
9028,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
9029,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
9030,What about extra params which can be used while training progress to customise loss for given input?,Expected Behaviour
9031,Some other ideas I jotted down while brainstorming my own class:,Expected Behaviour
9032,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
9033,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
9034,4.         Closer integration with HDF5 anyway,Expected Behaviour
9035,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
9036,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour
9037,"Feature Request: Vector ""File"" interface",Expected Behaviour
9038,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour
9039,"Feature Request: Vector ""File"" interface",Expected Behaviour
9040,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
9041,"To be more precise, we need support for pipelines where learning is done in an online fashion, and training data is generated by a system responding to actions of a TensorFlow network (learning Atari simulator, robotics simulator, robot interacting with real world, etc).",Expected Behaviour
9042,And _n_ would be user configurable.,Expected Behaviour
9043,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
9044,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
9045,I would be interested in a pipeline where:,Expected Behaviour
9046,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
9047,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
9048,My suggestion/request in the near term would be to have an option to make the vocabulary read only so that users who want to be able to leave spacy alone to do streaming data processing don't need to worry about changing memory requirements.,Expected Behaviour
9049,Streaming Data Memory Growth,Expected Behaviour
9050,"What I'd like is for CODE and CODE there to output elements in the same order (because they share the CODE step), but with different functions (CODE/CODE) applied.",Expected Behaviour
9051,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
9052,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
9053,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour
9054,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
9055,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
9056,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
9057,My suggestion/request in the near term would be to have an option to make the vocabulary read only so that users who want to be able to leave spacy alone to do streaming data processing don't need to worry about changing memory requirements.,Expected Behaviour
9058,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
9059,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
9060,"Feature Request: Vector ""File"" interface",Expected Behaviour
9061,Here my attempt to translate to small in-memory dataset some of the routines available in the TF's input pipeline for large dataset.,Expected Behaviour
9062,"So some concept of ""sample age"" would be nice.",Expected Behaviour
9063,We can see the features names of the columns with: CODE,Expected Behaviour
9064,2.         Dynamical changing and resizing methods:,Expected Behaviour
9065,CODE,Expected Behaviour
9066,*         multiprocessing rather than threading,Expected Behaviour
9067,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
9068,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
9069,"Whether anybody actually *wants* this ""max value""-based method, or whether we are fine with (in the future, after deprecation) only having the ""unique values""-based method.",Expected Behaviour
9070,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
9071,"One function that still seems to be missing, but would be essential for one of our primary use cases (see comment above: https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283186552) is a CODEused as inCODE function, where one element of CODE is mapped to one **or more** elements for CODE; i.e. #CODE >= #CODE.",Expected Behaviour
9072,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
9073,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
9074,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
9075,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour
9076,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
9077,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
9078,-         Most importantly we need to address the dequeueing overhead.,Expected Behaviour
9079,*         multiprocessing rather than threading,Expected Behaviour
9080,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
9081,*         [iter_tensors_slice] URL ,Expected Behaviour
9082,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour
9083,+1 to something like feed_dict.,Expected Behaviour
9084,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
9085,It would be great to have GPU resident queues.,Expected Behaviour
9086,4.         Closer integration with HDF5 anyway,Expected Behaviour
9087,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
9088,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
9089,Easy to use batch norm layer.,Expected Behaviour
9090,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
9091,"What I'd like is for CODE and CODE there to output elements in the same order (because they share the CODE step), but with different functions (CODE/CODE) applied.",Expected Behaviour
9092,Additional Language Support,Expected Behaviour
9093,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
9094,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
9095,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
9096,Please support reading hdf5 file directly.,Expected Behaviour
9097,"Additionally, would be great to get some clarity from the tensorflow team on what API's would be good to initially cover as I'm sure their roadmap has many changes on the way, and I wouldn't want to conflict.",Expected Behaviour
9098,*         [batch_iter] URL ,Expected Behaviour
9099,Streaming Data Memory Growth,Expected Behaviour
9100,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
9101,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
9102,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
9103,-         Support for SparseTensors.,Expected Behaviour
9104,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
9105,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
9106,Would greatly appreciate:,Expected Behaviour
9107,"Having some bundles, predefined ""easy-starter"" wrappers should be welcomed.",Expected Behaviour
9108,Streaming Data Memory Growth,Expected Behaviour
9109,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
9110,And _n_ would be user configurable.,Expected Behaviour
9111,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour
9112,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
9113,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
9114,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
9115,"In the long term, I think that an optimal solution would be to add some functionality for a timeout on vocabulary entries that aren't loaded at initialization.",Expected Behaviour
9116,Unfortunately the documentation is still lacking further explanations.,Expected Behaviour
9117,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
9118,What about extra params which can be used while training progress to customise loss for given input?,Expected Behaviour
9119,*         [shuffle_iter] URL ,Expected Behaviour
9120,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
9121,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
9122,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
9123,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour
9124,What about extra params which can be used while training progress to customise loss for given input?,Expected Behaviour
9125,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
9126,CODE,Expected Behaviour
9127,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
9128,"In the long term, I think that an optimal solution would be to add some functionality for a timeout on vocabulary entries that aren't loaded at initialization.",Expected Behaviour
9129,Additional Language Support,Expected Behaviour
9130,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
9131,*         [iter_tensors_slice] URL ,Expected Behaviour
9132,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour
9133,"Nevertheless, I wonder if it would be possible to make the English() object pickleable?",Expected Behaviour
9134,"To be more precise, we need support for pipelines where learning is done in an online fashion, and training data is generated by a system responding to actions of a TensorFlow network (learning Atari simulator, robotics simulator, robot interacting with real world, etc).",Expected Behaviour
9135,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
9136,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour
9137,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
9138,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
9139,I would be interested in a pipeline where:,Expected Behaviour
9140,Consider the dataframe CODE which equals: CODE,Expected Behaviour
9141,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
9142,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
9143,"For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful.",Expected Behaviour
9144,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
9145,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
9146,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
9147,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour
9148,Additional Language Support,Expected Behaviour
9149,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour
9150,"Would love to replace standard vector file and in-memory loading with my own Redis (or any other ""shared-memory-system"") interface to allow a distributed cluster of spacy nodes to share the same ""file"".",Expected Behaviour
9151,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
9152,"I would say that aside from the steep learning curve of input pipeline which can be overcome with documentation too, the key missing points are:",Expected Behaviour
9153,*         multiprocessing rather than threading,Expected Behaviour
9154,Streaming Data Memory Growth,Expected Behaviour
9155,*         [iter_tensors_slice] URL ,Expected Behaviour
9156,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
9157,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
9158,I would like to propose an additional instance method to the ensemble estimators to fit additional sub-estimators.,Expected Behaviour
9159,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
9160,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
9161,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
9162,Fitting additional estimators for ensemble methods,Expected Behaviour
9163,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
9164,What about extra params which can be used while training progress to customise loss for given input?,Expected Behaviour
9165,*         [batch_iter] URL ,Expected Behaviour
9166,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
9167,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour
9168,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
9169,Fitting additional estimators for ensemble methods,Expected Behaviour
9170,Really waiting for a machine library in JavaScript.,Expected Behaviour
9171,We can see the features names of the columns with: CODE,Expected Behaviour
9172,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
9173,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
9174,Additional Language Support,Expected Behaviour
9175,So I would really appreciate if you could let me to feed the data **freely** in terms of **when** and **how**.,Expected Behaviour
9176,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
9177,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
9178,I don't think fit_extend is a particularly great name so I'd welcome other suggestions.,Expected Behaviour
9179,2.         Dynamical changing and resizing methods:,Expected Behaviour
9180,Fitting additional estimators for ensemble methods,Expected Behaviour
9181,*         multiprocessing rather than threading,Expected Behaviour
9182,*         [iter_shuffle_batch_tensors] URL ,Expected Behaviour
9183,I would like to propose an additional instance method to the ensemble estimators to fit additional sub-estimators.,Expected Behaviour
9184,I would be interested in a pipeline where:,Expected Behaviour
9185,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
9186,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
9187,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
9188,"One function that still seems to be missing, but would be essential for one of our primary use cases (see comment above: https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283186552) is a CODEused as inCODE function, where one element of CODE is mapped to one **or more** elements for CODE; i.e. #CODE >= #CODE.",Expected Behaviour
9189,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour
9190,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
9191,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
9192,"What I'd like is for CODE and CODE there to output elements in the same order (because they share the CODE step), but with different functions (CODE/CODE) applied.",Expected Behaviour
9193,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
9194,It would be great to have GPU resident queues.,Expected Behaviour
9195,CODE,Expected Behaviour
9196,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
9197,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
9198,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
9199,"Additionally, would be great to get some clarity from the tensorflow team on what API's would be good to initially cover as I'm sure their roadmap has many changes on the way, and I wouldn't want to conflict.",Expected Behaviour
9200,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour
9201,"I would say that aside from the steep learning curve of input pipeline which can be overcome with documentation too, the key missing points are:",Expected Behaviour
9202,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour
9203,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour
9204,-         [product](https://docs.python.org/2/library/itertools.html#itertools.product),Expected Behaviour
9205,2.         Dynamical changing and resizing methods:,Expected Behaviour
9206,"The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings).",Expected Behaviour
9207,"So some concept of ""sample age"" would be nice.",Expected Behaviour
9208,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
9209,*         More iterators!,Expected Behaviour
9210,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
9211,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
9212,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
9213,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
9214,1.         Efficient random sampling:,Expected Behaviour
9215,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
9216,+1 to something like feed_dict.,Expected Behaviour
9217,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
9218,Consider the dataframe CODE which equals: CODE,Expected Behaviour
9219,4.         Closer integration with HDF5 anyway,Expected Behaviour
9220,Really waiting for a machine library in JavaScript.,Expected Behaviour
9221,What about supporting custom ops to create a Dataset?,Expected Behaviour
9222,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
9223,Additional Language Support,Expected Behaviour
9224,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
9225,Consider the dataframe CODE which equals: CODE,Expected Behaviour
9226,Node.js (JavaScript) Wrapper API,Expected Behaviour
9227,+1 to something like feed_dict.,Expected Behaviour
9228,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
9229,4.         Closer integration with HDF5 anyway,Expected Behaviour
9230,The following iterators would be great:,Expected Behaviour
9231,*         [batch_iter] URL ,Expected Behaviour
9232,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
9233,Fitting additional estimators for ensemble methods,Expected Behaviour
9234,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
9235,I don't think fit_extend is a particularly great name so I'd welcome other suggestions.,Expected Behaviour
9236,*         [iter_shuffle_batch_tensors] URL ,Expected Behaviour
9237,Really waiting for a machine library in JavaScript.,Expected Behaviour
9238,My suggestion/request in the near term would be to have an option to make the vocabulary read only so that users who want to be able to leave spacy alone to do streaming data processing don't need to worry about changing memory requirements.,Expected Behaviour
9239,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
9240,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
9241,*         [shuffle_iter] URL ,Expected Behaviour
9242,"Then a solution I really like to see, is to be able to receive(similar to dequeue) tensors from a different process.",Expected Behaviour
9243,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
9244,"Additionally, would be great to get some clarity from the tensorflow team on what API's would be good to initially cover as I'm sure their roadmap has many changes on the way, and I wouldn't want to conflict.",Expected Behaviour
9245,"For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful.",Expected Behaviour
9246,+1 to something like feed_dict.,Expected Behaviour
9247,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
9248,Unfortunately the documentation is still lacking further explanations.,Expected Behaviour
9249,Please support reading hdf5 file directly.,Expected Behaviour
9250,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
9251,*         [iter_tensors_slice] URL ,Expected Behaviour
9252,The following iterators would be great:,Expected Behaviour
9253,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
9254,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
9255,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour
9256,Consider the dataframe CODE which equals: CODE,Expected Behaviour
9257,*         [shuffle_iter] URL ,Expected Behaviour
9258,"For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful.",Expected Behaviour
9259,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
9260,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
9261,Additional Language Support,Expected Behaviour
9262,2.         Dynamical changing and resizing methods:,Expected Behaviour
9263,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour
9264,*         [iter_shuffle_batch_tensors] URL ,Expected Behaviour
9265,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour
9266,I would be interested in a pipeline where:,Expected Behaviour
9267,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
9268,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
9269,Would greatly appreciate:,Expected Behaviour
9270,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
9271,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
9272,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
9273,My suggestion/request in the near term would be to have an option to make the vocabulary read only so that users who want to be able to leave spacy alone to do streaming data processing don't need to worry about changing memory requirements.,Expected Behaviour
9274,Would greatly appreciate:,Expected Behaviour
9275,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour
9276,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour
9277,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
9278,I would be interested in a pipeline where:,Expected Behaviour
9279,*         More iterators!,Expected Behaviour
9280,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
9281,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
9282,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
9283,Really waiting for a machine library in JavaScript.,Expected Behaviour
9284,CODE,Expected Behaviour
9285,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour
9286,I'd like:,Expected Behaviour
9287,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
9288,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
9289,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
9290,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour
9291,Fitting additional estimators for ensemble methods,Expected Behaviour
9292,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
9293,-         The dataset class (and not the model) should probably the one to have batch_size passed to it.,Expected Behaviour
9294,*         [iter_tensors_slice] URL ,Expected Behaviour
9295,"Nevertheless, I wonder if it would be possible to make the English() object pickleable?",Expected Behaviour
9296,"One function that still seems to be missing, but would be essential for one of our primary use cases (see comment above: https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283186552) is a CODEused as inCODE function, where one element of CODE is mapped to one **or more** elements for CODE; i.e. #CODE >= #CODE.",Expected Behaviour
9297,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
9298,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour
9299,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
9300,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour
9301,Would be really interested to read something for the Python API + some example code.,Expected Behaviour
9302,-         Most importantly we need to address the dequeueing overhead.,Expected Behaviour
9303,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
9304,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
9305,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour
9306,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour
9307,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
9308,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour
9309,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
9310,Easy to use batch norm layer.,Expected Behaviour
9311,*         [shuffle_iter] URL ,Expected Behaviour
9312,Fitting additional estimators for ensemble methods,Expected Behaviour
9313,"Then a solution I really like to see, is to be able to receive(similar to dequeue) tensors from a different process.",Expected Behaviour
9314,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
9315,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
9316,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
9317,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour
9318,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
9319,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour
9320,I'd like to see two things improved though:,Expected Behaviour
9321,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
9322,"Then a solution I really like to see, is to be able to receive(similar to dequeue) tensors from a different process.",Expected Behaviour
9323,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour
9324,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour
9325,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour
9326,I'd like:,Expected Behaviour
9327,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
9328,*         [iter_tensors_slice] URL ,Expected Behaviour
9329,It would be great to have GPU resident queues.,Expected Behaviour
9330,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
9331,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
9332,I'd like:,Expected Behaviour
9333,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
9334,Like:CODE,Expected Behaviour
9335,I'd like to see two things improved though:,Expected Behaviour
9336,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
9337,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
9338,"Whether anybody actually *wants* this ""max value""-based method, or whether we are fine with (in the future, after deprecation) only having the ""unique values""-based method.",Expected Behaviour
9339,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
9340,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
9341,(Like #4836),Expected Behaviour
9342,Please support reading hdf5 file directly.,Expected Behaviour
9343,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
9344,(Like #4836),Expected Behaviour
9345,Some other ideas I jotted down while brainstorming my own class:,Expected Behaviour
9346,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour
9347,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour
9348,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
9349,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
9350,And _n_ would be user configurable.,Expected Behaviour
9351,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
9352,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
9353,What about supporting custom ops to create a Dataset?,Expected Behaviour
9354,*         [iter_shuffle_batch_window] URL ,Expected Behaviour
9355,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
9356,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour
9357,What about supporting custom ops to create a Dataset?,Expected Behaviour
9358,Fitting additional estimators for ensemble methods,Expected Behaviour
9359,*         The epoch concept does not have a clear semantic either.,Expected Behaviour
9360,I'd like to see two things improved though:,Expected Behaviour
9361,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
9362,Like:CODE,Expected Behaviour
9363,Like:CODE,Expected Behaviour
9364,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
9365,-         [product](https://docs.python.org/2/library/itertools.html#itertools.product),Expected Behaviour
9366,Easy to use batch norm layer.,Expected Behaviour
9367,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
9368,*         [batch_iter] URL ,Expected Behaviour
9369,"One function that still seems to be missing, but would be essential for one of our primary use cases (see comment above: https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283186552) is a CODEused as inCODE function, where one element of CODE is mapped to one **or more** elements for CODE; i.e. #CODE >= #CODE.",Expected Behaviour
9370,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour
9371,Please support reading hdf5 file directly.,Expected Behaviour
9372,"For my use case it seems like CODE could represent a collection of time series, and the CODE would behave like a python iterator/generator and could handle any preprocessing to form batches of examples?",Expected Behaviour
9373,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour
9374,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour
9375,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
9376,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour
9377,*         More iterators!,Expected Behaviour
9378,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
9379,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
9380,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour
9381,What about extra params which can be used while training progress to customise loss for given input?,Expected Behaviour
9382,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour
9383,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour
9384,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
9385,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour
9386,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour
9387,I'd like to see two things improved though:,Expected Behaviour
9388,+1 to something like feed_dict.,Expected Behaviour
9389,Here my attempt to translate to small in-memory dataset some of the routines available in the TF's input pipeline for large dataset.,Expected Behaviour
9390,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour
9391,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour
9392,CODE,Expected Behaviour
9393,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
9394,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour
9395,Thus my biggest wish would be to make that method more performant.,Expected Behaviour
9396,-         The dataset class (and not the model) should probably the one to have batch_size passed to it.,Expected Behaviour
9397,Additional Language Support,Expected Behaviour
9398,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour
9399,I'd like to see two things improved though:,Expected Behaviour
9400,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
9401,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour
9402,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
9403,2.         Dynamical changing and resizing methods:,Expected Behaviour
9404,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
9405,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
9406,The following iterators would be great:,Expected Behaviour
9407,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour
9408,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour
9409,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
9410,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
9411,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour
9412,Here my attempt to translate to small in-memory dataset some of the routines available in the TF's input pipeline for large dataset.,Expected Behaviour
9413,What about supporting custom ops to create a Dataset?,Expected Behaviour
9414,*         [iter_shuffle_batch_range] URL ,Expected Behaviour
9415,I'd like:,Expected Behaviour
9416,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour
9417,CODE,Expected Behaviour
9418,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour
9419,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
9420,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour
9421,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour
9422,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour
9423,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
9424,It would be great to have GPU resident queues.,Expected Behaviour
9425,"Additionally, would be great to get some clarity from the tensorflow team on what API's would be good to initially cover as I'm sure their roadmap has many changes on the way, and I wouldn't want to conflict.",Expected Behaviour
9426,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
9427,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour
9428,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour
9429,We can see the features names of the columns with: CODE,Expected Behaviour
9430,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour
9431,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
9432,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour
9433,1.         Efficient random sampling:,Expected Behaviour
9434,"Then a solution I really like to see, is to be able to receive(similar to dequeue) tensors from a different process.",Expected Behaviour
9435,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
9436,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour
9437,+1 to something like feed_dict.,Expected Behaviour
9438,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
9439,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour
9440,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour
9441,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour
9442,Easy to use batch norm layer.,Expected Behaviour
9443,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour
9444,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour
9445,Fitting additional estimators for ensemble methods,Expected Behaviour
9446,*         [shuffle_iter] URL ,Expected Behaviour
9447,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour
9448,DictVectorizer gives exactly what I need in this case.,Expected Behaviour
9449,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour
9450,4.         Closer integration with HDF5 anyway,Expected Behaviour
9451,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour
9452,I don't think fit_extend is a particularly great name so I'd welcome other suggestions.,Expected Behaviour
9453,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour
9454,*         More iterators!,Expected Behaviour
9455,Would greatly appreciate:,Expected Behaviour
9456,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour
9457,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour
9458,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour
9459,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour
9460,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour
9461,"However if you take the document that produces the error, pass it through CODE and then call CODE again, it works.",Investigation and Exploration
9462,"Something may have happened because of the Spyder install, but then why would it work for a day and then suddenly stop??",Investigation and Exploration
9463,I ran the benchmark you requested above - collecting metrics on the length of the CODE as memory Solution Usage grows.,Investigation and Exploration
9464,"Here are the results:<img width=""555"" alt=""screen shot 2016-08-16 at 2 24 25 pm"" src=""https://cloud.githubusercontent.com/assets/1669062/17711263/c23cb262-63be-11e6-9aaf-96e9763a00e0.png"">",Investigation and Exploration
9465,Paula: I could not get this snippet to freeze.,Investigation and Exploration
9466,"Curious thing, If you add a comma like this: CODE the error goes away.",Investigation and Exploration
9467,Can run the test again.,Investigation and Exploration
9468,These instructions are outdated believe me.,Investigation and Exploration
9469,or zip it,Investigation and Exploration
9470,CODE,Investigation and Exploration
9471,"The output is more than 1Mb in size, so I did not find a pastebin for that.",Investigation and Exploration
9472,or zip it,Investigation and Exploration
9473,Generally multiprocessing in Windows encounters a lot of problems.,Investigation and Exploration
9474,You're using XGBoost.,Investigation and Exploration
9475,"As above, if I use nlp(text) everything is fine.",Investigation and Exploration
9476,"@rasbt hmm, I wonder if the problem goes away in Sierra...",Investigation and Exploration
9477,"Certainly, for strings that occur once, there's no advantage.",Investigation and Exploration
9478,"They make a copy of the cell, then pass the cell argument along to the attention decoder embedding function, then to the attention decoder itself.",Investigation and Exploration
9479,"However, I don't think that this is a leak.",Investigation and Exploration
9480,Do you have this issue with the tf nightlies?,Investigation and Exploration
9481,"That seems to indicate, that this problem happens in some very specific combination of factors.",Investigation and Exploration
9482,"However, it is clear that the ""out-of-date"" -as you call it- instructions page may not be so out of date.",Investigation and Exploration
9483,"I have find the reason is ldconf,  ldconfig is a dynamic link library management command whose purpose is to allow the dynamic link library to be usedby the system.",Investigation and Exploration
9484,"At the developmenthead, this completes in 11s on my macbook, and in 7s at version 0.14(that's something to look into!)",Investigation and Exploration
9485,"After making sure CODE loaded up, the error disappeared in the virtual env with CODE.",Investigation and Exploration
9486,This is the status code the CODE method was ignoring.,Investigation and Exploration
9487,@lesteve @paulaceccon :I took Paula's excerpt code and made a complete run-able code snippet.,Investigation and Exploration
9488,"An example document where CODE causes the error, removing that one token everything is fine.",Investigation and Exploration
9489,"If one of you can reproduce the problem, please try to find a numpy random seed that trigger the issue (using CODE instead of CODE in the above snippet) and communicate the value here (along with the version of OSX and you python packages).",Investigation and Exploration
9490,@Lucidyan I don't understand what you mean by that.,Investigation and Exploration
9491,"So you can see from the third line, that it is using MKL.",Investigation and Exploration
9492,@lesteve paula has posted a snippet that also has the same problem.,Investigation and Exploration
9493,The only way I managed to reproduce this problem was to install numpy with both pip and conda in the same conda environment.,Investigation and Exploration
9494,"I thought the current OneHotEncoder would have categories [0, 1, 2, 3, 4, 5] (while current CategoricalEncoder would have categories [2, 3, 5]).",Investigation and Exploration
9495,"@yarikoptic, I can't find the CODE failure under 0.19.0-1 logs.",Investigation and Exploration
9496,"At the developmenthead, this completes in 11s on my macbook, and in 7s at version 0.14(that's something to look into!)",Investigation and Exploration
9497,"The conda version I have is 4.2.13, both the env which throws the error and the env with source built sklearn (which does not throw error) are inside conda.",Investigation and Exploration
9498,You're using XGBoost.,Investigation and Exploration
9499,"But you are right that the CODE is also only [2, 3, 5], essentially making them the same with the default value of CODE.",Investigation and Exploration
9500,Do you get this error when running the test on the wheel version of scikit-learn 0.19?,Investigation and Exploration
9501,CPU info: CODEPlatform info: CODE,Investigation and Exploration
9502,Could you please check it out and re-run the same code?,Investigation and Exploration
9503,I think it has nothing to do with tensorflow; my guess is that [GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] vs [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] is the culprit!?,Investigation and Exploration
9504,https://github.com/natb1/spaCy/blob/memory-benchmark/spacy/tests/benchmark/test_memory.py,Investigation and Exploration
9505,Otherwise everything should be the same.,Investigation and Exploration
9506,"Curious thing, If you add a comma like this: CODE the error goes away.",Investigation and Exploration
9507,"That's very small differences for float32 data, and a large range in exponent from min to max.",Investigation and Exploration
9508,"not sure if this is really the reason, but I think CODE may be an issue; since the error doesn't seem to occur via CODE",Investigation and Exploration
9509,"Can you point to some more information, more detail about what the problem is?",Investigation and Exploration
9510,i don't remember who and how placed it there but pretty much it overloaded the system default libcudnn.so.7.1.2 !!!,Investigation and Exploration
9511,Generally multiprocessing in Windows encounters a lot of problems.,Investigation and Exploration
9512,Running CODE indicated that both of them somehow didn't have CODE loaded.,Investigation and Exploration
9513,"The scorer function is ""score_model"", it doesn't use joblib.",Investigation and Exploration
9514,@zhongyuk depends which library you have installed.,Investigation and Exploration
9515,Can you try to see if adding the CODEif __name__CODE helps?,Investigation and Exploration
9516,@blang can you confirm?,Investigation and Exploration
9517,"Doing some research I found that libblas, liblapack and liblapack_atlas were missing from my /usr/lib/, also I did not see the directory /usr/lib/atlas-base/.",Investigation and Exploration
9518,CODE,Investigation and Exploration
9519,Will switch it to ATLAS and see what happens.,Investigation and Exploration
9520,"If you are all using compiled version on master branch, I believe that we are the same issue caused by the [recent commit] URL .",Investigation and Exploration
9521,What platform are you on? (e.g. CODE),Investigation and Exploration
9522,just doubling the length of the list is insufficient.,Investigation and Exploration
9523,IIRC @ogrisel's hunch was that it was CPU architecture related.,Investigation and Exploration
9524,Would be great if you can take a look and post a version of it that freezes.,Investigation and Exploration
9525,How did you install scikit-learn?,Investigation and Exploration
9526,@jnothman I am guessing that your conda environment uses MKL and not Accelerate.,Investigation and Exploration
9527,"@priidukull, What did you mean by telling that the divergence happened in C code?",Investigation and Exploration
9528,i think .9 is somewhat arbitrary but we'd like to be sure that thevariation isn't pointing to something more sinister,Investigation and Exploration
9529,"What about the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185, you didn't find a way to make it deterministic and still fail on your machine?",Investigation and Exploration
9530,What were you comparing it against?,Investigation and Exploration
9531,"Also for future reference, can you paste the output of:CODE",Investigation and Exploration
9532,I think it has nothing to do with tensorflow; my guess is that [GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] vs [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] is the culprit!?,Investigation and Exploration
9533,Setting CODE on Linux doesn't solve the issue for me.,Investigation and Exploration
9534,"you can email my personal address for the, thanks",Investigation and Exploration
9535,So it seems like this is happening when mixing numpy installed via pip and conda.,Investigation and Exploration
9536,here's the output of the above prints: CODE,Investigation and Exploration
9537,Or did anyone experience the bug not using conda?,Investigation and Exploration
9538,@blang can you confirm?,Investigation and Exploration
9539,"However, it is clear that the ""out-of-date"" -as you call it- instructions page may not be so out of date.",Investigation and Exploration
9540,what is crf?,Investigation and Exploration
9541,"
REFERENCE",Investigation and Exploration
9542,"if I start to change the constants (increase) with fixed X_SIZE=1750, it fails too.",Investigation and Exploration
9543,"I tried to read it but there is only the logs after iteration 200 (""QuadTree"" is way too verbose and I think we lose the beginning as the log growth too big).",Investigation and Exploration
9544,"
REFERENCE",Investigation and Exploration
9545,I done nothing since.,Investigation and Exploration
9546,"That repo looks like it's targeted at tf 1.0, not intermediate releases.",Investigation and Exploration
9547,"I will try the one from sklearn.model_selection, but something tells me I will have the same exact issue).",Investigation and Exploration
9548,What I've done is to reduce the size of X... with something like:,Investigation and Exploration
9549,"That's very small differences for float32 data, and a large range in exponent from min to max.",Investigation and Exploration
9550,Maybe this is some kind of degrees of freedom check run amok?,Investigation and Exploration
9551,@lesteve @paulaceccon :I took Paula's excerpt code and made a complete run-able code snippet.,Investigation and Exploration
9552,Do you recall which C function was responsible for the divergence?,Investigation and Exploration
9553,The first 20:CODE,Investigation and Exploration
9554,-         What version of scikit-learn is this?,Investigation and Exploration
9555,Up until now the snippet we have is non-deterministic (CODE is used and has no influence of numpy.random seed).,Investigation and Exploration
9556,Maybe it depends on the minor version of OSX.,Investigation and Exploration
9557,the FAQ link above?,Investigation and Exploration
9558,But it still points to a potential flaw in the design of the library.,Investigation and Exploration
9559,Is theinput to TSNE._tsne identical on both platforms?,Investigation and Exploration
9560,I don't want to upgrade OS yet b/z I thought I read somewhere that TensorFlow doesn't support Sierra yet (could be mistaken or no longer be true anymore since I don't remember where or how long ago I read it)?,Investigation and Exploration
9561,"I don't know what they do internally, it's very possible that's the issue.",Investigation and Exploration
9562,"They make a copy of the cell, then pass the cell argument along to the attention decoder embedding function, then to the attention decoder itself.",Investigation and Exploration
9563,Can you try to see if adding the CODEif __name__CODE helps?,Investigation and Exploration
9564,pip on the other hand will use wheels that are shipped with Accelerate (at the time of writing).,Investigation and Exploration
9565,Is the devp sklearn built from source code using OpenBLAS instead of MKL?,Investigation and Exploration
9566,"I noticed that the gradient in https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L387 explodes, until it becomes CODE in one position after the 25th iteration in the https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L386 for-loop",Investigation and Exploration
9567,"I'm not sure that this is quite sufficient to say that there is nothing fundamentally broken in the implementation (e.g. accessing randomly initialised memory), but that:",Investigation and Exploration
9568,"We need a way to reproduce the error, or we will need to skip the tests / lower the condition on certain architectures.",Investigation and Exploration
9569,IIRC @ogrisel's hunch was that it was CPU architecture related.,Investigation and Exploration
9570,Could be OS-related.,Investigation and Exploration
9571,Is the devp sklearn built from source code using OpenBLAS instead of MKL?,Investigation and Exploration
9572,"If one of you can reproduce the problem, please try to find a numpy random seed that trigger the issue (using CODE instead of CODE in the above snippet) and communicate the value here (along with the version of OSX and you python packages).",Investigation and Exploration
9573,@robmsylvester  shouldn't making changes in the scopes of the cells work?,Investigation and Exploration
9574,What platform are you on? (e.g. CODE),Investigation and Exploration
9575,How did you install scikit-learn?,Investigation and Exploration
9576,What would be really great is to continue where @rabst stopped and further isolate the problem:https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-258311980,Investigation and Exploration
9577,"If you believe that this is the cause of some kind of memory leak, I think we should really take a look at my testing script and update it as it's very rudimentary and I'm far from an expert profiler.",Investigation and Exploration
9578,It's working for the other two examples as well.,Investigation and Exploration
9579,"At first errors were still being produced, but after a few shuffles of the corpus to errors to my surprise went away.",Investigation and Exploration
9580,You're using XGBoost.,Investigation and Exploration
9581,CODE,Investigation and Exploration
9582,"*         it is more susceptible to numerical imprecision than we would like, but perhaps we should (seek contributions that) investigate stability improvements",Investigation and Exploration
9583,I suspect this is the same old multiprocessing in windows issue.,Investigation and Exploration
9584,"E.g., CODE reproduces the problem on my machine.",Investigation and Exploration
9585,Could be OS-related.,Investigation and Exploration
9586,Perhaps comparing outputs at verbose=20 will be more informative.,Investigation and Exploration
9587,"I think scikit learn is part of anaconda, but I did upgrade with pip (pip install --upgrade sklearn), but thats before I got this problem..",Investigation and Exploration
9588,What do you mean by the divergence?,Investigation and Exploration
9589,This freezing problem is specific to Accelerate and Python multiprocessing.,Investigation and Exploration
9590,"In any case, this is a known problem with Accelerate and Python multiprocessing.",Investigation and Exploration
9591,@blang can you confirm?,Investigation and Exploration
9592,"They make a copy of the cell, then pass the cell argument along to the attention decoder embedding function, then to the attention decoder itself.",Investigation and Exploration
9593,2.         A cache in the CODE,Investigation and Exploration
9594,@adverley Could you try the most recent version from GitHub on your Windows box?,Investigation and Exploration
9595,-         Multiprocessing has platform-specific issues.,Investigation and Exploration
9596,The issue is arising because the entity recogniser's push-down automaton finds itself in a state with no continuations.,Investigation and Exploration
9597,Thought it was German that made it break.,Investigation and Exploration
9598,I that due to a name mismatch. CODE?,Investigation and Exploration
9599,By pinpointing where this and other machines diverge in their calculation...,Investigation and Exploration
9600,"Curious thing, If you add a comma like this: CODE the error goes away.",Investigation and Exploration
9601,"After upgrading CODE to 1.11.2, I can no longer reproduce the error in either conda virtual environment.",Investigation and Exploration
9602,"I tried to read it but there is only the logs after iteration 200 (""QuadTree"" is way too verbose and I think we lose the beginning as the log growth too big).",Investigation and Exploration
9603,Here is the code I used to create the metrics.,Investigation and Exploration
9604,"If one of you can reproduce the problem, please try to find a numpy random seed that trigger the issue (using CODE instead of CODE in the above snippet) and communicate the value here (along with the version of OSX and you python packages).",Investigation and Exploration
9605,At least that way we might know if the problem went away after reinstalling miniconda is fundamentally linked to math library?,Investigation and Exploration
9606,"just to eliminate the possibility, could you try usingreturn_train_score=False?",Investigation and Exploration
9607,@blang can you confirm?,Investigation and Exploration
9608,"The cells passed here are used for both the backward and forward phase of the legacy seq2seq model, which throws an error because of same cells being used with different scopes.",Investigation and Exploration
9609,"That's very small differences for float32 data, and a large range in exponent from min to max.",Investigation and Exploration
9610,"Something may have happened because of the Spyder install, but then why would it work for a day and then suddenly stop??",Investigation and Exploration
9611,"Are you able to try this out in the current development version, to see ifit's still an issue?",Investigation and Exploration
9612,Actually @Ekliptor can reproduce the issue with python 3.5.1 from conda so it's probably not related to the version of Python either.,Investigation and Exploration
9613,It seems that reinstalling packages with conda may help but I am afraid there doesn't seem to be a very clear picture of the cause of the problem :(.,Investigation and Exploration
9614,"E.g., CODE reproduces the problem on my machine.",Investigation and Exploration
9615,I think the tutorial is deprecated since it uses a seq2seq model with bucketing in contrast to a dynamic seq2seq.,Investigation and Exploration
9616,CODE,Investigation and Exploration
9617,There'snothing about the average=macro option in 0.14 that suggests it should bemore likely to hang than the default average (weighted).,Investigation and Exploration
9618,"The default ldconf only search /lib and /usr/lib, as well as the library file under the directory listed in the configuration file /etc/ld. so. conf.",Investigation and Exploration
9619,@jnothman : I am using RandomizedSearchCV from sklearn.grid_search which does not have the return_train_score parameter.,Investigation and Exploration
9620,Though I have noticed that **it only occurs for a subset of my dataset and not with the whole thing**.,Investigation and Exploration
9621,"As above, if I use nlp(text) everything is fine.",Investigation and Exploration
9622,Is there a reason this test needs to use randn?,Investigation and Exploration
9623,"That's very small differences for float32 data, and a large range in exponent from min to max.",Investigation and Exploration
9624,I that due to a name mismatch. CODE?,Investigation and Exploration
9625,I done nothing since.,Investigation and Exploration
9626,This freezing problem is specific to Accelerate and Python multiprocessing.,Investigation and Exploration
9627,Just paste it into a Jupyter cell and run it.,Investigation and Exploration
9628,Try to run it multiple times just in case because the random seed is not set properly and there may be some randomness left in the snippet.,Investigation and Exploration
9629,"@priidukull, What did you mean by telling that the divergence happened in C code?",Investigation and Exploration
9630,"@zhongyuk If it helps, I have a very similar setup (can't reproduce the issue anymore since reinstalling miniconda), except that I have macOS Sierra instead of OS X El Capitan and that I have numpy 1.11.2 instead of 1.11.1.",Investigation and Exploration
9631,"*         it is more susceptible to numerical imprecision than we would like, but perhaps we should (seek contributions that) investigate stability improvements",Investigation and Exploration
9632,Could be OS-related.,Investigation and Exploration
9633,What I took from it is that fork() NOT followed by exec() call is bad.,Investigation and Exploration
9634,The first 20:CODE,Investigation and Exploration
9635,"Also for future reference, can you paste the output of:CODE",Investigation and Exploration
9636,This is the status code the CODE method was ignoring.,Investigation and Exploration
9637,Does it work then?,Investigation and Exploration
9638,"Since this is related to BLAS, my hunch is that something goes wrong in this [line](https://github.com/scikit-learn/scikit-learn/blob/46fc1be145bf952a916ef5abd06efec105105c2e/sklearn/manifold/_barnes_hut_tsne.pyx#L660) causing the gradient to have some non-finite values.",Investigation and Exploration
9639,This is a [well-known feature](http://docs.python.org/2/library/multiprocessing.html#windows) of Python multiprocessing on Windows: you have to run everything that uses CODE in an CODE block or you'll get freezes/crashes.,Investigation and Exploration
9640,The error is in [this](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L122) cluster of lines.,Investigation and Exploration
9641,http://scikit-learn.org/stable/faq.html#why-do-i-sometime-get-a-crash-freeze-with-n-jobs-1-under-osx-or-linux for more details.,Investigation and Exploration
9642,Importing the scorer also didn't help in my case.,Investigation and Exploration
9643,Generally multiprocessing in Windows encounters a lot of problems.,Investigation and Exploration
9644,Seems like you're running out of ram.,Investigation and Exploration
9645,"The scorer function is ""score_model"", it doesn't use joblib.",Investigation and Exploration
9646,@robmsylvester The same error persisted even when I tried with num_layers=1 which should effectively skip that line.,Investigation and Exploration
9647,What would be really great is to continue where @rabst stopped and further isolate the problem:https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-258311980,Investigation and Exploration
9648,pip on the other hand will use wheels that are shipped with Accelerate (at the time of writing).,Investigation and Exploration
9649,@robmsylvester The same error persisted even when I tried with num_layers=1 which should effectively skip that line.,Investigation and Exploration
9650,so all of this is caused by the  dynamic library of CUDA in the installed CUDA path such as : /path/cuda-9.0/lib64  or /path/cuda-9.0/lib. (for eample my CUDA is installed in /usr/local/cuda-9.0),Investigation and Exploration
9651,Does your scorer use joblib / n_jobs anywhere?,Investigation and Exploration
9652,This might have something to do with state between the documents (don't know what if any is kept).,Investigation and Exploration
9653,"So, somehow the CODE function doesn't work properly (maybe due to some BLAS thing).",Investigation and Exploration
9654,"However, it is clear that the ""out-of-date"" -as you call it- instructions page may not be so out of date.",Investigation and Exploration
9655,I ran the code fine after upgrading to 0.19.,Investigation and Exploration
9656,I think it has nothing to do with tensorflow; my guess is that [GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] vs [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] is the culprit!?,Investigation and Exploration
9657,Otherwise everything should be the same.,Investigation and Exploration
9658,While we are at it your CPU information (CODE according to Google) and your platform information (CODE) would be great.,Investigation and Exploration
9659,"If it's 0.14, does it still happen in the current development version?",Investigation and Exploration
9660,I ran the benchmark you requested above - collecting metrics on the length of the CODE as memory Solution Usage grows.,Investigation and Exploration
9661,So it seems that openblas is not the cause of this freeze.,Investigation and Exploration
9662,"Also, just for the sake of sanity, can you make sure you can reproduce the problem in a fresh conda environment.",Investigation and Exploration
9663,Do you get this error when running the test on the wheel version of scikit-learn 0.19?,Investigation and Exploration
9664,"
REFERENCE",Investigation and Exploration
9665,Although I haven't tried to create an virtualenv with MKL and CODE to see if this would reproduce the error.,Investigation and Exploration
9666,"One way to know once you have built scikit-learn from source is to run the equivalent of CODE (Google seems to say CODE) on CODE (name will be different if you are using Python 3, i.e. something like CODE).",Investigation and Exploration
9667,@robmsylvester The same error persisted even when I tried with num_layers=1 which should effectively skip that line.,Investigation and Exploration
9668,@adverley Could you try the most recent version from GitHub on your Windows box?,Investigation and Exploration
9669,Can you report the lengths of the CODE class in your two benchmark cases?,Investigation and Exploration
9670,"The custom scorer object was a mistake of me, the problem lies indeed in the multiprocessing on windows.",Investigation and Exploration
9671,"For the record, can you post the output of this snippet: CODE",Investigation and Exploration
9672,It prints the squared norm of the gradient and the error at each iteration so we can see which part of the code is diverging.,Investigation and Exploration
9673,I was putting print statements into the code and comparing the values of the variable X during different stages of execution...,Investigation and Exploration
9674,It's working for the other two examples as well.,Investigation and Exploration
9675,"Are you able to try this out in the current development version, to see ifit's still an issue?",Investigation and Exploration
9676,Will switch it to ATLAS and see what happens.,Investigation and Exploration
9677,One thing that stands out to me is in the referenced legacy seq2seq file: CODE,Investigation and Exploration
9678,Maybe this is some kind of degrees of freedom check run amok?,Investigation and Exploration
9679,Curious why it works for me now :/,Investigation and Exploration
9680,"Would be good to find a more light-weight example maybe, to add this particular case to the travis tests.",Investigation and Exploration
9681,Do you have an old(er) Miniconda/Anaconda 2.7 distro installed?,Investigation and Exploration
9682,Actually @Ekliptor can reproduce the issue with python 3.5.1 from conda so it's probably not related to the version of Python either.,Investigation and Exploration
9683,"There's apparently a bug in the logic to introduce this constraint, that's leaving the automaton with no available actions.",Investigation and Exploration
9684,"I don't know what they do internally, it's very possible that's the issue.",Investigation and Exploration
9685,I would wild guess that by updating scikit-learn with pip you updated numpy with pip too and you got the numpy wheels which uses Accelerate and has the limitation mentioned above.,Investigation and Exploration
9686,Can you try to see if adding the CODEif __name__CODE helps?,Investigation and Exploration
9687,"@tommoral, if we continue to not be able to reproduce this bug, what kind of debugging output do you think would help us understand what's going wrong?",Investigation and Exploration
9688,But I could not tell where exactly with full certainty because it is tough to debug.,Investigation and Exploration
9689,Running CODE indicated that both of them somehow didn't have CODE loaded.,Investigation and Exploration
9690,Running CODE indicated that both of them somehow didn't have CODE loaded.,Investigation and Exploration
9691,Where can I set verbose=20?,Investigation and Exploration
9692,Do you get this error when running the test on the wheel version of scikit-learn 0.19?,Investigation and Exploration
9693,**update** so the error going away didn't have anything to do with CODE.,Investigation and Exploration
9694,This might be a bug in itself.,Investigation and Exploration
9695,"The default ldconf only search /lib and /usr/lib, as well as the library file under the directory listed in the configuration file /etc/ld. so. conf.",Investigation and Exploration
9696,"If I cancel out the scoring=... line, the parallel execution works.",Investigation and Exploration
9697,"Just wanna say that I ran CODE on CODE (I assume this is the t_sne.py compiled file?), it seems like it's indeed using BLAS.",Investigation and Exploration
9698,"Sorry, missed it - pip.",Investigation and Exploration
9699,"To clarify a little bit, the current release version has three known places that could be growing in memory use.",Investigation and Exploration
9700,This is because the same cell definition is used both for encoder and decoder.,Investigation and Exploration
9701,"
REFERENCE",Investigation and Exploration
9702,**update** so the error going away didn't have anything to do with CODE.,Investigation and Exploration
9703,CODE,Investigation and Exploration
9704,"Also for future reference, can you paste the output of:CODE",Investigation and Exploration
9705,This has nothing to do with custom scorers.,Investigation and Exploration
9706,"So, somehow the CODE function doesn't work properly (maybe due to some BLAS thing).",Investigation and Exploration
9707,I created a new python2 environment like the one I had before installing Gensim.,Investigation and Exploration
9708,The root of the problem is that a number of spaCy classes carry large binary data structures.,Investigation and Exploration
9709,@Timonzimm I know and I think the whole issue is this f** naming libcublas.so.xxx that nvidia puts.,Investigation and Exploration
9710,"On the other machine (the one that works fine), the gradients are all < 0 after the same iteration.",Investigation and Exploration
9711,CODE,Investigation and Exploration
9712,Ok after playing extensively with different random seeds and platforms (mkl vs openblas PCA for the init) I think that 0.9 is just too strict.,Investigation and Exploration
9713,There'snothing about the average=macro option in 0.14 that suggests it should bemore likely to hang than the default average (weighted).,Investigation and Exploration
9714,Or maybe that comment was wrong and I was just confused because your outputisn't complete: the beginning is cut off,Investigation and Exploration
9715,EDIT: Same is true for iris.,Investigation and Exploration
9716,"Haven't updated the second mac to macOS Sierra yet, which is running on the former machine that has this problem.",Investigation and Exploration
9717,"I noticed that the gradient in https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L387 explodes, until it becomes CODE in one position after the 25th iteration in the https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L386 for-loop",Investigation and Exploration
9718,"This results in an invalid predicted action, leading the parser to return a status code (it can't raise an error, as it's in a CODE function).",Investigation and Exploration
9719,CPU info: CODEPlatform info: CODE,Investigation and Exploration
9720,The only difference is to the output above it is running on an older kernel (CODE).,Investigation and Exploration
9721,If you create a conda environment from scratch you should not have this problem.,Investigation and Exploration
9722,"However, both CODE and CODE seem to be float 64 arrays ...",Investigation and Exploration
9723,You may need to run it multiple times because unfortunately the seed is not set appropriately (you need to use CODE rather than CODE).,Investigation and Exploration
9724,CODE,Investigation and Exploration
9725,One of them is equipped with CODE and the other is equipped with CODE.,Investigation and Exploration
9726,this was working last Friday!!,Investigation and Exploration
9727,"@tommoral, if we continue to not be able to reproduce this bug, what kind of debugging output do you think would help us understand what's going wrong?",Investigation and Exploration
9728,But it still points to a potential flaw in the design of the library.,Investigation and Exploration
9729,Or did anyone experience the bug not using conda?,Investigation and Exploration
9730,"I thought the current OneHotEncoder would have categories [0, 1, 2, 3, 4, 5] (while current CategoricalEncoder would have categories [2, 3, 5]).",Investigation and Exploration
9731,"*         it is more susceptible to numerical imprecision than we would like, but perhaps we should (seek contributions that) investigate stability improvements",Investigation and Exploration
9732,"I have find the reason is ldconf,  ldconfig is a dynamic link library management command whose purpose is to allow the dynamic link library to be usedby the system.",Investigation and Exploration
9733,this was working last Friday!!,Investigation and Exploration
9734,"The scorer function is ""score_model"", it doesn't use joblib.",Investigation and Exploration
9735,Or maybe that comment was wrong and I was just confused because your outputisn't complete: the beginning is cut off,Investigation and Exploration
9736,[output.txt.zip] URL ,Investigation and Exploration
9737,"Could you put verbose=10 in cross_val_predict, too, so that we can perhapssee where it breaks for you?",Investigation and Exploration
9738,When parsing things like social media where there are many tokens that occur only once (e.g. links) storing them in the StringStore causes memory bloat.,Investigation and Exploration
9739,If you create a conda environment from scratch you should not have this problem.,Investigation and Exploration
9740,"This inherently is mismatch on linux systems whenever that number changes, so since it can not find the exact matches then it thinks the file doesn't exist and throws the error.",Investigation and Exploration
9741,"3.         The CODE, for tokens that are part of CODE, CODE and CODE patterns.",Investigation and Exploration
9742,"The pip wheels are using OpenBLAS and you don't have the problem when using OpenBLAS with conda (through the CODE trick) so this does look like a MKL problem, which on top of that is likely CPU-specific.",Investigation and Exploration
9743,"In fact, the copy.deepcopy is there because these are legacy functions andwe don't have the resources to maintain/update them.",Investigation and Exploration
9744,@lesteve paula has posted a snippet that also has the same problem.,Investigation and Exploration
9745,"Since this is related to BLAS, my hunch is that something goes wrong in this [line](https://github.com/scikit-learn/scikit-learn/blob/46fc1be145bf952a916ef5abd06efec105105c2e/sklearn/manifold/_barnes_hut_tsne.pyx#L660) causing the gradient to have some non-finite values.",Investigation and Exploration
9746,"Meanwhile, I will try to see if I can find an old backupstate to find out which conda version I had installed previously.",Investigation and Exploration
9747,"@KaisJM by the way, this page is out-of-date, since nowadays wheels are available on Linux and contain their own OpenBLAS.",Investigation and Exploration
9748,@lesteve paula has posted a snippet that also has the same problem.,Investigation and Exploration
9749,I don't want to upgrade OS yet b/z I thought I read somewhere that TensorFlow doesn't support Sierra yet (could be mistaken or no longer be true anymore since I don't remember where or how long ago I read it)?,Investigation and Exploration
9750,It prints the squared norm of the gradient and the error at each iteration so we can see which part of the code is diverging.,Investigation and Exploration
9751,"We need a way to reproduce the error, or we will need to skip the tests / lower the condition on certain architectures.",Investigation and Exploration
9752,At least that way we might know if the problem went away after reinstalling miniconda is fundamentally linked to math library?,Investigation and Exploration
9753,"could you try using conda packages without mkl, i.e. something like CODE so we can see whether that is a MKL vs openblas thing?",Investigation and Exploration
9754,Setting CODE on Linux doesn't solve the issue for me.,Investigation and Exploration
9755,What were you comparing it against?,Investigation and Exploration
9756,"Suppose you have one feature with values [2, 3, 5, 2].",Investigation and Exploration
9757,"They make a copy of the cell, then pass the cell argument along to the attention decoder embedding function, then to the attention decoder itself.",Investigation and Exploration
9758,Where can I set verbose=20?,Investigation and Exploration
9759,"i hit the same problem and was scratching my head for two days, until finally i discovered that local copy of libcudnn.so was used by conda, under:/miniconda3/lib/libcudnn.so which pointed to libcudnn.so.7 which pointed to libcudnn.so.7.0.5",Investigation and Exploration
9760,Or did anyone experience the bug not using conda?,Investigation and Exploration
9761,The snippet CODE reproduces the error (but it works fine on the nomkl env),Investigation and Exploration
9762,Here is the code I used to create the metrics.,Investigation and Exploration
9763,[output.txt.zip] URL ,Investigation and Exploration
9764,"As above, if I use nlp(text) everything is fine.",Investigation and Exploration
9765,Test code: CODE,Investigation and Exploration
9766,@jnothman : I am using RandomizedSearchCV from sklearn.grid_search which does not have the return_train_score parameter.,Investigation and Exploration
9767,Here is the code I used to create the metrics.,Investigation and Exploration
9768,"If you are all using compiled version on master branch, I believe that we are the same issue caused by the [recent commit] URL .",Investigation and Exploration
9769,Paula: I could not get this snippet to freeze.,Investigation and Exploration
9770,The problem arises very likely in some cython code in sklearn/manifold/_barnes_hut_tsne.pyx.,Investigation and Exploration
9771,Output: https://gist.github.com/priidukull/1453adb7cf2bca2093b2dd9d6646f64e,Investigation and Exploration
9772,"@zhongyuk If it helps, I have a very similar setup (can't reproduce the issue anymore since reinstalling miniconda), except that I have macOS Sierra instead of OS X El Capitan and that I have numpy 1.11.2 instead of 1.11.1.",Investigation and Exploration
9773,Test code: CODE,Investigation and Exploration
9774,"But you are right that the CODE is also only [2, 3, 5], essentially making them the same with the default value of CODE.",Investigation and Exploration
9775,@lesteve paula has posted a snippet that also has the same problem.,Investigation and Exploration
9776,EDIT: Same is true for iris.,Investigation and Exploration
9777,@paulaceccon are your Numpy and Scipy installations using ATLAS or OpenBLAS?,Investigation and Exploration
9778,this was working last Friday!!,Investigation and Exploration
9779,Can you try to see if adding the CODEif __name__CODE helps?,Investigation and Exploration
9780,@blang can you confirm?,Investigation and Exploration
9781,"That repo looks like it's targeted at tf 1.0, not intermediate releases.",Investigation and Exploration
9782,How did you install scikit-learn?,Investigation and Exploration
9783,Or what kind of more low-level unit tests might help us hone in on it?,Investigation and Exploration
9784,"We see that the first error is a small numerical imprecision at line 5, but that this quite quickly blows out.",Investigation and Exploration
9785,"After making sure CODE loaded up, the error disappeared in the virtual env with CODE.",Investigation and Exploration
9786,Here is the output for the first 100 iterations (it is still too big for the gist)[output.text] URL ,Investigation and Exploration
9787,"-         What do you mean by ""crashes""?",Investigation and Exploration
9788,Or did anyone experience the bug not using conda?,Investigation and Exploration
9789,Try to run it multiple times just in case because the random seed is not set properly and there may be some randomness left in the snippet.,Investigation and Exploration
9790,"Meanwhile, I will try to see if I can find an old backupstate to find out which conda version I had installed previously.",Investigation and Exploration
9791,"I don't know what they do internally, it's very possible that's the issue.",Investigation and Exploration
9792,@Lucidyan could you try the same snippet with scikit-learn master and see whether it fails too ?,Investigation and Exploration
9793,[output.txt.zip] URL ,Investigation and Exploration
9794,I done nothing since.,Investigation and Exploration
9795,"I tried to read it but there is only the logs after iteration 200 (""QuadTree"" is way too verbose and I think we lose the beginning as the log growth too big).",Investigation and Exploration
9796,"For the record, can you post the output of this snippet: CODE",Investigation and Exploration
9797,Do you have another system you're comparing against?,Investigation and Exploration
9798,I am getting the following on CODE: CODE,Investigation and Exploration
9799,"I haven't stepped through the automaton yet (if you want to do that, use the methodCODE) to see exactly where the problem is, but I'm pretty sure the error will come from an interaction with entities pre-set by the CODE class.",Investigation and Exploration
9800,It seems that reinstalling packages with conda may help but I am afraid there doesn't seem to be a very clear picture of the cause of the problem :(.,Investigation and Exploration
9801,Test code: CODE,Investigation and Exploration
9802,Here is the code I used to create the metrics.,Investigation and Exploration
9803,@zhongyuk depends which library you have installed.,Investigation and Exploration
9804,"If you believe that this is the cause of some kind of memory leak, I think we should really take a look at my testing script and update it as it's very rudimentary and I'm far from an expert profiler.",Investigation and Exploration
9805,-         Have you tried it on different datasets?,Investigation and Exploration
9806,"However if you take the document that produces the error, pass it through CODE and then call CODE again, it works.",Investigation and Exploration
9807,I done nothing since.,Investigation and Exploration
9808,"On the original machine, the exact method + PCA init was triggering the instability according to: https://github.com/scikit-learn/scikit-learn/issues/9393#issuecomment-322214890",Investigation and Exploration
9809,"If you believe that this is the cause of some kind of memory leak, I think we should really take a look at my testing script and update it as it's very rudimentary and I'm far from an expert profiler.",Investigation and Exploration
9810,"If you are all using compiled version on master branch, I believe that we are the same issue caused by the [recent commit] URL .",Investigation and Exploration
9811,"Hm none of the links at CODEtest_preserve_trustworthyness_approximatelyCODE above have failures for that, right?",Investigation and Exploration
9812,this was working last Friday!!,Investigation and Exploration
9813,Not that that's easy to do without at least a VM of the target machine.,Investigation and Exploration
9814,Directly doing: CODE is ok in both cases.,Investigation and Exploration
9815,"So if you haven't already (unfortunately we are not mind readers and ""not working for me"" does not tell us what you tried) could you try to run the snippet mentioned above in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185.",Investigation and Exploration
9816,Could you please check it out and re-run the same code?,Investigation and Exploration
9817,"Also how did you install scikit-learn, with pip, with conda, with one of the OSX package managers (brew, etc ...) ?",Investigation and Exploration
9818,Could you please check it out and re-run the same code?,Investigation and Exploration
9819,"We see that the first error is a small numerical imprecision at line 5, but that this quite quickly blows out.",Investigation and Exploration
9820,"As I said in my original post, I think that this is just part of how spacy works.",Investigation and Exploration
9821,How did you install scikit-learn?,Investigation and Exploration
9822,Ok after playing extensively with different random seeds and platforms (mkl vs openblas PCA for the init) I think that 0.9 is just too strict.,Investigation and Exploration
9823,Running GridSearchCV or RandomizedSearchCV in a loop and  n_jobs > 1 would hang silently in Jupiter & IntelliJ: CODE,Investigation and Exploration
9824,The root of the problem is that a number of spaCy classes carry large binary data structures.,Investigation and Exploration
9825,"There's currently no Python API for inspecting the size of the tokenizer's cache, so it's easiest to do this by elimination.",Investigation and Exploration
9826,"This may be be a BLAS problem indeed, the CODE env works fine.",Investigation and Exploration
9827,If you install a released scikit-learn with pip you will be using OpenBLAS.,Investigation and Exploration
9828,Although I haven't tried to create an virtualenv with MKL and CODE to see if this would reproduce the error.,Investigation and Exploration
9829,@Timonzimm I know and I think the whole issue is this f** naming libcublas.so.xxx that nvidia puts.,Investigation and Exploration
9830,Do you have this issue with the tf nightlies?,Investigation and Exploration
9831,This might have something to do with state between the documents (don't know what if any is kept).,Investigation and Exploration
9832,CODE,Investigation and Exploration
9833,I created a new python2 environment like the one I had before installing Gensim.,Investigation and Exploration
9834,"That is, if I do TSNE on the whole data set it **works**, if I do it on a reduced set it does not.",Investigation and Exploration
9835,Maybe this is some kind of degrees of freedom check run amok?,Investigation and Exploration
9836,"you can email my personal address for the, thanks",Investigation and Exploration
9837,Not that that's easy to do without at least a VM of the target machine.,Investigation and Exploration
9838,"If you are all using compiled version on master branch, I believe that we are the same issue caused by the [recent commit] URL .",Investigation and Exploration
9839,What platform are you on? (e.g. CODE),Investigation and Exploration
9840,It's using MKL as well.,Investigation and Exploration
9841,One of them is equipped with CODE and the other is equipped with CODE.,Investigation and Exploration
9842,[output.txt.zip] URL ,Investigation and Exploration
9843,*         If this freezes (i.e. it does not finish within one second) that means you are using Accelerate and the freeze is a known limitation with Python multiprocessing.,Investigation and Exploration
9844,And the one which threw error seems to use MKL..,Investigation and Exploration
9845,Notice that n_jobs=-1 and runs fine.,Investigation and Exploration
9846,"Hm, how would the conda scikit-learn version differ from the pip wheels?",Investigation and Exploration
9847,The highest likelihood is that OpenBLAS is causing the fees they are talking about in that page.,Investigation and Exploration
9848,"you can email my personal address for the, thanks",Investigation and Exploration
9849,"This inherently is mismatch on linux systems whenever that number changes, so since it can not find the exact matches then it thinks the file doesn't exist and throws the error.",Investigation and Exploration
9850,"However if you take the document that produces the error, pass it through CODE and then call CODE again, it works.",Investigation and Exploration
9851,"If you have old version of CUDA, the library link may point to the old library even you install the newer CUDA especially if you install it manually.",Investigation and Exploration
9852,*         If this freezes (i.e. it does not finish within one second) that means you are using Accelerate and the freeze is a known limitation with Python multiprocessing.,Investigation and Exploration
9853,@pbnsilva can you try this snippet posted below ?,Investigation and Exploration
9854,I checked a recent numpy wheel and it contains OpenBLAS 0.2.8.18.,Investigation and Exploration
9855,"The cells passed here are used for both the backward and forward phase of the legacy seq2seq model, which throws an error because of same cells being used with different scopes.",Investigation and Exploration
9856,I noticed that in my platform CODE is not loaded...,Investigation and Exploration
9857,https://github.com/natb1/spaCy/blob/memory-benchmark/spacy/tests/benchmark/test_memory.py,Investigation and Exploration
9858,"Also, just for the sake of sanity, can you make sure you can reproduce the problem in a fresh conda environment.",Investigation and Exploration
9859,"Curious thing, If you add a comma like this: CODE the error goes away.",Investigation and Exploration
9860,I ran the code fine after upgrading to 0.19.,Investigation and Exploration
9861,The root of the problem is that a number of spaCy classes carry large binary data structures.,Investigation and Exploration
9862,"Sure, the machine that causes this problem: CODE (tested it in a fresh conda environment)",Investigation and Exploration
9863,@yangfengKAUST with the current version of cuda and cudnn installed TF is just complaining that it cannot find the versions it is expecting.,Investigation and Exploration
9864,So it may have something to do with n_jobs=-1.,Investigation and Exploration
9865,@Timonzimm I know and I think the whole issue is this f** naming libcublas.so.xxx that nvidia puts.,Investigation and Exploration
9866,"As I said in my original post, I think that this is just part of how spacy works.",Investigation and Exploration
9867,This might have something to do with state between the documents (don't know what if any is kept).,Investigation and Exploration
9868,"Could you put verbose=10 in cross_val_predict, too, so that we can perhapssee where it breaks for you?",Investigation and Exploration
9869,CODE,Investigation and Exploration
9870,"Hm, how would the conda scikit-learn version differ from the pip wheels?",Investigation and Exploration
9871,"What's more, Numpy is using OpenBLAS and has the same config as the environment that exhibits the freeze (the one where Gensim was installed).",Investigation and Exploration
9872,@paulaceccon are your Numpy and Scipy installations using ATLAS or OpenBLAS?,Investigation and Exploration
9873,@yangfengKAUST with the current version of cuda and cudnn installed TF is just complaining that it cannot find the versions it is expecting.,Investigation and Exploration
9874,The problem is we also want the inverse mapping.,Investigation and Exploration
9875,Would be great if you can take a look and post a version of it that freezes.,Investigation and Exploration
9876,"@zhongyuk Hm, I think it's unlikely that it is related.",Investigation and Exploration
9877,So it seems like this is happening when mixing numpy installed via pip and conda.,Investigation and Exploration
9878,"That is, if I do TSNE on the whole data set it **works**, if I do it on a reduced set it does not.",Investigation and Exploration
9879,"Could you put verbose=10 in cross_val_predict, too, so that we can perhapssee where it breaks for you?",Investigation and Exploration
9880,You're using XGBoost.,Investigation and Exploration
9881,Some piece of information useful to have (just add what is missing to your earlier comment https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-320885103): CODE,Investigation and Exploration
9882,I've just realised we have a higher level of verbosity available to us.,Investigation and Exploration
9883,Generally multiprocessing in Windows encounters a lot of problems.,Investigation and Exploration
9884,One thing that stands out to me is in the referenced legacy seq2seq file: CODE,Investigation and Exploration
9885,"So, somehow the CODE function doesn't work properly (maybe due to some BLAS thing).",Investigation and Exploration
9886,@robmsylvester The same error persisted even when I tried with num_layers=1 which should effectively skip that line.,Investigation and Exploration
9887,what is crf?,Investigation and Exploration
9888,Because the latter seem to work on the same machine.,Investigation and Exploration
9889,"On the other machine (the one that works fine), the gradients are all < 0 after the same iteration.",Investigation and Exploration
9890,"I read the FAQ entry you refer to about ""Accelerate"".. its not much help for me.",Investigation and Exploration
9891,"Also, just for the sake of sanity, can you make sure you can reproduce the problem in a fresh conda environment.",Investigation and Exploration
9892,"I also reinstalled spaCy and the German model yesterday, but this din't fix the problem in my case.",Investigation and Exploration
9893,@lesteve are you saying that Openblas does not cause a freeze anymore?,Investigation and Exploration
9894,"*         it is more susceptible to numerical imprecision than we would like, but perhaps we should (seek contributions that) investigate stability improvements",Investigation and Exploration
9895,Try this snippet (taken from https://github.com/numpy/numpy/issues/4776):CODE,Investigation and Exploration
9896,I think it has to do with the GridSearchCV being placed in a for loop.,Investigation and Exploration
9897,"This may be be a BLAS problem indeed, the CODE env works fine.",Investigation and Exploration
9898,It's using MKL as well.,Investigation and Exploration
9899,Maybe it's somehow related to conda,Investigation and Exploration
9900,"If you believe that this is the cause of some kind of memory leak, I think we should really take a look at my testing script and update it as it's very rudimentary and I'm far from an expert profiler.",Investigation and Exploration
9901,"I haven't stepped through the automaton yet (if you want to do that, use the methodCODE) to see exactly where the problem is, but I'm pretty sure the error will come from an interaction with entities pre-set by the CODE class.",Investigation and Exploration
9902,"I tried it, and it fails with X_SIZE <= 1750 (Y_SIZE=20, n_components=2 became constants).",Investigation and Exploration
9903,"Actually, multiplying the data by 100 does not make the algorithm more stable with the PCA init, quite the opposite actually.",Investigation and Exploration
9904,"@tommoral, if we continue to not be able to reproduce this bug, what kind of debugging output do you think would help us understand what's going wrong?",Investigation and Exploration
9905,"Can you point to some more information, more detail about what the problem is?",Investigation and Exploration
9906,Running GridSearchCV or RandomizedSearchCV in a loop and  n_jobs > 1 would hang silently in Jupiter & IntelliJ: CODE,Investigation and Exploration
9907,Or maybe that comment was wrong and I was just confused because your outputisn't complete: the beginning is cut off,Investigation and Exploration
9908,this was working last Friday!!,Investigation and Exploration
9909,@jnothman I am guessing that your conda environment uses MKL and not Accelerate.,Investigation and Exploration
9910,One of them is equipped with CODE and the other is equipped with CODE.,Investigation and Exploration
9911,"Just wanna say that I ran CODE on CODE (I assume this is the t_sne.py compiled file?), it seems like it's indeed using BLAS.",Investigation and Exploration
9912,"This inherently is mismatch on linux systems whenever that number changes, so since it can not find the exact matches then it thinks the file doesn't exist and throws the error.",Investigation and Exploration
9913,"One way to know once you have built scikit-learn from source is to run the equivalent of CODE (Google seems to say CODE) on CODE (name will be different if you are using Python 3, i.e. something like CODE).",Investigation and Exploration
9914,"So, somehow the CODE function doesn't work properly (maybe due to some BLAS thing).",Investigation and Exploration
9915,@blang can you confirm?,Investigation and Exploration
9916,"I tried to read it but there is only the logs after iteration 200 (""QuadTree"" is way too verbose and I think we lose the beginning as the log growth too big).",Investigation and Exploration
9917,may be it could just be relaxed a little? ;),Investigation and Exploration
9918,the FAQ link above?,Investigation and Exploration
9919,CODE,Investigation and Exploration
9920,Do you have an old(er) Miniconda/Anaconda 2.7 distro installed?,Investigation and Exploration
9921,I think it has to do with the GridSearchCV being placed in a for loop.,Investigation and Exploration
9922,Test code: CODE,Investigation and Exploration
9923,"At the developmenthead, this completes in 11s on my macbook, and in 7s at version 0.14(that's something to look into!)",Investigation and Exploration
9924,Maybe this is some kind of degrees of freedom check run amok?,Investigation and Exploration
9925,"Still all we can compare by is error, and not, say, gradients:",Investigation and Exploration
9926,It's working for the other two examples as well.,Investigation and Exploration
9927,So it seems that openblas is not the cause of this freeze.,Investigation and Exploration
9928,These instructions are outdated believe me.,Investigation and Exploration
9929,"Also for future reference, can you paste the output of:CODE",Investigation and Exploration
9930,CODE,Investigation and Exploration
9931,"PS: Tensorflow works fine for me on Sierra, but I only do CPU and prototyping on my macs so I don't know about GPU issues related to Sierra",Investigation and Exploration
9932,The only way I managed to reproduce this problem was to install numpy with both pip and conda in the same conda environment.,Investigation and Exploration
9933,It's using MKL as well.,Investigation and Exploration
9934,"This results in an invalid predicted action, leading the parser to return a status code (it can't raise an error, as it's in a CODE function).",Investigation and Exploration
9935,"This is a conda bug, right?",Investigation and Exploration
9936,Thought it was German that made it break.,Investigation and Exploration
9937,Otherwise everything should be the same.,Investigation and Exploration
9938,"They make a copy of the cell, then pass the cell argument along to the attention decoder embedding function, then to the attention decoder itself.",Investigation and Exploration
9939,And the one which threw error seems to use MKL..,Investigation and Exploration
9940,"If you read in details, it says ""but can freeze joblib/multiprocessing prior to OpenBLAS version 0.2.8-4"".",Investigation and Exploration
9941,Where can I set verbose=20?,Investigation and Exploration
9942,"I noticed that the gradient in https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L387 explodes, until it becomes CODE in one position after the 25th iteration in the https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L386 for-loop",Investigation and Exploration
9943,"I tried it, and it fails with X_SIZE <= 1750 (Y_SIZE=20, n_components=2 became constants).",Investigation and Exploration
9944,@paulaceccon are your Numpy and Scipy installations using ATLAS or OpenBLAS?,Investigation and Exploration
9945,Maybe it depends on the minor version of OSX.,Investigation and Exploration
9946,"However, when I replace CODE by CODE it seems to be fine.",Investigation and Exploration
9947,One of them is equipped with CODE and the other is equipped with CODE.,Investigation and Exploration
9948,And the one which threw error seems to use MKL..,Investigation and Exploration
9949,@zhongyuk depends which library you have installed.,Investigation and Exploration
9950,IIRC @ogrisel's hunch was that it was CPU architecture related.,Investigation and Exploration
9951,So it seems like this is happening when mixing numpy installed via pip and conda.,Investigation and Exploration
9952,Where can I set verbose=20?,Investigation and Exploration
9953,"I read the FAQ entry you refer to about ""Accelerate"".. its not much help for me.",Investigation and Exploration
9954,"I have find the reason is ldconf,  ldconfig is a dynamic link library management command whose purpose is to allow the dynamic link library to be usedby the system.",Investigation and Exploration
9955,How did you install scikit-learn?,Investigation and Exploration
9956,Or maybe that comment was wrong and I was just confused because your outputisn't complete: the beginning is cut off,Investigation and Exploration
9957,Do you get this error when running the test on the wheel version of scikit-learn 0.19?,Investigation and Exploration
9958,I am getting the following on CODE: CODE,Investigation and Exploration
9959,The root of the problem is that a number of spaCy classes carry large binary data structures.,Investigation and Exploration
9960,"I don't know what they do internally, it's very possible that's the issue.",Investigation and Exploration
9961,Though I have noticed that **it only occurs for a subset of my dataset and not with the whole thing**.,Investigation and Exploration
9962,The only way I managed to reproduce this problem was to install numpy with both pip and conda in the same conda environment.,Investigation and Exploration
9963,Is the devp sklearn built from source code using OpenBLAS instead of MKL?,Investigation and Exploration
9964,"anyway this seems indicative of the problem I was mentioning, i.e. that you have mixed pip and conda which is a bad idea for a given package.",Investigation and Exploration
9965,"@rasbt hmm, I wonder if the problem goes away in Sierra...",Investigation and Exploration
9966,Could be OS-related.,Investigation and Exploration
9967,1.         The CODE,Investigation and Exploration
9968,These instructions are outdated believe me.,Investigation and Exploration
9969,"However, the error remained appearing in the env with CODE.",Investigation and Exploration
9970,"The freeze they are referring to is the one in https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-334155175, which you don't seem to have.",Investigation and Exploration
9971,"(right now, I have conda 4.2.12)",Investigation and Exploration
9972,"An example document where CODE causes the error, removing that one token everything is fine.",Investigation and Exploration
9973,may be it could just be relaxed a little? ;),Investigation and Exploration
9974,"(To not waste too much of your time, you should probably start at the run_tune_process() method which is being called at the bottom of the code and calls the method containing GridSearchCV() in a for loop)",Investigation and Exploration
9975,Can run the test again.,Investigation and Exploration
9976,"One way to know once you have built scikit-learn from source is to run the equivalent of CODE (Google seems to say CODE) on CODE (name will be different if you are using Python 3, i.e. something like CODE).",Investigation and Exploration
9977,i don't remember who and how placed it there but pretty much it overloaded the system default libcudnn.so.7.1.2 !!!,Investigation and Exploration
9978,"This may be be a BLAS problem indeed, the CODE env works fine.",Investigation and Exploration
9979,may be it could just be relaxed a little? ;),Investigation and Exploration
9980,*         the test is brittle and already provides only weak assurances in asserting t > 0.9,Investigation and Exploration
9981,"@lesteve I built scikit-learn in two conda virtual environments from source code (branch 0.18 release), the one uses MKL indeed throws the error; the one uses libBLAS does not throw error.",Investigation and Exploration
9982,I wonder if there may be a connection?,Investigation and Exploration
9983,Though I have noticed that **it only occurs for a subset of my dataset and not with the whole thing**.,Investigation and Exploration
9984,Can you try to see if adding the CODEif __name__CODE helps?,Investigation and Exploration
9985,"That seems to indicate, that this problem happens in some very specific combination of factors.",Investigation and Exploration
9986,This might have something to do with state between the documents (don't know what if any is kept).,Investigation and Exploration
9987,"There's currently no Python API for inspecting the size of the tokenizer's cache, so it's easiest to do this by elimination.",Investigation and Exploration
9988,the FAQ link above?,Investigation and Exploration
9989,"If I want to use the f1 score as evaluation method, I have to cancel out the parallel execution by setting n_jobs = 1.",Investigation and Exploration
9990,"
REFERENCE",Investigation and Exploration
9991,Because the latter seem to work on the same machine.,Investigation and Exploration
9992,I also saw that the tutorial is deprecated.,Investigation and Exploration
9993,Just paste it into a Jupyter cell and run it.,Investigation and Exploration
9994,And it's also bad to have unbounded memory use on the streaming process.,Investigation and Exploration
9995,Notice that n_jobs=-1 and runs fine.,Investigation and Exploration
9996,Seems there's something different between the TFon pypi and at that tag?,Investigation and Exploration
9997,Maybe there's sth funny going on in CODE.,Investigation and Exploration
9998,@jnothman how could we discover? ;),Investigation and Exploration
9999,You're using XGBoost.,Investigation and Exploration
10000,CODE,Investigation and Exploration
10001,"Consideration 2 is very useful, but it's only really a saving if strings occur multiple times.",Investigation and Exploration
10002,The only difference is to the output above it is running on an older kernel (CODE).,Investigation and Exploration
10003,"On the original machine, the exact method + PCA init was triggering the instability according to: https://github.com/scikit-learn/scikit-learn/issues/9393#issuecomment-322214890",Investigation and Exploration
10004,I think the tutorial is deprecated since it uses a seq2seq model with bucketing in contrast to a dynamic seq2seq.,Investigation and Exploration
10005,And then I debugged through the code on both of my environments and the best I could tell was that the divergence happened in C-code.,Investigation and Exploration
10006,"PS: Tensorflow works fine for me on Sierra, but I only do CPU and prototyping on my macs so I don't know about GPU issues related to Sierra",Investigation and Exploration
10007,So the error is reducing much more slowly...,Investigation and Exploration
10008,Ok after playing extensively with different random seeds and platforms (mkl vs openblas PCA for the init) I think that 0.9 is just too strict.,Investigation and Exploration
10009,How did you install scikit-learn?,Investigation and Exploration
10010,"But you are right that the CODE is also only [2, 3, 5], essentially making them the same with the default value of CODE.",Investigation and Exploration
10011,"-         What do you mean by ""crashes""?",Investigation and Exploration
10012,-         Have you tried it on different datasets?,Investigation and Exploration
10013,"What about the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185, you didn't find a way to make it deterministic and still fail on your machine?",Investigation and Exploration
10014,Or what kind of more low-level unit tests might help us hone in on it?,Investigation and Exploration
10015,It might be a bug somewhere in MultiRNNCell.,Investigation and Exploration
10016,"3.         The CODE, for tokens that are part of CODE, CODE and CODE patterns.",Investigation and Exploration
10017,@adverley Could you try the most recent version from GitHub on your Windows box?,Investigation and Exploration
10018,"(To not waste too much of your time, you should probably start at the run_tune_process() method which is being called at the bottom of the code and calls the method containing GridSearchCV() in a for loop)",Investigation and Exploration
10019,@priidukull your verbose=20 output would be welcome.,Investigation and Exploration
10020,At least that way we might know if the problem went away after reinstalling miniconda is fundamentally linked to math library?,Investigation and Exploration
10021,"That's very small differences for float32 data, and a large range in exponent from min to max.",Investigation and Exploration
10022,"Notice that you can switch between grid_search module and model_selection module, both ran fine for me.",Investigation and Exploration
10023,https://github.com/natb1/spaCy/blob/memory-benchmark/spacy/tests/benchmark/test_memory.py,Investigation and Exploration
10024,Could you please check it out and re-run the same code?,Investigation and Exploration
10025,Because the latter seem to work on the same machine.,Investigation and Exploration
10026,CODE,Investigation and Exploration
10027,"As it sounds complicated and the exact cause of the error is still obscure, I speculate it's probably a complication interweaved by incomplete MKL library loading and scikit-learn dependent libraries (possibly numpy?).",Investigation and Exploration
10028,Paula: I could not get this snippet to freeze.,Investigation and Exploration
10029,Can run the test again.,Investigation and Exploration
10030,Not sure if this was an issue with my string or with spaCy's processing.,Investigation and Exploration
10031,"If you believe that this is the cause of some kind of memory leak, I think we should really take a look at my testing script and update it as it's very rudimentary and I'm far from an expert profiler.",Investigation and Exploration
10032,"Would be good to find a more light-weight example maybe, to add this particular case to the travis tests.",Investigation and Exploration
10033,@Lucidyan could you try the same snippet with scikit-learn master and see whether it fails too ?,Investigation and Exploration
10034,"If you are all using compiled version on master branch, I believe that we are the same issue caused by the [recent commit] URL .",Investigation and Exploration
10035,"Certainly, for strings that occur once, there's no advantage.",Investigation and Exploration
10036,Seems there's something different between the TFon pypi and at that tag?,Investigation and Exploration
10037,"It is very likely that this @KaisJM's problem is due to the well known limitation on Accelerate with multiprocessing, see our [faq](http://scikit-learn.org/stable/faq.html#why-do-i-sometime-get-a-crash-freeze-with-n-jobs-1-under-osx-or-linux).",Investigation and Exploration
10038,"Hmmm, random guess maybe the mkl version, although if I believe the output of CODE the latest mkl version (11.3.3) is from 2016-05-13.",Investigation and Exploration
10039,Paula: I could not get this snippet to freeze.,Investigation and Exploration
10040,"*         If it does not freeze then you are not using Accelerate, and we would need a stand-alone snippet to investigate.",Investigation and Exploration
10041,"This just in, if I repeat the same 'broken' subset that doesn't work(by means of list*10) then it works.",Investigation and Exploration
10042,"That seems to indicate, that this problem happens in some very specific combination of factors.",Investigation and Exploration
10043,This result confirms my hypothesis but also shows that the memory increase really isn't all that significant (especially at the relatively low volume that I am currently processing).,Investigation and Exploration
10044,"That is, if I do TSNE on the whole data set it **works**, if I do it on a reduced set it does not.",Investigation and Exploration
10045,"Hum, that is likely related to issues of multiprocessing on windows.",Investigation and Exploration
10046,"On the other machine (the one that works fine), the gradients are all < 0 after the same iteration.",Investigation and Exploration
10047,"I tried to read it but there is only the logs after iteration 200 (""QuadTree"" is way too verbose and I think we lose the beginning as the log growth too big).",Investigation and Exploration
10048,i don't remember who and how placed it there but pretty much it overloaded the system default libcudnn.so.7.1.2 !!!,Investigation and Exploration
10049,"If it's 0.14, does it still happen in the current development version?",Investigation and Exploration
10050,"Anyway, the symptoms looks similar.",Investigation and Exploration
10051,may be it could just be relaxed a little? ;),Investigation and Exploration
10052,Is theinput to TSNE._tsne identical on both platforms?,Investigation and Exploration
10053,Can you try to see if adding the CODEif __name__CODE helps?,Investigation and Exploration
10054,Seems there's something different between the TFon pypi and at that tag?,Investigation and Exploration
10055,This line appears to be used because the same architecture is used on both the encoder and decoder side.,Investigation and Exploration
10056,"not sure if this is really the reason, but I think CODE may be an issue; since the error doesn't seem to occur via CODE",Investigation and Exploration
10057,"In order to preserve these entities, we restrict the actions of the entity recogniser, so that it can't over-write the previous ones.",Investigation and Exploration
10058,"@rasbt hmm, I wonder if the problem goes away in Sierra...",Investigation and Exploration
10059,"At the developmenthead, this completes in 11s on my macbook, and in 7s at version 0.14(that's something to look into!)",Investigation and Exploration
10060,"If you read in details, it says ""but can freeze joblib/multiprocessing prior to OpenBLAS version 0.2.8-4"".",Investigation and Exploration
10061,I think it has to do with the GridSearchCV being placed in a for loop.,Investigation and Exploration
10062,@adverley Could you try the most recent version from GitHub on your Windows box?,Investigation and Exploration
10063,Paula: I could not get this snippet to freeze.,Investigation and Exploration
10064,"I will try the one from sklearn.model_selection, but something tells me I will have the same exact issue).",Investigation and Exploration
10065,just doubling the length of the list is insufficient.,Investigation and Exploration
10066,"*         it is more susceptible to numerical imprecision than we would like, but perhaps we should (seek contributions that) investigate stability improvements",Investigation and Exploration
10067,"As I said in my original post, I think that this is just part of how spacy works.",Investigation and Exploration
10068,"But you are right that the CODE is also only [2, 3, 5], essentially making them the same with the default value of CODE.",Investigation and Exploration
10069,The different methods and inits produce different trustworthiness scores on all platforms.,Investigation and Exploration
10070,Do you do pylab imports in IPython notebook?,Investigation and Exploration
10071,"you can email my personal address for the, thanks",Investigation and Exploration
10072,"But the verbose output you have sent had substantial discrepancy with what it should, and not just in the numbers.",Investigation and Exploration
10073,"Also, just for the sake of sanity, can you make sure you can reproduce the problem in a fresh conda environment.",Investigation and Exploration
10074,Try to run it multiple times just in case because the random seed is not set properly and there may be some randomness left in the snippet.,Investigation and Exploration
10075,"@KaisJM by the way, this page is out-of-date, since nowadays wheels are available on Linux and contain their own OpenBLAS.",Investigation and Exploration
10076,"@zhongyuk If it helps, I have a very similar setup (can't reproduce the issue anymore since reinstalling miniconda), except that I have macOS Sierra instead of OS X El Capitan and that I have numpy 1.11.2 instead of 1.11.1.",Investigation and Exploration
10077,Not that that's easy to do without at least a VM of the target machine.,Investigation and Exploration
10078,This might have something to do with state between the documents (don't know what if any is kept).,Investigation and Exploration
10079,"Here are the results:<img width=""555"" alt=""screen shot 2016-08-16 at 2 24 25 pm"" src=""https://cloud.githubusercontent.com/assets/1669062/17711263/c23cb262-63be-11e6-9aaf-96e9763a00e0.png"">",Investigation and Exploration
10080,@priidukull your verbose=20 output would be welcome.,Investigation and Exploration
10081,So it seems like this is happening when mixing numpy installed via pip and conda.,Investigation and Exploration
10082,"However if you take the document that produces the error, pass it through CODE and then call CODE again, it works.",Investigation and Exploration
10083,You're using XGBoost.,Investigation and Exploration
10084,Do you have this issue with the tf nightlies?,Investigation and Exploration
10085,As the commit message says:,Investigation and Exploration
10086,@priidukull your verbose=20 output would be welcome.,Investigation and Exploration
10087,Do you recall which C function was responsible for the divergence?,Investigation and Exploration
10088,"(To not waste too much of your time, you should probably start at the run_tune_process() method which is being called at the bottom of the code and calls the method containing GridSearchCV() in a for loop)",Investigation and Exploration
10089,before I spend more time -- is there specific meaning for the threshold to be 0.9?,Investigation and Exploration
10090,Test code: CODE,Investigation and Exploration
10091,@lesteve are you saying that Openblas does not cause a freeze anymore?,Investigation and Exploration
10092,"That is, if I do TSNE on the whole data set it **works**, if I do it on a reduced set it does not.",Investigation and Exploration
10093,"Certainly, for strings that occur once, there's no advantage.",Investigation and Exploration
10094,Directly doing: CODE is ok in both cases.,Investigation and Exploration
10095,"As above, if I use nlp(text) everything is fine.",Investigation and Exploration
10096,"
REFERENCE",Investigation and Exploration
10097,Will switch it to ATLAS and see what happens.,Investigation and Exploration
10098,"Hm none of the links at CODEtest_preserve_trustworthyness_approximatelyCODE above have failures for that, right?",Investigation and Exploration
10099,Ran: CODE,Investigation and Exploration
10100,"The freeze they are referring to is the one in https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-334155175, which you don't seem to have.",Investigation and Exploration
10101,-         Have you tried it on different datasets?,Investigation and Exploration
10102,Do you recall which C function was responsible for the divergence?,Investigation and Exploration
10103,Output: https://gist.github.com/priidukull/1453adb7cf2bca2093b2dd9d6646f64e,Investigation and Exploration
10104,This is because the same cell definition is used both for encoder and decoder.,Investigation and Exploration
10105,One thing that stands out to me is in the referenced legacy seq2seq file: CODE,Investigation and Exploration
10106,"If you have old version of CUDA, the library link may point to the old library even you install the newer CUDA especially if you install it manually.",Investigation and Exploration
10107,"We see that the first error is a small numerical imprecision at line 5, but that this quite quickly blows out.",Investigation and Exploration
10108,"Since this is related to BLAS, my hunch is that something goes wrong in this [line](https://github.com/scikit-learn/scikit-learn/blob/46fc1be145bf952a916ef5abd06efec105105c2e/sklearn/manifold/_barnes_hut_tsne.pyx#L660) causing the gradient to have some non-finite values.",Investigation and Exploration
10109,And then I debugged through the code on both of my environments and the best I could tell was that the divergence happened in C-code.,Investigation and Exploration
10110,Maybe it's somehow related to conda,Investigation and Exploration
10111,The snippet CODE reproduces the error (but it works fine on the nomkl env),Investigation and Exploration
10112,I also saw that the tutorial is deprecated.,Investigation and Exploration
10113,"Sure, the machine that causes this problem: CODE (tested it in a fresh conda environment)",Investigation and Exploration
10114,"I'm not sure that this is quite sufficient to say that there is nothing fundamentally broken in the implementation (e.g. accessing randomly initialised memory), but that:",Investigation and Exploration
10115,it is caused by CODE not loaded!!!,Investigation and Exploration
10116,Or maybe that comment was wrong and I was just confused because your outputisn't complete: the beginning is cut off,Investigation and Exploration
10117,CODE CODE,Investigation and Exploration
10118,"I have find the reason is ldconf,  ldconfig is a dynamic link library management command whose purpose is to allow the dynamic link library to be usedby the system.",Investigation and Exploration
10119,what limitation are you referring to?,Investigation and Exploration
10120,so 9.1 won't cut it..,Investigation and Exploration
10121,"@zhongyuk Hm, I think it's unlikely that it is related.",Investigation and Exploration
10122,*         If this freezes (i.e. it does not finish within one second) that means you are using Accelerate and the freeze is a known limitation with Python multiprocessing.,Investigation and Exploration
10123,"However, I don't think that this is a leak.",Investigation and Exploration
10124,it is caused by CODE not loaded!!!,Investigation and Exploration
10125,"I don't know what they do internally, it's very possible that's the issue.",Investigation and Exploration
10126,"*         it is more susceptible to numerical imprecision than we would like, but perhaps we should (seek contributions that) investigate stability improvements",Investigation and Exploration
10127,"E.g., CODE reproduces the problem on my machine.",Investigation and Exploration
10128,all I can think that has changed (except for reinstalling conda) was rebooting :P,Investigation and Exploration
10129,@jnothman how could we discover? ;),Investigation and Exploration
10130,"After making sure CODE loaded up, the error disappeared in the virtual env with CODE.",Investigation and Exploration
10131,"Here are the results:<img width=""555"" alt=""screen shot 2016-08-16 at 2 24 25 pm"" src=""https://cloud.githubusercontent.com/assets/1669062/17711263/c23cb262-63be-11e6-9aaf-96e9763a00e0.png"">",Investigation and Exploration
10132,"-         What do you mean by ""crashes""?",Investigation and Exploration
10133,Generally multiprocessing in Windows encounters a lot of problems.,Investigation and Exploration
10134,@adverley Could you try the most recent version from GitHub on your Windows box?,Investigation and Exploration
10135,Is theinput to TSNE._tsne identical on both platforms?,Investigation and Exploration
10136,"The pip wheels are using OpenBLAS and you don't have the problem when using OpenBLAS with conda (through the CODE trick) so this does look like a MKL problem, which on top of that is likely CPU-specific.",Investigation and Exploration
10137,"We need a way to reproduce the error, or we will need to skip the tests / lower the condition on certain architectures.",Investigation and Exploration
10138,@Lucidyan I don't understand what you mean by that.,Investigation and Exploration
10139,"If I cancel out the scoring=... line, the parallel execution works.",Investigation and Exploration
10140,"Meanwhile, I will try to see if I can find an old backupstate to find out which conda version I had installed previously.",Investigation and Exploration
10141,Or did anyone experience the bug not using conda?,Investigation and Exploration
10142,"Hm, how would the conda scikit-learn version differ from the pip wheels?",Investigation and Exploration
10143,What would be really great is to continue where @rabst stopped and further isolate the problem:https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-258311980,Investigation and Exploration
10144,"just to eliminate the possibility, could you try usingreturn_train_score=False?",Investigation and Exploration
10145,Can you please provide a little more detail:,Investigation and Exploration
10146,Do you have another system you're comparing against?,Investigation and Exploration
10147,Let's use verbose=100 just to be sure (there are some things reported atverbose=20),Investigation and Exploration
10148,Is the devp sklearn built from source code using OpenBLAS instead of MKL?,Investigation and Exploration
10149,It prints the squared norm of the gradient and the error at each iteration so we can see which part of the code is diverging.,Investigation and Exploration
10150,The snippet CODE reproduces the error (but it works fine on the nomkl env),Investigation and Exploration
10151,@jnothman how could we discover? ;),Investigation and Exploration
10152,-         What version of scikit-learn is this?,Investigation and Exploration
10153,"Hm, how would the conda scikit-learn version differ from the pip wheels?",Investigation and Exploration
10154,Curious why it works for me now :/,Investigation and Exploration
10155,may be it could just be relaxed a little? ;),Investigation and Exploration
10156,@paulaceccon are your Numpy and Scipy installations using ATLAS or OpenBLAS?,Investigation and Exploration
10157,Seems like you're running out of ram.,Investigation and Exploration
10158,i don't remember who and how placed it there but pretty much it overloaded the system default libcudnn.so.7.1.2 !!!,Investigation and Exploration
10159,The different methods and inits produce different trustworthiness scores on all platforms.,Investigation and Exploration
10160,Where can I set verbose=20?,Investigation and Exploration
10161,"More generally, I have noticed wildly different results when using sklearn's TSNE (with identitical perplexity and other parameters) from the bh implementation published by Laurens van der Maaten and the MATLAB version.",Investigation and Exploration
10162,Because the latter seem to work on the same machine.,Investigation and Exploration
10163,"An example document where CODE causes the error, removing that one token everything is fine.",Investigation and Exploration
10164,Just paste it into a Jupyter cell and run it.,Investigation and Exploration
10165,"For the record, can you post the output of this snippet: CODE",Investigation and Exploration
10166,"If it's 0.14, does it still happen in the current development version?",Investigation and Exploration
10167,The first 20:CODE,Investigation and Exploration
10168,Directly doing: CODE is ok in both cases.,Investigation and Exploration
10169,all I can think that has changed (except for reinstalling conda) was rebooting :P,Investigation and Exploration
10170,"if I start to change the constants (increase) with fixed X_SIZE=1750, it fails too.",Investigation and Exploration
10171,"@lesteve I built scikit-learn in two conda virtual environments from source code (branch 0.18 release), the one uses MKL indeed throws the error; the one uses libBLAS does not throw error.",Investigation and Exploration
10172,"I noticed that the gradient in https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L387 explodes, until it becomes CODE in one position after the 25th iteration in the https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L386 for-loop",Investigation and Exploration
10173,"Before I reinstalled miniconda, I also had the problem in macOS Sierra.",Investigation and Exploration
10174,before I spend more time -- is there specific meaning for the threshold to be 0.9?,Investigation and Exploration
10175,i think .9 is somewhat arbitrary but we'd like to be sure that thevariation isn't pointing to something more sinister,Investigation and Exploration
10176,I guess it is not fully deterministic...,Investigation and Exploration
10177,Can you report the lengths of the CODE class in your two benchmark cases?,Investigation and Exploration
10178,"@yarikoptic, I can't find the CODE failure under 0.19.0-1 logs.",Investigation and Exploration
10179,I think it has nothing to do with tensorflow; my guess is that [GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] vs [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] is the culprit!?,Investigation and Exploration
10180,Try this snippet (taken from https://github.com/numpy/numpy/issues/4776):CODE,Investigation and Exploration
10181,"Meanwhile, I will try to see if I can find an old backupstate to find out which conda version I had installed previously.",Investigation and Exploration
10182,i don't remember who and how placed it there but pretty much it overloaded the system default libcudnn.so.7.1.2 !!!,Investigation and Exploration
10183,"Could you put verbose=10 in cross_val_predict, too, so that we can perhapssee where it breaks for you?",Investigation and Exploration
10184,The output running CODE on CODE is here (in case MKL version gives you any clue?) CODE,Investigation and Exploration
10185,This has nothing to do with custom scorers.,Investigation and Exploration
10186,Do you have an old(er) Miniconda/Anaconda 2.7 distro installed?,Investigation and Exploration
10187,This might be a bug in itself.,Investigation and Exploration
10188,"At first errors were still being produced, but after a few shuffles of the corpus to errors to my surprise went away.",Investigation and Exploration
10189,"Might aswell limit n_iter to 250, as we know divergence precedes that.",Investigation and Exploration
10190,"What about the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185, you didn't find a way to make it deterministic and still fail on your machine?",Investigation and Exploration
10191,and it seems to happen only on OSX by the way (i.e. not on my Ubuntu box).,Investigation and Exploration
10192,Or did anyone experience the bug not using conda?,Investigation and Exploration
10193,What is weird though it that the despite the CODE line I get different results for the output of CODE.,Investigation and Exploration
10194,"I also reinstalled spaCy and the German model yesterday, but this din't fix the problem in my case.",Investigation and Exploration
10195,Running CODE indicated that both of them somehow didn't have CODE loaded.,Investigation and Exploration
10196,**update** so the error going away didn't have anything to do with CODE.,Investigation and Exploration
10197,What I took from it is that fork() NOT followed by exec() call is bad.,Investigation and Exploration
10198,The different methods and inits produce different trustworthiness scores on all platforms.,Investigation and Exploration
10199,Ran: CODE,Investigation and Exploration
10200,@lesteve @paulaceccon :I took Paula's excerpt code and made a complete run-able code snippet.,Investigation and Exploration
10201,"Just wanna say that I ran CODE on CODE (I assume this is the t_sne.py compiled file?), it seems like it's indeed using BLAS.",Investigation and Exploration
10202,"That repo looks like it's targeted at tf 1.0, not intermediate releases.",Investigation and Exploration
10203,If you create a conda environment from scratch you should not have this problem.,Investigation and Exploration
10204,"@priidukull, could you please provide the output of: CODE and of:CODE",Investigation and Exploration
10205,Let's use verbose=100 just to be sure (there are some things reported atverbose=20),Investigation and Exploration
10206,The root of the problem is that a number of spaCy classes carry large binary data structures.,Investigation and Exploration
10207,Let's use verbose=100 just to be sure (there are some things reported atverbose=20),Investigation and Exploration
10208,"Just wanna say that I ran CODE on CODE (I assume this is the t_sne.py compiled file?), it seems like it's indeed using BLAS.",Investigation and Exploration
10209,"However if you take the document that produces the error, pass it through CODE and then call CODE again, it works.",Investigation and Exploration
10210,"This snippet crashes because of scoring=metrics.make_scorer(metrics.scorer.f1_score, average=""macro"") where metrics refers to sklearn.metrics module.",Investigation and Exploration
10211,CODE,Investigation and Exploration
10212,"@KaisJM by the way, this page is out-of-date, since nowadays wheels are available on Linux and contain their own OpenBLAS.",Investigation and Exploration
10213,Do you think it could be related to some issue in the old conda?,Investigation and Exploration
10214,Nothing is being printed... ![screen shot 2017-08-08 at 16 43 35] URL ,Investigation and Exploration
10215,Would be great if you can take a look and post a version of it that freezes.,Investigation and Exploration
10216,@jnothman how could we discover? ;),Investigation and Exploration
10217,Not sure if this was an issue with my string or with spaCy's processing.,Investigation and Exploration
10218,"Can you point to some more information, more detail about what the problem is?",Investigation and Exploration
10219,Generally multiprocessing in Windows encounters a lot of problems.,Investigation and Exploration
10220,I don't want to upgrade OS yet b/z I thought I read somewhere that TensorFlow doesn't support Sierra yet (could be mistaken or no longer be true anymore since I don't remember where or how long ago I read it)?,Investigation and Exploration
10221,Will switch it to ATLAS and see what happens.,Investigation and Exploration
10222,The highest likelihood is that OpenBLAS is causing the fees they are talking about in that page.,Investigation and Exploration
10223,"I will try the one from sklearn.model_selection, but something tells me I will have the same exact issue).",Investigation and Exploration
10224,Which appears to be a mismatch between 9.0 (TF wants) vs 9.1 Which is most current Nvidia.,Investigation and Exploration
10225,As the commit message says:,Investigation and Exploration
10226,"Certainly, for strings that occur once, there's no advantage.",Investigation and Exploration
10227,Let's use verbose=100 just to be sure (there are some things reported atverbose=20),Investigation and Exploration
10228,Perhaps comparing outputs at verbose=20 will be more informative.,Investigation and Exploration
10229,"Hm, interesting, so it's not a conda issue after all then ...",Investigation and Exploration
10230,Could you please check it out and re-run the same code?,Investigation and Exploration
10231,"This inherently is mismatch on linux systems whenever that number changes, so since it can not find the exact matches then it thinks the file doesn't exist and throws the error.",Investigation and Exploration
10232,CODE,Investigation and Exploration
10233,So the error is reducing much more slowly...,Investigation and Exploration
10234,I think the tutorial is deprecated since it uses a seq2seq model with bucketing in contrast to a dynamic seq2seq.,Investigation and Exploration
10235,Could you please check it out and re-run the same code?,Investigation and Exploration
10236,"@priidukull, What did you mean by telling that the divergence happened in C code?",Investigation and Exploration
10237,"Sorry, missed it - pip.",Investigation and Exploration
10238,I remember that I reininstalled miniconda the other week due to some other problems.,Investigation and Exploration
10239,"There's currently no Python API for inspecting the size of the tokenizer's cache, so it's easiest to do this by elimination.",Investigation and Exploration
10240,These instructions are outdated believe me.,Investigation and Exploration
10241,"I thought the current OneHotEncoder would have categories [0, 1, 2, 3, 4, 5] (while current CategoricalEncoder would have categories [2, 3, 5]).",Investigation and Exploration
10242,It's using MKL as well.,Investigation and Exploration
10243,"We therefore store the string, causing the memory growth.",Investigation and Exploration
10244,what limitation are you referring to?,Investigation and Exploration
10245,"Something may have happened because of the Spyder install, but then why would it work for a day and then suddenly stop??",Investigation and Exploration
10246,"I just created a new conda virtualenv and built a devp version of sklearn from the source code freshly forked from the sciki-learn master branch, the error disappeared.",Investigation and Exploration
10247,The issue is arising because the entity recogniser's push-down automaton finds itself in a state with no continuations.,Investigation and Exploration
10248,Just want to add a quick update: I had 2 virtual envs in conda both using MKL.,Investigation and Exploration
10249,As the commit message says:,Investigation and Exploration
10250,"That repo looks like it's targeted at tf 1.0, not intermediate releases.",Investigation and Exploration
10251,"After upgrading CODE to 1.11.2, I can no longer reproduce the error in either conda virtual environment.",Investigation and Exploration
10252,@ebrevdo  It's [this ] URL  tutorial.,Investigation and Exploration
10253,"could you try using conda packages without mkl, i.e. something like CODE so we can see whether that is a MKL vs openblas thing?",Investigation and Exploration
10254,The root of the problem is that a number of spaCy classes carry large binary data structures.,Investigation and Exploration
10255,Or did anyone experience the bug not using conda?,Investigation and Exploration
10256,"3.         The CODE, for tokens that are part of CODE, CODE and CODE patterns.",Investigation and Exploration
10257,what is crf?,Investigation and Exploration
10258,Here is the code I used to create the metrics.,Investigation and Exploration
10259,"Before I reinstalled miniconda, I also had the problem in macOS Sierra.",Investigation and Exploration
10260,"As above, if I use nlp(text) everything is fine.",Investigation and Exploration
10261,"That seems to indicate, that this problem happens in some very specific combination of factors.",Investigation and Exploration
10262,This might have something to do with state between the documents (don't know what if any is kept).,Investigation and Exploration
10263,I've just realised we have a higher level of verbosity available to us.,Investigation and Exploration
10264,"@zhongyuk Hm, I think it's unlikely that it is related.",Investigation and Exploration
10265,If you create a conda environment from scratch you should not have this problem.,Investigation and Exploration
10266,"After upgrading CODE to 1.11.2, I can no longer reproduce the error in either conda virtual environment.",Investigation and Exploration
10267,"I boiled it down to single words, while german words work, english words like 'windows' don't work.",Investigation and Exploration
10268,http://scikit-learn.org/stable/faq.html#why-do-i-sometime-get-a-crash-freeze-with-n-jobs-1-under-osx-or-linux for more details.,Investigation and Exploration
10269,**update** so the error going away didn't have anything to do with CODE.,Investigation and Exploration
10270,"Could you put verbose=10 in cross_val_predict, too, so that we can perhapssee where it breaks for you?",Investigation and Exploration
10271,"@rasbt hmm, that's good to know that TF works fine on Sierra.",Investigation and Exploration
10272,Try this snippet (taken from https://github.com/numpy/numpy/issues/4776):CODE,Investigation and Exploration
10273,"
REFERENCE",Investigation and Exploration
10274,Try to run it multiple times just in case because the random seed is not set properly and there may be some randomness left in the snippet.,Investigation and Exploration
10275,"After making sure CODE loaded up, the error disappeared in the virtual env with CODE.",Investigation and Exploration
10276,CODE,Investigation and Exploration
10277,"*         If it does not freeze then you are not using Accelerate, and we would need a stand-alone snippet to investigate.",Investigation and Exploration
10278,What I've done is to reduce the size of X... with something like:,Investigation and Exploration
10279,I know sklearn.grid_search is depricated..,Investigation and Exploration
10280,Output: https://gist.github.com/priidukull/1453adb7cf2bca2093b2dd9d6646f64e,Investigation and Exploration
10281,[output.txt.zip] URL ,Investigation and Exploration
10282,Curious why it works for me now :/,Investigation and Exploration
10283,Or did anyone experience the bug not using conda?,Investigation and Exploration
10284,I am getting the following on CODE: CODE,Investigation and Exploration
10285,**update** so the error going away didn't have anything to do with CODE.,Investigation and Exploration
10286,"I also reinstalled spaCy and the German model yesterday, but this din't fix the problem in my case.",Investigation and Exploration
10287,"@lesteve I built scikit-learn in two conda virtual environments from source code (branch 0.18 release), the one uses MKL indeed throws the error; the one uses libBLAS does not throw error.",Investigation and Exploration
10288,It prints the squared norm of the gradient and the error at each iteration so we can see which part of the code is diverging.,Investigation and Exploration
10289,"An example document where CODE causes the error, removing that one token everything is fine.",Investigation and Exploration
10290,And it's also bad to have unbounded memory use on the streaming process.,Investigation and Exploration
10291,"In any case, this is a known problem with Accelerate and Python multiprocessing.",Investigation and Exploration
10292,"Now, this is an integer representation --- so why not just use the hash?",Investigation and Exploration
10293,"Also how did you install scikit-learn, with pip, with conda, with one of the OSX package managers (brew, etc ...) ?",Investigation and Exploration
10294,"However, both CODE and CODE seem to be float 64 arrays ...",Investigation and Exploration
10295,"An example document where CODE causes the error, removing that one token everything is fine.",Investigation and Exploration
10296,"What about the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185, you didn't find a way to make it deterministic and still fail on your machine?",Investigation and Exploration
10297,@lesteve @paulaceccon :I took Paula's excerpt code and made a complete run-able code snippet.,Investigation and Exploration
10298,@jnothman I am guessing that your conda environment uses MKL and not Accelerate.,Investigation and Exploration
10299,[output2.txt.zip] URL ,Investigation and Exploration
10300,"In order to preserve these entities, we restrict the actions of the entity recogniser, so that it can't over-write the previous ones.",Investigation and Exploration
10301,The only way I managed to reproduce this problem was to install numpy with both pip and conda in the same conda environment.,Investigation and Exploration
10302,Setting CODE on Linux doesn't solve the issue for me.,Investigation and Exploration
10303,*         the test is brittle and already provides only weak assurances in asserting t > 0.9,Investigation and Exploration
10304,"On the original machine, the exact method + PCA init was triggering the instability according to: https://github.com/scikit-learn/scikit-learn/issues/9393#issuecomment-322214890",Investigation and Exploration
10305,If you create a conda environment from scratch you should not have this problem.,Investigation and Exploration
10306,"i hit the same problem and was scratching my head for two days, until finally i discovered that local copy of libcudnn.so was used by conda, under:/miniconda3/lib/libcudnn.so which pointed to libcudnn.so.7 which pointed to libcudnn.so.7.0.5",Investigation and Exploration
10307,"If I cancel out the scoring=... line, the parallel execution works.",Investigation and Exploration
10308,Importing the scorer also didn't help in my case.,Investigation and Exploration
10309,"Curious thing, If you add a comma like this: CODE the error goes away.",Investigation and Exploration
10310,"Here are the results:<img width=""555"" alt=""screen shot 2016-08-16 at 2 24 25 pm"" src=""https://cloud.githubusercontent.com/assets/1669062/17711263/c23cb262-63be-11e6-9aaf-96e9763a00e0.png"">",Investigation and Exploration
10311,Nothing is being printed... ![screen shot 2017-08-08 at 16 43 35] URL ,Investigation and Exploration
10312,**update** so the error going away didn't have anything to do with CODE.,Investigation and Exploration
10313,What would be really great is to continue where @rabst stopped and further isolate the problem:https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-258311980,Investigation and Exploration
10314,"Here are the results:<img width=""555"" alt=""screen shot 2016-08-16 at 2 24 25 pm"" src=""https://cloud.githubusercontent.com/assets/1669062/17711263/c23cb262-63be-11e6-9aaf-96e9763a00e0.png"">",Investigation and Exploration
10315,"@zhongyuk Hm, I think it's unlikely that it is related.",Investigation and Exploration
10316,"I thought the current OneHotEncoder would have categories [0, 1, 2, 3, 4, 5] (while current CategoricalEncoder would have categories [2, 3, 5]).",Investigation and Exploration
10317,"The default ldconf only search /lib and /usr/lib, as well as the library file under the directory listed in the configuration file /etc/ld. so. conf.",Investigation and Exploration
10318,"At first errors were still being produced, but after a few shuffles of the corpus to errors to my surprise went away.",Investigation and Exploration
10319,"That's very small differences for float32 data, and a large range in exponent from min to max.",Investigation and Exploration
10320,Generally multiprocessing in Windows encounters a lot of problems.,Investigation and Exploration
10321,"Hum, that is likely related to issues of multiprocessing on windows.",Investigation and Exploration
10322,Maybe there's sth funny going on in CODE.,Investigation and Exploration
10323,Setting CODE on Linux doesn't solve the issue for me.,Investigation and Exploration
10324,But I could not tell where exactly with full certainty because it is tough to debug.,Investigation and Exploration
10325,CODE CODE,Investigation and Exploration
10326,This is because the same cell definition is used both for encoder and decoder.,Investigation and Exploration
10327,[output2.txt.zip] URL ,Investigation and Exploration
10328,"The custom scorer object was a mistake of me, the problem lies indeed in the multiprocessing on windows.",Investigation and Exploration
10329,"This inherently is mismatch on linux systems whenever that number changes, so since it can not find the exact matches then it thinks the file doesn't exist and throws the error.",Investigation and Exploration
10330,CODE,Investigation and Exploration
10331,Is it possible that caused the problem?,Investigation and Exploration
10332,"Actually, multiplying the data by 100 does not make the algorithm more stable with the PCA init, quite the opposite actually.",Investigation and Exploration
10333,CODE,Investigation and Exploration
10334,Directly doing: CODE is ok in both cases.,Investigation and Exploration
10335,"*         If it does not freeze then you are not using Accelerate, and we would need a stand-alone snippet to investigate.",Investigation and Exploration
10336,or zip it,Investigation and Exploration
10337,"Just wanna say that I ran CODE on CODE (I assume this is the t_sne.py compiled file?), it seems like it's indeed using BLAS.",Investigation and Exploration
10338,Do you wanna run CODE on the CODE file in your platform to see which math library sklearn using underneath?,Investigation and Exploration
10339,Can you report the lengths of the CODE class in your two benchmark cases?,Investigation and Exploration
10340,I guess it is not fully deterministic...,Investigation and Exploration
10341,"The cells passed here are used for both the backward and forward phase of the legacy seq2seq model, which throws an error because of same cells being used with different scopes.",Investigation and Exploration
10342,The root of the problem is that a number of spaCy classes carry large binary data structures.,Investigation and Exploration
10343,One thing that stands out to me is in the referenced legacy seq2seq file: CODE,Investigation and Exploration
10344,I think the problem is that numpy is using OpenBlas.,Investigation and Exploration
10345,Can you report the lengths of the CODE class in your two benchmark cases?,Investigation and Exploration
10346,Notice that n_jobs=-1 and runs fine.,Investigation and Exploration
10347,"I then tried to break it down to a specific sentence, but even after having removed this and succesively the follwoing sentences from my texts, the problem remained the same.",Investigation and Exploration
10348,You may need to run it multiple times because unfortunately the seed is not set appropriately (you need to use CODE rather than CODE).,Investigation and Exploration
10349,"I think scikit learn is part of anaconda, but I did upgrade with pip (pip install --upgrade sklearn), but thats before I got this problem..",Investigation and Exploration
10350,"However, I don't think that this is a leak.",Investigation and Exploration
10351,"@lesteve I built scikit-learn in two conda virtual environments from source code (branch 0.18 release), the one uses MKL indeed throws the error; the one uses libBLAS does not throw error.",Investigation and Exploration
10352,"I will try the one from sklearn.model_selection, but something tells me I will have the same exact issue).",Investigation and Exploration
10353,"Just wanna say that I ran CODE on CODE (I assume this is the t_sne.py compiled file?), it seems like it's indeed using BLAS.",Investigation and Exploration
10354,Running GridSearchCV or RandomizedSearchCV in a loop and  n_jobs > 1 would hang silently in Jupiter & IntelliJ: CODE,Investigation and Exploration
10355,why intern the strings?,Investigation and Exploration
10356,Running CODE indicated that both of them somehow didn't have CODE loaded.,Investigation and Exploration
10357,My code and results are available here: https://github.com/ELind77/spacy_memory_growth,Investigation and Exploration
10358,And it's also bad to have unbounded memory use on the streaming process.,Investigation and Exploration
10359,CODE CODE,Investigation and Exploration
10360,Do you have any more information on this issue since it cropped up a few months ago?,Investigation and Exploration
10361,The only difference is to the output above it is running on an older kernel (CODE).,Investigation and Exploration
10362,it is caused by CODE not loaded!!!,Investigation and Exploration
10363,[output2.txt.zip] URL ,Investigation and Exploration
10364,what limitation are you referring to?,Investigation and Exploration
10365,"If you have old version of CUDA, the library link may point to the old library even you install the newer CUDA especially if you install it manually.",Investigation and Exploration
10366,Here is the output for the first 100 iterations (it is still too big for the gist)[output.text] URL ,Investigation and Exploration
10367,Can you report the lengths of the CODE class in your two benchmark cases?,Investigation and Exploration
10368,Do you wanna run CODE on the CODE file in your platform to see which math library sklearn using underneath?,Investigation and Exploration
10369,The output running CODE on CODE is here (in case MKL version gives you any clue?) CODE,Investigation and Exploration
10370,Actually @Ekliptor can reproduce the issue with python 3.5.1 from conda so it's probably not related to the version of Python either.,Investigation and Exploration
10371,Otherwise everything should be the same.,Investigation and Exploration
10372,Will switch it to ATLAS and see what happens.,Investigation and Exploration
10373,it is caused by CODE not loaded!!!,Investigation and Exploration
10374,"Notice that you can switch between grid_search module and model_selection module, both ran fine for me.",Investigation and Exploration
10375,"I boiled it down to single words, while german words work, english words like 'windows' don't work.",Investigation and Exploration
10376,"I'm not sure that this is quite sufficient to say that there is nothing fundamentally broken in the implementation (e.g. accessing randomly initialised memory), but that:",Investigation and Exploration
10377,Another (more time-intensive) way to debug this problem would be to track down where the NaNs appear in the code.,Investigation and Exploration
10378,it is caused by CODE not loaded!!!,Investigation and Exploration
10379,The only difference is to the output above it is running on an older kernel (CODE).,Investigation and Exploration
10380,"On the other machine (the one that works fine), the gradients are all < 0 after the same iteration.",Investigation and Exploration
10381,I think the problem is that numpy is using OpenBlas.,Investigation and Exploration
10382,How did you install scikit-learn?,Investigation and Exploration
10383,"Now, I think I have good news in some way: I just wanted to rerun the above example that previously caused this issue to confirm CODE and I am no longer getting this problem.",Investigation and Exploration
10384,This has nothing to do with custom scorers.,Investigation and Exploration
10385,"However, when I replace CODE by CODE it seems to be fine.",Investigation and Exploration
10386,Not that that's easy to do without at least a VM of the target machine.,Investigation and Exploration
10387,"What about the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185, you didn't find a way to make it deterministic and still fail on your machine?",Investigation and Exploration
10388,"It shouldn't, and that could maybe cause problems (though I think joblib should detect that).",Investigation and Exploration
10389,It might be a bug somewhere in MultiRNNCell.,Investigation and Exploration
10390,i don't remember who and how placed it there but pretty much it overloaded the system default libcudnn.so.7.1.2 !!!,Investigation and Exploration
10391,Just paste it into a Jupyter cell and run it.,Investigation and Exploration
10392,I would wild guess that by updating scikit-learn with pip you updated numpy with pip too and you got the numpy wheels which uses Accelerate and has the limitation mentioned above.,Investigation and Exploration
10393,I think the tutorial is deprecated since it uses a seq2seq model with bucketing in contrast to a dynamic seq2seq.,Investigation and Exploration
10394,There'snothing about the average=macro option in 0.14 that suggests it should bemore likely to hang than the default average (weighted).,Investigation and Exploration
10395,"@rasbt hmm, that's good to know that TF works fine on Sierra.",Investigation and Exploration
10396,I don't want to upgrade OS yet b/z I thought I read somewhere that TensorFlow doesn't support Sierra yet (could be mistaken or no longer be true anymore since I don't remember where or how long ago I read it)?,Investigation and Exploration
10397,"Now, this is an integer representation --- so why not just use the hash?",Investigation and Exploration
10398,"Suppose you have one feature with values [2, 3, 5, 2].",Investigation and Exploration
10399,"not sure if this is really the reason, but I think CODE may be an issue; since the error doesn't seem to occur via CODE",Investigation and Exploration
10400,Try this snippet (taken from https://github.com/numpy/numpy/issues/4776):CODE,Investigation and Exploration
10401,The snippet CODE reproduces the error (but it works fine on the nomkl env),Investigation and Exploration
10402,@Lucidyan I don't understand what you mean by that.,Investigation and Exploration
10403,1.         The CODE,Investigation and Exploration
10404,"Could you put verbose=10 in cross_val_predict, too, so that we can perhapssee where it breaks for you?",Investigation and Exploration
10405,Do you have this issue with the tf nightlies?,Investigation and Exploration
10406,"However, both CODE and CODE seem to be float 64 arrays ...",Investigation and Exploration
10407,"@tommoral, if we continue to not be able to reproduce this bug, what kind of debugging output do you think would help us understand what's going wrong?",Investigation and Exploration
10408,If you create a conda environment from scratch you should not have this problem.,Investigation and Exploration
10409,"I think scikit learn is part of anaconda, but I did upgrade with pip (pip install --upgrade sklearn), but thats before I got this problem..",Investigation and Exploration
10410,"If you are all using compiled version on master branch, I believe that we are the same issue caused by the [recent commit] URL .",Investigation and Exploration
10411,I know sklearn.grid_search is depricated..,Investigation and Exploration
10412,Here is the output for the first 100 iterations (it is still too big for the gist)[output.text] URL ,Investigation and Exploration
10413,CODE CODE,Investigation and Exploration
10414,# Code: CODE,Investigation and Exploration
10415,There'snothing about the average=macro option in 0.14 that suggests it should bemore likely to hang than the default average (weighted).,Investigation and Exploration
10416,"just to eliminate the possibility, could you try usingreturn_train_score=False?",Investigation and Exploration
10417,Do you think it could be related to some issue in the old conda?,Investigation and Exploration
10418,One of them is equipped with CODE and the other is equipped with CODE.,Investigation and Exploration
10419,"If it's 0.14, does it still happen in the current development version?",Investigation and Exploration
10420,@adverley Could you try the most recent version from GitHub on your Windows box?,Investigation and Exploration
10421,One thing that stands out to me is in the referenced legacy seq2seq file: CODE,Investigation and Exploration
10422,"But you are right that the CODE is also only [2, 3, 5], essentially making them the same with the default value of CODE.",Investigation and Exploration
10423,"3.         The CODE, for tokens that are part of CODE, CODE and CODE patterns.",Investigation and Exploration
10424,CODE,Investigation and Exploration
10425,"After upgrading CODE to 1.11.2, I can no longer reproduce the error in either conda virtual environment.",Investigation and Exploration
10426,@pbnsilva can you try this snippet posted below ?,Investigation and Exploration
10427,Try this snippet (taken from https://github.com/numpy/numpy/issues/4776):CODE,Investigation and Exploration
10428,The only difference is to the output above it is running on an older kernel (CODE).,Investigation and Exploration
10429,Notice that n_jobs=-1 and runs fine.,Investigation and Exploration
10430,This might be a bug in itself.,Investigation and Exploration
10431,I think the tutorial is deprecated since it uses a seq2seq model with bucketing in contrast to a dynamic seq2seq.,Investigation and Exploration
10432,"So you can see from the third line, that it is using MKL.",Investigation and Exploration
10433,I checked a recent numpy wheel and it contains OpenBLAS 0.2.8.18.,Investigation and Exploration
10434,CODE,Investigation and Exploration
10435,one environment my Mac desktop and another one that I had set up with docker running on my Mac.,Investigation and Exploration
10436,And it's also bad to have unbounded memory use on the streaming process.,Investigation and Exploration
10437,"
REFERENCE",Investigation and Exploration
10438,"Sorry, missed it - pip.",Investigation and Exploration
10439,"E.g., CODE reproduces the problem on my machine.",Investigation and Exploration
10440,"PS: Tensorflow works fine for me on Sierra, but I only do CPU and prototyping on my macs so I don't know about GPU issues related to Sierra",Investigation and Exploration
10441,Output: https://gist.github.com/priidukull/1453adb7cf2bca2093b2dd9d6646f64e,Investigation and Exploration
10442,@jnothman : I am using RandomizedSearchCV from sklearn.grid_search which does not have the return_train_score parameter.,Investigation and Exploration
10443,@ebrevdo  It's [this ] URL  tutorial.,Investigation and Exploration
10444,"@zhongyuk Hm, I think it's unlikely that it is related.",Investigation and Exploration
10445,Up until now the snippet we have is non-deterministic (CODE is used and has no influence of numpy.random seed).,Investigation and Exploration
10446,It seems that reinstalling packages with conda may help but I am afraid there doesn't seem to be a very clear picture of the cause of the problem :(.,Investigation and Exploration
10447,CODE,Investigation and Exploration
10448,"After making sure CODE loaded up, the error disappeared in the virtual env with CODE.",Investigation and Exploration
10449,Test code: CODE,Investigation and Exploration
10450,I would wild guess that by updating scikit-learn with pip you updated numpy with pip too and you got the numpy wheels which uses Accelerate and has the limitation mentioned above.,Investigation and Exploration
10451,"Also, just for the sake of sanity, can you make sure you can reproduce the problem in a fresh conda environment.",Investigation and Exploration
10452,Although I haven't tried to create an virtualenv with MKL and CODE to see if this would reproduce the error.,Investigation and Exploration
10453,so 9.1 won't cut it..,Investigation and Exploration
10454,And the one which threw error seems to use MKL..,Investigation and Exploration
10455,"At the developmenthead, this completes in 11s on my macbook, and in 7s at version 0.14(that's something to look into!)",Investigation and Exploration
10456,I don't want to upgrade OS yet b/z I thought I read somewhere that TensorFlow doesn't support Sierra yet (could be mistaken or no longer be true anymore since I don't remember where or how long ago I read it)?,Investigation and Exploration
10457,I've just realised we have a higher level of verbosity available to us.,Investigation and Exploration
10458,"If one of you can reproduce the problem, please try to find a numpy random seed that trigger the issue (using CODE instead of CODE in the above snippet) and communicate the value here (along with the version of OSX and you python packages).",Investigation and Exploration
10459,"not sure if this is really the reason, but I think CODE may be an issue; since the error doesn't seem to occur via CODE",Investigation and Exploration
10460,I noticed that in my platform CODE is not loaded...,Investigation and Exploration
10461,"Now, I think I have good news in some way: I just wanted to rerun the above example that previously caused this issue to confirm CODE and I am no longer getting this problem.",Investigation and Exploration
10462,Otherwise everything should be the same.,Investigation and Exploration
10463,Curious why it works for me now :/,Investigation and Exploration
10464,The output running CODE on CODE is here (in case MKL version gives you any clue?) CODE,Investigation and Exploration
10465,"There's currently no Python API for inspecting the size of the tokenizer's cache, so it's easiest to do this by elimination.",Investigation and Exploration
10466,"Something may have happened because of the Spyder install, but then why would it work for a day and then suddenly stop??",Investigation and Exploration
10467,"As I said in my original post, I think that this is just part of how spacy works.",Investigation and Exploration
10468,Paula: I could not get this snippet to freeze.,Investigation and Exploration
10469,1.         The CODE,Investigation and Exploration
10470,Does your scorer use joblib / n_jobs anywhere?,Investigation and Exploration
10471,"We can't do without 1 entirely â it's too fundamental to how spaCy is working, and we definitely don't want to be making lots of string comparisons.",Investigation and Exploration
10472,"In order to preserve these entities, we restrict the actions of the entity recogniser, so that it can't over-write the previous ones.",Investigation and Exploration
10473,# Code: CODE,Investigation and Exploration
10474,"Something may have happened because of the Spyder install, but then why would it work for a day and then suddenly stop??",Investigation and Exploration
10475,"Hum, that is likely related to issues of multiprocessing on windows.",Investigation and Exploration
10476,[output2.txt.zip] URL ,Investigation and Exploration
10477,"E.g., CODE reproduces the problem on my machine.",Investigation and Exploration
10478,"If I cancel out the scoring=... line, the parallel execution works.",Investigation and Exploration
10479,Just paste it into a Jupyter cell and run it.,Investigation and Exploration
10480,"Can you point to some more information, more detail about what the problem is?",Investigation and Exploration
10481,CODE,Investigation and Exploration
10482,Maybe it depends on the minor version of OSX.,Investigation and Exploration
10483,I think the problem is that numpy is using OpenBlas.,Investigation and Exploration
10484,This is a [well-known feature](http://docs.python.org/2/library/multiprocessing.html#windows) of Python multiprocessing on Windows: you have to run everything that uses CODE in an CODE block or you'll get freezes/crashes.,Investigation and Exploration
10485,here's the output of the above prints: CODE,Investigation and Exploration
10486,"What about the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185, you didn't find a way to make it deterministic and still fail on your machine?",Investigation and Exploration
10487,"That repo looks like it's targeted at tf 1.0, not intermediate releases.",Investigation and Exploration
10488,"There's apparently a bug in the logic to introduce this constraint, that's leaving the automaton with no available actions.",Investigation and Exploration
10489,"@yarikoptic, I can't find the CODE failure under 0.19.0-1 logs.",Investigation and Exploration
10490,There'snothing about the average=macro option in 0.14 that suggests it should bemore likely to hang than the default average (weighted).,Investigation and Exploration
10491,"I tried it, and it fails with X_SIZE <= 1750 (Y_SIZE=20, n_components=2 became constants).",Investigation and Exploration
10492,"@priidukull, could you please provide the output of: CODE and of:CODE",Investigation and Exploration
10493,"I think scikit learn is part of anaconda, but I did upgrade with pip (pip install --upgrade sklearn), but thats before I got this problem..",Investigation and Exploration
10494,"At the developmenthead, this completes in 11s on my macbook, and in 7s at version 0.14(that's something to look into!)",Investigation and Exploration
10495,It's our most upvoted issue.,Motivation
10496,This results in garbage results and/orCUDA_ERROR_ILLEGAL_ADDRESS failures.,Motivation
10497,"I'd like to understand more about your use case, though.",Motivation
10498,This makes spaCy much more useable for including in our docker environment where we literally have 100s of these containers running in parallel and memory is wasted for each instance.,Motivation
10499,These are the features I really missed from a private system I've been using.,Motivation
10500,"It's relatively straightforward for us to, in Python, generate a new draw from our original data set for every epoch, but it seems like in the API proposed above, we'd have to figure out how to implement this behavior as an CODE, which seems less straightforward.",Motivation
10501,Our biggest issue with the current data loading scheme is just that it's very complicated and involves a lot of new concepts.,Motivation
10502,The use case is when you want to combine several estimators together.,Motivation
10503,"It is natural for average-like ensembles, but makes no sense in boosted ensembles.",Motivation
10504,"Problematic was that the program just stopped and waited for some process to begin filling the queue, but there was non, so it just did nothing, but also didn't throw an exception or give any kind of warning, which made understanding what was happening a bit difficult.",Motivation
10505,"Now when I switched from a normal Session to using MonitoredSession and added a logging hook and told it to log the 'accuracy' tensor, it tried in vain to evaluate the first session run call as the hook had added that tensor to the fetch list, but with the queue being still empty there was no way to evaluate accuracy yet.",Motivation
10506,Our biggest issue with the current data loading scheme is just that it's very complicated and involves a lot of new concepts.,Motivation
10507,A collection of train/valid/test data or simply a collection of data?,Motivation
10508,"Until the fix is available, the only workaround is todowngrade to CUDA 8.0.xor disable XLA:GPU.",Motivation
10509,That is one of my biggest issues with the current API.,Motivation
10510,"That implements predicting with a subset of the estimators, which is also very helpful.",Motivation
10511,*         See #7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.,Motivation
10512,"In fact for these kinds of higher-level abstractions, sooner seems better than later â one of the greatest frustrations of reading published TF research code is that the vast majority of codebases use their own idiosyncratic layers library, as opposed to e.g. the ones in CODE or CODE, and these libraries are all different, which makes it more difficult than it should be to share work.",Motivation
10513,This doesn't seem to be supported?,Motivation
10514,@jnothman I suppose you acknowledge there *can* be a difference in practice?,Motivation
10515,"Assume there is a large training data set which is in text format, and we need to convert it into tfrecord format.",Motivation
10516,directory?,Motivation
10517,"Google developers implemented a small portion of Tensorflow in Javascript in their [playground] URL , the neural network implementation is [here] URL  and does include [back propagation](https://github.com/tensorflow/playground/blob/master/src/nn.ts#L282).",Motivation
10518,"We primarily deal with time series data, and prefer to not have to batch preprocess the whole dataset prior to training every unique model input architecture.",Motivation
10519,"If I could create some sort of input method (Queue, Dataset, whatever) where I can cleanly swap between training and validation inputs, that would be much nicer (again, CODE is great for this, but if it will always be slower, it'd be nice to have a more performant alternative).",Motivation
10520,We've noticed that one of the biggest challenges in getting started with TensorFlow is how to load your own data into your programs.,Motivation
10521,I'm also interested in nodejs tensorflow API   to be able to use it in a node-red flows that would chain tensorflows graphs and may be other kinds of data analysis nodes.,Motivation
10522,"2.         An easy and established way to change the input pipeline of a graph, after it has been created, because it is the most typical usage pattern.",Motivation
10523,-         One of our models is a localization model.,Motivation
10524,It's close integration with Spark will be a great advantage for many researchers.,Motivation
10525,I'm still not sure what you're suggesting is the practical difference due to inferring categories from the max value.,Motivation
10526,http://pytorch.org/docs/data.html,Motivation
10527,"And what is a ""dataset"", anyway?",Motivation
10528,(the output you get depending on the data you have),Motivation
10529,I'm trying to do some work on the text from Wiki Dump.,Motivation
10530,"The Python threading API isn't perfect, but in general when we're doing mostly non-GIL-taking tasks in NumPy or whatever, the TF queue API seems more of a burden than a help.",Motivation
10531,The CODE class described in the original post already exists in Python: it is a list of tuples.,Motivation
10532,2.         (theoretically) doesn't require an extra python thread in the training process.,Motivation
10533,What would be your use cases ?,Motivation
10534,"This is necessary for most of the applications at OpenAI, here's one example -- https://github.com/openai/universe-starter-agent",Motivation
10535,"I'd like to understand more about your use case, though.",Motivation
10536,@pprett I think there should be an easy way to do easy things.,Motivation
10537,"@mrry One ""data set"" can be composed of anything between ~500-30,000 dynamically generated samples.",Motivation
10538,This concept is inspired by [dask distributed] URL  and other executor frameworks -- I think the flexibility offered by this abstraction is great!,Motivation
10539,"It's relatively straightforward for us to, in Python, generate a new draw from our original data set for every epoch, but it seems like in the API proposed above, we'd have to figure out how to implement this behavior as an CODE, which seems less straightforward.",Motivation
10540,"Currently it is certainly still OK, there are not too many incompatible options (but also partly because I moved CODE into the CODE option).",Motivation
10541,However they could all share this binding in common.,Motivation
10542,The use case is when you want to combine several estimators together.,Motivation
10543,"Then, CODE is created by (randomly) iterating over each element CODE of CODE, and for each of these elements the function CODE samples a (variable) number of sub-images [and sub-labels] (e.g. 256x256 each) from CODE, taken from various regions of CODE.",Motivation
10544,"I notice TensorFlow is now accessible from Go, Rust and Haskell.",Motivation
10545,"Apache Spark ships with a package called [cloudpickle] URL  which is meant to support a wider set of Python constructs, but serialisation with cloudpickle also fails resulting in a segmentation fault: CODE",Motivation
10546,There are clear problems with queues like you said.,Motivation
10547,It may not be the right place to ask but I'd like to know why others developers look for a nodejs api/add-on for tensorflow ?,Motivation
10548,There is something slightly similar in the adaboost pr: #522.,Motivation
10549,A fix in CUDA 9.1.121 is expected in late February 2018.,Motivation
10550,Currently using spacy to get the POS tags. (from sentence subtree etc),Motivation
10551,"We use scikit-image CODE objects to apply cropping and resizing operations for this model, because those objects let us easily translate our model output back to the original input coordinate space.",Motivation
10552,It may not be the right place to ask but I'd like to know why others developers look for a nodejs api/add-on for tensorflow ?,Motivation
10553,"I also had issues with pickling with [SFrame] URL , which behaves similarly to how Spark has been described to work here.",Motivation
10554,The input pipeline is definitely thesteepest part of the learning curve.,Motivation
10555,generator?,Motivation
10556,"Something that provides similar functionality as the generator feed function in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/inputs/queues/feeding_functions.py  (but it would be cool if the source of the data could be from an arbitrary source, maybe using a kind of publisher/subscriber model?)",Motivation
10557,its implementation converting coo to csr is alsoweird.,Motivation
10558,Many of the things said already resonate with my experience.,Motivation
10559,"Not ideal, but also not a big deal imho.",Motivation
10560,"This is necessary for most of the applications at OpenAI, here's one example -- https://github.com/openai/universe-starter-agent",Motivation
10561,Many non-experts are using the following code http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow?answertab=votes#tab-top.,Motivation
10562,"We use scikit-image CODE objects to apply cropping and resizing operations for this model, because those objects let us easily translate our model output back to the original input coordinate space.",Motivation
10563,"When using CODE, this is very simple, and this is what I'm used to.",Motivation
10564,CODE supports SparseTensor and automatic batching of SparseTensor would make my life a whole lot easier,Motivation
10565,"-         We want to add more encoding options (eg binary encoding, mean target encoding, unary encoding, ...).",Motivation
10566,"The most similar words to CODE might be things like CODE, while the most similar words to CODE might be CODE or CODE.",Motivation
10567,I'm trying to do some work on the text from Wiki Dump.,Motivation
10568,I'm just wondering about what things users will come up with (w.r.t. data generation and usage) that would otherwise require (specific) additions to the API...,Motivation
10569,"*         There is a clearer distinction between input shapes, for training you usually want batches, but for prediction you often care only about single examples",Motivation
10570,Redoing this for consistency in naming is not worth it imho.,Motivation
10571,"Personally, I'm a very big fan of the CODE method of feeding data into the graph.",Motivation
10572,"These inputs are in a HDF5 file or a Numpy array either on disk or in memory, so I typically feed with CODEfeed_dictCODE, potentially asynchronously into a queue.",Motivation
10573,"And in the future when we want to load more advanced, and possible context dependant models, and on the fly language switching it would be even more necessary.",Motivation
10574,"I am only starting to read into the new API, but I want to share two problems that I had with the old Input Queues in concurrence with using MonitoredSession with SessionRunHooks.",Motivation
10575,And this is why availability of a binary that supports 9.1 would be nice: (from the TF1.6 release notes),Motivation
10576,"More specifically, we currently have a use case where we employ two queues; an outer one, using a string_input_producer (with shuffling), where each string denotes/points to a ""data set"", and the inner queue is then produced by generating a variable amount of samples from each ""data set"".",Motivation
10577,"As @yaroslavvb mentioned, the CODEfeed_dictCODE memcpy (on a single CPU core?) can be a huge performance bottleneck, and I'd like to see this addressed in any refactor of TensorFlow's input handling.",Motivation
10578,"This is necessary for most of the applications at OpenAI, here's one example -- https://github.com/openai/universe-starter-agent",Motivation
10579,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
10580,"Here's the paper I mentioned, titled ""sense2vec"": http://arxiv.org/pdf/1511.06388.pdf , by @iamtrask",Motivation
10581,Or a '(mean) target encoder'?,Motivation
10582,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
10583,"a monitor api is very flexible but actually you want to do early stopping **every time** you use an estimator, right?",Motivation
10584,"*         @omoindrot: I agree that the CODE construction is pretty ugly, and we should try to find ways to improve it.",Motivation
10585,"That's what I referred to when I said ""redoing this for consistency is not worth it"".",Motivation
10586,Primarily I am interested in using it to switch between training and validation datasets in the same process.,Motivation
10587,"Current CODE provides such functionality, but it is rather hacky.",Motivation
10588,"I would have imagined that if we had a stacking interface, you could specify one estimator as the base estimator and another as the one on top.",Motivation
10589,I often try to use TensorFlow on very large inputs (potentially >1GB minibatch) with relatively light computation on each minibatch.,Motivation
10590,"The most similar words to CODE might be things like CODE, while the most similar words to CODE might be CODE or CODE.",Motivation
10591,We might end up with use-cases where the vectors data is many gigabytes.,Motivation
10592,"The most similar words to CODE might be things like CODE, while the most similar words to CODE might be CODE or CODE.",Motivation
10593,We might end up with use-cases where the vectors data is many gigabytes.,Motivation
10594,"Then test it on my cross-validation set and if my cv score is still falling, I can continue training.",Motivation
10595,"That implements predicting with a subset of the estimators, which is also very helpful.",Motivation
10596,I want to wrap this function using CODE and use it to build a CODE.,Motivation
10597,Because NodeJS it's fast!,Motivation
10598,There's been a few things that are currently missing and I had to work around:,Motivation
10599,They are great.,Motivation
10600,Assume CODE is a list of large images (e.g. 8192x8192 each) [with corresponding labels].,Motivation
10601,"It's great that this batch normalization layer works for better training convergence, but if you can't apply the model in production, there isn't much of a point in using it.",Motivation
10602,The use case is when you want to combine several estimators together.,Motivation
10603,Many of the things said already resonate with my experience.,Motivation
10604,And what if someone wants to add a 'binary encoding'?,Motivation
10605,"Biggest benefits would come for sure from server-side applications that operate on node.js that could directly interact with Tensorflow, but also node-webkit (desktop applications) could potentially spawn dozens of interesting projects.",Motivation
10606,Our biggest issue with the current data loading scheme is just that it's very complicated and involves a lot of new concepts.,Motivation
10607,"Where we're stuck is that to optimally follow recommendations, we end up in an awkward situation, one of:",Motivation
10608,@khelkun answer is rather simple: providing mature JavaScript package that allows easy interaction with Tensorflow opens myriad new possibilities.,Motivation
10609,Currently using spacy to get the POS tags. (from sentence subtree etc),Motivation
10610,"When used for batch jobs the additional memory overhead of storing a new lexeme struct for each new word form encountered in parsing is negligible compared to the speed gains, and because most text conforms to the assumption that vocabulary size grows logarithmically as the total number of tokens grows linearly this is usually a safe bet.",Motivation
10611,Here is a feature that would help my use-case:,Motivation
10612,"Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect!",Motivation
10613,Iterators implementing CODE are great for progress report.,Motivation
10614,What other pain points have we missed?,Motivation
10615,"@mrry One ""data set"" can be composed of anything between ~500-30,000 dynamically generated samples.",Motivation
10616,"More specifically, we currently have a use case where we employ two queues; an outer one, using a string_input_producer (with shuffling), where each string denotes/points to a ""data set"", and the inner queue is then produced by generating a variable amount of samples from each ""data set"".",Motivation
10617,"If not too difficult from your end, having the language models pickleable would provide a better out of box experience for Apache Spark users.",Motivation
10618,"By the way CODE does only inference, no training, so no backpropagation.",Motivation
10619,The potential for impact in solving this issue is huge.,Motivation
10620,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation
10621,"Here's the paper I mentioned, titled ""sense2vec"": http://arxiv.org/pdf/1511.06388.pdf , by @iamtrask",Motivation
10622,What is the use-case for your interface except parallelization?,Motivation
10623,"Here's the paper I mentioned, titled ""sense2vec"": http://arxiv.org/pdf/1511.06388.pdf , by @iamtrask",Motivation
10624,What @drasmuss suggests is very useful for segmentation tasks where both labels and images need to be augmented.,Motivation
10625,As quoted from the offical website http://www.tensorflow.org/,Motivation
10626,"Then test it on my cross-validation set and if my cv score is still falling, I can continue training.",Motivation
10627,Which and how many samples are generated differs per epoch (potentially conditional on past training behavior).,Motivation
10628,We are not consistent in naming anywhere.,Motivation
10629,"What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.",Motivation
10630,"Personally, I'm a very big fan of the CODE method of feeding data into the graph.",Motivation
10631,"a monitor api is very flexible but actually you want to do early stopping **every time** you use an estimator, right?",Motivation
10632,What would be your use cases ?,Motivation
10633,"I'm using that and following your sense2vec implementation, with a few changes, to attempt the [word clustering that is mentioned on Google Code word2vec page] URL .",Motivation
10634,Primarily I am interested in using it to switch between training and validation datasets in the same process.,Motivation
10635,The benefits are:,Motivation
10636,And documented too (when it comes to CODE).,Motivation
10637,Ideally we would get rid of all the weird behaviors.,Motivation
10638,I guess we kept OneHotEncoder because it's more efficient when it can be used....,Motivation
10639,I'd like to understand your use case a little better.,Motivation
10640,We are not consistent in naming anywhere.,Motivation
10641,"The Python threading API isn't perfect, but in general when we're doing mostly non-GIL-taking tasks in NumPy or whatever, the TF queue API seems more of a burden than a help.",Motivation
10642,"The tutorial page [here] URL  mainly just suggests using separate processes, but this can be a pain, especially if I want to do early stopping based on the validation data.",Motivation
10643,"In another instance, it might return 389 new pairs, etc.",Motivation
10644,"For instance, if you want to just recognise entities and store them in textual form, you don't care that the CODE instances can diverge between your shards.",Motivation
10645,"More specifically, we currently have a use case where we employ two queues; an outer one, using a string_input_producer (with shuffling), where each string denotes/points to a ""data set"", and the inner queue is then produced by generating a variable amount of samples from each ""data set"".",Motivation
10646,"-         We want to add an option specific to one of the encodings (eg for 'onehot' encoding to drop the first (redundant) column, or for 'ordinal' encoding base the order of the categories on the frequency, ...).",Motivation
10647,As you mentioned that would be heaven to see this code just work: CODE,Motivation
10648,"In another instance, it might return 389 new pairs, etc.",Motivation
10649,I'm trying to do some work on the text from Wiki Dump.,Motivation
10650,"We use scikit-image CODE objects to apply cropping and resizing operations for this model, because those objects let us easily translate our model output back to the original input coordinate space.",Motivation
10651,"agreed, didn't really mean the information was usable or retrievable, rather that the scoring of vectors **not** using POS tagging is influenced by these ""use cases"" and that making this information explicit seems a natural extension.",Motivation
10652,*         See #7945 and [many Stack Overflow questions] URL  for some examples of users who have been bitten by this problem.,Motivation
10653,its implementation converting coo to csr is alsoweird.,Motivation
10654,A couple of concrete use cases that come up for us:,Motivation
10655,Because NodeJS it's fast!,Motivation
10656,"Where we're stuck is that to optimally follow recommendations, we end up in an awkward situation, one of:",Motivation
10657,"It does not help *as such*, but it makes it less complex to have specific options specifically tailored to the different encoding types.",Motivation
10658,"It is probably most useful in an interactive setting, righ?",Motivation
10659,-         The keyword argument CODE specifies *how* to encode those data,Motivation
10660,"-         We have data that comes from a large number of imbalanced segments, and in training we use some custom stratified sampling logic to ensure we present examples from each segment evenly.",Motivation
10661,Ideally we would get rid of all the weird behaviors.,Motivation
10662,What other pain points have we missed?,Motivation
10663,For example:,Motivation
10664,"The more diverse they are, often the better.",Motivation
10665,"3.         If the message protocol supports pub/sub, then (1) multiple training sessions can subcribe and reuse the same input data, which is very useful when trying new models.",Motivation
10666,"A similar pattern turns up in many different settings, including [Java's Stream API] URL , [Scala's collections] URL  (and hence Spark's RDDs), and [.NET's Language Integrated Query] URL .",Motivation
10667,It may not be the right place to ask but I'd like to know why others developers look for a nodejs api/add-on for tensorflow ?,Motivation
10668,"The Python threading API isn't perfect, but in general when we're doing mostly non-GIL-taking tasks in NumPy or whatever, the TF queue API seems more of a burden than a help.",Motivation
10669,What features do you miss from other systems?,Motivation
10670,"The one I'm currently struggling with is the integration of CODE with the ability of picking the source from which the input should come, for having train/val data in the same symbolic variable.",Motivation
10671,"More specifically, we currently have a use case where we employ two queues; an outer one, using a string_input_producer (with shuffling), where each string denotes/points to a ""data set"", and the inner queue is then produced by generating a variable amount of samples from each ""data set"".",Motivation
10672,1.         Anything that helps me analyze if and where the bottleneck lies in the input pipeline would be great.,Motivation
10673,"Long story short: With a slightly out-of-the-ordinary use case, we've been hit by pretty much all of the problems you have mentioned above, and our workarounds have not been pretty.",Motivation
10674,The potential for impact in solving this issue is huge.,Motivation
10675,"2.         An easy and established way to change the input pipeline of a graph, after it has been created, because it is the most typical usage pattern.",Motivation
10676,Assume CODE is a list of large images (e.g. 8192x8192 each) [with corresponding labels].,Motivation
10677,"The use case that affects me the most is [do n times: train for k iter/epoch, validate model, repeat].",Motivation
10678,I don't see how the proposed change would help with the missing values that much.,Motivation
10679,"-         With CODE I was able to solve most of my input-related problems, like loading .mat files in a symbolic-ish manner.",Motivation
10680,Currently using spacy to get the POS tags. (from sentence subtree etc),Motivation
10681,"Google developers implemented a small portion of Tensorflow in Javascript in their [playground] URL , the neural network implementation is [here] URL  and does include [back propagation](https://github.com/tensorflow/playground/blob/master/src/nn.ts#L282).",Motivation
10682,The CODE class described in the original post already exists in Python: it is a list of tuples.,Motivation
10683,"Then, CODE is created by (randomly) iterating over each element CODE of CODE, and for each of these elements the function CODE samples a (variable) number of sub-images [and sub-labels] (e.g. 256x256 each) from CODE, taken from various regions of CODE.",Motivation
10684,"It does not help *as such*, but it makes it less complex to have specific options specifically tailored to the different encoding types.",Motivation
10685,"Where we're stuck is that to optimally follow recommendations, we end up in an awkward situation, one of:",Motivation
10686,"Now when I switched from a normal Session to using MonitoredSession and added a logging hook and told it to log the 'accuracy' tensor, it tried in vain to evaluate the first session run call as the hook had added that tensor to the fetch list, but with the queue being still empty there was no way to evaluate accuracy yet.",Motivation
10687,"A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.",Motivation
10688,For example:,Motivation
10689,"I don't want to have 3 different gan classes: each with their own create graph and fit methods, simply because one dataset doesn't fit in memory, the other is an np.array, and the other is generated on the fly.",Motivation
10690,For me it is mainly a question of scalability in adding more features to a single class.,Motivation
10691,"We don't find it spectacularly difficult to write a multithreaded data loader ourselves in Python, and generally we don't find it overly difficult to ensure that our data loading and preprocessing runs sufficiently quickly that it doesn't actually bottleneck training.",Motivation
10692,"-         We want to add more encoding options (eg binary encoding, mean target encoding, unary encoding, ...).",Motivation
10693,I've been trying to do NLP with Spark with NLTK and Stanford and etc.,Motivation
10694,*         See #6845 for a discussion of input pipeline performance.,Motivation
10695,"Google developers implemented a small portion of Tensorflow in Javascript in their [playground] URL , the neural network implementation is [here] URL  and does include [back propagation](https://github.com/tensorflow/playground/blob/master/src/nn.ts#L282).",Motivation
10696,There is something slightly similar in the adaboost pr: #522.,Motivation
10697,In which setting do you want to do that except for parallelization?,Motivation
10698,The TensorFlow team wants the NodeJS community to benefit from TensorFlow.,Motivation
10699,"What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.",Motivation
10700,In case of Stacking the estimators might be completely different (say to you want to merge forests with svms).,Motivation
10701,"So the setting is that you have trained some bagging estimators and want to combine them together, right?",Motivation
10702,This makes spaCy much more useable for including in our docker environment where we literally have 100s of these containers running in parallel and memory is wasted for each instance.,Motivation
10703,I'm also interested in nodejs tensorflow API   to be able to use it in a node-red flows that would chain tensorflows graphs and may be other kinds of data analysis nodes.,Motivation
10704,I like the tf record and queue runner thing now that I'm used to it; the issue is the tight binding to the graph....,Motivation
10705,Example: I trained using TFRecords and input queues; I got my weights/model.,Motivation
10706,That is one of my biggest issues with the current API.,Motivation
10707,"As far as I understand it, CODE preserves a 1:1 mapping, which is not sufficient for our use case.",Motivation
10708,"What do you think does the scenario / code look like, where a user wants CODE?",Motivation
10709,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation
10710,We are not consistent in naming anywhere.,Motivation
10711,I can pick up pytorch's dataset API in 5 minutes and it's good enough for all the popular academic datasets.,Motivation
10712,"@mrry One ""data set"" can be composed of anything between ~500-30,000 dynamically generated samples.",Motivation
10713,This would be interesting for pure front-end graph exportation for direct Solution Usage on web clients.,Motivation
10714,It's close integration with Spark will be a great advantage for many researchers.,Motivation
10715,-         The class name CODE says what type of data it accepts (categorical data),Motivation
10716,Because JavaScript is Awesome,Motivation
10717,*         See #7945 and [many Stack Overflow questions] URL  for some examples of users who have been bitten by this problem.,Motivation
10718,This makes spaCy much more useable for including in our docker environment where we literally have 100s of these containers running in parallel and memory is wasted for each instance.,Motivation
10719,"A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.",Motivation
10720,"Until the fix is available, the only workaround is todowngrade to CUDA 8.0.xor disable XLA:GPU.",Motivation
10721,Reason: the automatic preevaluation of pending enqueues.,Motivation
10722,3.         A way to control and monitor the epochs - currently they are rather deeply hidden and unaccessible even simple checks.,Motivation
10723,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
10724,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
10725,"As a result, these versions of ptxas miscompile most XLA programs which usemore than 4GB of temp memory.",Motivation
10726,Are each data item (input/target) couple?,Motivation
10727,@jnothman I suppose you acknowledge there *can* be a difference in practice?,Motivation
10728,I think that a *huge* effort should be placed in tutorials: the hugest difficulty I am having -- and some colleagues with me -- is that the documentation that you can find is quite lousy and not very self-contained.,Motivation
10729,"As @yaroslavvb mentioned, the CODEfeed_dictCODE memcpy (on a single CPU core?) can be a huge performance bottleneck, and I'd like to see this addressed in any refactor of TensorFlow's input handling.",Motivation
10730,the other factor for me is that everyone thinks the current auto mode inOneHotEncoder is weird.,Motivation
10731,"In fact for these kinds of higher-level abstractions, sooner seems better than later â one of the greatest frustrations of reading published TF research code is that the vast majority of codebases use their own idiosyncratic layers library, as opposed to e.g. the ones in CODE or CODE, and these libraries are all different, which makes it more difficult than it should be to share work.",Motivation
10732,"*         The current pipelines use TensorFlow queues and multiple Python threads, which can lead to poor performance (lock contention in the queues and the Python GIL) and hard-to-understand exceptions (CODE).",Motivation
10733,I would like to train a small number of sub-estimators at a time (and wait a relatively short time).,Motivation
10734,Why would anyone need another Javascript library?,Motivation
10735,Why ignore JavaScript ?,Motivation
10736,"I'm using that and following your sense2vec implementation, with a few changes, to attempt the [word clustering that is mentioned on Google Code word2vec page] URL .",Motivation
10737,-         The keyword argument CODE specifies *how* to encode those data,Motivation
10738,http://pytorch.org/docs/data.html,Motivation
10739,"Something that provides similar functionality as the generator feed function in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/inputs/queues/feeding_functions.py  (but it would be cool if the source of the data could be from an arbitrary source, maybe using a kind of publisher/subscriber model?)",Motivation
10740,"The more diverse they are, often the better.",Motivation
10741,This results in garbage results and/orCUDA_ERROR_ILLEGAL_ADDRESS failures.,Motivation
10742,We do not expect afix for CUDA 9.0.x.,Motivation
10743,"A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.",Motivation
10744,"Where we're stuck is that to optimally follow recommendations, we end up in an awkward situation, one of:",Motivation
10745,"If I could create some sort of input method (Queue, Dataset, whatever) where I can cleanly swap between training and validation inputs, that would be much nicer (again, CODE is great for this, but if it will always be slower, it'd be nice to have a more performant alternative).",Motivation
10746,"I mainly created this issue in case someone else is running into similar problems when trying spaCy on Spark, as the error messages raised by Spark when failing to pickle the language models are not very helpful (workers just crash because of segmentation fault).",Motivation
10747,"I understand these functions were initially thought for simple use cases, but it would be nice to have more control of the pipeline without the burden of managing _everything_ (e.g. using CODE but being forced to feed queues and manage threads kind of manually).",Motivation
10748,I'm just wondering about what things users will come up with (w.r.t. data generation and usage) that would otherwise require (specific) additions to the API...,Motivation
10749,They are great.,Motivation
10750,Are each data item (input/target) couple?,Motivation
10751,What other suggestions do you have?,Motivation
10752,"Are there any specific operations that you perform at the end of a ""data set"" or can your training loop handle the concatenation of records from different ""data sets""?",Motivation
10753,"The problem here is that we then need to add additional keyword arguments to CODE that are or are not active depending on what you passed for CODE kwarg, which is not the nicest API design.",Motivation
10754,Now I can stop writing my own (horrible) dataset class.,Motivation
10755,"For example, let's say I have a Python function which returns a new batch on each call (a generator).",Motivation
10756,"*         The current pipelines use TensorFlow queues and multiple Python threads, which can lead to poor performance (lock contention in the queues and the Python GIL) and hard-to-understand exceptions (CODE).",Motivation
10757,I'm also interested in nodejs tensorflow API   to be able to use it in a node-red flows that would chain tensorflows graphs and may be other kinds of data analysis nodes.,Motivation
10758,"and telling people ""if you want to one hotencode strings, go to CategoricalEncoder instead"" is awkward, because OHEis already intended for categoricals...",Motivation
10759,"As you can see, the real-world problems are more than just feeding into a series of images or texts.",Motivation
10760,For spaCy to work out of the box with [Apache Spark] URL  the language modles need to be pickled so that they can be initialised on the master node and then sent to the workers.,Motivation
10761,I don't see how the proposed change would help with the missing values that much.,Motivation
10762,Why would anybody use a JS library to train NNs?,Motivation
10763,"Where we're stuck is that to optimally follow recommendations, we end up in an awkward situation, one of:",Motivation
10764,"A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.",Motivation
10765,"I'd love to have fast, parallel GPU compute power at my fingertips with the ease and composability of JS.",Motivation
10766,"*         The pipelines behave poorly if you forget to call CODE: in fact, they hang indefinitely and deadlock the user program.",Motivation
10767,Please note there are examples of where we already generate language bindings.,Motivation
10768,Why would anyone need another Javascript library?,Motivation
10769,Assume CODE is a list of large images (e.g. 8192x8192 each) [with corresponding labels].,Motivation
10770,http://pytorch.org/docs/data.html,Motivation
10771,Why would anybody use a JS library to train NNs?,Motivation
10772,"The one I'm currently struggling with is the integration of CODE with the ability of picking the source from which the input should come, for having train/val data in the same symbolic variable.",Motivation
10773,"In fact for these kinds of higher-level abstractions, sooner seems better than later â one of the greatest frustrations of reading published TF research code is that the vast majority of codebases use their own idiosyncratic layers library, as opposed to e.g. the ones in CODE or CODE, and these libraries are all different, which makes it more difficult than it should be to share work.",Motivation
10774,"-         We have data that comes from a large number of imbalanced segments, and in training we use some custom stratified sampling logic to ensure we present examples from each segment evenly.",Motivation
10775,And the people at the university of Groningen would probably be happy to see another parser for Dutch so they can compare Alpino to it :),Motivation
10776,"-         We want to add an option specific to one of the encodings (eg for 'onehot' encoding to drop the first (redundant) column, or for 'ordinal' encoding base the order of the categories on the frequency, ...).",Motivation
10777,I have been using spacy for streaming data (twitter and news stories mostly) and I believe that the fundamental design of the vocab/StringStore in spacy is problematic for streaming processing.,Motivation
10778,Which and how many samples are generated differs per epoch (potentially conditional on past training behavior).,Motivation
10779,"Then test it on my cross-validation set and if my cv score is still falling, I can continue training.",Motivation
10780,I've been trying to do NLP with Spark with NLTK and Stanford and etc.,Motivation
10781,the other factor for me is that everyone thinks the current auto mode inOneHotEncoder is weird.,Motivation
10782,-         The keyword argument CODE specifies *how* to encode those data,Motivation
10783,Is that always true?,Motivation
10784,"This is necessary for most of the applications at OpenAI, here's one example -- https://github.com/openai/universe-starter-agent",Motivation
10785,This lets you see different vectors for CODE and CODE.,Motivation
10786,"a monitor api is very flexible but actually you want to do early stopping **every time** you use an estimator, right?",Motivation
10787,"At the moment, we don't perform specific operations at the end of each data set, i.e. everything gets put into the same (large) random shuffle queue, to mix samples between data sets.",Motivation
10788,The number of elements generated each time is variable and conditional on the properties of element CODE.,Motivation
10789,I want to wrap this function using CODE and use it to build a CODE.,Motivation
10790,I think that a *huge* effort should be placed in tutorials: the hugest difficulty I am having -- and some colleagues with me -- is that the documentation that you can find is quite lousy and not very self-contained.,Motivation
10791,"When using CODE, this is very simple, and this is what I'm used to.",Motivation
10792,The benefits are:,Motivation
10793,This concept is inspired by [dask distributed] URL  and other executor frameworks -- I think the flexibility offered by this abstraction is great!,Motivation
10794,"My goal: POS tag the English language Wikipedia dump (approx 23GB, maybe 3B words).",Motivation
10795,The TensorFlow team wants the NodeJS community to benefit from TensorFlow.,Motivation
10796,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation
10797,It's our most upvoted issue.,Motivation
10798,"Assume there is a large training data set which is in text format, and we need to convert it into tfrecord format.",Motivation
10799,"1.         A decent way to make custom preprocessing of the data, whether it be based on queue's or not, the idea of being able to foresee all possible data input needs is doomed.",Motivation
10800,(the output you get depending on the data you have),Motivation
10801,"Then, CODE is created by (randomly) iterating over each element CODE of CODE, and for each of these elements the function CODE samples a (variable) number of sub-images [and sub-labels] (e.g. 256x256 each) from CODE, taken from various regions of CODE.",Motivation
10802,"It is by far the most flexible, makes debugging way easier and makes for much simpler code.",Motivation
10803,"(Indirectly, this could also be used to implement subsampling strategies or for monitoring the fitting process.)",Motivation
10804,"It does not help *as such*, but it makes it less complex to have specific options specifically tailored to the different encoding types.",Motivation
10805,The question is how frequently users have such consecutive integers as categories without having used LabelEncoder as the previous step ..,Motivation
10806,And I think the idea of partial language support is important and overdue.,Motivation
10807,This doesn't seem to be supported?,Motivation
10808,I'm also interested in nodejs tensorflow API   to be able to use it in a node-red flows that would chain tensorflows graphs and may be other kinds of data analysis nodes.,Motivation
10809,"The tutorial page [here] URL  mainly just suggests using separate processes, but this can be a pain, especially if I want to do early stopping based on the validation data.",Motivation
10810,It may not be the right place to ask but I'd like to know why others developers look for a nodejs api/add-on for tensorflow ?,Motivation
10811,Or a '(mean) target encoder'?,Motivation
10812,"More specifically, we currently have a use case where we employ two queues; an outer one, using a string_input_producer (with shuffling), where each string denotes/points to a ""data set"", and the inner queue is then produced by generating a variable amount of samples from each ""data set"".",Motivation
10813,#8168,Motivation
10814,"I'd support @nicolasdespres for ""no Dataset"" pledge, mainly because all-in-one bundle is not flexible, not future proof and also - not consistent with the TF's paradigm of providing small, stable, well-defined and assemble-able blocks for building custom models.",Motivation
10815,"When running with multiple GPUs, TensorFlow is not able to even saturate the PCI-e bandwidth to the GPUs because of the memcpy from the feed_dict to the CPU tensor.",Motivation
10816,This makes spaCy much more useable for including in our docker environment where we literally have 100s of these containers running in parallel and memory is wasted for each instance.,Motivation
10817,Because JavaScript is Awesome,Motivation
10818,This concept is inspired by [dask distributed] URL  and other executor frameworks -- I think the flexibility offered by this abstraction is great!,Motivation
10819,"Right now, this method starves my GPU all the time, which is a shame because most other DL frameworks (even those based on computational graphs) manage to make this much more performantly.",Motivation
10820,We do not expect afix for CUDA 9.0.x.,Motivation
10821,I'm trying to do some work on the text from Wiki Dump.,Motivation
10822,"So the setting is that you have trained some bagging estimators and want to combine them together, right?",Motivation
10823,"Right now, this method starves my GPU all the time, which is a shame because most other DL frameworks (even those based on computational graphs) manage to make this much more performantly.",Motivation
10824,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
10825,"Also, when randomly creating a sample set, it seemed like the samples were consumed when I wanted them left in the buffer.",Motivation
10826,"By the way CODE does only inference, no training, so no backpropagation.",Motivation
10827,For spaCy to work out of the box with [Apache Spark] URL  the language modles need to be pickled so that they can be initialised on the master node and then sent to the workers.,Motivation
10828,There are clear problems with queues like you said.,Motivation
10829,One simple sub case is where a column is numerical but has some missing values.,Motivation
10830,I'm just wondering about what things users will come up with (w.r.t. data generation and usage) that would otherwise require (specific) additions to the API...,Motivation
10831,Are each data item (input/target) couple?,Motivation
10832,So summary of how it is now:,Motivation
10833,-         One of our models is a localization model.,Motivation
10834,"So the setting is that you have trained some bagging estimators and want to combine them together, right?",Motivation
10835,what about f** I just only want to use tensorflow1.8 and cuda9.1?,Motivation
10836,"2.         An easy and established way to change the input pipeline of a graph, after it has been created, because it is the most typical usage pattern.",Motivation
10837,"-         With CODE I was able to solve most of my input-related problems, like loading .mat files in a symbolic-ish manner.",Motivation
10838,"The most similar words to CODE might be things like CODE, while the most similar words to CODE might be CODE or CODE.",Motivation
10839,3.         A way to control and monitor the epochs - currently they are rather deeply hidden and unaccessible even simple checks.,Motivation
10840,"It's relatively straightforward for us to, in Python, generate a new draw from our original data set for every epoch, but it seems like in the API proposed above, we'd have to figure out how to implement this behavior as an CODE, which seems less straightforward.",Motivation
10841,*         See #7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.,Motivation
10842,Is it just a file?,Motivation
10843,Reason: the automatic preevaluation of pending enqueues.,Motivation
10844,"The one I'm currently struggling with is the integration of CODE with the ability of picking the source from which the input should come, for having train/val data in the same symbolic variable.",Motivation
10845,What is the use-case for your interface except parallelization?,Motivation
10846,"What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.",Motivation
10847,This could make things easier too.,Motivation
10848,"Not ideal, but also not a big deal imho.",Motivation
10849,We're announcing this plan early because we want to collect feedback on what features you&mdash;as TensorFlow users&mdash;would like to see in an input pipeline API.,Motivation
10850,"For instance, if you want to just recognise entities and store them in textual form, you don't care that the CODE instances can diverge between your shards.",Motivation
10851,what about f** I just only want to use tensorflow1.8 and cuda9.1?,Motivation
10852,"A similar pattern turns up in many different settings, including [Java's Stream API] URL , [Scala's collections] URL  (and hence Spark's RDDs), and [.NET's Language Integrated Query] URL .",Motivation
10853,One simple sub case is where a column is numerical but has some missing values.,Motivation
10854,"I would have imagined that if we had a stacking interface, you could specify one estimator as the base estimator and another as the one on top.",Motivation
10855,I really like Spacy's simple and all in one approach.,Motivation
10856,I want to wrap this function using CODE and use it to build a CODE.,Motivation
10857,"For me it would be brilliant, because I have 100+ [Celery] URL  workers and the 100M for each instance to load the vector model makes it hard to scale across docker containers.",Motivation
10858,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation
10859,Using XLA:GPU with CUDA 9 and CUDA 9.1 results in garbage results and/orCUDA_ILLEGAL_ADDRESS failures.,Motivation
10860,"Currently it is certainly still OK, there are not too many incompatible options (but also partly because I moved CODE into the CODE option).",Motivation
10861,We're announcing this plan early because we want to collect feedback on what features you&mdash;as TensorFlow users&mdash;would like to see in an input pipeline API.,Motivation
10862,What @drasmuss suggests is very useful for segmentation tasks where both labels and images need to be augmented.,Motivation
10863,"And what is a ""dataset"", anyway?",Motivation
10864,"a monitor api is very flexible but actually you want to do early stopping **every time** you use an estimator, right?",Motivation
10865,Are each data item (input/target) couple?,Motivation
10866,Primarily I am interested in using it to switch between training and validation datasets in the same process.,Motivation
10867,"(Indirectly, this could also be used to implement subsampling strategies or for monitoring the fitting process.)",Motivation
10868,"A worker takes a few documents off the task queue, aggregates the vocabulary, and asks the vectors service for all vectors active on the batch.",Motivation
10869,*         See #7525 and [many more Stack Overflow questions] URL  for an example of the confusing error.,Motivation
10870,I'd like to understand your use case a little better.,Motivation
10871,I've been trying to do NLP with Spark with NLTK and Stanford and etc.,Motivation
10872,"Here's the paper I mentioned, titled ""sense2vec"": http://arxiv.org/pdf/1511.06388.pdf , by @iamtrask",Motivation
10873,And having incompatible options is something that happens often in scikit-learn.,Motivation
10874,"Aside from that, we use two different input pipelines for training and validation data that we connect to the network part of our graph alternating through a switch implemented through CODE.",Motivation
10875,"In fact, the preprocessed dataset size for one input architecture variant can be easily an order of magnitude larger than the unprocessed file set size.",Motivation
10876,It's close integration with Spark will be a great advantage for many researchers.,Motivation
10877,*         See #7945 and [many Stack Overflow questions] URL  for some examples of users who have been bitten by this problem.,Motivation
10878,I can pick up pytorch's dataset API in 5 minutes and it's good enough for all the popular academic datasets.,Motivation
10879,"As far as I understand it, CODE preserves a 1:1 mapping, which is not sufficient for our use case.",Motivation
10880,"While TensorFlow has several methods that can be used to build complex input pipelines (such as [CODE] URL , [CODE] URL , etc.), they were designed for a particular use case (processing a static set of files repeatedly), and the average user experience with these methods is not great.",Motivation
10881,What other pain points have we missed?,Motivation
10882,#8168,Motivation
10883,"We don't find it spectacularly difficult to write a multithreaded data loader ourselves in Python, and generally we don't find it overly difficult to ensure that our data loading and preprocessing runs sufficiently quickly that it doesn't actually bottleneck training.",Motivation
10884,"Currently it is certainly still OK, there are not too many incompatible options (but also partly because I moved CODE into the CODE option).",Motivation
10885,I'm still not sure what you're suggesting is the practical difference due to inferring categories from the max value.,Motivation
10886,Our biggest issue with the current data loading scheme is just that it's very complicated and involves a lot of new concepts.,Motivation
10887,The TensorFlow team wants the NodeJS community to benefit from TensorFlow.,Motivation
10888,Currently I am worried that my training/prediction preprocessing will diverge over time.,Motivation
10889,For example:,Motivation
10890,CODE supports SparseTensor and automatic batching of SparseTensor would make my life a whole lot easier,Motivation
10891,"Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect!",Motivation
10892,This would be interesting for pure front-end graph exportation for direct Solution Usage on web clients.,Motivation
10893,"We also used two separate queues, one handling input data_files as string names and the other one the resulting input data with preprocessing being done in between those two.",Motivation
10894,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
10895,"For instance, if you want to just recognise entities and store them in textual form, you don't care that the CODE instances can diverge between your shards.",Motivation
10896,"Problematic was that the program just stopped and waited for some process to begin filling the queue, but there was non, so it just did nothing, but also didn't throw an exception or give any kind of warning, which made understanding what was happening a bit difficult.",Motivation
10897,"What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.",Motivation
10898,"It's relatively straightforward for us to, in Python, generate a new draw from our original data set for every epoch, but it seems like in the API proposed above, we'd have to figure out how to implement this behavior as an CODE, which seems less straightforward.",Motivation
10899,(2) data can be generated from different machines if the pre-processing is too heavy for a single CPU.,Motivation
10900,generator?,Motivation
10901,"agreed, didn't really mean the information was usable or retrievable, rather that the scoring of vectors **not** using POS tagging is influenced by these ""use cases"" and that making this information explicit seems a natural extension.",Motivation
10902,its implementation converting coo to csr is alsoweird.,Motivation
10903,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
10904,"What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.",Motivation
10905,This was mostly an issue where the GPU would get the data from the CPU.,Motivation
10906,"And what is a ""dataset"", anyway?",Motivation
10907,I guess we kept OneHotEncoder because it's more efficient when it can be used....,Motivation
10908,There are clear problems with queues like you said.,Motivation
10909,We needed to make sure that the enqueue operations fills at least a certain multiple of the batch size into the first queue for our code to run without problems (otherwise the second input queue stalled),Motivation
10910,And the people at the university of Groningen would probably be happy to see another parser for Dutch so they can compare Alpino to it :),Motivation
10911,"By the way CODE does only inference, no training, so no backpropagation.",Motivation
10912,I've been trying to do NLP with Spark with NLTK and Stanford and etc.,Motivation
10913,"It is probably most useful in an interactive setting, righ?",Motivation
10914,The benefits are:,Motivation
10915,"Long story short: With a slightly out-of-the-ordinary use case, we've been hit by pretty much all of the problems you have mentioned above, and our workarounds have not been pretty.",Motivation
10916,However they could all share this binding in common.,Motivation
10917,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
10918,Ideally we would get rid of all the weird behaviors.,Motivation
10919,"It does not help *as such*, but it makes it less complex to have specific options specifically tailored to the different encoding types.",Motivation
10920,"If not too difficult from your end, having the language models pickleable would provide a better out of box experience for Apache Spark users.",Motivation
10921,"What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.",Motivation
10922,"Digital Reasoning wrote a paper showing this got them good results, and early examination of the vectors is looking good to me too.",Motivation
10923,Javascript happens to be to most prevalent language currently in existance..,Motivation
10924,Is it just a file?,Motivation
10925,"(Indirectly, this could also be used to implement subsampling strategies or for monitoring the fitting process.)",Motivation
10926,"I'd love to have fast, parallel GPU compute power at my fingertips with the ease and composability of JS.",Motivation
10927,"If I could create some sort of input method (Queue, Dataset, whatever) where I can cleanly swap between training and validation inputs, that would be much nicer (again, CODE is great for this, but if it will always be slower, it'd be nice to have a more performant alternative).",Motivation
10928,3.         A way to control and monitor the epochs - currently they are rather deeply hidden and unaccessible even simple checks.,Motivation
10929,"I don't want to have 3 different gan classes: each with their own create graph and fit methods, simply because one dataset doesn't fit in memory, the other is an np.array, and the other is generated on the fly.",Motivation
10930,For spaCy to work out of the box with [Apache Spark] URL  the language modles need to be pickled so that they can be initialised on the master node and then sent to the workers.,Motivation
10931,"As far as I understand it, CODE preserves a 1:1 mapping, which is not sufficient for our use case.",Motivation
10932,Please note there are examples of where we already generate language bindings.,Motivation
10933,What is the use-case for your interface except parallelization?,Motivation
10934,"By the way CODE does only inference, no training, so no backpropagation.",Motivation
10935,"When using CODE, this is very simple, and this is what I'm used to.",Motivation
10936,"When using CODE, this is very simple, and this is what I'm used to.",Motivation
10937,Why would anyone need another Javascript library?,Motivation
10938,In which setting do you want to do that except for parallelization?,Motivation
10939,I'm trying to do some work on the text from Wiki Dump.,Motivation
10940,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
10941,"It's great that this batch normalization layer works for better training convergence, but if you can't apply the model in production, there isn't much of a point in using it.",Motivation
10942,We needed to make sure that the enqueue operations fills at least a certain multiple of the batch size into the first queue for our code to run without problems (otherwise the second input queue stalled),Motivation
10943,This was mostly an issue where the GPU would get the data from the CPU.,Motivation
10944,We've noticed that one of the biggest challenges in getting started with TensorFlow is how to load your own data into your programs.,Motivation
10945,@pprett I think there should be an easy way to do easy things.,Motivation
10946,For spaCy to work out of the box with [Apache Spark] URL  the language modles need to be pickled so that they can be initialised on the master node and then sent to the workers.,Motivation
10947,"(Indirectly, this could also be used to implement subsampling strategies or for monitoring the fitting process.)",Motivation
10948,For me it is mainly a question of scalability in adding more features to a single class.,Motivation
10949,"As far as I understand it, CODE preserves a 1:1 mapping, which is not sufficient for our use case.",Motivation
10950,"I'd love to have fast, parallel GPU compute power at my fingertips with the ease and composability of JS.",Motivation
10951,I want to wrap this function using CODE and use it to build a CODE.,Motivation
10952,See [tensorflow/go/genop/main.go] URL  and [tensorflow/go/op/generate.go] URL  for inspiration.,Motivation
10953,One concrete example of why this would be useful:,Motivation
10954,"I would have imagined that if we had a stacking interface, you could specify one estimator as the base estimator and another as the one on top.",Motivation
10955,"Personally, I'm a very big fan of the CODE method of feeding data into the graph.",Motivation
10956,So summary of how it is now:,Motivation
10957,"A must-have for one of our use cases is ad-hoc creation of data elements via a callback function (which creates tensors on the fly, e.g. using py_func() or through some other means).",Motivation
10958,"It is by far the most flexible, makes debugging way easier and makes for much simpler code.",Motivation
10959,The input pipeline is definitely thesteepest part of the learning curve.,Motivation
10960,"-         We want to add more encoding options (eg binary encoding, mean target encoding, unary encoding, ...).",Motivation
10961,(2) data can be generated from different machines if the pre-processing is too heavy for a single CPU.,Motivation
10962,"1.         A decent way to make custom preprocessing of the data, whether it be based on queue's or not, the idea of being able to foresee all possible data input needs is doomed.",Motivation
10963,"Aside from that, we use two different input pipelines for training and validation data that we connect to the network part of our graph alternating through a switch implemented through CODE.",Motivation
10964,This could make things easier too.,Motivation
10965,"Also, when randomly creating a sample set, it seemed like the samples were consumed when I wanted them left in the buffer.",Motivation
10966,The CODE class described in the original post already exists in Python: it is a list of tuples.,Motivation
10967,The use case is when you want to combine several estimators together.,Motivation
10968,Many of the things said already resonate with my experience.,Motivation
10969,-         One of our models is a localization model.,Motivation
10970,"Google developers implemented a small portion of Tensorflow in Javascript in their [playground] URL , the neural network implementation is [here] URL  and does include [back propagation](https://github.com/tensorflow/playground/blob/master/src/nn.ts#L282).",Motivation
10971,"As I see it, the point of stacking is to combine the predictions of estimators of different nature.",Motivation
10972,"*         The pipelines behave poorly if you forget to call CODE: in fact, they hang indefinitely and deadlock the user program.",Motivation
10973,"*         There is a clearer distinction between input shapes, for training you usually want batches, but for prediction you often care only about single examples",Motivation
10974,"How frequently do you move from one outer ""data set"" to the next?",Motivation
10975,Why ignore JavaScript ?,Motivation
10976,I often try to use TensorFlow on very large inputs (potentially >1GB minibatch) with relatively light computation on each minibatch.,Motivation
10977,"While TensorFlow has several methods that can be used to build complex input pipelines (such as [CODE] URL , [CODE] URL , etc.), they were designed for a particular use case (processing a static set of files repeatedly), and the average user experience with these methods is not great.",Motivation
10978,"[**TL;DR:** We're designing a new input pipeline API for TensorFlow, and we'd like to collect your feature requests on this issue.]",Motivation
10979,The CODE class described in the original post already exists in Python: it is a list of tuples.,Motivation
10980,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
10981,"anyway, JavaScript is awesome!",Motivation
10982,For example:,Motivation
10983,It's close integration with Spark will be a great advantage for many researchers.,Motivation
10984,So summary of how it is now:,Motivation
10985,And documented too (when it comes to CODE).,Motivation
10986,Because JavaScript is Awesome,Motivation
10987,There's been a few things that are currently missing and I had to work around:,Motivation
10988,"The Python threading API isn't perfect, but in general when we're doing mostly non-GIL-taking tasks in NumPy or whatever, the TF queue API seems more of a burden than a help.",Motivation
10989,"I'd support @nicolasdespres for ""no Dataset"" pledge, mainly because all-in-one bundle is not flexible, not future proof and also - not consistent with the TF's paradigm of providing small, stable, well-defined and assemble-able blocks for building custom models.",Motivation
10990,"JavaScript operates on every mobile platform, all major desktop Operating systems & in all the browsers so possibilities are endless.",Motivation
10991,"For example, a CODE receives the number of epochs to be generated but there seems to be no way of knowing the epoch of one sample without counting how many we have already evaluated.",Motivation
10992,"It does not help *as such*, but it makes it less complex to have specific options specifically tailored to the different encoding types.",Motivation
10993,"-         We want to add more encoding options (eg binary encoding, mean target encoding, unary encoding, ...).",Motivation
10994,"@mrry One ""data set"" can be composed of anything between ~500-30,000 dynamically generated samples.",Motivation
10995,"I've recently been trying to make the switch from CODE, but this has been (at least in my limited experience) a major difficulty.",Motivation
10996,"-         Reimplementing our data loading and transformation pipeline with TF primitives, perhaps with CODE, but still using the TF API for managing queue runners",Motivation
10997,"-         We want to add an option specific to one of the encodings (eg for 'onehot' encoding to drop the first (redundant) column, or for 'ordinal' encoding base the order of the categories on the frequency, ...).",Motivation
10998,"Apache Spark ships with a package called [cloudpickle] URL  which is meant to support a wider set of Python constructs, but serialisation with cloudpickle also fails resulting in a segmentation fault: CODE",Motivation
10999,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation
11000,And I think the idea of partial language support is important and overdue.,Motivation
11001,"Problematic was that the program just stopped and waited for some process to begin filling the queue, but there was non, so it just did nothing, but also didn't throw an exception or give any kind of warning, which made understanding what was happening a bit difficult.",Motivation
11002,"For a lot of my use cases, my input data is either 1. not on the file system, or 2. require complex preprocessing unavailable in TensorFlow.",Motivation
11003,(the output you get depending on the data you have),Motivation
11004,Why would anybody use a JS library to train NNs?,Motivation
11005,This would be interesting for pure front-end graph exportation for direct Solution Usage on web clients.,Motivation
11006,"Problematic was that the program just stopped and waited for some process to begin filling the queue, but there was non, so it just did nothing, but also didn't throw an exception or give any kind of warning, which made understanding what was happening a bit difficult.",Motivation
11007,We are not consistent in naming anywhere.,Motivation
11008,I'm giving a shot at migrating to tensorflow for our deep learning models for devices; but the input pipeline is so tightly bound to the rest of the compute graph that its like performing surgery to run inference against it.,Motivation
11009,"Something that provides similar functionality as the generator feed function in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/inputs/queues/feeding_functions.py  (but it would be cool if the source of the data could be from an arbitrary source, maybe using a kind of publisher/subscriber model?)",Motivation
11010,Primarily I am interested in using it to switch between training and validation datasets in the same process.,Motivation
11011,"We use scikit-image CODE objects to apply cropping and resizing operations for this model, because those objects let us easily translate our model output back to the original input coordinate space.",Motivation
11012,-         The class name CODE says what type of data it accepts (categorical data),Motivation
11013,more code (on earth) is written in javascript than ANY other high level language..,Motivation
11014,"a monitor api is very flexible but actually you want to do early stopping **every time** you use an estimator, right?",Motivation
11015,-         One of our models is a localization model.,Motivation
11016,"-         With CODE I was able to solve most of my input-related problems, like loading .mat files in a symbolic-ish manner.",Motivation
11017,I can pick up pytorch's dataset API in 5 minutes and it's good enough for all the popular academic datasets.,Motivation
11018,*         See #7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.,Motivation
11019,For example:,Motivation
11020,"The more diverse they are, often the better.",Motivation
11021,"When running with multiple GPUs, TensorFlow is not able to even saturate the PCI-e bandwidth to the GPUs because of the memcpy from the feed_dict to the CPU tensor.",Motivation
11022,"@amueller, are you persuaded by the issue that we ultimately want different additional parameters (e.g. drop_first, nan handling) depending on the encoding, and that justifies having a different discrete encoder for each encoding format?",Motivation
11023,"Then we want to run it faster, we would change the worker count to 20, 30, 40, ...",Motivation
11024,"A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.",Motivation
11025,"1.         Can use whatever tools/languages to produce data from any sources, as long as they're finally sent with certain message protocol.",Motivation
11026,"I don't want to have 3 different gan classes: each with their own create graph and fit methods, simply because one dataset doesn't fit in memory, the other is an np.array, and the other is generated on the fly.",Motivation
11027,"If not too difficult from your end, having the language models pickleable would provide a better out of box experience for Apache Spark users.",Motivation
11028,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
11029,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
11030,"At the moment, we don't perform specific operations at the end of each data set, i.e. everything gets put into the same (large) random shuffle queue, to mix samples between data sets.",Motivation
11031,"I don't want to have 3 different gan classes: each with their own create graph and fit methods, simply because one dataset doesn't fit in memory, the other is an np.array, and the other is generated on the fly.",Motivation
11032,There are clear problems with queues like you said.,Motivation
11033,"(Indirectly, this could also be used to implement subsampling strategies or for monitoring the fitting process.)",Motivation
11034,There's been a few things that are currently missing and I had to work around:,Motivation
11035,This results in garbage results and/orCUDA_ERROR_ILLEGAL_ADDRESS failures.,Motivation
11036,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
11037,"anyway, JavaScript is awesome!",Motivation
11038,"I think he is right, that extending the documentation and providing better tutorials is highly important.",Motivation
11039,Or better: in what use cases do you need a different interface for boosted ensembles and bagging?,Motivation
11040,I have been using spacy for streaming data (twitter and news stories mostly) and I believe that the fundamental design of the vocab/StringStore in spacy is problematic for streaming processing.,Motivation
11041,I think that a *huge* effort should be placed in tutorials: the hugest difficulty I am having -- and some colleagues with me -- is that the documentation that you can find is quite lousy and not very self-contained.,Motivation
11042,"What do you think does the scenario / code look like, where a user wants CODE?",Motivation
11043,"A must-have for one of our use cases is ad-hoc creation of data elements via a callback function (which creates tensors on the fly, e.g. using py_func() or through some other means).",Motivation
11044,"As a result, these versions of ptxas miscompile most XLA programs which usemore than 4GB of temp memory.",Motivation
11045,This makes spaCy much more useable for including in our docker environment where we literally have 100s of these containers running in parallel and memory is wasted for each instance.,Motivation
11046,generator?,Motivation
11047,"I don't want to have 3 different gan classes: each with their own create graph and fit methods, simply because one dataset doesn't fit in memory, the other is an np.array, and the other is generated on the fly.",Motivation
11048,"I also had issues with pickling with [SFrame] URL , which behaves similarly to how Spark has been described to work here.",Motivation
11049,It would be nice to have an official batch norm layer given its importance in training DNNs.,Motivation
11050,"-         Reimplementing our data loading and transformation pipeline with TF primitives, perhaps with CODE, but still using the TF API for managing queue runners",Motivation
11051,"It is probably most useful in an interactive setting, righ?",Motivation
11052,"*         The pipelines behave poorly if you forget to call CODE: in fact, they hang indefinitely and deadlock the user program.",Motivation
11053,"Then, CODE is created by (randomly) iterating over each element CODE of CODE, and for each of these elements the function CODE samples a (variable) number of sub-images [and sub-labels] (e.g. 256x256 each) from CODE, taken from various regions of CODE.",Motivation
11054,"Apache Spark ships with a package called [cloudpickle] URL  which is meant to support a wider set of Python constructs, but serialisation with cloudpickle also fails resulting in a segmentation fault: CODE",Motivation
11055,"(Indirectly, this could also be used to implement subsampling strategies or for monitoring the fitting process.)",Motivation
11056,"More specifically, we currently have a use case where we employ two queues; an outer one, using a string_input_producer (with shuffling), where each string denotes/points to a ""data set"", and the inner queue is then produced by generating a variable amount of samples from each ""data set"".",Motivation
11057,"It is probably most useful in an interactive setting, righ?",Motivation
11058,"For example, let's say I have a Python function which returns a new batch on each call (a generator).",Motivation
11059,"Problematic was that the program just stopped and waited for some process to begin filling the queue, but there was non, so it just did nothing, but also didn't throw an exception or give any kind of warning, which made understanding what was happening a bit difficult.",Motivation
11060,Which and how many samples are generated differs per epoch (potentially conditional on past training behavior).,Motivation
11061,"Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect!",Motivation
11062,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
11063,"2.         An easy and established way to change the input pipeline of a graph, after it has been created, because it is the most typical usage pattern.",Motivation
11064,I'm still not sure what you're suggesting is the practical difference due to inferring categories from the max value.,Motivation
11065,I don't see how the proposed change would help with the missing values that much.,Motivation
11066,Example: I trained using TFRecords and input queues; I got my weights/model.,Motivation
11067,-         One of our models is a localization model.,Motivation
11068,A collection of train/valid/test data or simply a collection of data?,Motivation
11069,A couple of concrete use cases that come up for us:,Motivation
11070,"A worker takes a few documents off the task queue, aggregates the vocabulary, and asks the vectors service for all vectors active on the batch.",Motivation
11071,"By the way CODE does only inference, no training, so no backpropagation.",Motivation
11072,This is one of the blocking issues for us now.,Motivation
11073,"However, our case is very high-load system with streaming data (hundreds of thousands emails per day).",Motivation
11074,"But for streaming text, especially for social media where new terms are invented by the minute (hashtags and URLs in particular) this assumption no longer holds and the spacy vocabulary storage represents a dynamic element in what should be a completely static production deployment.",Motivation
11075,"As far as I understand it, CODE preserves a 1:1 mapping, which is not sufficient for our use case.",Motivation
11076,Are each data item (input/target) couple?,Motivation
11077,(the output you get depending on the data you have),Motivation
11078,The CODE class described in the original post already exists in Python: it is a list of tuples.,Motivation
11079,"As @yaroslavvb mentioned, the CODEfeed_dictCODE memcpy (on a single CPU core?) can be a huge performance bottleneck, and I'd like to see this addressed in any refactor of TensorFlow's input handling.",Motivation
11080,Primarily I am interested in using it to switch between training and validation datasets in the same process.,Motivation
11081,*         See #7525 and [many more Stack Overflow questions] URL  for an example of the confusing error.,Motivation
11082,"*         @omoindrot: I agree that the CODE construction is pretty ugly, and we should try to find ways to improve it.",Motivation
11083,"-         Reimplementing our data loading and transformation pipeline with TF primitives, perhaps with CODE, but still using the TF API for managing queue runners",Motivation
11084,A couple of concrete use cases that come up for us:,Motivation
11085,-         One of our models is a localization model.,Motivation
11086,It's our most upvoted issue.,Motivation
11087,"When using CODE, this is very simple, and this is what I'm used to.",Motivation
11088,*         See #6845 for a discussion of input pipeline performance.,Motivation
11089,"*         Once you reach the end of a pipeline, it becomes closed and you can never use it again in the same session.",Motivation
11090,-         One of our models is a localization model.,Motivation
11091,"-         We want to add an option specific to one of the encodings (eg for 'onehot' encoding to drop the first (redundant) column, or for 'ordinal' encoding base the order of the categories on the frequency, ...).",Motivation
11092,The use case is when you want to combine several estimators together.,Motivation
11093,Reason: the automatic preevaluation of pending enqueues.,Motivation
11094,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
11095,"My goal: POS tag the English language Wikipedia dump (approx 23GB, maybe 3B words).",Motivation
11096,"Not ideal, but also not a big deal imho.",Motivation
11097,"Then test it on my cross-validation set and if my cv score is still falling, I can continue training.",Motivation
11098,"We primarily deal with time series data, and prefer to not have to batch preprocess the whole dataset prior to training every unique model input architecture.",Motivation
11099,"In a way this information is already contained in word vectors because two verbs will be seen in more similar contexts than adjectives but guess that by reducing ambiguity and ""false positives"" it could make quite a difference.",Motivation
11100,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
11101,"Here's the paper I mentioned, titled ""sense2vec"": http://arxiv.org/pdf/1511.06388.pdf , by @iamtrask",Motivation
11102,"Are there any specific operations that you perform at the end of a ""data set"" or can your training loop handle the concatenation of records from different ""data sets""?",Motivation
11103,"While TensorFlow has several methods that can be used to build complex input pipelines (such as [CODE] URL , [CODE] URL , etc.), they were designed for a particular use case (processing a static set of files repeatedly), and the average user experience with these methods is not great.",Motivation
11104,"It is natural for average-like ensembles, but makes no sense in boosted ensembles.",Motivation
11105,Because JavaScript is Awesome,Motivation
11106,Currently using spacy to get the POS tags. (from sentence subtree etc),Motivation
11107,"I'm using that and following your sense2vec implementation, with a few changes, to attempt the [word clustering that is mentioned on Google Code word2vec page] URL .",Motivation
11108,(although they can be modeled by its primitives).,Motivation
11109,generator?,Motivation
11110,There's been a few things that are currently missing and I had to work around:,Motivation
11111,Ideally we would get rid of all the weird behaviors.,Motivation
11112,This lets you see different vectors for CODE and CODE.,Motivation
11113,We're announcing this plan early because we want to collect feedback on what features you&mdash;as TensorFlow users&mdash;would like to see in an input pipeline API.,Motivation
11114,What other pain points have we missed?,Motivation
11115,"We use scikit-image CODE objects to apply cropping and resizing operations for this model, because those objects let us easily translate our model output back to the original input coordinate space.",Motivation
11116,"Until the fix is available, the only workaround is todowngrade to CUDA 8.0.xor disable XLA:GPU.",Motivation
11117,"Then, CODE is created by (randomly) iterating over each element CODE of CODE, and for each of these elements the function CODE samples a (variable) number of sub-images [and sub-labels] (e.g. 256x256 each) from CODE, taken from various regions of CODE.",Motivation
11118,"It's relatively straightforward for us to, in Python, generate a new draw from our original data set for every epoch, but it seems like in the API proposed above, we'd have to figure out how to implement this behavior as an CODE, which seems less straightforward.",Motivation
11119,This concept is inspired by [dask distributed] URL  and other executor frameworks -- I think the flexibility offered by this abstraction is great!,Motivation
11120,"For me it would be brilliant, because I have 100+ [Celery] URL  workers and the 100M for each instance to load the vector model makes it hard to scale across docker containers.",Motivation
11121,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
11122,We might end up with use-cases where the vectors data is many gigabytes.,Motivation
11123,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
11124,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
11125,The question is how frequently users have such consecutive integers as categories without having used LabelEncoder as the previous step ..,Motivation
11126,I can only find some basic infos in the C++ API docs.,Motivation
11127,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
11128,"And in the future when we want to load more advanced, and possible context dependant models, and on the fly language switching it would be even more necessary.",Motivation
11129,"Actually, we don't even use the nomenclature of an epoch anymore, since the same data is never seen twice, and above mentioned generation/sampling goes beyond the usual data augmentation.",Motivation
11130,"I also had issues with pickling with [SFrame] URL , which behaves similarly to how Spark has been described to work here.",Motivation
11131,directory?,Motivation
11132,Why would anyone need another Javascript library?,Motivation
11133,This would make it easier to coordinate multiple elements of a model that all want to read from the iterator before advancing it one step.,Motivation
11134,The number of elements generated each time is variable and conditional on the properties of element CODE.,Motivation
11135,I often try to use TensorFlow on very large inputs (potentially >1GB minibatch) with relatively light computation on each minibatch.,Motivation
11136,What features do you miss from other systems?,Motivation
11137,"However, our case is very high-load system with streaming data (hundreds of thousands emails per day).",Motivation
11138,2.         (theoretically) doesn't require an extra python thread in the training process.,Motivation
11139,"It is by far the most flexible, makes debugging way easier and makes for much simpler code.",Motivation
11140,What @drasmuss suggests is very useful for segmentation tasks where both labels and images need to be augmented.,Motivation
11141,I think that a *huge* effort should be placed in tutorials: the hugest difficulty I am having -- and some colleagues with me -- is that the documentation that you can find is quite lousy and not very self-contained.,Motivation
11142,"Are there any specific operations that you perform at the end of a ""data set"" or can your training loop handle the concatenation of records from different ""data sets""?",Motivation
11143,"A similar pattern turns up in many different settings, including [Java's Stream API] URL , [Scala's collections] URL  (and hence Spark's RDDs), and [.NET's Language Integrated Query] URL .",Motivation
11144,"This currently doesn't work with plain pickle, failing as follows: CODE",Motivation
11145,"It is probably most useful in an interactive setting, righ?",Motivation
11146,Assume CODE is a list of large images (e.g. 8192x8192 each) [with corresponding labels].,Motivation
11147,"With consistency, are you pointing to the naming scheme of ""what it accepts"" vs ""what it does"" ?",Motivation
11148,This would make it easier to coordinate multiple elements of a model that all want to read from the iterator before advancing it one step.,Motivation
11149,We are not consistent in naming anywhere.,Motivation
11150,This lets you see different vectors for CODE and CODE.,Motivation
11151,"I mainly created this issue in case someone else is running into similar problems when trying spaCy on Spark, as the error messages raised by Spark when failing to pickle the language models are not very helpful (workers just crash because of segmentation fault).",Motivation
11152,"[**TL;DR:** We're designing a new input pipeline API for TensorFlow, and we'd like to collect your feature requests on this issue.]",Motivation
11153,"I would have imagined that if we had a stacking interface, you could specify one estimator as the base estimator and another as the one on top.",Motivation
11154,"And what is a ""dataset"", anyway?",Motivation
11155,This doesn't seem to be supported?,Motivation
11156,I think that a *huge* effort should be placed in tutorials: the hugest difficulty I am having -- and some colleagues with me -- is that the documentation that you can find is quite lousy and not very self-contained.,Motivation
11157,"-         With CODE I was able to solve most of my input-related problems, like loading .mat files in a symbolic-ish manner.",Motivation
11158,For me it is mainly a question of scalability in adding more features to a single class.,Motivation
11159,As quoted from the offical website http://www.tensorflow.org/,Motivation
11160,And the people at the university of Groningen would probably be happy to see another parser for Dutch so they can compare Alpino to it :),Motivation
11161,I would like to train a small number of sub-estimators at a time (and wait a relatively short time).,Motivation
11162,We do not expect afix for CUDA 9.0.x.,Motivation
11163,What other pain points have we missed?,Motivation
11164,"I currently use this method with CODE ops and it works nicely but I'd like to find a way to do this for evaluation as well (and figured maybe Dataset is a good way to do this with the ""reintializable"" iterator).",Motivation
11165,One simple sub case is where a column is numerical but has some missing values.,Motivation
11166,"My goal: POS tag the English language Wikipedia dump (approx 23GB, maybe 3B words).",Motivation
11167,"I am only starting to read into the new API, but I want to share two problems that I had with the old Input Queues in concurrence with using MonitoredSession with SessionRunHooks.",Motivation
11168,@khelkun answer is rather simple: providing mature JavaScript package that allows easy interaction with Tensorflow opens myriad new possibilities.,Motivation
11169,it would be great if we could do this without re-generate the training data.,Motivation
11170,I'm trying to do some work on the text from Wiki Dump.,Motivation
11171,I've been trying to do NLP with Spark with NLTK and Stanford and etc.,Motivation
11172,"Then we want to run it faster, we would change the worker count to 20, 30, 40, ...",Motivation
11173,"-         We have data that comes from a large number of imbalanced segments, and in training we use some custom stratified sampling logic to ensure we present examples from each segment evenly.",Motivation
11174,I can pick up pytorch's dataset API in 5 minutes and it's good enough for all the popular academic datasets.,Motivation
11175,"At the moment, we don't perform specific operations at the end of each data set, i.e. everything gets put into the same (large) random shuffle queue, to mix samples between data sets.",Motivation
11176,As you mentioned that would be heaven to see this code just work: CODE,Motivation
11177,Here is a feature that would help my use-case:,Motivation
11178,"I'd love to have fast, parallel GPU compute power at my fingertips with the ease and composability of JS.",Motivation
11179,"@amueller, are you persuaded by the issue that we ultimately want different additional parameters (e.g. drop_first, nan handling) depending on the encoding, and that justifies having a different discrete encoder for each encoding format?",Motivation
11180,*         See #7945 and [many Stack Overflow questions] URL  for some examples of users who have been bitten by this problem.,Motivation
11181,"As you can see, the real-world problems are more than just feeding into a series of images or texts.",Motivation
11182,"1.         Can use whatever tools/languages to produce data from any sources, as long as they're finally sent with certain message protocol.",Motivation
11183,it deserves a redesign.,Motivation
11184,It seems tricky to square this with a fully tensor-based API.,Motivation
11185,-         The keyword argument CODE specifies *how* to encode those data,Motivation
11186,"-         We want to add an option specific to one of the encodings (eg for 'onehot' encoding to drop the first (redundant) column, or for 'ordinal' encoding base the order of the categories on the frequency, ...).",Motivation
11187,Our biggest issue with the current data loading scheme is just that it's very complicated and involves a lot of new concepts.,Motivation
11188,generator?,Motivation
11189,"-         We want to add an option specific to one of the encodings (eg for 'onehot' encoding to drop the first (redundant) column, or for 'ordinal' encoding base the order of the categories on the frequency, ...).",Motivation
11190,"and telling people ""if you want to one hotencode strings, go to CategoricalEncoder instead"" is awkward, because OHEis already intended for categoricals...",Motivation
11191,"-         We want to add more encoding options (eg binary encoding, mean target encoding, unary encoding, ...).",Motivation
11192,"I'd like to change the current set up, because I want to support vectors keyed by different information, e.g. vectors keyed by lemma and part-of-speech.",Motivation
11193,A couple of concrete use cases that come up for us:,Motivation
11194,"Currently it is certainly still OK, there are not too many incompatible options (but also partly because I moved CODE into the CODE option).",Motivation
11195,This was mostly an issue where the GPU would get the data from the CPU.,Motivation
11196,"*         The current pipelines use TensorFlow queues and multiple Python threads, which can lead to poor performance (lock contention in the queues and the Python GIL) and hard-to-understand exceptions (CODE).",Motivation
11197,There is something slightly similar in the adaboost pr: #522.,Motivation
11198,"When running with multiple GPUs, TensorFlow is not able to even saturate the PCI-e bandwidth to the GPUs because of the memcpy from the feed_dict to the CPU tensor.",Motivation
11199,"As you can see, the real-world problems are more than just feeding into a series of images or texts.",Motivation
11200,"With consistency, are you pointing to the naming scheme of ""what it accepts"" vs ""what it does"" ?",Motivation
11201,"This is necessary for most of the applications at OpenAI, here's one example -- https://github.com/openai/universe-starter-agent",Motivation
11202,Ideally we would get rid of all the weird behaviors.,Motivation
11203,"I'd like to change the current set up, because I want to support vectors keyed by different information, e.g. vectors keyed by lemma and part-of-speech.",Motivation
11204,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
11205,"For example, a CODE receives the number of epochs to be generated but there seems to be no way of knowing the epoch of one sample without counting how many we have already evaluated.",Motivation
11206,"(Indirectly, this could also be used to implement subsampling strategies or for monitoring the fitting process.)",Motivation
11207,Could you link the papers here and I'll have a look at that as well.,Motivation
11208,"Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect!",Motivation
11209,I'm giving a shot at migrating to tensorflow for our deep learning models for devices; but the input pipeline is so tightly bound to the rest of the compute graph that its like performing surgery to run inference against it.,Motivation
11210,@jnothman I suppose you acknowledge there *can* be a difference in practice?,Motivation
11211,"I also had issues with pickling with [SFrame] URL , which behaves similarly to how Spark has been described to work here.",Motivation
11212,*         See #7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.,Motivation
11213,"The more diverse they are, often the better.",Motivation
11214,"The Python threading API isn't perfect, but in general when we're doing mostly non-GIL-taking tasks in NumPy or whatever, the TF queue API seems more of a burden than a help.",Motivation
11215,"I think he is right, that extending the documentation and providing better tutorials is highly important.",Motivation
11216,"Where we're stuck is that to optimally follow recommendations, we end up in an awkward situation, one of:",Motivation
11217,This lets you see different vectors for CODE and CODE.,Motivation
11218,I don't see how the proposed change would help with the missing values that much.,Motivation
11219,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
11220,"There's a diversity of visions out there on friendly modern high-level idiomatic JS and ML APIs, each catering to different use cases.",Motivation
11221,It's close integration with Spark will be a great advantage for many researchers.,Motivation
11222,I've seen dozens and dozens of cases where (in the profiler; iirc MEMCpyWhatever) was really slow.,Motivation
11223,-         The keyword argument CODE specifies *how* to encode those data,Motivation
11224,"*         @omoindrot: I agree that the CODE construction is pretty ugly, and we should try to find ways to improve it.",Motivation
11225,"It's relatively straightforward for us to, in Python, generate a new draw from our original data set for every epoch, but it seems like in the API proposed above, we'd have to figure out how to implement this behavior as an CODE, which seems less straightforward.",Motivation
11226,"Personally, I'm a very big fan of the CODE method of feeding data into the graph.",Motivation
11227,And having incompatible options is something that happens often in scikit-learn.,Motivation
11228,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
11229,A couple of concrete use cases that come up for us:,Motivation
11230,"I'm using that and following your sense2vec implementation, with a few changes, to attempt the [word clustering that is mentioned on Google Code word2vec page] URL .",Motivation
11231,"*         The pipelines behave poorly if you forget to call CODE: in fact, they hang indefinitely and deadlock the user program.",Motivation
11232,"Personally, I'm a very big fan of the CODE method of feeding data into the graph.",Motivation
11233,"-         We have data that comes from a large number of imbalanced segments, and in training we use some custom stratified sampling logic to ensure we present examples from each segment evenly.",Motivation
11234,Currently I am worried that my training/prediction preprocessing will diverge over time.,Motivation
11235,What other pain points have we missed?,Motivation
11236,"My goal: POS tag the English language Wikipedia dump (approx 23GB, maybe 3B words).",Motivation
11237,"These inputs are in a HDF5 file or a Numpy array either on disk or in memory, so I typically feed with CODEfeed_dictCODE, potentially asynchronously into a queue.",Motivation
11238,*         See #7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.,Motivation
11239,"Current CODE provides such functionality, but it is rather hacky.",Motivation
11240,"This currently doesn't work with plain pickle, failing as follows: CODE",Motivation
11241,(2) data can be generated from different machines if the pre-processing is too heavy for a single CPU.,Motivation
11242,3.         A way to control and monitor the epochs - currently they are rather deeply hidden and unaccessible even simple checks.,Motivation
11243,It seems tricky to square this with a fully tensor-based API.,Motivation
11244,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation
11245,See [tensorflow/go/genop/main.go] URL  and [tensorflow/go/op/generate.go] URL  for inspiration.,Motivation
11246,"These inputs are in a HDF5 file or a Numpy array either on disk or in memory, so I typically feed with CODEfeed_dictCODE, potentially asynchronously into a queue.",Motivation
11247,"Then test it on my cross-validation set and if my cv score is still falling, I can continue training.",Motivation
11248,We are not consistent in naming anywhere.,Motivation
11249,See issue here: http://stackoverflow.com/questions/43708616/tensorflow-inference,Motivation
11250,"Like, think trigram vectors, or vectors for subject/verb/object triples.",Motivation
11251,"Now when I switched from a normal Session to using MonitoredSession and added a logging hook and told it to log the 'accuracy' tensor, it tried in vain to evaluate the first session run call as the hook had added that tensor to the fetch list, but with the queue being still empty there was no way to evaluate accuracy yet.",Motivation
11252,In which setting do you want to do that except for parallelization?,Motivation
11253,Or better: in what use cases do you need a different interface for boosted ensembles and bagging?,Motivation
11254,"I mainly created this issue in case someone else is running into similar problems when trying spaCy on Spark, as the error messages raised by Spark when failing to pickle the language models are not very helpful (workers just crash because of segmentation fault).",Motivation
11255,"In fact for these kinds of higher-level abstractions, sooner seems better than later â one of the greatest frustrations of reading published TF research code is that the vast majority of codebases use their own idiosyncratic layers library, as opposed to e.g. the ones in CODE or CODE, and these libraries are all different, which makes it more difficult than it should be to share work.",Motivation
11256,"The Python threading API isn't perfect, but in general when we're doing mostly non-GIL-taking tasks in NumPy or whatever, the TF queue API seems more of a burden than a help.",Motivation
11257,Assume CODE is a list of large images (e.g. 8192x8192 each) [with corresponding labels].,Motivation
11258,"Here's the paper I mentioned, titled ""sense2vec"": http://arxiv.org/pdf/1511.06388.pdf , by @iamtrask",Motivation
11259,I'd like to understand your use case a little better.,Motivation
11260,"Right now, this method starves my GPU all the time, which is a shame because most other DL frameworks (even those based on computational graphs) manage to make this much more performantly.",Motivation
11261,"-         Reimplementing our data loading and transformation pipeline with TF primitives, perhaps with CODE, but still using the TF API for managing queue runners",Motivation
11262,"a monitor api is very flexible but actually you want to do early stopping **every time** you use an estimator, right?",Motivation
11263,"Long story short: With a slightly out-of-the-ordinary use case, we've been hit by pretty much all of the problems you have mentioned above, and our workarounds have not been pretty.",Motivation
11264,(although they can be modeled by its primitives).,Motivation
11265,"3.         If the message protocol supports pub/sub, then (1) multiple training sessions can subcribe and reuse the same input data, which is very useful when trying new models.",Motivation
11266,"anyway, JavaScript is awesome!",Motivation
11267,@pprett I think there should be an easy way to do easy things.,Motivation
11268,We are not consistent in naming anywhere.,Motivation
11269,"Then, CODE is created by (randomly) iterating over each element CODE of CODE, and for each of these elements the function CODE samples a (variable) number of sub-images [and sub-labels] (e.g. 256x256 each) from CODE, taken from various regions of CODE.",Motivation
11270,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
11271,In case of Stacking the estimators might be completely different (say to you want to merge forests with svms).,Motivation
11272,"Until the fix is available, the only workaround is todowngrade to CUDA 8.0.xor disable XLA:GPU.",Motivation
11273,"I notice TensorFlow is now accessible from Go, Rust and Haskell.",Motivation
11274,"What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.",Motivation
11275,(2) data can be generated from different machines if the pre-processing is too heavy for a single CPU.,Motivation
11276,What @drasmuss suggests is very useful for segmentation tasks where both labels and images need to be augmented.,Motivation
11277,This results in garbage results and/orCUDA_ERROR_ILLEGAL_ADDRESS failures.,Motivation
11278,"I'd support @nicolasdespres for ""no Dataset"" pledge, mainly because all-in-one bundle is not flexible, not future proof and also - not consistent with the TF's paradigm of providing small, stable, well-defined and assemble-able blocks for building custom models.",Motivation
11279,"I'd like to understand more about your use case, though.",Motivation
11280,Why ignore JavaScript ?,Motivation
11281,-         One of our models is a localization model.,Motivation
11282,I'm just wondering about what things users will come up with (w.r.t. data generation and usage) that would otherwise require (specific) additions to the API...,Motivation
11283,"In dealing with RL problems and the training replay buffer, I couldn't find an easy way to use the Queues to speed up this feeding of samples through the feed_dict.",Motivation
11284,"I mainly created this issue in case someone else is running into similar problems when trying spaCy on Spark, as the error messages raised by Spark when failing to pickle the language models are not very helpful (workers just crash because of segmentation fault).",Motivation
11285,"For example the images could very reasonably use bilinear interpolation, but interpolating label values is not okay because a label pixel boundary of 0 and 2 should not be interpolated to the completely different label of 1.",Motivation
11286,See [tensorflow/go/genop/main.go] URL  and [tensorflow/go/op/generate.go] URL  for inspiration.,Motivation
11287,"Here's the paper I mentioned, titled ""sense2vec"": http://arxiv.org/pdf/1511.06388.pdf , by @iamtrask",Motivation
11288,That is one of my biggest issues with the current API.,Motivation
11289,3.         A way to control and monitor the epochs - currently they are rather deeply hidden and unaccessible even simple checks.,Motivation
11290,"When using CODE, this is very simple, and this is what I'm used to.",Motivation
11291,Example: I trained using TFRecords and input queues; I got my weights/model.,Motivation
11292,"1.         A decent way to make custom preprocessing of the data, whether it be based on queue's or not, the idea of being able to foresee all possible data input needs is doomed.",Motivation
11293,I would like to train a small number of sub-estimators at a time (and wait a relatively short time).,Motivation
11294,"And in the future when we want to load more advanced, and possible context dependant models, and on the fly language switching it would be even more necessary.",Motivation
11295,"Personally, I'm a very big fan of the CODE method of feeding data into the graph.",Motivation
11296,"In fact for these kinds of higher-level abstractions, sooner seems better than later â one of the greatest frustrations of reading published TF research code is that the vast majority of codebases use their own idiosyncratic layers library, as opposed to e.g. the ones in CODE or CODE, and these libraries are all different, which makes it more difficult than it should be to share work.",Motivation
11297,In case of Stacking the estimators might be completely different (say to you want to merge forests with svms).,Motivation
11298,"Long story short: With a slightly out-of-the-ordinary use case, we've been hit by pretty much all of the problems you have mentioned above, and our workarounds have not been pretty.",Motivation
11299,It may not be the right place to ask but I'd like to know why others developers look for a nodejs api/add-on for tensorflow ?,Motivation
11300,"[**TL;DR:** We're designing a new input pipeline API for TensorFlow, and we'd like to collect your feature requests on this issue.]",Motivation
11301,"At the moment, we don't perform specific operations at the end of each data set, i.e. everything gets put into the same (large) random shuffle queue, to mix samples between data sets.",Motivation
11302,And I think the idea of partial language support is important and overdue.,Motivation
11303,Google discovered in mid-December 2017 that the PTX-to-SASS compiler in CUDA 9and CUDA 9.1 sometimes does not properly compute the carry bit whendecomposing 64-bit address calculations with large offsets (e.g. load [x + large_constant]) into 32-bit arithmetic in SASS.,Motivation
11304,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
11305,In case of Stacking the estimators might be completely different (say to you want to merge forests with svms).,Motivation
11306,"-         We want to add more encoding options (eg binary encoding, mean target encoding, unary encoding, ...).",Motivation
11307,This is one of the blocking issues for us now.,Motivation
11308,See issue here: http://stackoverflow.com/questions/43708616/tensorflow-inference,Motivation
11309,"I'd like to understand more about your use case, though.",Motivation
11310,"Also, when randomly creating a sample set, it seemed like the samples were consumed when I wanted them left in the buffer.",Motivation
11311,-         Using CODE and suffering any relevant performance hits,Motivation
11312,What is the use-case for your interface except parallelization?,Motivation
11313,"How frequently do you move from one outer ""data set"" to the next?",Motivation
11314,"Apache Spark ships with a package called [cloudpickle] URL  which is meant to support a wider set of Python constructs, but serialisation with cloudpickle also fails resulting in a segmentation fault: CODE",Motivation
11315,"It's relatively straightforward for us to, in Python, generate a new draw from our original data set for every epoch, but it seems like in the API proposed above, we'd have to figure out how to implement this behavior as an CODE, which seems less straightforward.",Motivation
11316,It seems tricky to square this with a fully tensor-based API.,Motivation
11317,This was mostly an issue where the GPU would get the data from the CPU.,Motivation
11318,This doesn't seem to be supported?,Motivation
11319,Could you link the papers here and I'll have a look at that as well.,Motivation
11320,"By default Apache Spark uses pickle, but can be told to use cloudpickle instead.",Motivation
11321,"@amueller, are you persuaded by the issue that we ultimately want different additional parameters (e.g. drop_first, nan handling) depending on the encoding, and that justifies having a different discrete encoder for each encoding format?",Motivation
11322,"That implements predicting with a subset of the estimators, which is also very helpful.",Motivation
11323,Or a '(mean) target encoder'?,Motivation
11324,Example: I trained using TFRecords and input queues; I got my weights/model.,Motivation
11325,*         See #7945 and [many Stack Overflow questions] URL  for some examples of users who have been bitten by this problem.,Motivation
11326,This would make it easier to coordinate multiple elements of a model that all want to read from the iterator before advancing it one step.,Motivation
11327,What @drasmuss suggests is very useful for segmentation tasks where both labels and images need to be augmented.,Motivation
11328,I often try to use TensorFlow on very large inputs (potentially >1GB minibatch) with relatively light computation on each minibatch.,Motivation
11329,"JavaScript operates on every mobile platform, all major desktop Operating systems & in all the browsers so possibilities are endless.",Motivation
11330,"In another instance, it might return 389 new pairs, etc.",Motivation
11331,"*         The pipelines behave poorly if you forget to call CODE: in fact, they hang indefinitely and deadlock the user program.",Motivation
11332,(although they can be modeled by its primitives).,Motivation
11333,"1.         A decent way to make custom preprocessing of the data, whether it be based on queue's or not, the idea of being able to foresee all possible data input needs is doomed.",Motivation
11334,"and telling people ""if you want to one hotencode strings, go to CategoricalEncoder instead"" is awkward, because OHEis already intended for categoricals...",Motivation
11335,"It's awkward to ask for batch_size as a parameter during fitting and during dataset/queue creation, and ideally the compute graph doesn't have batch_size baked in.",Motivation
11336,"*         The current pipelines use TensorFlow queues and multiple Python threads, which can lead to poor performance (lock contention in the queues and the Python GIL) and hard-to-understand exceptions (CODE).",Motivation
11337,"*         There is a clearer distinction between input shapes, for training you usually want batches, but for prediction you often care only about single examples",Motivation
11338,It seems tricky to square this with a fully tensor-based API.,Motivation
11339,"As a result, these versions of ptxas miscompile most XLA programs which usemore than 4GB of temp memory.",Motivation
11340,*         See #7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.,Motivation
11341,The benefits are:,Motivation
11342,Because otherwise the people will stick with feed_dict inputs until TensorFlow 3.0 and moan about bad performance of TF,Motivation
11343,A collection of train/valid/test data or simply a collection of data?,Motivation
11344,"*         The pipelines behave poorly if you forget to call CODE: in fact, they hang indefinitely and deadlock the user program.",Motivation
11345,"I'd love to have fast, parallel GPU compute power at my fingertips with the ease and composability of JS.",Motivation
11346,"Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect!",Motivation
11347,I'm trying to do some work on the text from Wiki Dump.,Motivation
11348,The CODE class described in the original post already exists in Python: it is a list of tuples.,Motivation
11349,Is the dictionary part of the text dataset?,Motivation
11350,#8168,Motivation
11351,"I'd like to change the current set up, because I want to support vectors keyed by different information, e.g. vectors keyed by lemma and part-of-speech.",Motivation
11352,This could make things easier too.,Motivation
11353,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation
11354,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
11355,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
11356,"We use scikit-image CODE objects to apply cropping and resizing operations for this model, because those objects let us easily translate our model output back to the original input coordinate space.",Motivation
11357,The benefits are:,Motivation
11358,So summary of how it is now:,Motivation
11359,Because NodeJS it's fast!,Motivation
11360,There is something slightly similar in the adaboost pr: #522.,Motivation
11361,Below is why we need it:,Motivation
11362,I'd like to understand your use case a little better.,Motivation
11363,We are not consistent in naming anywhere.,Motivation
11364,"A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.",Motivation
11365,@jnothman I suppose you acknowledge there *can* be a difference in practice?,Motivation
11366,This would be interesting for pure front-end graph exportation for direct Solution Usage on web clients.,Motivation
11367,I'm still not sure what you're suggesting is the practical difference due to inferring categories from the max value.,Motivation
11368,"It's relatively straightforward for us to, in Python, generate a new draw from our original data set for every epoch, but it seems like in the API proposed above, we'd have to figure out how to implement this behavior as an CODE, which seems less straightforward.",Motivation
11369,@jnothman I suppose you acknowledge there *can* be a difference in practice?,Motivation
11370,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation
11371,What @drasmuss suggests is very useful for segmentation tasks where both labels and images need to be augmented.,Motivation
11372,Iterators implementing CODE are great for progress report.,Motivation
11373,"These inputs are in a HDF5 file or a Numpy array either on disk or in memory, so I typically feed with CODEfeed_dictCODE, potentially asynchronously into a queue.",Motivation
11374,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation
11375,"More specifically, we currently have a use case where we employ two queues; an outer one, using a string_input_producer (with shuffling), where each string denotes/points to a ""data set"", and the inner queue is then produced by generating a variable amount of samples from each ""data set"".",Motivation
11376,And documented too (when it comes to CODE).,Motivation
11377,"If not too difficult from your end, having the language models pickleable would provide a better out of box experience for Apache Spark users.",Motivation
11378,"That implements predicting with a subset of the estimators, which is also very helpful.",Motivation
11379,"Where we're stuck is that to optimally follow recommendations, we end up in an awkward situation, one of:",Motivation
11380,"*         The current pipelines use TensorFlow queues and multiple Python threads, which can lead to poor performance (lock contention in the queues and the Python GIL) and hard-to-understand exceptions (CODE).",Motivation
11381,I'm just wondering about what things users will come up with (w.r.t. data generation and usage) that would otherwise require (specific) additions to the API...,Motivation
11382,"Then, CODE is created by (randomly) iterating over each element CODE of CODE, and for each of these elements the function CODE samples a (variable) number of sub-images [and sub-labels] (e.g. 256x256 each) from CODE, taken from various regions of CODE.",Motivation
11383,They are great.,Motivation
11384,"-         We want to add an option specific to one of the encodings (eg for 'onehot' encoding to drop the first (redundant) column, or for 'ordinal' encoding base the order of the categories on the frequency, ...).",Motivation
11385,"I would have imagined that if we had a stacking interface, you could specify one estimator as the base estimator and another as the one on top.",Motivation
11386,Redoing this for consistency in naming is not worth it imho.,Motivation
11387,"In fact for these kinds of higher-level abstractions, sooner seems better than later â one of the greatest frustrations of reading published TF research code is that the vast majority of codebases use their own idiosyncratic layers library, as opposed to e.g. the ones in CODE or CODE, and these libraries are all different, which makes it more difficult than it should be to share work.",Motivation
11388,more code (on earth) is written in javascript than ANY other high level language..,Motivation
11389,We've noticed that one of the biggest challenges in getting started with TensorFlow is how to load your own data into your programs.,Motivation
11390,"I'd like to understand more about your use case, though.",Motivation
11391,For example:,Motivation
11392,"*         Once you reach the end of a pipeline, it becomes closed and you can never use it again in the same session.",Motivation
11393,A couple of concrete use cases that come up for us:,Motivation
11394,The choice of the data container is driven by a lot of constrains depending on its size and the execution environment.,Motivation
11395,Ideally we would get rid of all the weird behaviors.,Motivation
11396,"Until the fix is available, the only workaround is todowngrade to CUDA 8.0.xor disable XLA:GPU.",Motivation
11397,"-         We want to add an option specific to one of the encodings (eg for 'onehot' encoding to drop the first (redundant) column, or for 'ordinal' encoding base the order of the categories on the frequency, ...).",Motivation
11398,"Long story short: With a slightly out-of-the-ordinary use case, we've been hit by pretty much all of the problems you have mentioned above, and our workarounds have not been pretty.",Motivation
11399,"1.         Can use whatever tools/languages to produce data from any sources, as long as they're finally sent with certain message protocol.",Motivation
11400,For me it is mainly a question of scalability in adding more features to a single class.,Motivation
11401,"The Python threading API isn't perfect, but in general when we're doing mostly non-GIL-taking tasks in NumPy or whatever, the TF queue API seems more of a burden than a help.",Motivation
11402,"It does not help *as such*, but it makes it less complex to have specific options specifically tailored to the different encoding types.",Motivation
11403,This would make it easier to coordinate multiple elements of a model that all want to read from the iterator before advancing it one step.,Motivation
11404,As opposed to training a large number of sub-estimators and waiting a long time (several hours for me).,Motivation
11405,"Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect!",Motivation
11406,"I would have imagined that if we had a stacking interface, you could specify one estimator as the base estimator and another as the one on top.",Motivation
11407,Need use bothTensorflow andTSNEin Jupyter notebook ....,Motivation
11408,"What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.",Motivation
11409,I have been using spacy for streaming data (twitter and news stories mostly) and I believe that the fundamental design of the vocab/StringStore in spacy is problematic for streaming processing.,Motivation
11410,2.         (theoretically) doesn't require an extra python thread in the training process.,Motivation
11411,"In a way this information is already contained in word vectors because two verbs will be seen in more similar contexts than adjectives but guess that by reducing ambiguity and ""false positives"" it could make quite a difference.",Motivation
11412,Using XLA:GPU with CUDA 9 and CUDA 9.1 results in garbage results and/orCUDA_ILLEGAL_ADDRESS failures.,Motivation
11413,I'm just wondering about what things users will come up with (w.r.t. data generation and usage) that would otherwise require (specific) additions to the API...,Motivation
11414,"2.         An easy and established way to change the input pipeline of a graph, after it has been created, because it is the most typical usage pattern.",Motivation
11415,"*         There is a clearer distinction between input shapes, for training you usually want batches, but for prediction you often care only about single examples",Motivation
11416,-         One of our models is a localization model.,Motivation
11417,Because otherwise the people will stick with feed_dict inputs until TensorFlow 3.0 and moan about bad performance of TF,Motivation
11418,CODE supports SparseTensor and automatic batching of SparseTensor would make my life a whole lot easier,Motivation
11419,"Personally, I'm a very big fan of the CODE method of feeding data into the graph.",Motivation
11420,Because NodeJS it's fast!,Motivation
11421,Many non-experts are using the following code http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow?answertab=votes#tab-top.,Motivation
11422,(although they can be modeled by its primitives).,Motivation
11423,Because NodeJS it's fast!,Motivation
11424,"Assume there is a large training data set which is in text format, and we need to convert it into tfrecord format.",Motivation
11425,Could you link the papers here and I'll have a look at that as well.,Motivation
11426,"Biggest benefits would come for sure from server-side applications that operate on node.js that could directly interact with Tensorflow, but also node-webkit (desktop applications) could potentially spawn dozens of interesting projects.",Motivation
11427,Iterators implementing CODE are great for progress report.,Motivation
11428,"*         The pipelines behave poorly if you forget to call CODE: in fact, they hang indefinitely and deadlock the user program.",Motivation
11429,"-         With CODE I was able to solve most of my input-related problems, like loading .mat files in a symbolic-ish manner.",Motivation
11430,Many non-experts are using the following code http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow?answertab=votes#tab-top.,Motivation
11431,"-         With CODE I was able to solve most of my input-related problems, like loading .mat files in a symbolic-ish manner.",Motivation
11432,The use case is when you want to combine several estimators together.,Motivation
11433,CODE supports SparseTensor and automatic batching of SparseTensor would make my life a whole lot easier,Motivation
11434,"anyway, JavaScript is awesome!",Motivation
11435,*         See #7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.,Motivation
11436,"-         We have data that comes from a large number of imbalanced segments, and in training we use some custom stratified sampling logic to ensure we present examples from each segment evenly.",Motivation
11437,"I'd support @nicolasdespres for ""no Dataset"" pledge, mainly because all-in-one bundle is not flexible, not future proof and also - not consistent with the TF's paradigm of providing small, stable, well-defined and assemble-able blocks for building custom models.",Motivation
11438,"But for streaming text, especially for social media where new terms are invented by the minute (hashtags and URLs in particular) this assumption no longer holds and the spacy vocabulary storage represents a dynamic element in what should be a completely static production deployment.",Motivation
11439,"Actually, we don't even use the nomenclature of an epoch anymore, since the same data is never seen twice, and above mentioned generation/sampling goes beyond the usual data augmentation.",Motivation
11440,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation
11441,the other factor for me is that everyone thinks the current auto mode inOneHotEncoder is weird.,Motivation
11442,"Not ideal, but also not a big deal imho.",Motivation
11443,"As I see it, the point of stacking is to combine the predictions of estimators of different nature.",Motivation
11444,"For example the images could very reasonably use bilinear interpolation, but interpolating label values is not okay because a label pixel boundary of 0 and 2 should not be interpolated to the completely different label of 1.",Motivation
11445,The number of elements generated each time is variable and conditional on the properties of element CODE.,Motivation
11446,Are each data item (input/target) couple?,Motivation
11447,"As far as I understand it, CODE preserves a 1:1 mapping, which is not sufficient for our use case.",Motivation
11448,"Like, think trigram vectors, or vectors for subject/verb/object triples.",Motivation
11449,In which setting do you want to do that except for parallelization?,Motivation
11450,This could make things easier too.,Motivation
11451,"We also used two separate queues, one handling input data_files as string names and the other one the resulting input data with preprocessing being done in between those two.",Motivation
11452,its implementation converting coo to csr is alsoweird.,Motivation
11453,"Then, CODE is created by (randomly) iterating over each element CODE of CODE, and for each of these elements the function CODE samples a (variable) number of sub-images [and sub-labels] (e.g. 256x256 each) from CODE, taken from various regions of CODE.",Motivation
11454,"Problematic was that the program just stopped and waited for some process to begin filling the queue, but there was non, so it just did nothing, but also didn't throw an exception or give any kind of warning, which made understanding what was happening a bit difficult.",Motivation
11455,I think that a *huge* effort should be placed in tutorials: the hugest difficulty I am having -- and some colleagues with me -- is that the documentation that you can find is quite lousy and not very self-contained.,Motivation
11456,"As @yaroslavvb mentioned, the CODEfeed_dictCODE memcpy (on a single CPU core?) can be a huge performance bottleneck, and I'd like to see this addressed in any refactor of TensorFlow's input handling.",Motivation
11457,"*         The pipelines behave poorly if you forget to call CODE: in fact, they hang indefinitely and deadlock the user program.",Motivation
11458,"a monitor api is very flexible but actually you want to do early stopping **every time** you use an estimator, right?",Motivation
11459,"My goal: POS tag the English language Wikipedia dump (approx 23GB, maybe 3B words).",Motivation
11460,What @drasmuss suggests is very useful for segmentation tasks where both labels and images need to be augmented.,Motivation
11461,I think that a *huge* effort should be placed in tutorials: the hugest difficulty I am having -- and some colleagues with me -- is that the documentation that you can find is quite lousy and not very self-contained.,Motivation
11462,@jnothman I suppose you acknowledge there *can* be a difference in practice?,Motivation
11463,@khelkun answer is rather simple: providing mature JavaScript package that allows easy interaction with Tensorflow opens myriad new possibilities.,Motivation
11464,"In dealing with RL problems and the training replay buffer, I couldn't find an easy way to use the Queues to speed up this feeding of samples through the feed_dict.",Motivation
11465,See issue here: http://stackoverflow.com/questions/43708616/tensorflow-inference,Motivation
11466,"We primarily deal with time series data, and prefer to not have to batch preprocess the whole dataset prior to training every unique model input architecture.",Motivation
11467,"In dealing with RL problems and the training replay buffer, I couldn't find an easy way to use the Queues to speed up this feeding of samples through the feed_dict.",Motivation
11468,It would be nice to have an official batch norm layer given its importance in training DNNs.,Motivation
11469,"For example the images could very reasonably use bilinear interpolation, but interpolating label values is not okay because a label pixel boundary of 0 and 2 should not be interpolated to the completely different label of 1.",Motivation
11470,There are clear problems with queues like you said.,Motivation
11471,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation
11472,"My goal: POS tag the English language Wikipedia dump (approx 23GB, maybe 3B words).",Motivation
11473,1.         Anything that helps me analyze if and where the bottleneck lies in the input pipeline would be great.,Motivation
11474,"This currently doesn't work with plain pickle, failing as follows: CODE",Motivation
11475,"By default Apache Spark uses pickle, but can be told to use cloudpickle instead.",Motivation
11476,"*         The current pipelines use TensorFlow queues and multiple Python threads, which can lead to poor performance (lock contention in the queues and the Python GIL) and hard-to-understand exceptions (CODE).",Motivation
11477,"2.         An easy and established way to change the input pipeline of a graph, after it has been created, because it is the most typical usage pattern.",Motivation
11478,Because otherwise the people will stick with feed_dict inputs until TensorFlow 3.0 and moan about bad performance of TF,Motivation
11479,What other pain points have we missed?,Motivation
11480,"*         Once you reach the end of a pipeline, it becomes closed and you can never use it again in the same session.",Motivation
11481,@jnothman I suppose you acknowledge there *can* be a difference in practice?,Motivation
11482,Which and how many samples are generated differs per epoch (potentially conditional on past training behavior).,Motivation
11483,Primarily I am interested in using it to switch between training and validation datasets in the same process.,Motivation
11484,Which and how many samples are generated differs per epoch (potentially conditional on past training behavior).,Motivation
11485,"It is natural for average-like ensembles, but makes no sense in boosted ensembles.",Motivation
11486,"And in the future when we want to load more advanced, and possible context dependant models, and on the fly language switching it would be even more necessary.",Motivation
11487,"@amueller, are you persuaded by the issue that we ultimately want different additional parameters (e.g. drop_first, nan handling) depending on the encoding, and that justifies having a different discrete encoder for each encoding format?",Motivation
11488,"The more diverse they are, often the better.",Motivation
11489,"In dealing with RL problems and the training replay buffer, I couldn't find an easy way to use the Queues to speed up this feeding of samples through the feed_dict.",Motivation
11490,For me it is mainly a question of scalability in adding more features to a single class.,Motivation
11491,"1.         Can use whatever tools/languages to produce data from any sources, as long as they're finally sent with certain message protocol.",Motivation
11492,I'm still not sure what you're suggesting is the practical difference due to inferring categories from the max value.,Motivation
11493,"Long story short: With a slightly out-of-the-ordinary use case, we've been hit by pretty much all of the problems you have mentioned above, and our workarounds have not been pretty.",Motivation
11494,"In dealing with RL problems and the training replay buffer, I couldn't find an easy way to use the Queues to speed up this feeding of samples through the feed_dict.",Motivation
11495,"As @yaroslavvb mentioned, the CODEfeed_dictCODE memcpy (on a single CPU core?) can be a huge performance bottleneck, and I'd like to see this addressed in any refactor of TensorFlow's input handling.",Motivation
11496,@pprett I think there should be an easy way to do easy things.,Motivation
11497,"and telling people ""if you want to one hotencode strings, go to CategoricalEncoder instead"" is awkward, because OHEis already intended for categoricals...",Motivation
11498,"I think he is right, that extending the documentation and providing better tutorials is highly important.",Motivation
11499,Can you explain that?,Motivation
11500,A couple of concrete use cases that come up for us:,Motivation
11501,its implementation converting coo to csr is alsoweird.,Motivation
11502,(2) data can be generated from different machines if the pre-processing is too heavy for a single CPU.,Motivation
11503,And this is why availability of a binary that supports 9.1 would be nice: (from the TF1.6 release notes),Motivation
11504,A fix in CUDA 9.1.121 is expected in late February 2018.,Motivation
11505,-         One of our models is a localization model.,Motivation
11506,Reason: the automatic preevaluation of pending enqueues.,Motivation
11507,"I'd love to have fast, parallel GPU compute power at my fingertips with the ease and composability of JS.",Motivation
11508,what about f** I just only want to use tensorflow1.8 and cuda9.1?,Motivation
11509,1.         Anything that helps me analyze if and where the bottleneck lies in the input pipeline would be great.,Motivation
11510,There are clear problems with queues like you said.,Motivation
11511,"Problematic was that the program just stopped and waited for some process to begin filling the queue, but there was non, so it just did nothing, but also didn't throw an exception or give any kind of warning, which made understanding what was happening a bit difficult.",Motivation
11512,*         See #6845 for a discussion of input pipeline performance.,Motivation
11513,"As I see it, the point of stacking is to combine the predictions of estimators of different nature.",Motivation
11514,Primarily I am interested in using it to switch between training and validation datasets in the same process.,Motivation
11515,"A similar pattern turns up in many different settings, including [Java's Stream API] URL , [Scala's collections] URL  (and hence Spark's RDDs), and [.NET's Language Integrated Query] URL .",Motivation
11516,What @drasmuss suggests is very useful for segmentation tasks where both labels and images need to be augmented.,Motivation
11517,We needed to make sure that the enqueue operations fills at least a certain multiple of the batch size into the first queue for our code to run without problems (otherwise the second input queue stalled),Motivation
11518,These are the features I really missed from a private system I've been using.,Motivation
11519,"-         Reimplementing our data loading and transformation pipeline with TF primitives, perhaps with CODE, but still using the TF API for managing queue runners",Motivation
11520,One concrete example of why this would be useful:,Motivation
11521,This would make it easier to coordinate multiple elements of a model that all want to read from the iterator before advancing it one step.,Motivation
11522,Reason: the automatic preevaluation of pending enqueues.,Motivation
11523,"When used for batch jobs the additional memory overhead of storing a new lexeme struct for each new word form encountered in parsing is negligible compared to the speed gains, and because most text conforms to the assumption that vocabulary size grows logarithmically as the total number of tokens grows linearly this is usually a safe bet.",Motivation
11524,Many non-experts are using the following code http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow?answertab=votes#tab-top.,Motivation
11525,"For a lot of my use cases, my input data is either 1. not on the file system, or 2. require complex preprocessing unavailable in TensorFlow.",Motivation
11526,Because otherwise the people will stick with feed_dict inputs until TensorFlow 3.0 and moan about bad performance of TF,Motivation
11527,what about f** I just only want to use tensorflow1.8 and cuda9.1?,Motivation
11528,Or better: in what use cases do you need a different interface for boosted ensembles and bagging?,Motivation
11529,"I notice TensorFlow is now accessible from Go, Rust and Haskell.",Motivation
11530,I can only find some basic infos in the C++ API docs.,Motivation
11531,Why would anyone need another Javascript library?,Motivation
11532,This doesn't seem to be supported?,Motivation
11533,"And in the future when we want to load more advanced, and possible context dependant models, and on the fly language switching it would be even more necessary.",Motivation
11534,Iterators implementing CODE are great for progress report.,Motivation
11535,"Also, when randomly creating a sample set, it seemed like the samples were consumed when I wanted them left in the buffer.",Motivation
11536,"Actually, we don't even use the nomenclature of an epoch anymore, since the same data is never seen twice, and above mentioned generation/sampling goes beyond the usual data augmentation.",Motivation
11537,"We also used two separate queues, one handling input data_files as string names and the other one the resulting input data with preprocessing being done in between those two.",Motivation
11538,the other factor for me is that everyone thinks the current auto mode inOneHotEncoder is weird.,Motivation
11539,The input pipeline is definitely thesteepest part of the learning curve.,Motivation
11540,For me it is mainly a question of scalability in adding more features to a single class.,Motivation
11541,"Then test it on my cross-validation set and if my cv score is still falling, I can continue training.",Motivation
11542,In case of Stacking the estimators might be completely different (say to you want to merge forests with svms).,Motivation
11543,"At the moment, we don't perform specific operations at the end of each data set, i.e. everything gets put into the same (large) random shuffle queue, to mix samples between data sets.",Motivation
11544,*         See #7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.,Motivation
11545,What other suggestions do you have?,Motivation
11546,(2) data can be generated from different machines if the pre-processing is too heavy for a single CPU.,Motivation
11547,For example:,Motivation
11548,"I understand these functions were initially thought for simple use cases, but it would be nice to have more control of the pipeline without the burden of managing _everything_ (e.g. using CODE but being forced to feed queues and manage threads kind of manually).",Motivation
11549,"Aside from that, we use two different input pipelines for training and validation data that we connect to the network part of our graph alternating through a switch implemented through CODE.",Motivation
11550,"In a way this information is already contained in word vectors because two verbs will be seen in more similar contexts than adjectives but guess that by reducing ambiguity and ""false positives"" it could make quite a difference.",Motivation
11551,Need use bothTensorflow andTSNEin Jupyter notebook ....,Motivation
11552,"Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect!",Motivation
11553,I've seen dozens and dozens of cases where (in the profiler; iirc MEMCpyWhatever) was really slow.,Motivation
11554,"Actually, we don't even use the nomenclature of an epoch anymore, since the same data is never seen twice, and above mentioned generation/sampling goes beyond the usual data augmentation.",Motivation
11555,"We don't find it spectacularly difficult to write a multithreaded data loader ourselves in Python, and generally we don't find it overly difficult to ensure that our data loading and preprocessing runs sufficiently quickly that it doesn't actually bottleneck training.",Motivation
11556,@khelkun answer is rather simple: providing mature JavaScript package that allows easy interaction with Tensorflow opens myriad new possibilities.,Motivation
11557,"I currently use this method with CODE ops and it works nicely but I'd like to find a way to do this for evaluation as well (and figured maybe Dataset is a good way to do this with the ""reintializable"" iterator).",Motivation
11558,"It is probably most useful in an interactive setting, righ?",Motivation
11559,"Then we want to run it faster, we would change the worker count to 20, 30, 40, ...",Motivation
11560,As opposed to training a large number of sub-estimators and waiting a long time (several hours for me).,Motivation
11561,"Something that provides similar functionality as the generator feed function in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/inputs/queues/feeding_functions.py  (but it would be cool if the source of the data could be from an arbitrary source, maybe using a kind of publisher/subscriber model?)",Motivation
11562,I think that a *huge* effort should be placed in tutorials: the hugest difficulty I am having -- and some colleagues with me -- is that the documentation that you can find is quite lousy and not very self-contained.,Motivation
11563,"At the moment, we don't perform specific operations at the end of each data set, i.e. everything gets put into the same (large) random shuffle queue, to mix samples between data sets.",Motivation
11564,Please note there are examples of where we already generate language bindings.,Motivation
11565,"But for streaming text, especially for social media where new terms are invented by the minute (hashtags and URLs in particular) this assumption no longer holds and the spacy vocabulary storage represents a dynamic element in what should be a completely static production deployment.",Motivation
11566,"Google developers implemented a small portion of Tensorflow in Javascript in their [playground] URL , the neural network implementation is [here] URL  and does include [back propagation](https://github.com/tensorflow/playground/blob/master/src/nn.ts#L282).",Motivation
11567,"I'd love to have fast, parallel GPU compute power at my fingertips with the ease and composability of JS.",Motivation
11568,This would be interesting for pure front-end graph exportation for direct Solution Usage on web clients.,Motivation
11569,I'm still not sure what you're suggesting is the practical difference due to inferring categories from the max value.,Motivation
11570,I'm trying to do some work on the text from Wiki Dump.,Motivation
11571,Many of the things said already resonate with my experience.,Motivation
11572,So summary of how it is now:,Motivation
11573,"It is by far the most flexible, makes debugging way easier and makes for much simpler code.",Motivation
11574,"I would have imagined that if we had a stacking interface, you could specify one estimator as the base estimator and another as the one on top.",Motivation
11575,"For instance, if you want to just recognise entities and store them in textual form, you don't care that the CODE instances can diverge between your shards.",Motivation
11576,"I mainly created this issue in case someone else is running into similar problems when trying spaCy on Spark, as the error messages raised by Spark when failing to pickle the language models are not very helpful (workers just crash because of segmentation fault).",Motivation
11577,And what if someone wants to add a 'binary encoding'?,Motivation
11578,I like the tf record and queue runner thing now that I'm used to it; the issue is the tight binding to the graph....,Motivation
11579,For me it is mainly a question of scalability in adding more features to a single class.,Motivation
11580,directory?,Motivation
11581,"That's the only way to learn by interacting with external world (training robot arms, Atari games, [Universe] URL  ).",Motivation
11582,Many of the things said already resonate with my experience.,Motivation
11583,-         The class name CODE says what type of data it accepts (categorical data),Motivation
11584,"Right now, this method starves my GPU all the time, which is a shame because most other DL frameworks (even those based on computational graphs) manage to make this much more performantly.",Motivation
11585,"JavaScript operates on every mobile platform, all major desktop Operating systems & in all the browsers so possibilities are endless.",Motivation
11586,"Google developers implemented a small portion of Tensorflow in Javascript in their [playground] URL , the neural network implementation is [here] URL  and does include [back propagation](https://github.com/tensorflow/playground/blob/master/src/nn.ts#L282).",Motivation
11587,Why ignore JavaScript ?,Motivation
11588,We are not consistent in naming anywhere.,Motivation
11589,@pprett I think there should be an easy way to do easy things.,Motivation
11590,"However, our case is very high-load system with streaming data (hundreds of thousands emails per day).",Motivation
11591,"We don't find it spectacularly difficult to write a multithreaded data loader ourselves in Python, and generally we don't find it overly difficult to ensure that our data loading and preprocessing runs sufficiently quickly that it doesn't actually bottleneck training.",Motivation
11592,"*         There is a clearer distinction between input shapes, for training you usually want batches, but for prediction you often care only about single examples",Motivation
11593,What other suggestions do you have?,Motivation
11594,There's been a few things that are currently missing and I had to work around:,Motivation
11595,Which and how many samples are generated differs per epoch (potentially conditional on past training behavior).,Motivation
11596,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation
11597,"Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect!",Motivation
11598,"I currently use this method with CODE ops and it works nicely but I'd like to find a way to do this for evaluation as well (and figured maybe Dataset is a good way to do this with the ""reintializable"" iterator).",Motivation
11599,"I've recently been trying to make the switch from CODE, but this has been (at least in my limited experience) a major difficulty.",Motivation
11600,A fix in CUDA 9.1.121 is expected in late February 2018.,Motivation
11601,I'm still not sure what you're suggesting is the practical difference due to inferring categories from the max value.,Motivation
11602,One concrete example of why this would be useful:,Motivation
11603,"For example the images could very reasonably use bilinear interpolation, but interpolating label values is not okay because a label pixel boundary of 0 and 2 should not be interpolated to the completely different label of 1.",Motivation
11604,I really like Spacy's simple and all in one approach.,Motivation
11605,Primarily I am interested in using it to switch between training and validation datasets in the same process.,Motivation
11606,"We also used two separate queues, one handling input data_files as string names and the other one the resulting input data with preprocessing being done in between those two.",Motivation
11607,This would make it easier to coordinate multiple elements of a model that all want to read from the iterator before advancing it one step.,Motivation
11608,"Right now, this method starves my GPU all the time, which is a shame because most other DL frameworks (even those based on computational graphs) manage to make this much more performantly.",Motivation
11609,"Then we want to run it faster, we would change the worker count to 20, 30, 40, ...",Motivation
11610,generator?,Motivation
11611,"What do you think does the scenario / code look like, where a user wants CODE?",Motivation
11612,"I understand these functions were initially thought for simple use cases, but it would be nice to have more control of the pipeline without the burden of managing _everything_ (e.g. using CODE but being forced to feed queues and manage threads kind of manually).",Motivation
11613,"[**TL;DR:** We're designing a new input pipeline API for TensorFlow, and we'd like to collect your feature requests on this issue.]",Motivation
11614,"JavaScript operates on every mobile platform, all major desktop Operating systems & in all the browsers so possibilities are endless.",Motivation
11615,1.         Anything that helps me analyze if and where the bottleneck lies in the input pipeline would be great.,Motivation
11616,*         See #2514 and #4535 for feature requests about handling multiple epochs.,Motivation
11617,"By default Apache Spark uses pickle, but can be told to use cloudpickle instead.",Motivation
11618,When trying to run a t-SNE CODE,Observed Bug Behaviour
11619,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour
11620,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
11621,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
11622,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
11623,"ok, nothing is working!!",Observed Bug Behaviour
11624,CODE,Observed Bug Behaviour
11625,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
11626,Then I installed Gensim.,Observed Bug Behaviour
11627,With crashing I actually mean freezing.,Observed Bug Behaviour
11628,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
11629,I have a similar issue with RandomizedSearchCV; it hangs indefinitely.,Observed Bug Behaviour
11630,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour
11631,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
11632,"I know from previous runs that it take about 60 min to finish, but I waited a lot longer than that and nothing happens, it just hangs, no error msgs, nothing and my computer heats up and sucks power like there's no tomorrow.",Observed Bug Behaviour
11633,Code below.,Observed Bug Behaviour
11634,I have a similar problem.,Observed Bug Behaviour
11635,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
11636,CODE,Observed Bug Behaviour
11637,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
11638,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
11639,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
11640,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
11641,only one copy of each package etc.,Observed Bug Behaviour
11642,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
11643,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
11644,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
11645,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour
11646,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
11647,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
11648,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
11649,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
11650,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour
11651,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
11652,We have to deal with it as though it were a memory leak and periodically re-initialize the code.,Observed Bug Behaviour
11653,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
11654,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
11655,"Still, this code worked fine last Friday!",Observed Bug Behaviour
11656,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour
11657,"ok, nothing is working!!",Observed Bug Behaviour
11658,"However, the CPU utilization remains 0 for all python processes.",Observed Bug Behaviour
11659,"I used a ubuntu virtual instance in google cloud compute engine (bumpy, spicy, scikit etc were not the most up to date).",Observed Bug Behaviour
11660,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
11661,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour
11662,"Also if you execute CODE before the same CODE call, CODE does not raise an exception (a dictionary is built?)",Observed Bug Behaviour
11663,The script hangs forever and the CPU utilization is low.,Observed Bug Behaviour
11664,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour
11665,"I am on platform ""Windows-7-6.1.7601-SP1"".",Observed Bug Behaviour
11666,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
11667,I am using IPython Notebook.,Observed Bug Behaviour
11668,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
11669,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
11670,I don't use pylab.,Observed Bug Behaviour
11671,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
11672,At least on my machine.,Observed Bug Behaviour
11673,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
11674,CODE.,Observed Bug Behaviour
11675,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour
11676,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
11677,I have been searching hours on this problem and can consistently replicate it: CODE,Observed Bug Behaviour
11678,@amueller I didn't use the CODE.,Observed Bug Behaviour
11679,If you use CODE it works fine.,Observed Bug Behaviour
11680,The problem is still the same,Observed Bug Behaviour
11681,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
11682,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour
11683,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour
11684,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
11685,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
11686,t-SNE fails with array must not contain infs or NaNs (OSX specific),Observed Bug Behaviour
11687,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
11688,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
11689,If you use CODE it works fine.,Observed Bug Behaviour
11690,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
11691,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour
11692,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
11693,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
11694,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
11695,"n_jobs=1 works,but takes forever of course (it worked in the previous env as well).",Observed Bug Behaviour
11696,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
11697,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
11698,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
11699,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
11700,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
11701,I am using IPython Notebook.,Observed Bug Behaviour
11702,"Still, this code worked fine last Friday!",Observed Bug Behaviour
11703,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
11704,only one copy of each package etc.,Observed Bug Behaviour
11705,"Thank you @thomberg1 , but addingCODEdid not help.",Observed Bug Behaviour
11706,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour
11707,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
11708,building 0.19b2 on debian/ubuntus ...,Observed Bug Behaviour
11709,Here is the code I used:CODE,Observed Bug Behaviour
11710,"Below is my code, it only works when CODE CODE",Observed Bug Behaviour
11711,"ok, nothing is working!!",Observed Bug Behaviour
11712,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour
11713,Sure - here's the full code - http://pastebin.com/yUE26SNs,Observed Bug Behaviour
11714,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
11715,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
11716,@amueller I didn't use the CODE.,Observed Bug Behaviour
11717,@amueller I didn't use the CODE.,Observed Bug Behaviour
11718,"When it freezes, it shows no error message.",Observed Bug Behaviour
11719,Sure - here's the full code - http://pastebin.com/yUE26SNs,Observed Bug Behaviour
11720,The problem is still the same,Observed Bug Behaviour
11721,The problem is still the same,Observed Bug Behaviour
11722,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
11723,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
11724,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
11725,Full Stack Trace: CODE,Observed Bug Behaviour
11726,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour
11727,Code below.,Observed Bug Behaviour
11728,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
11729,I have a similar problem.,Observed Bug Behaviour
11730,Code below.,Observed Bug Behaviour
11731,"did you use CODEif __name__ == ""__main__""CODE?",Observed Bug Behaviour
11732,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour
11733,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
11734,However CODE,Observed Bug Behaviour
11735,<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x10210d5c0> with a different variable scope than its first use.,Observed Bug Behaviour
11736,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
11737,GridSearchCV parallel execution with own scorer freezes,Observed Bug Behaviour
11738,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
11739,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
11740,"FWIW, this issue still happens on 32bit debian stretch with 0.19.1CODE",Observed Bug Behaviour
11741,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour
11742,"However, the CPU utilization remains 0 for all python processes.",Observed Bug Behaviour
11743,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
11744,"I am using a 3 year old macbook pro, 16GB ram and core i7 and my scikit-learn version is 0.19.",Observed Bug Behaviour
11745,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
11746,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
11747,Code is from a tutorial : https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/,Observed Bug Behaviour
11748,Still the same problem.,Observed Bug Behaviour
11749,Full Stack Trace: CODE,Observed Bug Behaviour
11750,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
11751,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
11752,I am using IPython Notebook.,Observed Bug Behaviour
11753,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour
11754,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour
11755,Trying to run in parallel processing.,Observed Bug Behaviour
11756,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
11757,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
11758,only one copy of each package etc.,Observed Bug Behaviour
11759,Issue is still there guys.,Observed Bug Behaviour
11760,"Below is my code, it only works when CODE CODE",Observed Bug Behaviour
11761,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
11762,Can you share the code of the scorer?,Observed Bug Behaviour
11763,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour
11764,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour
11765,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
11766,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
11767,Debian test failures (was test_preserve_trustworthiness_approximately fails on 32bit: AssertionError: 0.89166666666666661 not greater than 0.9),Observed Bug Behaviour
11768,However CODE,Observed Bug Behaviour
11769,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
11770,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour
11771,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
11772,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
11773,**after installing Gensim**numpy (1.10.4) updated to numpy (1.13.3)scipy (0.16.1)   updated to scipy (0.19.1),Observed Bug Behaviour
11774,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
11775,"Interesting, it's a only on a combo of numpy 1.12.1 and 32 bit python...",Observed Bug Behaviour
11776,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
11777,It basically ran until I ran out of memory on a 4G box.,Observed Bug Behaviour
11778,After that the code freezes.,Observed Bug Behaviour
11779,"Once again, this code works on my computer only when I change n_jobs to 1 or when I don't define a scoring= argument.",Observed Bug Behaviour
11780,Here is the code I used:CODE,Observed Bug Behaviour
11781,Trace CODE,Observed Bug Behaviour
11782,CODE,Observed Bug Behaviour
11783,CODE,Observed Bug Behaviour
11784,CODE,Observed Bug Behaviour
11785,Still the same problem.,Observed Bug Behaviour
11786,@amueller I didn't use the CODE.,Observed Bug Behaviour
11787,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
11788,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
11789,@KaisJM  I'm running the same snippet here (windows) and it freezes. CODE,Observed Bug Behaviour
11790,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
11791,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
11792,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
11793,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour
11794,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
11795,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
11796,only one copy of each package etc.,Observed Bug Behaviour
11797,CODE.,Observed Bug Behaviour
11798,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
11799,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
11800,Then I installed Gensim.,Observed Bug Behaviour
11801,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
11802,I have a similar problem.,Observed Bug Behaviour
11803,only one copy of each package etc.,Observed Bug Behaviour
11804,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
11805,Then I installed Gensim.,Observed Bug Behaviour
11806,"This is scikit-learn version 0.14, last updated and run using Enthought Canopy.",Observed Bug Behaviour
11807,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
11808,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
11809,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
11810,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
11811,However CODE,Observed Bug Behaviour
11812,GridSearchCV parallel execution with own scorer freezes,Observed Bug Behaviour
11813,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
11814,Still the same problem.,Observed Bug Behaviour
11815,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour
11816,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
11817,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
11818,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
11819,However CODE,Observed Bug Behaviour
11820,building 0.19b2 on debian/ubuntus ...,Observed Bug Behaviour
11821,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
11822,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
11823,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
11824,At least on my machine.,Observed Bug Behaviour
11825,Issue is still there guys.,Observed Bug Behaviour
11826,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour
11827,The processes are still there and consume a constant amount of RAM but require no processing time.,Observed Bug Behaviour
11828,Debian test failures (was test_preserve_trustworthiness_approximately fails on 32bit: AssertionError: 0.89166666666666661 not greater than 0.9),Observed Bug Behaviour
11829,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
11830,To clarify the current behaviour a little: CODE is currently interning _all_ strings seen.,Observed Bug Behaviour
11831,The processes are still there and consume a constant amount of RAM but require no processing time.,Observed Bug Behaviour
11832,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
11833,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
11834,I was getting the CODE message.,Observed Bug Behaviour
11835,Can you share the code of the scorer?,Observed Bug Behaviour
11836,"Still, this code worked fine last Friday!",Observed Bug Behaviour
11837,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
11838,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
11839,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
11840,If you use CODE it works fine.,Observed Bug Behaviour
11841,The processes are still there and consume a constant amount of RAM but require no processing time.,Observed Bug Behaviour
11842,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
11843,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
11844,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
11845,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
11846,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
11847,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
11848,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
11849,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
11850,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
11851,I was getting the CODE message.,Observed Bug Behaviour
11852,Trace CODE,Observed Bug Behaviour
11853,"I am using a 3 year old macbook pro, 16GB ram and core i7 and my scikit-learn version is 0.19.",Observed Bug Behaviour
11854,"I am on platform ""Windows-7-6.1.7601-SP1"".",Observed Bug Behaviour
11855,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
11856,Code is from a tutorial : https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/,Observed Bug Behaviour
11857,I am using IPython Notebook.,Observed Bug Behaviour
11858,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour
11859,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour
11860,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
11861,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
11862,@amueller I didn't use the CODE.,Observed Bug Behaviour
11863,only one copy of each package etc.,Observed Bug Behaviour
11864,"FWIW, this issue still happens on 32bit debian stretch with 0.19.1CODE",Observed Bug Behaviour
11865,@amueller I didn't use the CODE.,Observed Bug Behaviour
11866,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
11867,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour
11868,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
11869,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
11870,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
11871,The code ran fine.,Observed Bug Behaviour
11872,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
11873,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour
11874,Basically memory grows at a logarithmic-ish pace.,Observed Bug Behaviour
11875,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
11876,The code ran fine.,Observed Bug Behaviour
11877,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
11878,Can you share the code of the scorer?,Observed Bug Behaviour
11879,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
11880,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
11881,Full Stack Trace: CODE,Observed Bug Behaviour
11882,CODE,Observed Bug Behaviour
11883,I have a similar issue with RandomizedSearchCV; it hangs indefinitely.,Observed Bug Behaviour
11884,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
11885,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
11886,"I am on platform ""Windows-7-6.1.7601-SP1"".",Observed Bug Behaviour
11887,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
11888,Basically memory grows at a logarithmic-ish pace.,Observed Bug Behaviour
11889,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
11890,"n_jobs=1 works,but takes forever of course (it worked in the previous env as well).",Observed Bug Behaviour
11891,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
11892,With crashing I actually mean freezing.,Observed Bug Behaviour
11893,The script hangs forever and the CPU utilization is low.,Observed Bug Behaviour
11894,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
11895,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
11896,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
11897,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
11898,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
11899,I don't use pylab.,Observed Bug Behaviour
11900,Basically memory grows at a logarithmic-ish pace.,Observed Bug Behaviour
11901,t-SNE fails with array must not contain infs or NaNs (OSX specific),Observed Bug Behaviour
11902,Here is the code I used:CODE,Observed Bug Behaviour
11903,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour
11904,When trying to run a t-SNE CODE,Observed Bug Behaviour
11905,I don't use pylab.,Observed Bug Behaviour
11906,"Still, this code worked fine last Friday!",Observed Bug Behaviour
11907,The problem is still the same,Observed Bug Behaviour
11908,I have a similar problem.,Observed Bug Behaviour
11909,"However, the CPU utilization remains 0 for all python processes.",Observed Bug Behaviour
11910,"Still, this code worked fine last Friday!",Observed Bug Behaviour
11911,"*         Python 3.6.5,*         scikit-learn 0.19.1,*         Arch Linux,*         CPU cores: 8.",Observed Bug Behaviour
11912,Trying to run in parallel processing.,Observed Bug Behaviour
11913,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
11914,If you use CODE it works fine.,Observed Bug Behaviour
11915,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour
11916,"ok, nothing is working!!",Observed Bug Behaviour
11917,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
11918,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour
11919,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour
11920,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
11921,"did you use CODEif __name__ == ""__main__""CODE?",Observed Bug Behaviour
11922,only one copy of each package etc.,Observed Bug Behaviour
11923,I installed tf-nightly build and I get the following error on import of tensorflow.,Observed Bug Behaviour
11924,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
11925,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
11926,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
11927,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour
11928,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour
11929,CODE,Observed Bug Behaviour
11930,After that the code freezes.,Observed Bug Behaviour
11931,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
11932,The code ran fine.,Observed Bug Behaviour
11933,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
11934,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour
11935,We have to deal with it as though it were a memory leak and periodically re-initialize the code.,Observed Bug Behaviour
11936,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
11937,I don't use pylab.,Observed Bug Behaviour
11938,"I used a ubuntu virtual instance in google cloud compute engine (bumpy, spicy, scikit etc were not the most up to date).",Observed Bug Behaviour
11939,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
11940,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour
11941,It basically ran until I ran out of memory on a 4G box.,Observed Bug Behaviour
11942,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
11943,Here is the code I used:CODE,Observed Bug Behaviour
11944,raises: CODE,Observed Bug Behaviour
11945,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
11946,I was getting the CODE message.,Observed Bug Behaviour
11947,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour
11948,"ok, nothing is working!!",Observed Bug Behaviour
11949,Here is the code I used:CODE,Observed Bug Behaviour
11950,raises: CODE,Observed Bug Behaviour
11951,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
11952,"I know from previous runs that it take about 60 min to finish, but I waited a lot longer than that and nothing happens, it just hangs, no error msgs, nothing and my computer heats up and sucks power like there's no tomorrow.",Observed Bug Behaviour
11953,The text it tried to parse isn't relevant: CODE but I did update global CODE in a loop while parsing the doc in the same loop.,Observed Bug Behaviour
11954,CODE,Observed Bug Behaviour
11955,only one copy of each package etc.,Observed Bug Behaviour
11956,"This is scikit-learn version 0.14, last updated and run using Enthought Canopy.",Observed Bug Behaviour
11957,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
11958,The code ran fine.,Observed Bug Behaviour
11959,After that the code freezes.,Observed Bug Behaviour
11960,Code below.,Observed Bug Behaviour
11961,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
11962,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
11963,"ok, nothing is working!!",Observed Bug Behaviour
11964,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
11965,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
11966,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
11967,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour
11968,Still the same problem.,Observed Bug Behaviour
11969,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
11970,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
11971,To clarify the current behaviour a little: CODE is currently interning _all_ strings seen.,Observed Bug Behaviour
11972,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour
11973,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
11974,I have been searching hours on this problem and can consistently replicate it: CODE,Observed Bug Behaviour
11975,CODE,Observed Bug Behaviour
11976,However CODE,Observed Bug Behaviour
11977,With crashing I actually mean freezing.,Observed Bug Behaviour
11978,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
11979,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
11980,The problem is still the same,Observed Bug Behaviour
11981,I am using IPython Notebook.,Observed Bug Behaviour
11982,Trace CODE,Observed Bug Behaviour
11983,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour
11984,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
11985,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
11986,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
11987,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour
11988,"Interesting, it's a only on a combo of numpy 1.12.1 and 32 bit python...",Observed Bug Behaviour
11989,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
11990,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
11991,Can you share the code of the scorer?,Observed Bug Behaviour
11992,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
11993,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour
11994,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour
11995,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
11996,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
11997,Code is from a tutorial : https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/,Observed Bug Behaviour
11998,Trace CODE,Observed Bug Behaviour
11999,building 0.19b2 on debian/ubuntus ...,Observed Bug Behaviour
12000,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
12001,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
12002,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour
12003,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
12004,We have to deal with it as though it were a memory leak and periodically re-initialize the code.,Observed Bug Behaviour
12005,"In windows, custom scorer still freezes.",Observed Bug Behaviour
12006,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour
12007,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
12008,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
12009,Trace CODE,Observed Bug Behaviour
12010,Trace CODE,Observed Bug Behaviour
12011,Please create a new instance of the cell if you would like it to use a different set of weights.,Observed Bug Behaviour
12012,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour
12013,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour
12014,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour
12015,"I am on platform ""Windows-7-6.1.7601-SP1"".",Observed Bug Behaviour
12016,The code ran fine.,Observed Bug Behaviour
12017,Please create a new instance of the cell if you would like it to use a different set of weights.,Observed Bug Behaviour
12018,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
12019,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12020,only one copy of each package etc.,Observed Bug Behaviour
12021,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
12022,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
12023,Trace CODE,Observed Bug Behaviour
12024,At least on my machine.,Observed Bug Behaviour
12025,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12026,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
12027,"Thank you @thomberg1 , but addingCODEdid not help.",Observed Bug Behaviour
12028,With crashing I actually mean freezing.,Observed Bug Behaviour
12029,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
12030,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
12031,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
12032,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
12033,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
12034,Debian test failures (was test_preserve_trustworthiness_approximately fails on 32bit: AssertionError: 0.89166666666666661 not greater than 0.9),Observed Bug Behaviour
12035,CODE.,Observed Bug Behaviour
12036,Full Stack Trace: CODE,Observed Bug Behaviour
12037,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
12038,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
12039,Full Stack Trace: CODE,Observed Bug Behaviour
12040,I have a similar issue with RandomizedSearchCV; it hangs indefinitely.,Observed Bug Behaviour
12041,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
12042,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
12043,Issue is still there guys.,Observed Bug Behaviour
12044,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12045,"I am using a 3 year old macbook pro, 16GB ram and core i7 and my scikit-learn version is 0.19.",Observed Bug Behaviour
12046,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour
12047,Full Stack Trace: CODE,Observed Bug Behaviour
12048,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
12049,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
12050,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12051,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
12052,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
12053,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
12054,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
12055,"I am using a 3 year old macbook pro, 16GB ram and core i7 and my scikit-learn version is 0.19.",Observed Bug Behaviour
12056,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
12057,I installed tf-nightly build and I get the following error on import of tensorflow.,Observed Bug Behaviour
12058,CODE.,Observed Bug Behaviour
12059,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
12060,We have to deal with it as though it were a memory leak and periodically re-initialize the code.,Observed Bug Behaviour
12061,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
12062,"If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).",Observed Bug Behaviour
12063,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12064,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
12065,The problem is still the same,Observed Bug Behaviour
12066,"Below is my code, it only works when CODE CODE",Observed Bug Behaviour
12067,CODE.,Observed Bug Behaviour
12068,The script hangs forever and the CPU utilization is low.,Observed Bug Behaviour
12069,"This is scikit-learn version 0.14, last updated and run using Enthought Canopy.",Observed Bug Behaviour
12070,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
12071,I installed tf-nightly build and I get the following error on import of tensorflow.,Observed Bug Behaviour
12072,"Once again, this code works on my computer only when I change n_jobs to 1 or when I don't define a scoring= argument.",Observed Bug Behaviour
12073,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
12074,"If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).",Observed Bug Behaviour
12075,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
12076,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
12077,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12078,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
12079,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour
12080,Code is from a tutorial : https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/,Observed Bug Behaviour
12081,I have a similar issue with RandomizedSearchCV; it hangs indefinitely.,Observed Bug Behaviour
12082,The processes are still there and consume a constant amount of RAM but require no processing time.,Observed Bug Behaviour
12083,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
12084,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12085,"Once again, this code works on my computer only when I change n_jobs to 1 or when I don't define a scoring= argument.",Observed Bug Behaviour
12086,I have a similar issue with RandomizedSearchCV; it hangs indefinitely.,Observed Bug Behaviour
12087,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
12088,"I first performed some minor preprocessing to remove newlines from the data so that it could be read line by line so that it wouldn't all be kept in memory, then I ran spacy with all models set to false, only the tokenizer loaded.",Observed Bug Behaviour
12089,"This is scikit-learn version 0.14, last updated and run using Enthought Canopy.",Observed Bug Behaviour
12090,"I first performed some minor preprocessing to remove newlines from the data so that it could be read line by line so that it wouldn't all be kept in memory, then I ran spacy with all models set to false, only the tokenizer loaded.",Observed Bug Behaviour
12091,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
12092,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12093,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12094,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12095,Here is the code I used:CODE,Observed Bug Behaviour
12096,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
12097,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
12098,"However, the CPU utilization remains 0 for all python processes.",Observed Bug Behaviour
12099,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
12100,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
12101,raises: CODE,Observed Bug Behaviour
12102,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour
12103,Trace CODE,Observed Bug Behaviour
12104,The script hangs forever and the CPU utilization is low.,Observed Bug Behaviour
12105,@amueller I didn't use the CODE.,Observed Bug Behaviour
12106,"did you use CODEif __name__ == ""__main__""CODE?",Observed Bug Behaviour
12107,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
12108,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour
12109,Still the same problem.,Observed Bug Behaviour
12110,If you use CODE it works fine.,Observed Bug Behaviour
12111,Code below.,Observed Bug Behaviour
12112,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
12113,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12114,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
12115,Full Stack Trace: CODE,Observed Bug Behaviour
12116,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12117,When trying to run a t-SNE CODE,Observed Bug Behaviour
12118,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
12119,building 0.19b2 on debian/ubuntus ...,Observed Bug Behaviour
12120,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12121,"Interesting, it's a only on a combo of numpy 1.12.1 and 32 bit python...",Observed Bug Behaviour
12122,Trying to run in parallel processing.,Observed Bug Behaviour
12123,Trying to run in parallel processing.,Observed Bug Behaviour
12124,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
12125,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
12126,t-SNE fails with array must not contain infs or NaNs (OSX specific),Observed Bug Behaviour
12127,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12128,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
12129,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12130,Still the same problem.,Observed Bug Behaviour
12131,Full Stack Trace: CODE,Observed Bug Behaviour
12132,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour
12133,Code is from a tutorial : https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/,Observed Bug Behaviour
12134,<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x10210d5c0> with a different variable scope than its first use.,Observed Bug Behaviour
12135,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
12136,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
12137,Code is from a tutorial : https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/,Observed Bug Behaviour
12138,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
12139,Please create a new instance of the cell if you would like it to use a different set of weights.,Observed Bug Behaviour
12140,With crashing I actually mean freezing.,Observed Bug Behaviour
12141,in both cases python-numpy is CODE (i.e. 1.12.1 numpy) and passed ok with numpy 1.8.2 in Debian jessie.,Observed Bug Behaviour
12142,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12143,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12144,Trying to run in parallel processing.,Observed Bug Behaviour
12145,CODE,Observed Bug Behaviour
12146,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12147,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12148,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
12149,Issue is still there guys.,Observed Bug Behaviour
12150,"However, the CPU utilization remains 0 for all python processes.",Observed Bug Behaviour
12151,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour
12152,"When it freezes, it shows no error message.",Observed Bug Behaviour
12153,Code is from a tutorial : https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/,Observed Bug Behaviour
12154,"When it freezes, it shows no error message.",Observed Bug Behaviour
12155,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
12156,I am using IPython Notebook.,Observed Bug Behaviour
12157,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
12158,However CODE,Observed Bug Behaviour
12159,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
12160,t-SNE fails with array must not contain infs or NaNs (OSX specific),Observed Bug Behaviour
12161,"*         Python 3.6.5,*         scikit-learn 0.19.1,*         Arch Linux,*         CPU cores: 8.",Observed Bug Behaviour
12162,"I know from previous runs that it take about 60 min to finish, but I waited a lot longer than that and nothing happens, it just hangs, no error msgs, nothing and my computer heats up and sucks power like there's no tomorrow.",Observed Bug Behaviour
12163,"I know from previous runs that it take about 60 min to finish, but I waited a lot longer than that and nothing happens, it just hangs, no error msgs, nothing and my computer heats up and sucks power like there's no tomorrow.",Observed Bug Behaviour
12164,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
12165,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour
12166,CODE,Observed Bug Behaviour
12167,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
12168,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour
12169,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12170,"did you use CODEif __name__ == ""__main__""CODE?",Observed Bug Behaviour
12171,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
12172,@amueller I didn't use the CODE.,Observed Bug Behaviour
12173,Still the same problem.,Observed Bug Behaviour
12174,Code below.,Observed Bug Behaviour
12175,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour
12176,Sure - here's the full code - http://pastebin.com/yUE26SNs,Observed Bug Behaviour
12177,"I know from previous runs that it take about 60 min to finish, but I waited a lot longer than that and nothing happens, it just hangs, no error msgs, nothing and my computer heats up and sucks power like there's no tomorrow.",Observed Bug Behaviour
12178,@KaisJM  I'm running the same snippet here (windows) and it freezes. CODE,Observed Bug Behaviour
12179,CODE,Observed Bug Behaviour
12180,CODE.,Observed Bug Behaviour
12181,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
12182,I am using IPython Notebook.,Observed Bug Behaviour
12183,When trying to run a t-SNE CODE,Observed Bug Behaviour
12184,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12185,CODE,Observed Bug Behaviour
12186,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12187,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
12188,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
12189,CODE,Observed Bug Behaviour
12190,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12191,@KaisJM  I'm running the same snippet here (windows) and it freezes. CODE,Observed Bug Behaviour
12192,building 0.19b2 on debian/ubuntus ...,Observed Bug Behaviour
12193,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
12194,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
12195,"n_jobs=1 works,but takes forever of course (it worked in the previous env as well).",Observed Bug Behaviour
12196,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12197,I have a similar problem.,Observed Bug Behaviour
12198,"@honnibal  I'm also facing the same issue, (spacy 1.5.0).",Observed Bug Behaviour
12199,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12200,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
12201,CODE.,Observed Bug Behaviour
12202,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12203,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour
12204,"When it freezes, it shows no error message.",Observed Bug Behaviour
12205,At least on my machine.,Observed Bug Behaviour
12206,Here is the code I used:CODE,Observed Bug Behaviour
12207,raises: CODE,Observed Bug Behaviour
12208,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
12209,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12210,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
12211,However CODE,Observed Bug Behaviour
12212,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
12213,Then I installed Gensim.,Observed Bug Behaviour
12214,With crashing I actually mean freezing.,Observed Bug Behaviour
12215,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
12216,Sure - here's the full code - http://pastebin.com/yUE26SNs,Observed Bug Behaviour
12217,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12218,Please create a new instance of the cell if you would like it to use a different set of weights.,Observed Bug Behaviour
12219,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
12220,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour
12221,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
12222,Then I installed Gensim.,Observed Bug Behaviour
12223,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour
12224,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12225,Then I installed Gensim.,Observed Bug Behaviour
12226,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12227,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12228,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
12229,"I am on platform ""Windows-7-6.1.7601-SP1"".",Observed Bug Behaviour
12230,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
12231,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
12232,I have a similar issue with RandomizedSearchCV; it hangs indefinitely.,Observed Bug Behaviour
12233,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
12234,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour
12235,"Once again, this code works on my computer only when I change n_jobs to 1 or when I don't define a scoring= argument.",Observed Bug Behaviour
12236,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
12237,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12238,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12239,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
12240,Issue is still there guys.,Observed Bug Behaviour
12241,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
12242,I don't use pylab.,Observed Bug Behaviour
12243,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
12244,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
12245,"Below is my code, it only works when CODE CODE",Observed Bug Behaviour
12246,CODE,Observed Bug Behaviour
12247,Full Stack Trace: CODE,Observed Bug Behaviour
12248,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
12249,After that the code freezes.,Observed Bug Behaviour
12250,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
12251,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
12252,Full Stack Trace: CODE,Observed Bug Behaviour
12253,raises: CODE,Observed Bug Behaviour
12254,The text it tried to parse isn't relevant: CODE but I did update global CODE in a loop while parsing the doc in the same loop.,Observed Bug Behaviour
12255,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
12256,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
12257,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
12258,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12259,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12260,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12261,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
12262,"Still, this code worked fine last Friday!",Observed Bug Behaviour
12263,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
12264,I installed tf-nightly build and I get the following error on import of tensorflow.,Observed Bug Behaviour
12265,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
12266,I am using IPython Notebook.,Observed Bug Behaviour
12267,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
12268,With crashing I actually mean freezing.,Observed Bug Behaviour
12269,Can you share the code of the scorer?,Observed Bug Behaviour
12270,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
12271,"Still, this code worked fine last Friday!",Observed Bug Behaviour
12272,"Thank you @thomberg1 , but addingCODEdid not help.",Observed Bug Behaviour
12273,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
12274,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
12275,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
12276,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
12277,"n_jobs=1 works,but takes forever of course (it worked in the previous env as well).",Observed Bug Behaviour
12278,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
12279,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
12280,The script hangs forever and the CPU utilization is low.,Observed Bug Behaviour
12281,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
12282,"In windows, custom scorer still freezes.",Observed Bug Behaviour
12283,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12284,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
12285,Then I installed Gensim.,Observed Bug Behaviour
12286,Sure - here's the full code - http://pastebin.com/yUE26SNs,Observed Bug Behaviour
12287,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
12288,"If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).",Observed Bug Behaviour
12289,I have been searching hours on this problem and can consistently replicate it: CODE,Observed Bug Behaviour
12290,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour
12291,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
12292,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
12293,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour
12294,I don't use pylab.,Observed Bug Behaviour
12295,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
12296,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12297,Issue is still there guys.,Observed Bug Behaviour
12298,"n_jobs=1 works,but takes forever of course (it worked in the previous env as well).",Observed Bug Behaviour
12299,"In windows, custom scorer still freezes.",Observed Bug Behaviour
12300,At least on my machine.,Observed Bug Behaviour
12301,CODE,Observed Bug Behaviour
12302,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour
12303,I was getting the CODE message.,Observed Bug Behaviour
12304,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour
12305,I was getting the CODE message.,Observed Bug Behaviour
12306,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12307,"I used a ubuntu virtual instance in google cloud compute engine (bumpy, spicy, scikit etc were not the most up to date).",Observed Bug Behaviour
12308,CODE,Observed Bug Behaviour
12309,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
12310,GridSearchCV parallel execution with own scorer freezes,Observed Bug Behaviour
12311,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
12312,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
12313,I have a similar problem.,Observed Bug Behaviour
12314,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12315,After that the code freezes.,Observed Bug Behaviour
12316,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
12317,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
12318,Basically memory grows at a logarithmic-ish pace.,Observed Bug Behaviour
12319,@amueller I didn't use the CODE.,Observed Bug Behaviour
12320,"I first performed some minor preprocessing to remove newlines from the data so that it could be read line by line so that it wouldn't all be kept in memory, then I ran spacy with all models set to false, only the tokenizer loaded.",Observed Bug Behaviour
12321,If you use CODE it works fine.,Observed Bug Behaviour
12322,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
12323,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12324,However CODE,Observed Bug Behaviour
12325,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12326,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
12327,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour
12328,I don't use pylab.,Observed Bug Behaviour
12329,"In windows, custom scorer still freezes.",Observed Bug Behaviour
12330,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour
12331,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12332,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour
12333,Sure - here's the full code - http://pastebin.com/yUE26SNs,Observed Bug Behaviour
12334,"Once again, this code works on my computer only when I change n_jobs to 1 or when I don't define a scoring= argument.",Observed Bug Behaviour
12335,To clarify the current behaviour a little: CODE is currently interning _all_ strings seen.,Observed Bug Behaviour
12336,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
12337,If you use CODE it works fine.,Observed Bug Behaviour
12338,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
12339,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
12340,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12341,"I know from previous runs that it take about 60 min to finish, but I waited a lot longer than that and nothing happens, it just hangs, no error msgs, nothing and my computer heats up and sucks power like there's no tomorrow.",Observed Bug Behaviour
12342,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
12343,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12344,@amueller I didn't use the CODE.,Observed Bug Behaviour
12345,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
12346,The error message is -CODE,Observed Bug Behaviour
12347,I am using IPython Notebook.,Observed Bug Behaviour
12348,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
12349,The error message is -CODE,Observed Bug Behaviour
12350,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
12351,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12352,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
12353,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12354,Can you share the code of the scorer?,Observed Bug Behaviour
12355,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour
12356,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
12357,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
12358,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12359,CODE,Observed Bug Behaviour
12360,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12361,CODE.,Observed Bug Behaviour
12362,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12363,However CODE,Observed Bug Behaviour
12364,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
12365,**after installing Gensim**numpy (1.10.4) updated to numpy (1.13.3)scipy (0.16.1)   updated to scipy (0.19.1),Observed Bug Behaviour
12366,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
12367,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12368,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour
12369,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
12370,"This is scikit-learn version 0.14, last updated and run using Enthought Canopy.",Observed Bug Behaviour
12371,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
12372,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour
12373,"I know from previous runs that it take about 60 min to finish, but I waited a lot longer than that and nothing happens, it just hangs, no error msgs, nothing and my computer heats up and sucks power like there's no tomorrow.",Observed Bug Behaviour
12374,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour
12375,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12376,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour
12377,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12378,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
12379,Can you share the code of the scorer?,Observed Bug Behaviour
12380,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12381,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour
12382,Full Stack Trace: CODE,Observed Bug Behaviour
12383,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
12384,Then I installed Gensim.,Observed Bug Behaviour
12385,Code below.,Observed Bug Behaviour
12386,"When it freezes, it shows no error message.",Observed Bug Behaviour
12387,Still the same problem.,Observed Bug Behaviour
12388,"FWIW, this issue still happens on 32bit debian stretch with 0.19.1CODE",Observed Bug Behaviour
12389,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
12390,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
12391,However CODE,Observed Bug Behaviour
12392,"When i did not use custom cost function, i did not face these freezes in parallel processing",Observed Bug Behaviour
12393,Code below.,Observed Bug Behaviour
12394,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour
12395,"*         Python 3.6.5,*         scikit-learn 0.19.1,*         Arch Linux,*         CPU cores: 8.",Observed Bug Behaviour
12396,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12397,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
12398,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
12399,I was getting the CODE message.,Observed Bug Behaviour
12400,"I first performed some minor preprocessing to remove newlines from the data so that it could be read line by line so that it wouldn't all be kept in memory, then I ran spacy with all models set to false, only the tokenizer loaded.",Observed Bug Behaviour
12401,CODE.,Observed Bug Behaviour
12402,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
12403,CODE,Observed Bug Behaviour
12404,The error message is -CODE,Observed Bug Behaviour
12405,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12406,"@honnibal  I'm also facing the same issue, (spacy 1.5.0).",Observed Bug Behaviour
12407,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
12408,I was getting the CODE message.,Observed Bug Behaviour
12409,"I first performed some minor preprocessing to remove newlines from the data so that it could be read line by line so that it wouldn't all be kept in memory, then I ran spacy with all models set to false, only the tokenizer loaded.",Observed Bug Behaviour
12410,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
12411,"Below is my code, it only works when CODE CODE",Observed Bug Behaviour
12412,@amueller I didn't use the CODE.,Observed Bug Behaviour
12413,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12414,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
12415,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
12416,"n_jobs=1 works,but takes forever of course (it worked in the previous env as well).",Observed Bug Behaviour
12417,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
12418,"When i did not use custom cost function, i did not face these freezes in parallel processing",Observed Bug Behaviour
12419,CODE.,Observed Bug Behaviour
12420,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
12421,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12422,CODE,Observed Bug Behaviour
12423,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12424,"Interesting, it's a only on a combo of numpy 1.12.1 and 32 bit python...",Observed Bug Behaviour
12425,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
12426,I was getting the CODE message.,Observed Bug Behaviour
12427,"ok, nothing is working!!",Observed Bug Behaviour
12428,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
12429,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12430,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12431,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
12432,I was getting the CODE message.,Observed Bug Behaviour
12433,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
12434,I have been searching hours on this problem and can consistently replicate it: CODE,Observed Bug Behaviour
12435,It basically ran until I ran out of memory on a 4G box.,Observed Bug Behaviour
12436,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12437,"*         Python 3.6.5,*         scikit-learn 0.19.1,*         Arch Linux,*         CPU cores: 8.",Observed Bug Behaviour
12438,With crashing I actually mean freezing.,Observed Bug Behaviour
12439,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
12440,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
12441,Trace CODE,Observed Bug Behaviour
12442,"@honnibal  I'm also facing the same issue, (spacy 1.5.0).",Observed Bug Behaviour
12443,CODE.,Observed Bug Behaviour
12444,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour
12445,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
12446,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12447,When trying to run a t-SNE CODE,Observed Bug Behaviour
12448,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12449,Here is the code I used:CODE,Observed Bug Behaviour
12450,Sure - here's the full code - http://pastebin.com/yUE26SNs,Observed Bug Behaviour
12451,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
12452,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12453,With crashing I actually mean freezing.,Observed Bug Behaviour
12454,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
12455,"Still, this code worked fine last Friday!",Observed Bug Behaviour
12456,I was getting the CODE message.,Observed Bug Behaviour
12457,"I used a ubuntu virtual instance in google cloud compute engine (bumpy, spicy, scikit etc were not the most up to date).",Observed Bug Behaviour
12458,To clarify the current behaviour a little: CODE is currently interning _all_ strings seen.,Observed Bug Behaviour
12459,"However, the CPU utilization remains 0 for all python processes.",Observed Bug Behaviour
12460,The script hangs forever and the CPU utilization is low.,Observed Bug Behaviour
12461,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour
12462,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
12463,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour
12464,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
12465,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12466,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12467,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
12468,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour
12469,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour
12470,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12471,@amueller I didn't use the CODE.,Observed Bug Behaviour
12472,Can you share the code of the scorer?,Observed Bug Behaviour
12473,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12474,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12475,"*         Python 3.6.5,*         scikit-learn 0.19.1,*         Arch Linux,*         CPU cores: 8.",Observed Bug Behaviour
12476,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour
12477,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
12478,I installed tf-nightly build and I get the following error on import of tensorflow.,Observed Bug Behaviour
12479,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12480,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
12481,@amueller I didn't use the CODE.,Observed Bug Behaviour
12482,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
12483,At least on my machine.,Observed Bug Behaviour
12484,"n_jobs=1 works,but takes forever of course (it worked in the previous env as well).",Observed Bug Behaviour
12485,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
12486,Debian test failures (was test_preserve_trustworthiness_approximately fails on 32bit: AssertionError: 0.89166666666666661 not greater than 0.9),Observed Bug Behaviour
12487,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
12488,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
12489,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
12490,"I used a ubuntu virtual instance in google cloud compute engine (bumpy, spicy, scikit etc were not the most up to date).",Observed Bug Behaviour
12491,Here is the code I used:CODE,Observed Bug Behaviour
12492,"I am on platform ""Windows-7-6.1.7601-SP1"".",Observed Bug Behaviour
12493,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
12494,Code below.,Observed Bug Behaviour
12495,Here is the code I used:CODE,Observed Bug Behaviour
12496,"I first performed some minor preprocessing to remove newlines from the data so that it could be read line by line so that it wouldn't all be kept in memory, then I ran spacy with all models set to false, only the tokenizer loaded.",Observed Bug Behaviour
12497,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
12498,"I used a ubuntu virtual instance in google cloud compute engine (bumpy, spicy, scikit etc were not the most up to date).",Observed Bug Behaviour
12499,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour
12500,"When i did not use custom cost function, i did not face these freezes in parallel processing",Observed Bug Behaviour
12501,The code ran fine.,Observed Bug Behaviour
12502,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour
12503,"Still, this code worked fine last Friday!",Observed Bug Behaviour
12504,However CODE,Observed Bug Behaviour
12505,Full Stack Trace: CODE,Observed Bug Behaviour
12506,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
12507,Trying to run in parallel processing.,Observed Bug Behaviour
12508,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
12509,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
12510,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour
12511,t-SNE fails with array must not contain infs or NaNs (OSX specific),Observed Bug Behaviour
12512,"FWIW, this issue still happens on 32bit debian stretch with 0.19.1CODE",Observed Bug Behaviour
12513,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12514,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour
12515,Basically memory grows at a logarithmic-ish pace.,Observed Bug Behaviour
12516,Debian test failures (was test_preserve_trustworthiness_approximately fails on 32bit: AssertionError: 0.89166666666666661 not greater than 0.9),Observed Bug Behaviour
12517,After that the code freezes.,Observed Bug Behaviour
12518,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
12519,It basically ran until I ran out of memory on a 4G box.,Observed Bug Behaviour
12520,CODE,Observed Bug Behaviour
12521,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
12522,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
12523,"When it freezes, it shows no error message.",Observed Bug Behaviour
12524,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
12525,Still the same problem.,Observed Bug Behaviour
12526,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12527,The script hangs forever and the CPU utilization is low.,Observed Bug Behaviour
12528,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
12529,"If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).",Observed Bug Behaviour
12530,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour
12531,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12532,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
12533,After that the code freezes.,Observed Bug Behaviour
12534,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
12535,Then I installed Gensim.,Observed Bug Behaviour
12536,The text it tried to parse isn't relevant: CODE but I did update global CODE in a loop while parsing the doc in the same loop.,Observed Bug Behaviour
12537,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour
12538,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
12539,Please create a new instance of the cell if you would like it to use a different set of weights.,Observed Bug Behaviour
12540,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12541,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12542,I have a similar problem.,Observed Bug Behaviour
12543,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
12544,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour
12545,The error message is -CODE,Observed Bug Behaviour
12546,At least on my machine.,Observed Bug Behaviour
12547,The code ran fine.,Observed Bug Behaviour
12548,CODE,Observed Bug Behaviour
12549,only one copy of each package etc.,Observed Bug Behaviour
12550,I am using IPython Notebook.,Observed Bug Behaviour
12551,**after installing Gensim**numpy (1.10.4) updated to numpy (1.13.3)scipy (0.16.1)   updated to scipy (0.19.1),Observed Bug Behaviour
12552,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
12553,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
12554,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12555,Code below.,Observed Bug Behaviour
12556,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
12557,After that the code freezes.,Observed Bug Behaviour
12558,If you use CODE it works fine.,Observed Bug Behaviour
12559,"Thank you @thomberg1 , but addingCODEdid not help.",Observed Bug Behaviour
12560,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
12561,GridSearchCV parallel execution with own scorer freezes,Observed Bug Behaviour
12562,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
12563,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
12564,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12565,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
12566,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
12567,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
12568,CODE.,Observed Bug Behaviour
12569,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12570,"When it freezes, it shows no error message.",Observed Bug Behaviour
12571,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
12572,At least on my machine.,Observed Bug Behaviour
12573,"Also if you execute CODE before the same CODE call, CODE does not raise an exception (a dictionary is built?)",Observed Bug Behaviour
12574,<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x10210d5c0> with a different variable scope than its first use.,Observed Bug Behaviour
12575,After that the code freezes.,Observed Bug Behaviour
12576,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
12577,"*         Python 3.6.5,*         scikit-learn 0.19.1,*         Arch Linux,*         CPU cores: 8.",Observed Bug Behaviour
12578,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
12579,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
12580,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour
12581,Code is from a tutorial : https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/,Observed Bug Behaviour
12582,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
12583,GridSearchCV parallel execution with own scorer freezes,Observed Bug Behaviour
12584,"Once again, this code works on my computer only when I change n_jobs to 1 or when I don't define a scoring= argument.",Observed Bug Behaviour
12585,"When i did not use custom cost function, i did not face these freezes in parallel processing",Observed Bug Behaviour
12586,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
12587,Please create a new instance of the cell if you would like it to use a different set of weights.,Observed Bug Behaviour
12588,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
12589,building 0.19b2 on debian/ubuntus ...,Observed Bug Behaviour
12590,The problem is still the same,Observed Bug Behaviour
12591,t-SNE fails with array must not contain infs or NaNs (OSX specific),Observed Bug Behaviour
12592,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
12593,Full Stack Trace: CODE,Observed Bug Behaviour
12594,If you use CODE it works fine.,Observed Bug Behaviour
12595,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
12596,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
12597,"When it freezes, it shows no error message.",Observed Bug Behaviour
12598,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
12599,"Thank you @thomberg1 , but addingCODEdid not help.",Observed Bug Behaviour
12600,Code below.,Observed Bug Behaviour
12601,"When it freezes, it shows no error message.",Observed Bug Behaviour
12602,"Still, this code worked fine last Friday!",Observed Bug Behaviour
12603,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12604,Debian test failures (was test_preserve_trustworthiness_approximately fails on 32bit: AssertionError: 0.89166666666666661 not greater than 0.9),Observed Bug Behaviour
12605,"FWIW, this issue still happens on 32bit debian stretch with 0.19.1CODE",Observed Bug Behaviour
12606,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour
12607,However CODE,Observed Bug Behaviour
12608,Full Stack Trace: CODE,Observed Bug Behaviour
12609,The code ran fine.,Observed Bug Behaviour
12610,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
12611,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12612,"Thank you @thomberg1 , but addingCODEdid not help.",Observed Bug Behaviour
12613,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12614,After that the code freezes.,Observed Bug Behaviour
12615,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
12616,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12617,Basically memory grows at a logarithmic-ish pace.,Observed Bug Behaviour
12618,CODE,Observed Bug Behaviour
12619,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
12620,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
12621,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12622,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12623,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
12624,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12625,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
12626,"In windows, custom scorer still freezes.",Observed Bug Behaviour
12627,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
12628,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour
12629,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12630,I don't use pylab.,Observed Bug Behaviour
12631,"When it freezes, it shows no error message.",Observed Bug Behaviour
12632,At least on my machine.,Observed Bug Behaviour
12633,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
12634,"*         Python 3.6.5,*         scikit-learn 0.19.1,*         Arch Linux,*         CPU cores: 8.",Observed Bug Behaviour
12635,Full Stack Trace: CODE,Observed Bug Behaviour
12636,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12637,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12638,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
12639,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
12640,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
12641,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
12642,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
12643,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
12644,Still the same problem.,Observed Bug Behaviour
12645,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
12646,Full Stack Trace: CODE,Observed Bug Behaviour
12647,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12648,CODE,Observed Bug Behaviour
12649,**after installing Gensim**numpy (1.10.4) updated to numpy (1.13.3)scipy (0.16.1)   updated to scipy (0.19.1),Observed Bug Behaviour
12650,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
12651,"When i did not use custom cost function, i did not face these freezes in parallel processing",Observed Bug Behaviour
12652,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
12653,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12654,The error message is -CODE,Observed Bug Behaviour
12655,The problem is still the same,Observed Bug Behaviour
12656,"FWIW, this issue still happens on 32bit debian stretch with 0.19.1CODE",Observed Bug Behaviour
12657,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
12658,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
12659,GridSearchCV parallel execution with own scorer freezes,Observed Bug Behaviour
12660,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12661,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
12662,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour
12663,The error message is -CODE,Observed Bug Behaviour
12664,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12665,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12666,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12667,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12668,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour
12669,To clarify the current behaviour a little: CODE is currently interning _all_ strings seen.,Observed Bug Behaviour
12670,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
12671,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
12672,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
12673,"I am using a 3 year old macbook pro, 16GB ram and core i7 and my scikit-learn version is 0.19.",Observed Bug Behaviour
12674,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour
12675,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
12676,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour
12677,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour
12678,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
12679,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12680,The code ran fine.,Observed Bug Behaviour
12681,"Thank you @thomberg1 , but addingCODEdid not help.",Observed Bug Behaviour
12682,The code ran fine.,Observed Bug Behaviour
12683,The code ran fine.,Observed Bug Behaviour
12684,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
12685,I have a similar issue with RandomizedSearchCV; it hangs indefinitely.,Observed Bug Behaviour
12686,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
12687,Full Stack Trace: CODE,Observed Bug Behaviour
12688,t-SNE fails with array must not contain infs or NaNs (OSX specific),Observed Bug Behaviour
12689,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
12690,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
12691,We have to deal with it as though it were a memory leak and periodically re-initialize the code.,Observed Bug Behaviour
12692,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
12693,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
12694,Full Stack Trace: CODE,Observed Bug Behaviour
12695,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
12696,"Interesting, it's a only on a combo of numpy 1.12.1 and 32 bit python...",Observed Bug Behaviour
12697,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12698,Trying to run in parallel processing.,Observed Bug Behaviour
12699,"did you use CODEif __name__ == ""__main__""CODE?",Observed Bug Behaviour
12700,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12701,"@honnibal  I'm also facing the same issue, (spacy 1.5.0).",Observed Bug Behaviour
12702,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
12703,Trace CODE,Observed Bug Behaviour
12704,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
12705,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12706,The problem is still the same,Observed Bug Behaviour
12707,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
12708,CODE.,Observed Bug Behaviour
12709,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
12710,**after installing Gensim**numpy (1.10.4) updated to numpy (1.13.3)scipy (0.16.1)   updated to scipy (0.19.1),Observed Bug Behaviour
12711,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
12712,raises: CODE,Observed Bug Behaviour
12713,"Once again, this code works on my computer only when I change n_jobs to 1 or when I don't define a scoring= argument.",Observed Bug Behaviour
12714,raises: CODE,Observed Bug Behaviour
12715,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour
12716,Full Stack Trace: CODE,Observed Bug Behaviour
12717,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
12718,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12719,"When it freezes, it shows no error message.",Observed Bug Behaviour
12720,CODE,Observed Bug Behaviour
12721,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
12722,If you use CODE it works fine.,Observed Bug Behaviour
12723,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
12724,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour
12725,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour
12726,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour
12727,**after installing Gensim**numpy (1.10.4) updated to numpy (1.13.3)scipy (0.16.1)   updated to scipy (0.19.1),Observed Bug Behaviour
12728,We have to deal with it as though it were a memory leak and periodically re-initialize the code.,Observed Bug Behaviour
12729,I have a similar problem.,Observed Bug Behaviour
12730,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
12731,in both cases python-numpy is CODE (i.e. 1.12.1 numpy) and passed ok with numpy 1.8.2 in Debian jessie.,Observed Bug Behaviour
12732,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
12733,Code below.,Observed Bug Behaviour
12734,"*         Python 3.6.5,*         scikit-learn 0.19.1,*         Arch Linux,*         CPU cores: 8.",Observed Bug Behaviour
12735,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
12736,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
12737,The processes are still there and consume a constant amount of RAM but require no processing time.,Observed Bug Behaviour
12738,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
12739,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
12740,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12741,Debian test failures (was test_preserve_trustworthiness_approximately fails on 32bit: AssertionError: 0.89166666666666661 not greater than 0.9),Observed Bug Behaviour
12742,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour
12743,pipe(): ValueError Error parsing doc,Observed Bug Behaviour
12744,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour
12745,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12746,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour
12747,I have a similar issue with RandomizedSearchCV; it hangs indefinitely.,Observed Bug Behaviour
12748,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
12749,"Below is my code, it only works when CODE CODE",Observed Bug Behaviour
12750,"did you use CODEif __name__ == ""__main__""CODE?",Observed Bug Behaviour
12751,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12752,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour
12753,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
12754,raises: CODE,Observed Bug Behaviour
12755,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour
12756,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour
12757,Trying to run in parallel processing.,Observed Bug Behaviour
12758,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour
12759,However CODE,Observed Bug Behaviour
12760,"I used a ubuntu virtual instance in google cloud compute engine (bumpy, spicy, scikit etc were not the most up to date).",Observed Bug Behaviour
12761,"In windows, custom scorer still freezes.",Observed Bug Behaviour
12762,If you use CODE it works fine.,Observed Bug Behaviour
12763,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12764,Full Stack Trace: CODE,Observed Bug Behaviour
12765,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour
12766,The code ran fine.,Observed Bug Behaviour
12767,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12768,Trace CODE,Observed Bug Behaviour
12769,I have a similar problem.,Observed Bug Behaviour
12770,<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x10210d5c0> with a different variable scope than its first use.,Observed Bug Behaviour
12771,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
12772,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks Solution Usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour
12773,The error message is -CODE,Observed Bug Behaviour
12774,@amueller I didn't use the CODE.,Observed Bug Behaviour
12775,Sure - here's the full code - http://pastebin.com/yUE26SNs,Observed Bug Behaviour
12776,I was getting the CODE message.,Observed Bug Behaviour
12777,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour
12778,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour
12779,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
12780,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
12781,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour
12782,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour
12783,Code below.,Observed Bug Behaviour
12784,t-SNE fails with array must not contain infs or NaNs (OSX specific),Observed Bug Behaviour
12785,At least on my machine.,Observed Bug Behaviour
12786,I was getting the CODE message.,Observed Bug Behaviour
12787,I am using IPython Notebook.,Observed Bug Behaviour
12788,"Still, this code worked fine last Friday!",Observed Bug Behaviour
12789,Basically memory grows at a logarithmic-ish pace.,Observed Bug Behaviour
12790,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
12791,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour
12792,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour
12793,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour
12794,"Interesting, it's a only on a combo of numpy 1.12.1 and 32 bit python...",Observed Bug Behaviour
12795,Trying to run in parallel processing.,Observed Bug Behaviour
12796,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour
12797,I am not sure if I am the first who met the following error:,Observed Bug Behaviour
12798,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour
12799,"Also if you execute CODE before the same CODE call, CODE does not raise an exception (a dictionary is built?)",Observed Bug Behaviour
12800,"If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).",Observed Bug Behaviour
12801,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
12802,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour
12803,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12804,GridSearchCV parallel execution with own scorer freezes,Observed Bug Behaviour
12805,"did you use CODEif __name__ == ""__main__""CODE?",Observed Bug Behaviour
12806,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour
12807,I don't use pylab.,Observed Bug Behaviour
12808,After that the code freezes.,Observed Bug Behaviour
12809,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12810,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour
12811,Issue is still there guys.,Observed Bug Behaviour
12812,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour
12813,The problem is still the same,Observed Bug Behaviour
12814,CODE,Observed Bug Behaviour
12815,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour
12816,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
12817,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12818,The script hangs forever and the CPU utilization is low.,Observed Bug Behaviour
12819,Here is the code I used:CODE,Observed Bug Behaviour
12820,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12821,"In windows, custom scorer still freezes.",Observed Bug Behaviour
12822,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour
12823,"Interesting, it's a only on a combo of numpy 1.12.1 and 32 bit python...",Observed Bug Behaviour
12824,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
12825,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour
12826,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour
12827,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12828,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12829,I have a similar problem.,Observed Bug Behaviour
12830,@amueller I didn't use the CODE.,Observed Bug Behaviour
12831,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12832,I was getting the CODE message.,Observed Bug Behaviour
12833,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour
12834,Can you share the code of the scorer?,Observed Bug Behaviour
12835,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
12836,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour
12837,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour
12838,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour
12839,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12840,![captura de pantalla de 2018-05-25 17-53-11] URL ,Observed Bug Behaviour
12841,![captura de pantalla de 2018-05-25 17-54-59] URL ,Observed Bug Behaviour
12842,If you use CODE it works fine.,Observed Bug Behaviour
12843,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour
12844,"@honnibal  I'm also facing the same issue, (spacy 1.5.0).",Observed Bug Behaviour
12845,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour
12846,However CODE,Observed Bug Behaviour
12847,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
12848,The processes are still there and consume a constant amount of RAM but require no processing time.,Observed Bug Behaviour
12849,"n_jobs=1 works,but takes forever of course (it worked in the previous env as well).",Observed Bug Behaviour
12850,**after installing Gensim**numpy (1.10.4) updated to numpy (1.13.3)scipy (0.16.1)   updated to scipy (0.19.1),Observed Bug Behaviour
12851,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour
12852,Then I installed Gensim.,Observed Bug Behaviour
12853,"Still, this code worked fine last Friday!",Observed Bug Behaviour
12854,The error message is -CODE,Observed Bug Behaviour
12855,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour
12856,"I used a ubuntu virtual instance in google cloud compute engine (bumpy, spicy, scikit etc were not the most up to date).",Observed Bug Behaviour
12857,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour
12858,"Below is my code, it only works when CODE CODE",Observed Bug Behaviour
12859,Issue is still there guys.,Observed Bug Behaviour
12860,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12861,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour
12862,Full Stack Trace: CODE,Observed Bug Behaviour
12863,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour
12864,The code ran fine.,Observed Bug Behaviour
12865,@amueller I didn't use the CODE.,Observed Bug Behaviour
12866,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour
12867,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour
12868,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour
12869,We have to deal with it as though it were a memory leak and periodically re-initialize the code.,Observed Bug Behaviour
12870,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour
12871,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour
12872,building 0.19b2 on debian/ubuntus ...,Observed Bug Behaviour
12873,CODE,Observed Bug Behaviour
12874,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour
12875,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour
12876,<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x10210d5c0> with a different variable scope than its first use.,Observed Bug Behaviour
12877,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
12878,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour
12879,"Thank you @thomberg1 , but addingCODEdid not help.",Observed Bug Behaviour
12880,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
12881,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour
12882,CODE,Observed Bug Behaviour
12883,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour
12884,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour
12885,"When it freezes, it shows no error message.",Observed Bug Behaviour
12886,CODE,Observed Bug Behaviour
12887,only one copy of each package etc.,Observed Bug Behaviour
12888,After that the code freezes.,Observed Bug Behaviour
12889,"did you use CODEif __name__ == ""__main__""CODE?",Observed Bug Behaviour
12890,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour
12891,Please create a new instance of the cell if you would like it to use a different set of weights.,Observed Bug Behaviour
12892,@KaisJM  I'm running the same snippet here (windows) and it freezes. CODE,Observed Bug Behaviour
12893,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour
12894,The text it tried to parse isn't relevant: CODE but I did update global CODE in a loop while parsing the doc in the same loop.,Observed Bug Behaviour
12895,"However, the CPU utilization remains 0 for all python processes.",Observed Bug Behaviour
12896,CODE.,Observed Bug Behaviour
12897,GridSearchCV parallel execution with own scorer freezes,Observed Bug Behaviour
12898,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests
12899,at the first CODE suggesting there is [a platform conflict] URL .,Potential New Issues and Requests
12900,i had wondered iffinding and data close to 0 would help here.,Potential New Issues and Requests
12901,"Among other things, we support a narrower range of platforms.",Potential New Issues and Requests
12902,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
12903,"If there is any interest, I would be glad to improve the service to enable communication with spaCy.",Potential New Issues and Requests
12904,"So yes, please open an issue.",Potential New Issues and Requests
12905,Say I suspect that some of the values from 1...1024 are meaningful.,Potential New Issues and Requests
12906,"However, I think that #3265 would basically want to implement it like this.",Potential New Issues and Requests
12907,It's a result of CODE being the same as CODE on a machine with 1 core.,Potential New Issues and Requests
12908,I am trying to make a QnA system.,Potential New Issues and Requests
12909,*         https://github.com/PAIR-code/deeplearnjs/issues/238,Potential New Issues and Requests
12910,"There is no central documentation for that, right?",Potential New Issues and Requests
12911,"@magick93 your issue seems to be something else, not the CUDA version.",Potential New Issues and Requests
12912,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests
12913,The n_jobs=1 issue has been fixed.,Potential New Issues and Requests
12914,I'm guessing Gensim would hesitate to depend on spaCy.,Potential New Issues and Requests
12915,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
12916,"Still, for a Debian release of 0.19.0 I'm not sure how this could work: can you apply some patches on the original .tar.gz to skip tests/modify code when needed?",Potential New Issues and Requests
12917,"The nearest neighbour of CODE turns out to be a misspelling, that the POS tagger seems to often tag correctly: CODE",Potential New Issues and Requests
12918,"We're in the process of abstracting away particular vector stores (in-memory matrix, sharded on-disk store, approximate kNN index...) from gensim, behind a common API.",Potential New Issues and Requests
12919,"It's certainly related, but not exactly a mean target encoding.",Potential New Issues and Requests
12920,"@magick93 your issue seems to be something else, not the CUDA version.",Potential New Issues and Requests
12921,"*         [x] CODE [arm64] URL ,  [ppc64] URL , [ppc64el] URL , [s390x] URL .",Potential New Issues and Requests
12922,General directions to install on OSX:CODE,Potential New Issues and Requests
12923,"The 16 byte alignment issue comes from Eigen, unfortunately, which requires the beginning of the memory addresses to be aligned with 16 bytes.",Potential New Issues and Requests
12924,See Issue #124,Potential New Issues and Requests
12925,We probably need to raise a CODE if CODE.,Potential New Issues and Requests
12926,@lastmjs I explain in more detail in the link I provided.,Potential New Issues and Requests
12927,I can easily make the matches list a numpy array if necessary.,Potential New Issues and Requests
12928,"Actually, the above Docker setup with conda wouldn't have worked anyway for other platforms, it should have been, something along the lines of, I think,CODE",Potential New Issues and Requests
12929,The n_jobs=1 issue has been fixed.,Potential New Issues and Requests
12930,Taking logs won't help here.,Potential New Issues and Requests
12931,Example: CODE,Potential New Issues and Requests
12932,"@jnothman I just tried, but I'm not able to run e.g. a ppc64 Docker image on my amd64 system.",Potential New Issues and Requests
12933,I want spaCy and Gensim to interoperate sanely.,Potential New Issues and Requests
12934,Some queries produce more confusing results: CODE,Potential New Issues and Requests
12935,This only seems to occur when I have more than 1 bucket.,Potential New Issues and Requests
12936,"So yes, please open an issue.",Potential New Issues and Requests
12937,i had wondered iffinding and data close to 0 would help here.,Potential New Issues and Requests
12938,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests
12939,"The next release islikely to include a fixed-width discretizer, but following on from a logtransform or a quantile transform it should act quite similar to what youwant...",Potential New Issues and Requests
12940,This only seems to occur when I have more than 1 bucket.,Potential New Issues and Requests
12941,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
12942,It would be great to be able to plug it in spaCy.,Potential New Issues and Requests
12943,Related and possibly of interest: I managed to get TF running in the browser via Webassembly.,Potential New Issues and Requests
12944,We should really think about the organization of the docs.,Potential New Issues and Requests
12945,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
12946,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests
12947,"First of all - deeplearn.js is a library that only mirrors to some extent ""the style of TensorFlow API"" and operates purely in the browser and the other would be a direct API to whole Tensorflow goodness.",Potential New Issues and Requests
12948,Any ideas how to fix here?,Potential New Issues and Requests
12949,Say you have an integer numeric feature which takes a large range of values.,Potential New Issues and Requests
12950,But a class action _lawsuit_ is definitely a type of lawsuit: CODE,Potential New Issues and Requests
12951,PS: Now I'm getting CODE and I have no idea if it's relevant or not..,Potential New Issues and Requests
12952,*         [ ] CODE (not listed above): [mips] URL .,Potential New Issues and Requests
12953,"@magick93 your issue seems to be something else, not the CUDA version.",Potential New Issues and Requests
12954,"Unfortunately, that's not the issue here (although it should be fixed):compute_gradient is only ever called with stop=-1.",Potential New Issues and Requests
12955,"The 16 byte alignment issue comes from Eigen, unfortunately, which requires the beginning of the memory addresses to be aligned with 16 bytes.",Potential New Issues and Requests
12956,"First of all - deeplearn.js is a library that only mirrors to some extent ""the style of TensorFlow API"" and operates purely in the browser and the other would be a direct API to whole Tensorflow goodness.",Potential New Issues and Requests
12957,Definitely want to get together on this.,Potential New Issues and Requests
12958,@jhseu You mentioned that you consider removing the CODEfeed_dictCODE copy as orthogonal to this issue.,Potential New Issues and Requests
12959,What do you think?,Potential New Issues and Requests
12960,Instead of: CODE,Potential New Issues and Requests
12961,"It's certainly related, but not exactly a mean target encoding.",Potential New Issues and Requests
12962,"I think tensorflow need 2 hyper methods that change the model state, something like torch.",Potential New Issues and Requests
12963,"test_pairwise_parallel I had missed, but I also suspect it's something we'll find impossible to debug...",Potential New Issues and Requests
12964,"I'll be writing more about these vectors, and of course releasing the code. I'd like to sharpen up one or two things and run it on more data first.",Potential New Issues and Requests
12965,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests
12966,"@eamartin there have been a number of changes since the beginning of March by @alextp to speed up feed_dict; when the memory is aligned with 16 bytes, I think we share buffers with numpy, so nightly releases may be faster for you.",Potential New Issues and Requests
12967,You can do: CODE,Potential New Issues and Requests
12968,Will need to find a VM image instead...,Potential New Issues and Requests
12969,"Could we make the underlying workings of word embeddings compositional/consistent as well (what if we need to do text analysis over legal+finance texts, or multi-lingual texts)?",Potential New Issues and Requests
12970,Do you have a link for that?,Potential New Issues and Requests
12971,"I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency.",Potential New Issues and Requests
12972,PR in ~#9734~ #9830,Potential New Issues and Requests
12973,i had wondered iffinding and data close to 0 would help here.,Potential New Issues and Requests
12974,That is 22 indicates something specific which is quite different from 21 or 23.,Potential New Issues and Requests
12975,"Hi guys, would appreciate your input on issue https://github.com/piskvorky/gensim/issues/527.",Potential New Issues and Requests
12976,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests
12977,"I did a little looking around, and it looks like https://github.com/tensorflow/tensorflow/commits?author=alextp&since=2017-03-01T06:00:00Z&until=2017-04-01T05:00:00Z are the relevant commits.",Potential New Issues and Requests
12978,"I have found the ""convert to a string"" and then DictVectorizer method to be very useful for discovering which these are.",Potential New Issues and Requests
12979,I see in the logs there an alarming number of fails for a final release :(((,Potential New Issues and Requests
12980,@lastmjs I explain in more detail in the link I provided.,Potential New Issues and Requests
12981,For larger values you suspect this isnât the case.,Potential New Issues and Requests
12982,A few bonus queries on the chunked model. 1)         The vector space seems like it'll give a good way to show compositionality:,Potential New Issues and Requests
12983,from [kfreebsd-amd64] URL ,Potential New Issues and Requests
12984,"Hi guys, would appreciate your input on issue https://github.com/piskvorky/gensim/issues/527.",Potential New Issues and Requests
12985,Will review.,Potential New Issues and Requests
12986,"The results at the moment are quite messy, and many of the phrases need to be pruned from the vocab.",Potential New Issues and Requests
12987,"but this still wouldn't help unless someone has access to non amd64 platforms and is able to run it there, using the [appropriate Docker Debian image](https://github.com/docker-library/official-images#architectures-other-than-amd64) ...",Potential New Issues and Requests
12988,So you're using it for a non-linear discretisation?,Potential New Issues and Requests
12989,But I want to leave all the values over 1024 as numerical as I don't think those specific values mean much.,Potential New Issues and Requests
12990,"""fair game"" is not a type of game: CODE",Potential New Issues and Requests
12991,Would it be possible for numpy to share buffers with tensorflow variableswhen they are returned from a session run?,Potential New Issues and Requests
12992,"I'd like to minimize the number of mechanisms we have in sklearn, and we definitely need one (more?) for efficient model selection.",Potential New Issues and Requests
12993,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests
12994,"Anyway, I think this could be a feature that more people than I might be interested in and should/could possibly be integrated into master.",Potential New Issues and Requests
12995,And a quick sample to show how it's used together with deeplearnjs:CODE,Potential New Issues and Requests
12996,"Re: fusion of SpaCy and gensim APIs, I personally find the current gensim API tree not as straightforward/simple as scikit-learn (don't mistake me, gensim is extremely uniquely useful, e.g LDA, wikicorpus, etc).",Potential New Issues and Requests
12997,Reddit also thinks hot dogs are practically salad: CODE,Potential New Issues and Requests
12998,"I did a little looking around, and it looks like https://github.com/tensorflow/tensorflow/commits?author=alextp&since=2017-03-01T06:00:00Z&until=2017-04-01T05:00:00Z are the relevant commits.",Potential New Issues and Requests
12999,I'm guessing Gensim would hesitate to depend on spaCy.,Potential New Issues and Requests
13000,"@magick93 your issue seems to be something else, not the CUDA version.",Potential New Issues and Requests
13001,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests
13002,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
13003,Trying to narrow the scope of ParserStateError right now.,Potential New Issues and Requests
13004,"I think tensorflow need 2 hyper methods that change the model state, something like torch.",Potential New Issues and Requests
13005,"I'm not sure why Eigen was not written to handle unaligned first and last ""packets"" so it wouldn't matter.",Potential New Issues and Requests
13006,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests
13007,This only seems to occur when I have more than 1 bucket.,Potential New Issues and Requests
13008,I don't think it's due to floating point error.,Potential New Issues and Requests
13009,[change model state](https://github.com/torch/nn/blob/master/doc/module.md#training).,Potential New Issues and Requests
13010,"I'm afraid I'm getting this, too, in version 1.5.0: CODE",Potential New Issues and Requests
13011,"We're in the process of abstracting away particular vector stores (in-memory matrix, sharded on-disk store, approximate kNN index...) from gensim, behind a common API.",Potential New Issues and Requests
13012,"Since this basically tests that in CODE we can disable the CODE functionality (enabled by default) and it doesn't validate any new functionality, it might be OK to skip it on failure on 32 bit?",Potential New Issues and Requests
13013,"It could be a +1 - 1 = 0or a +3 - 2 = 1 (instead of 3+2=5) as long the value in the hash bucketis lower than the sum of the absolute value of hashed terms, it issufficient to determine whether CODE is used or not duringthe hash collisions, I think..",Potential New Issues and Requests
13014,"It's certainly related, but not exactly a mean target encoding.",Potential New Issues and Requests
13015,full traceback:CODE,Potential New Issues and Requests
13016,"maybe for hobbyists but not for commercial use, where one would need clusters of machines to aim the computing process.",Potential New Issues and Requests
13017,"Got this error in version 1.7.3: Traceback (most recent call last):File ""<stdin>"", line 1, in <module>File ""/home/ktyao/anaconda3/envs/python27/lib/python2.7/site-packages/spacy/language.py"", line 350, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 207, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:7730)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:u'Meet Linux.Mirai Trojan, a DDoS nightmare'",Potential New Issues and Requests
13018,"It's certainly related, but not exactly a mean target encoding.",Potential New Issues and Requests
13019,"Also, it adds columns, not replaces, so will not yet work out of the box for string categorical data (but that is more feedback on that PR, not to discuss here).",Potential New Issues and Requests
13020,"Got this error in version 1.7.3: Traceback (most recent call last):File ""<stdin>"", line 1, in <module>File ""/home/ktyao/anaconda3/envs/python27/lib/python2.7/site-packages/spacy/language.py"", line 350, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 207, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:7730)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:u'Meet Linux.Mirai Trojan, a DDoS nightmare'",Potential New Issues and Requests
13021,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests
13022,"If you want to further discuss the specific non-linear discretization or mixed numeric/string encoding, feel free to open a new issue.",Potential New Issues and Requests
13023,"Re: fusion of SpaCy and gensim APIs, I personally find the current gensim API tree not as straightforward/simple as scikit-learn (don't mistake me, gensim is extremely uniquely useful, e.g LDA, wikicorpus, etc).",Potential New Issues and Requests
13024,I am running tf 1.2.1 (GPU)  on ubuntu 16.04 lts.,Potential New Issues and Requests
13025,*         [ ] CODE (not listed above): [mips] URL .,Potential New Issues and Requests
13026,*         https://github.com/PAIR-code/deeplearnjs/issues/238,Potential New Issues and Requests
13027,"From my checking, these didn't make it into TF 1.1 but hopefully will be in 1.2.",Potential New Issues and Requests
13028,"Could we make the underlying workings of word embeddings compositional/consistent as well (what if we need to do text analysis over legal+finance texts, or multi-lingual texts)?",Potential New Issues and Requests
13029,I'll submit a PR to reduce precision of the test.,Potential New Issues and Requests
13030,The segfault is caused by matcher.,Potential New Issues and Requests
13031,"@rth, do you mind looking into the CODE failure above?",Potential New Issues and Requests
13032,*         https://github.com/PAIR-code/deeplearnjs/issues/238,Potential New Issues and Requests
13033,"If you want to further discuss the specific non-linear discretization or mixed numeric/string encoding, feel free to open a new issue.",Potential New Issues and Requests
13034,So unless I missed something it doesn't look like this could be reproducible in Docker.,Potential New Issues and Requests
13035,It seems to think CODE and CODE are very similar: CODE,Potential New Issues and Requests
13036,"maybe for hobbyists but not for commercial use, where one would need clusters of machines to aim the computing process.",Potential New Issues and Requests
13037,"there was apparently also a 32bit failure on windows for 0.19.1, but I don't think it was this one.",Potential New Issues and Requests
13038,"Unfortunately, that's not the issue here (although it should be fixed):compute_gradient is only ever called with stop=-1.",Potential New Issues and Requests
13039,"Here is the trace: Traceback (most recent call last):File ""tests/test_spacy_nlp.py"", line 231, in test_should_return_none_when_spacy_parsing_failsdoc = self.spacy_nlp.parse(query)File ""spacy_nlp.py"", line 49, in parsereturn SpacyDoc(self.__instance.parser(query))File ""lib/python3.5/site-packages/spacy/language.py"", line 328, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 146, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:6114)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:'splash On'",Potential New Issues and Requests
13040,"I'm not sure why Eigen was not written to handle unaligned first and last ""packets"" so it wouldn't matter.",Potential New Issues and Requests
13041,See Issue #124,Potential New Issues and Requests
13042,"Also, its not even remotely close to being called an alternative to Tensorflow...",Potential New Issues and Requests
13043,That would be less dependent on the actual hashing implementation...,Potential New Issues and Requests
13044,@jnothman So far I am not able to reproduce the CODE failure above.,Potential New Issues and Requests
13045,from [kfreebsd-amd64] URL ,Potential New Issues and Requests
13046,Definitely want to get together on this.,Potential New Issues and Requests
13047,"If there is any interest, I would be glad to improve the service to enable communication with spaCy.",Potential New Issues and Requests
13048,But I want to leave all the values over 1024 as numerical as I don't think those specific values mean much.,Potential New Issues and Requests
13049,Some queries produce more confusing results: CODE,Potential New Issues and Requests
13050,Was wondering if spacy gives a direct method to find similarity between 2 sentences?,Potential New Issues and Requests
13051,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests
13052,"We could try to make this test more robust, by just taking a large number of tokens N, hashing them with a hash table size = 1 (or any small number), and checking that with CODE the sum of hashed values is equal to CODE, and that it's strictly lower than CODE if  CODE (since some +1 / -1 are bound to cancel out if N is large enough).",Potential New Issues and Requests
13053,"Here is the trace: Traceback (most recent call last):File ""tests/test_spacy_nlp.py"", line 231, in test_should_return_none_when_spacy_parsing_failsdoc = self.spacy_nlp.parse(query)File ""spacy_nlp.py"", line 49, in parsereturn SpacyDoc(self.__instance.parser(query))File ""lib/python3.5/site-packages/spacy/language.py"", line 328, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 146, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:6114)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:'splash On'",Potential New Issues and Requests
13054,Then you can investigate what's going on.,Potential New Issues and Requests
13055,"As for SpaCy, I hope there's a portable way to train/retrieve the word embeddings across domains (pharma, legal, finance, etc) and natural languages.",Potential New Issues and Requests
13056,Is this testing a collision where the sign alternates and hence the valuelands up at 0?,Potential New Issues and Requests
13057,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests
13058,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests
13059,A reference could be the dropout implementation here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L433-L435,Potential New Issues and Requests
13060,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
13061,I consistently get the failure about CODE (that was resolved since as far as I understand) but not the one about hashing.,Potential New Issues and Requests
13062,"@prashantserai Don't exactly know, but what you met seems to be another issue.",Potential New Issues and Requests
13063,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
13064,I think of it as a demo what you can achieve with JavaScript and neural networks...,Potential New Issues and Requests
13065,I consistently get the failure about CODE (that was resolved since as far as I understand) but not the one about hashing.,Potential New Issues and Requests
13066,"The next release islikely to include a fixed-width discretizer, but following on from a logtransform or a quantile transform it should act quite similar to what youwant...",Potential New Issues and Requests
13067,I want spaCy and Gensim to interoperate sanely.,Potential New Issues and Requests
13068,"I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency.",Potential New Issues and Requests
13069,I've created a fork of headless-gl that works with deeplearnjs (which in turn works with tensorflow) - this allows models to be run natively on the GPU from node.js (note that it's only been tested on OSX so far).,Potential New Issues and Requests
13070,"As for SpaCy, I hope there's a portable way to train/retrieve the word embeddings across domains (pharma, legal, finance, etc) and natural languages.",Potential New Issues and Requests
13071,I can easily make the matches list a numpy array if necessary.,Potential New Issues and Requests
13072,"Searching for ""CountTransformer"" does not give any results",Potential New Issues and Requests
13073,Do we have a rough plan for the change of APIs?,Potential New Issues and Requests
13074,"Unfortunately, that's not the issue here (although it should be fixed):compute_gradient is only ever called with stop=-1.",Potential New Issues and Requests
13075,FWIW -- locally I had only the test_multi_output_classification_partial_fit_parallelism to popup and indeed it was due to inability to do multiprocessing in my case (absent bound to /dev/shm I guess):CODE,Potential New Issues and Requests
13076,I am running tf 1.2.1 (GPU)  on ubuntu 16.04 lts.,Potential New Issues and Requests
13077,The test is failing where the importances in a model are being asserted identical to the importance in a similar model trained with sample_weight=3*orig_weights.,Potential New Issues and Requests
13078,"Could we make the underlying workings of word embeddings compositional/consistent as well (what if we need to do text analysis over legal+finance texts, or multi-lingual texts)?",Potential New Issues and Requests
13079,@jnothman any ideas about the CODEtest_pairwise_parallelCODE failure?,Potential New Issues and Requests
13080,What do you think?,Potential New Issues and Requests
13081,"@jnothman I just tried, but I'm not able to run e.g. a ppc64 Docker image on my amd64 system.",Potential New Issues and Requests
13082,"Also, its not even remotely close to being called an alternative to Tensorflow...",Potential New Issues and Requests
13083,See https://humantoanimal.com for a demo; I will be providing more details in the future.,Potential New Issues and Requests
13084,"Still, for a Debian release of 0.19.0 I'm not sure how this could work: can you apply some patches on the original .tar.gz to skip tests/modify code when needed?",Potential New Issues and Requests
13085,Do you have a link for that?,Potential New Issues and Requests
13086,"but this still wouldn't help unless someone has access to non amd64 platforms and is able to run it there, using the [appropriate Docker Debian image](https://github.com/docker-library/official-images#architectures-other-than-amd64) ...",Potential New Issues and Requests
13087,I've trained a model on one month of Reddit comments.,Potential New Issues and Requests
13088,"*         [x] CODE: [mips] URL , [powerpc] URL , [hppa] URL , [ppc64] URL , [s390x] URL , [sparc64] URL  fixed in #9710",Potential New Issues and Requests
13089,"Right, I don't think the value of zero matters.",Potential New Issues and Requests
13090,"@nuchi, so did you compile the necessary TensorFlow code from the C API to WebAssembly?",Potential New Issues and Requests
13091,"Could SpaCy keep an eye on Apache Flink, Apache Spark, and TensorFlow's about-to-be-released distributed processing framework as well?",Potential New Issues and Requests
13092,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
13093,"I hope to discuss what kinds of behaviour people expect from such ""vector stores"", so we can design a sane API.",Potential New Issues and Requests
13094,"However you suspect that for some small values, the precise value is significant.",Potential New Issues and Requests
13095,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
13096,The n_jobs=1 issue has been fixed.,Potential New Issues and Requests
13097,I think I could migrate my class over to this tutorial pretty easily by using static RNN's.,Potential New Issues and Requests
13098,"I think tensorflow need 2 hyper methods that change the model state, something like torch.",Potential New Issues and Requests
13099,"I could investigate this later, maybe in another issue.",Potential New Issues and Requests
13100,full traceback:CODE,Potential New Issues and Requests
13101,Or just testing that values are stored in the same spot dueto collision?,Potential New Issues and Requests
13102,"@eamartin there have been a number of changes since the beginning of March by @alextp to speed up feed_dict; when the memory is aligned with 16 bytes, I think we share buffers with numpy, so nightly releases may be faster for you.",Potential New Issues and Requests
13103,from [kfreebsd-amd64] URL ,Potential New Issues and Requests
13104,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests
13105,"@jnothman I just tried, but I'm not able to run e.g. a ppc64 Docker image on my amd64 system.",Potential New Issues and Requests
13106,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests
13107,I think I could migrate my class over to this tutorial pretty easily by using static RNN's.,Potential New Issues and Requests
13108,"there was apparently also a 32bit failure on windows for 0.19.1, but I don't think it was this one.",Potential New Issues and Requests
13109,Then you can investigate what's going on.,Potential New Issues and Requests
13110,I just suspect that *some* values are but I don't know which ones or how many there are.,Potential New Issues and Requests
13111,I don't think it's due to floating point error.,Potential New Issues and Requests
13112,"Tried to build scikit-learn 0.19.2 it in a Debian sid/unstable i386 VM, were scipy and numpy 1.2.1 were installed with apt-get.",Potential New Issues and Requests
13113,#589 issue still exists.,Potential New Issues and Requests
13114,A HTTP query will return a base 64 encoding of the vector.,Potential New Issues and Requests
13115,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
13116,Should I open another issue for that segfault? CODE,Potential New Issues and Requests
13117,"We're in the process of abstracting away particular vector stores (in-memory matrix, sharded on-disk store, approximate kNN index...) from gensim, behind a common API.",Potential New Issues and Requests
13118,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
13119,"@jnothman I just tried, but I'm not able to run e.g. a ppc64 Docker image on my amd64 system.",Potential New Issues and Requests
13120,I'll submit a PR to reduce precision of the test.,Potential New Issues and Requests
13121,Taking logs won't help here.,Potential New Issues and Requests
13122,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests
13123,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests
13124,"*         [x] CODE [arm64] URL ,  [ppc64] URL , [ppc64el] URL , [s390x] URL .",Potential New Issues and Requests
13125,Trying to narrow the scope of ParserStateError right now.,Potential New Issues and Requests
13126,"The results at the moment are quite messy, and many of the phrases need to be pruned from the vocab.",Potential New Issues and Requests
13127,"I was also asking for the help from @ry to make my personal repository to be supported officially, there are few things we have to do like building some example models especially RNN cases, but unfortunately I'm got to work on other fields and have no time for these few months, if someone is interested in making this be happened, email to me, I'd love to guide you how to start.",Potential New Issues and Requests
13128,I've trained a model on one month of Reddit comments.,Potential New Issues and Requests
13129,2)         Similarity between entities can be kind of fun. Here's what Reddit thinks of Donald Trump: CODE,Potential New Issues and Requests
13130,at the first CODE suggesting there is [a platform conflict] URL .,Potential New Issues and Requests
13131,I want spaCy and Gensim to interoperate sanely.,Potential New Issues and Requests
13132,"As for SpaCy, I hope there's a portable way to train/retrieve the word embeddings across domains (pharma, legal, finance, etc) and natural languages.",Potential New Issues and Requests
13133,I have now opened a new issue at https://github.com/tensorflow/tensorflow/issues/17629.,Potential New Issues and Requests
13134,"I'll be writing more about these vectors, and of course releasing the code. I'd like to sharpen up one or two things and run it on more data first.",Potential New Issues and Requests
13135,A few bonus queries on the chunked model. 1)         The vector space seems like it'll give a good way to show compositionality:,Potential New Issues and Requests
13136,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests
13137,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests
13138,This test assumes that the hash value of the tested tokens always produces the same results (in which case two of those produce a collision).,Potential New Issues and Requests
13139,The error points to this function in seq2seq_model.py which is line 142 in seq2seq_model.py: CODE,Potential New Issues and Requests
13140,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests
13141,"@rth could the CODE failure be because of floating point error (i.e. a small number was in Xt.data instead of 0, and so was not removed)?",Potential New Issues and Requests
13142,"Despite that comment in murmurhash3, I'm not sure the hash value is actually platform dependent: after all this test passes on Appveyor 32bit and 64bit (and it works fine for me on i386) .",Potential New Issues and Requests
13143,"""fair game"" is not a type of game: CODE",Potential New Issues and Requests
13144,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests
13145,"So, I'd say it's more of a design thing.",Potential New Issues and Requests
13146,"Could SpaCy keep an eye on Apache Flink, Apache Spark, and TensorFlow's about-to-be-released distributed processing framework as well?",Potential New Issues and Requests
13147,Related and possibly of interest: I managed to get TF running in the browser via Webassembly.,Potential New Issues and Requests
13148,Taking logs won't help here.,Potential New Issues and Requests
13149,Was wondering if spacy gives a direct method to find similarity between 2 sentences?,Potential New Issues and Requests
13150,Keep in mind it wouldhave to be a backwards compatible change.,Potential New Issues and Requests
13151,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests
13152,I consistently get the failure about CODE (that was resolved since as far as I understand) but not the one about hashing.,Potential New Issues and Requests
13153,"Right, I don't think the value of zero matters.",Potential New Issues and Requests
13154,JavaScript APIs for TensorFlow were [announced] URL  earlier this month.,Potential New Issues and Requests
13155,"Do you know if there's any issue or work being done on removing the copy (at least in some cases, like row-major Numpy arrays with nice strides)?",Potential New Issues and Requests
13156,@jhseu You mentioned that you consider removing the CODEfeed_dictCODE copy as orthogonal to this issue.,Potential New Issues and Requests
13157,But the log transform might alone be sufficient in your setting.,Potential New Issues and Requests
13158,We're not calling eliminate_zeros anywhere.,Potential New Issues and Requests
13159,"If you want to further discuss the specific non-linear discretization or mixed numeric/string encoding, feel free to open a new issue.",Potential New Issues and Requests
13160,I don't think it's due to floating point error.,Potential New Issues and Requests
13161,"but this still wouldn't help unless someone has access to non amd64 platforms and is able to run it there, using the [appropriate Docker Debian image](https://github.com/docker-library/official-images#architectures-other-than-amd64) ...",Potential New Issues and Requests
13162,"I think it'd be great to introduce an API lineage of scikit-learn flavour, or that simple.",Potential New Issues and Requests
13163,"Got this error in version 1.7.3: Traceback (most recent call last):File ""<stdin>"", line 1, in <module>File ""/home/ktyao/anaconda3/envs/python27/lib/python2.7/site-packages/spacy/language.py"", line 350, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 207, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:7730)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:u'Meet Linux.Mirai Trojan, a DDoS nightmare'",Potential New Issues and Requests
13164,But there are also some interesting results in there too.,Potential New Issues and Requests
13165,"Still, for a Debian release of 0.19.0 I'm not sure how this could work: can you apply some patches on the original .tar.gz to skip tests/modify code when needed?",Potential New Issues and Requests
13166,"@nuchi, so did you compile the necessary TensorFlow code from the C API to WebAssembly?",Potential New Issues and Requests
13167,"Love the link between bacon and broccoli, wonder what adding sentiment into the mix would change about that :P",Potential New Issues and Requests
13168,Why is it not mean target encoding?,Potential New Issues and Requests
13169,I can easily make the matches list a numpy array if necessary.,Potential New Issues and Requests
13170,2)         Similarity between entities can be kind of fun. Here's what Reddit thinks of Donald Trump: CODE,Potential New Issues and Requests
13171,"A ""class action"" is only very weakly a type of action: CODE",Potential New Issues and Requests
13172,"*         [x] CODE: [mips] URL , [powerpc] URL , [hppa] URL , [ppc64] URL , [s390x] URL , [sparc64] URL  fixed in #9710",Potential New Issues and Requests
13173,And a quick sample to show how it's used together with deeplearnjs:CODE,Potential New Issues and Requests
13174,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
13175,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
13176,"The 16 byte alignment issue comes from Eigen, unfortunately, which requires the beginning of the memory addresses to be aligned with 16 bytes.",Potential New Issues and Requests
13177,"However you suspect that for some small values, the precise value is significant.",Potential New Issues and Requests
13178,"maybe for hobbyists but not for commercial use, where one would need clusters of machines to aim the computing process.",Potential New Issues and Requests
13179,But it does seem like a plausible suspect.,Potential New Issues and Requests
13180,Just to get enlightened: it seems great idea but does that mean that SpaCy and gensim will work together?,Potential New Issues and Requests
13181,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests
13182,I don't think it's due to floating point error.,Potential New Issues and Requests
13183,I can easily make the matches list a numpy array if necessary.,Potential New Issues and Requests
13184,I am trying to make a QnA system.,Potential New Issues and Requests
13185,**Dockerfile**CODEbuilt withCODE,Potential New Issues and Requests
13186,I see in the logs there an alarming number of fails for a final release :(((,Potential New Issues and Requests
13187,Do we have a rough plan for the change of APIs?,Potential New Issues and Requests
13188,"It won't grow much after this, I'm just curious how much entities it can hold and how it will affect the memory and performance.",Potential New Issues and Requests
13189,But the log transform might alone be sufficient in your setting.,Potential New Issues and Requests
13190,"But it's more important that both libraries stay internally consistent, and they have fairly different API norms.",Potential New Issues and Requests
13191,Is this testing a collision where the sign alternates and hence the valuelands up at 0?,Potential New Issues and Requests
13192,"The next release islikely to include a fixed-width discretizer, but following on from a logtransform or a quantile transform it should act quite similar to what youwant...",Potential New Issues and Requests
13193,Example: CODE,Potential New Issues and Requests
13194,"Right, I don't think the value of zero matters.",Potential New Issues and Requests
13195,You can do: CODE,Potential New Issues and Requests
13196,have we seen this before:,Potential New Issues and Requests
13197,Taking logs won't help here.,Potential New Issues and Requests
13198,Was wondering if spacy gives a direct method to find similarity between 2 sentences?,Potential New Issues and Requests
13199,@jnothman So far I am not able to reproduce the CODE failure above.,Potential New Issues and Requests
13200,"@jnothman  To be a little clearer,  I don't know that 22 is significant.",Potential New Issues and Requests
13201,"@prashantserai Don't exactly know, but what you met seems to be another issue.",Potential New Issues and Requests
13202,at the first CODE suggesting there is [a platform conflict] URL .,Potential New Issues and Requests
13203,I think this is relevant: https://github.com/spacy-io/spaCy/issues/413,Potential New Issues and Requests
13204,"From my checking, these didn't make it into TF 1.1 but hopefully will be in 1.2.",Potential New Issues and Requests
13205,"*         [x] CODE: [mips] URL , [powerpc] URL , [hppa] URL , [ppc64] URL , [s390x] URL , [sparc64] URL  fixed in #9710",Potential New Issues and Requests
13206,"A simple thing to do is to convert all small values to strings, run DictVectorizer as above and then perform feature selection or just use your favorite classifier directly.",Potential New Issues and Requests
13207,I think I could migrate my class over to this tutorial pretty easily by using static RNN's.,Potential New Issues and Requests
13208,A HTTP query will return a base 64 encoding of the vector.,Potential New Issues and Requests
13209,*         https://github.com/PAIR-code/deeplearnjs/issues/407,Potential New Issues and Requests
13210,"This will be used throughout gensim (doc2vec, word2vec, docsim...).",Potential New Issues and Requests
13211,Trying to narrow the scope of ParserStateError right now.,Potential New Issues and Requests
13212,and I know another WebAssemble research on TensorFlow at here:https://medium.com/@tomasreimers/compiling-tensorflow-for-the-browser-f3387b8e1e1c,Potential New Issues and Requests
13213,Say you have an integer numeric feature which takes a large range of values.,Potential New Issues and Requests
13214,A HTTP query will return a base 64 encoding of the vector.,Potential New Issues and Requests
13215,"Do you know if there's any issue or work being done on removing the copy (at least in some cases, like row-major Numpy arrays with nice strides)?",Potential New Issues and Requests
13216,we're going to release a bug-fix release in any case.,Potential New Issues and Requests
13217,"I do have a translator that works pretty similar to this one but creates cells through a separate class that allows for inserting bidirectional layers where you want, residuals where you want, merging inputs with concat vs. sum, and a few other things.",Potential New Issues and Requests
13218,"All was fine, until I added some matcher rules and an on_match callback: CODEwhere unit is 'BOPD', for example.",Potential New Issues and Requests
13219,"Could SpaCy keep an eye on Apache Flink, Apache Spark, and TensorFlow's about-to-be-released distributed processing framework as well?",Potential New Issues and Requests
13220,Was wondering if spacy gives a direct method to find similarity between 2 sentences?,Potential New Issues and Requests
13221,"Searching for ""CountTransformer"" does not give any results",Potential New Issues and Requests
13222,A segfault via the Python API (as opposed to the Cython API) is always a bug.,Potential New Issues and Requests
13223,"@lesshaste For the issue about NaNs as separate category, see https://github.com/scikit-learn/scikit-learn/issues/10465",Potential New Issues and Requests
13224,"So, I'd say it's more of a design thing.",Potential New Issues and Requests
13225,"@lesshaste For the issue about NaNs as separate category, see https://github.com/scikit-learn/scikit-learn/issues/10465",Potential New Issues and Requests
13226,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests
13227,That would be less dependent on the actual hashing implementation...,Potential New Issues and Requests
13228,"And it looks like mumurhash3 [doesn't actually produce the same results in 64bit and 32bit](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/src/MurmurHash3.cpp#L5), which would explain why this test fail.",Potential New Issues and Requests
13229,See details on the [deeplearn.js] URL  homepage.,Potential New Issues and Requests
13230,A reference could be the dropout implementation here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L433-L435,Potential New Issues and Requests
13231,PR in ~#9734~ #9830,Potential New Issues and Requests
13232,That would be less dependent on the actual hashing implementation...,Potential New Issues and Requests
13233,"I have found the ""convert to a string"" and then DictVectorizer method to be very useful for discovering which these are.",Potential New Issues and Requests
13234,"Re: fusion of SpaCy and gensim APIs, I personally find the current gensim API tree not as straightforward/simple as scikit-learn (don't mistake me, gensim is extremely uniquely useful, e.g LDA, wikicorpus, etc).",Potential New Issues and Requests
13235,*         https://github.com/PAIR-code/deeplearnjs/issues/407,Potential New Issues and Requests
13236,"Among other things, we support a narrower range of platforms.",Potential New Issues and Requests
13237,@jnothman So far I am not able to reproduce the CODE failure above.,Potential New Issues and Requests
13238,"Among other things, we support a narrower range of platforms.",Potential New Issues and Requests
13239,"There is no central documentation for that, right?",Potential New Issues and Requests
13240,The vectors for the verb and noun senses are quite different: CODE,Potential New Issues and Requests
13241,This test assumes that the hash value of the tested tokens always produces the same results (in which case two of those produce a collision).,Potential New Issues and Requests
13242,"*         [x] CODE: [mips] URL , [powerpc] URL , [hppa] URL , [ppc64] URL , [s390x] URL , [sparc64] URL  fixed in #9710",Potential New Issues and Requests
13243,The former I think.,Potential New Issues and Requests
13244,"I think it'd be great to introduce an API lineage of scikit-learn flavour, or that simple.",Potential New Issues and Requests
13245,"I was also asking for the help from @ry to make my personal repository to be supported officially, there are few things we have to do like building some example models especially RNN cases, but unfortunately I'm got to work on other fields and have no time for these few months, if someone is interested in making this be happened, email to me, I'd love to guide you how to start.",Potential New Issues and Requests
13246,This test assumes that the hash value of the tested tokens always produces the same results (in which case two of those produce a collision).,Potential New Issues and Requests
13247,"Also, it adds columns, not replaces, so will not yet work out of the box for string categorical data (but that is more feedback on that PR, not to discuss here).",Potential New Issues and Requests
13248,"And it looks like mumurhash3 [doesn't actually produce the same results in 64bit and 32bit](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/src/MurmurHash3.cpp#L5), which would explain why this test fail.",Potential New Issues and Requests
13249,"Here is our test:nlp = spacy.en.English()nlp.matcher.add('splash', 'my entity', {},[ [{LEMMA: 'splash'}, {LEMMA: 'on'}]])nlp('splash On')",Potential New Issues and Requests
13250,"A simple thing to do is to convert all small values to strings, run DictVectorizer as above and then perform feature selection or just use your favorite classifier directly.",Potential New Issues and Requests
13251,"Hi guys, would appreciate your input on issue https://github.com/piskvorky/gensim/issues/527.",Potential New Issues and Requests
13252,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests
13253,"Here is the trace: Traceback (most recent call last):File ""tests/test_spacy_nlp.py"", line 231, in test_should_return_none_when_spacy_parsing_failsdoc = self.spacy_nlp.parse(query)File ""spacy_nlp.py"", line 49, in parsereturn SpacyDoc(self.__instance.parser(query))File ""lib/python3.5/site-packages/spacy/language.py"", line 328, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 146, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:6114)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:'splash On'",Potential New Issues and Requests
13254,We probably need to raise a CODE if CODE.,Potential New Issues and Requests
13255,"I think it'd be great to introduce an API lineage of scikit-learn flavour, or that simple.",Potential New Issues and Requests
13256,"Right, I don't think the value of zero matters.",Potential New Issues and Requests
13257,full traceback:CODE,Potential New Issues and Requests
13258,"but this still wouldn't help unless someone has access to non amd64 platforms and is able to run it there, using the [appropriate Docker Debian image](https://github.com/docker-library/official-images#architectures-other-than-amd64) ...",Potential New Issues and Requests
13259,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests
13260,"I have found the ""convert to a string"" and then DictVectorizer method to be very useful for discovering which these are.",Potential New Issues and Requests
13261,I think of it as a demo what you can achieve with JavaScript and neural networks...,Potential New Issues and Requests
13262,"The nearest neighbour of CODE turns out to be a misspelling, that the POS tagger seems to often tag correctly: CODE",Potential New Issues and Requests
13263,Keep in mind it wouldhave to be a backwards compatible change.,Potential New Issues and Requests
13264,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests
13265,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
13266,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
13267,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
13268,"I think tensorflow need 2 hyper methods that change the model state, something like torch.",Potential New Issues and Requests
13269,"maybe for hobbyists but not for commercial use, where one would need clusters of machines to aim the computing process.",Potential New Issues and Requests
13270,Do you have a link for that?,Potential New Issues and Requests
13271,"there was apparently also a 32bit failure on windows for 0.19.1, but I don't think it was this one.",Potential New Issues and Requests
13272,I did not use Tensorflow.js in any way.,Potential New Issues and Requests
13273,I see in the logs there an alarming number of fails for a final release :(((,Potential New Issues and Requests
13274,have we seen this before:,Potential New Issues and Requests
13275,"However you suspect that for some small values, the precise value is significant.",Potential New Issues and Requests
13276,"The 16 byte alignment issue comes from Eigen, unfortunately, which requires the beginning of the memory addresses to be aligned with 16 bytes.",Potential New Issues and Requests
13277,This test assumes that the hash value of the tested tokens always produces the same results (in which case two of those produce a collision).,Potential New Issues and Requests
13278,"I'm afraid I'm getting this, too, in version 1.5.0: CODE",Potential New Issues and Requests
13279,"@nuchi, so did you compile the necessary TensorFlow code from the C API to WebAssembly?",Potential New Issues and Requests
13280,Short version: I added Webassembly as an XLA compilation target.,Potential New Issues and Requests
13281,I could only find sentence tokenizations and word similarities.,Potential New Issues and Requests
13282,"@nuchi, so did you compile the necessary TensorFlow code from the C API to WebAssembly?",Potential New Issues and Requests
13283,Is this testing a collision where the sign alternates and hence the valuelands up at 0?,Potential New Issues and Requests
13284,I've trained a model on one month of Reddit comments.,Potential New Issues and Requests
13285,"Could we make the underlying workings of word embeddings compositional/consistent as well (what if we need to do text analysis over legal+finance texts, or multi-lingual texts)?",Potential New Issues and Requests
13286,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
13287,I'm guessing Gensim would hesitate to depend on spaCy.,Potential New Issues and Requests
13288,"Anyway, I think this could be a feature that more people than I might be interested in and should/could possibly be integrated into master.",Potential New Issues and Requests
13289,For larger values you suspect this isnât the case.,Potential New Issues and Requests
13290,I see in the logs there an alarming number of fails for a final release :(((,Potential New Issues and Requests
13291,"Actually, the above Docker setup with conda wouldn't have worked anyway for other platforms, it should have been, something along the lines of, I think,CODE",Potential New Issues and Requests
13292,It's a result of CODE being the same as CODE on a machine with 1 core.,Potential New Issues and Requests
13293,"No matter how much we optimize it, feed_dict will never be the fastest way to feed data into a training job.",Potential New Issues and Requests
13294,That is 22 indicates something specific which is quite different from 21 or 23.,Potential New Issues and Requests
13295,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests
13296,I am running tf 1.2.1 (GPU)  on ubuntu 16.04 lts.,Potential New Issues and Requests
13297,But the log transform might alone be sufficient in your setting.,Potential New Issues and Requests
13298,"@magick93 your issue seems to be something else, not the CUDA version.",Potential New Issues and Requests
13299,"So, I'd say it's more of a design thing.",Potential New Issues and Requests
13300,"But it's more important that both libraries stay internally consistent, and they have fairly different API norms.",Potential New Issues and Requests
13301,"Since this basically tests that in CODE we can disable the CODE functionality (enabled by default) and it doesn't validate any new functionality, it might be OK to skip it on failure on 32 bit?",Potential New Issues and Requests
13302,@lastmjs I explain in more detail in the link I provided.,Potential New Issues and Requests
13303,Discussion of Bill Cosby makes some obvious (and some less obvious) comparisons: CODE,Potential New Issues and Requests
13304,"No matter how much we optimize it, feed_dict will never be the fastest way to feed data into a training job.",Potential New Issues and Requests
13305,"If there is any interest, I would be glad to improve the service to enable communication with spaCy.",Potential New Issues and Requests
13306,General directions to install on OSX:CODE,Potential New Issues and Requests
13307,"The results at the moment are quite messy, and many of the phrases need to be pruned from the vocab.",Potential New Issues and Requests
13308,#589 issue still exists.,Potential New Issues and Requests
13309,"I think it'd be great to introduce an API lineage of scikit-learn flavour, or that simple.",Potential New Issues and Requests
13310,Taking logs won't help here.,Potential New Issues and Requests
13311,"I did a little looking around, and it looks like https://github.com/tensorflow/tensorflow/commits?author=alextp&since=2017-03-01T06:00:00Z&until=2017-04-01T05:00:00Z are the relevant commits.",Potential New Issues and Requests
13312,"I hope to discuss what kinds of behaviour people expect from such ""vector stores"", so we can design a sane API.",Potential New Issues and Requests
13313,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
13314,"Hi guys, would appreciate your input on issue https://github.com/piskvorky/gensim/issues/527.",Potential New Issues and Requests
13315,We probably need to raise a CODE if CODE.,Potential New Issues and Requests
13316,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
13317,Then you can investigate what's going on.,Potential New Issues and Requests
13318,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
13319,The vectors for the verb and noun senses are quite different: CODE,Potential New Issues and Requests
13320,It would be great to be able to plug it in spaCy.,Potential New Issues and Requests
13321,I did not use Tensorflow.js in any way.,Potential New Issues and Requests
13322,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
13323,So unless I missed something it doesn't look like this could be reproducible in Docker.,Potential New Issues and Requests
13324,And none of them are about CODE CODE,Potential New Issues and Requests
13325,"Anyway, I think this could be a feature that more people than I might be interested in and should/could possibly be integrated into master.",Potential New Issues and Requests
13326,"I think it'd be great to introduce an API lineage of scikit-learn flavour, or that simple.",Potential New Issues and Requests
13327,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests
13328,"How do you use such stores in spaCy, what metrics do you employ, what API signatures?",Potential New Issues and Requests
13329,"A ""class action"" is only very weakly a type of action: CODE",Potential New Issues and Requests
13330,Example: CODE,Potential New Issues and Requests
13331,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests
13332,Do you have a link for that?,Potential New Issues and Requests
13333,"However you suspect that for some small values, the precise value is significant.",Potential New Issues and Requests
13334,Then you can investigate what's going on.,Potential New Issues and Requests
13335,"I was also asking for the help from @ry to make my personal repository to be supported officially, there are few things we have to do like building some example models especially RNN cases, but unfortunately I'm got to work on other fields and have no time for these few months, if someone is interested in making this be happened, email to me, I'd love to guide you how to start.",Potential New Issues and Requests
13336,"I'll do it tomorrow, once I know the steps to reproduce it.",Potential New Issues and Requests
13337,"I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency.",Potential New Issues and Requests
13338,@jnothman any ideas about the CODEtest_pairwise_parallelCODE failure?,Potential New Issues and Requests
13339,"We should make feed_dict faster (likely by not copying the numpy.arrays like @yaroslavvb mentioned), but that's orthogonal to this change.",Potential New Issues and Requests
13340,See Issue #124,Potential New Issues and Requests
13341,This only seems to occur when I have more than 1 bucket.,Potential New Issues and Requests
13342,"Love the link between bacon and broccoli, wonder what adding sentiment into the mix would change about that :P",Potential New Issues and Requests
13343,Discussion of Bill Cosby makes some obvious (and some less obvious) comparisons: CODE,Potential New Issues and Requests
13344,PS: Now I'm getting CODE and I have no idea if it's relevant or not..,Potential New Issues and Requests
13345,So you're using it for a non-linear discretisation?,Potential New Issues and Requests
13346,"No matter how much we optimize it, feed_dict will never be the fastest way to feed data into a training job.",Potential New Issues and Requests
13347,"Got this error in version 1.7.3: Traceback (most recent call last):File ""<stdin>"", line 1, in <module>File ""/home/ktyao/anaconda3/envs/python27/lib/python2.7/site-packages/spacy/language.py"", line 350, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 207, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:7730)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:u'Meet Linux.Mirai Trojan, a DDoS nightmare'",Potential New Issues and Requests
13348,Just to get enlightened: it seems great idea but does that mean that SpaCy and gensim will work together?,Potential New Issues and Requests
13349,I consistently get the failure about CODE (that was resolved since as far as I understand) but not the one about hashing.,Potential New Issues and Requests
13350,"I think it'd be great to introduce an API lineage of scikit-learn flavour, or that simple.",Potential New Issues and Requests
13351,Any ideas how to fix here?,Potential New Issues and Requests
13352,2)         Similarity between entities can be kind of fun. Here's what Reddit thinks of Donald Trump: CODE,Potential New Issues and Requests
13353,"How do you use such stores in spaCy, what metrics do you employ, what API signatures?",Potential New Issues and Requests
13354,It sounds like you know too much about your variable for a generictransform to be the sort of thing you need.,Potential New Issues and Requests
13355,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
13356,"Also, its not even remotely close to being called an alternative to Tensorflow...",Potential New Issues and Requests
13357,"There is no central documentation for that, right?",Potential New Issues and Requests
13358,"If you want to further discuss the specific non-linear discretization or mixed numeric/string encoding, feel free to open a new issue.",Potential New Issues and Requests
13359,"We'd like to end up with something that is flexible enough to cover all standard use cases (CODE, CODE, CODE etc) but still concise and clearly scoped.",Potential New Issues and Requests
13360,"Unfortunately, that's not the issue here (although it should be fixed):compute_gradient is only ever called with stop=-1.",Potential New Issues and Requests
13361,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests
13362,FWIW -- locally I had only the test_multi_output_classification_partial_fit_parallelism to popup and indeed it was due to inability to do multiprocessing in my case (absent bound to /dev/shm I guess):CODE,Potential New Issues and Requests
13363,"First of all - deeplearn.js is a library that only mirrors to some extent ""the style of TensorFlow API"" and operates purely in the browser and the other would be a direct API to whole Tensorflow goodness.",Potential New Issues and Requests
13364,"I've been playing with an extension of this idea, where noun chunks and named entities are also merged.",Potential New Issues and Requests
13365,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
13366,I've trained a model on one month of Reddit comments.,Potential New Issues and Requests
13367,"From my checking, these didn't make it into TF 1.1 but hopefully will be in 1.2.",Potential New Issues and Requests
13368,But I want to leave all the values over 1024 as numerical as I don't think those specific values mean much.,Potential New Issues and Requests
13369,"Sorry, CountFeaturizer #9614",Potential New Issues and Requests
13370,"Could we make the underlying workings of word embeddings compositional/consistent as well (what if we need to do text analysis over legal+finance texts, or multi-lingual texts)?",Potential New Issues and Requests
13371,The test is failing where the importances in a model are being asserted identical to the importance in a similar model trained with sample_weight=3*orig_weights.,Potential New Issues and Requests
13372,The error points to this function in seq2seq_model.py which is line 142 in seq2seq_model.py: CODE,Potential New Issues and Requests
13373,"Among other things, we support a narrower range of platforms.",Potential New Issues and Requests
13374,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
13375,"(As a side point, @ogrisel, I note there seems to be a lot more joblibparallelisation overhead in master -- on OS X at least -- that wasn't therein 0.14...)",Potential New Issues and Requests
13376,I've created a fork of headless-gl that works with deeplearnjs (which in turn works with tensorflow) - this allows models to be run natively on the GPU from node.js (note that it's only been tested on OSX so far).,Potential New Issues and Requests
13377,I am receiving the same CODE but with CODE.,Potential New Issues and Requests
13378,I see in the logs there an alarming number of fails for a final release :(((,Potential New Issues and Requests
13379,We've been using an external server for word2vec for over a year now.,Potential New Issues and Requests
13380,"Hi, We are getting a parser state error.",Potential New Issues and Requests
13381,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests
13382,@jnothman So far I am not able to reproduce the CODE failure above.,Potential New Issues and Requests
13383,Will review.,Potential New Issues and Requests
13384,I'm guessing Gensim would hesitate to depend on spaCy.,Potential New Issues and Requests
13385,The on_match callback is being called.,Potential New Issues and Requests
13386,"I'll do it tomorrow, once I know the steps to reproduce it.",Potential New Issues and Requests
13387,and I know another WebAssemble research on TensorFlow at here:https://medium.com/@tomasreimers/compiling-tensorflow-for-the-browser-f3387b8e1e1c,Potential New Issues and Requests
13388,"I've been playing with an extension of this idea, where noun chunks and named entities are also merged.",Potential New Issues and Requests
13389,I'm guessing Gensim would hesitate to depend on spaCy.,Potential New Issues and Requests
13390,The n_jobs=1 issue has been fixed.,Potential New Issues and Requests
13391,"However, I think that #3265 would basically want to implement it like this.",Potential New Issues and Requests
13392,2)         Similarity between entities can be kind of fun. Here's what Reddit thinks of Donald Trump: CODE,Potential New Issues and Requests
13393,"I think tensorflow need 2 hyper methods that change the model state, something like torch.",Potential New Issues and Requests
13394,"You can find the install directions and a basic sample at https://github.com/dfoody/headless-glAnd, of course https://deeplearnjs.org for more details.",Potential New Issues and Requests
13395,The test is failing where the importances in a model are being asserted identical to the importance in a similar model trained with sample_weight=3*orig_weights.,Potential New Issues and Requests
13396,Currently we are accessing the vector space through the https://github.com/3Top/word2vec-api/ project.,Potential New Issues and Requests
13397,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests
13398,Will need to find a VM image instead...,Potential New Issues and Requests
13399,"So the test fails on [this line](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/tests/test_feature_hasher.py#L122), where the expected values are CODE and  CODE (and I get those in the 32bit VM as well).",Potential New Issues and Requests
13400,"I am using a customized tokenizer that merges the three tokens, 'Linux', '.' and 'Mirai', into one token.",Potential New Issues and Requests
13401,Feel free to open other more specific FRs.,Potential New Issues and Requests
13402,I see in the logs there an alarming number of fails for a final release :(((,Potential New Issues and Requests
13403,Do you have a link for that?,Potential New Issues and Requests
13404,We should really think about the organization of the docs.,Potential New Issues and Requests
13405,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests
13406,"@lesshaste For the issue about NaNs as separate category, see https://github.com/scikit-learn/scikit-learn/issues/10465",Potential New Issues and Requests
13407,Keep in mind it wouldhave to be a backwards compatible change.,Potential New Issues and Requests
13408,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests
13409,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests
13410,from [kfreebsd-amd64] URL ,Potential New Issues and Requests
13411,A HTTP query will return a base 64 encoding of the vector.,Potential New Issues and Requests
13412,"Unfortunately, that's not the issue here (although it should be fixed):compute_gradient is only ever called with stop=-1.",Potential New Issues and Requests
13413,I want spaCy and Gensim to interoperate sanely.,Potential New Issues and Requests
13414,"@nuchi, so did you compile the necessary TensorFlow code from the C API to WebAssembly?",Potential New Issues and Requests
13415,i had wondered iffinding and data close to 0 would help here.,Potential New Issues and Requests
13416,"The number of matches I have is up to a million, python process eats about 4 GB of ram, and there's still enough for it to grow.",Potential New Issues and Requests
13417,"@jnothman I just tried, but I'm not able to run e.g. a ppc64 Docker image on my amd64 system.",Potential New Issues and Requests
13418,we're going to release a bug-fix release in any case.,Potential New Issues and Requests
13419,**Dockerfile**CODEbuilt withCODE,Potential New Issues and Requests
13420,"Re: fusion of SpaCy and gensim APIs, I personally find the current gensim API tree not as straightforward/simple as scikit-learn (don't mistake me, gensim is extremely uniquely useful, e.g LDA, wikicorpus, etc).",Potential New Issues and Requests
13421,PR in #9733,Potential New Issues and Requests
13422,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests
13423,"I did a little looking around, and it looks like https://github.com/tensorflow/tensorflow/commits?author=alextp&since=2017-03-01T06:00:00Z&until=2017-04-01T05:00:00Z are the relevant commits.",Potential New Issues and Requests
13424,Is the match proliferation expected for your use-case?,Potential New Issues and Requests
13425,Example: CODE,Potential New Issues and Requests
13426,"Could we make the underlying workings of word embeddings compositional/consistent as well (what if we need to do text analysis over legal+finance texts, or multi-lingual texts)?",Potential New Issues and Requests
13427,I am trying to make a QnA system.,Potential New Issues and Requests
13428,I think of it as a demo what you can achieve with JavaScript and neural networks...,Potential New Issues and Requests
13429,Keep in mind it wouldhave to be a backwards compatible change.,Potential New Issues and Requests
13430,For larger values you suspect this isnât the case.,Potential New Issues and Requests
13431,"I am using a customized tokenizer that merges the three tokens, 'Linux', '.' and 'Mirai', into one token.",Potential New Issues and Requests
13432,Why is it not mean target encoding?,Potential New Issues and Requests
13433,The former I think.,Potential New Issues and Requests
13434,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
13435,"There is no central documentation for that, right?",Potential New Issues and Requests
13436,We should really think about the organization of the docs.,Potential New Issues and Requests
13437,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
13438,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
13439,"It won't grow much after this, I'm just curious how much entities it can hold and how it will affect the memory and performance.",Potential New Issues and Requests
13440,"The number of matches I have is up to a million, python process eats about 4 GB of ram, and there's still enough for it to grow.",Potential New Issues and Requests
13441,I see in the logs there an alarming number of fails for a final release :(((,Potential New Issues and Requests
13442,I had no idea it worked differently on 64-bit and 32-bit...,Potential New Issues and Requests
13443,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests
13444,I had no idea it worked differently on 64-bit and 32-bit...,Potential New Issues and Requests
13445,Should I open another issue for that segfault? CODE,Potential New Issues and Requests
13446,I consistently get the failure about CODE (that was resolved since as far as I understand) but not the one about hashing.,Potential New Issues and Requests
13447,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
13448,We should really think about the organization of the docs.,Potential New Issues and Requests
13449,"So the test fails on [this line](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/tests/test_feature_hasher.py#L122), where the expected values are CODE and  CODE (and I get those in the 32bit VM as well).",Potential New Issues and Requests
13450,"Anyway, I think this could be a feature that more people than I might be interested in and should/could possibly be integrated into master.",Potential New Issues and Requests
13451,"I realise this will probably raise all sorts of mutability and stateissues, but these should be avoidable by setting the WRITABLE flag on thereturned numpy arrays to false.",Potential New Issues and Requests
13452,"There is no central documentation for that, right?",Potential New Issues and Requests
13453,Related and possibly of interest: I managed to get TF running in the browser via Webassembly.,Potential New Issues and Requests
13454,See details on the [deeplearn.js] URL  homepage.,Potential New Issues and Requests
13455,I'm facing this error:CODE,Potential New Issues and Requests
13456,See https://humantoanimal.com for a demo; I will be providing more details in the future.,Potential New Issues and Requests
13457,"I could investigate this later, maybe in another issue.",Potential New Issues and Requests
13458,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
13459,This doesn't explain why I can't reproduce it though.,Potential New Issues and Requests
13460,I've created a fork of headless-gl that works with deeplearnjs (which in turn works with tensorflow) - this allows models to be run natively on the GPU from node.js (note that it's only been tested on OSX so far).,Potential New Issues and Requests
13461,But the log transform might alone be sufficient in your setting.,Potential New Issues and Requests
13462,A reference could be the dropout implementation here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L433-L435,Potential New Issues and Requests
13463,"Anyway, I think this could be a feature that more people than I might be interested in and should/could possibly be integrated into master.",Potential New Issues and Requests
13464,And a quick sample to show how it's used together with deeplearnjs:CODE,Potential New Issues and Requests
13465,I don't think it's due to floating point error.,Potential New Issues and Requests
13466,"This will be used throughout gensim (doc2vec, word2vec, docsim...).",Potential New Issues and Requests
13467,We're not calling eliminate_zeros anywhere.,Potential New Issues and Requests
13468,FWIW -- locally I had only the test_multi_output_classification_partial_fit_parallelism to popup and indeed it was due to inability to do multiprocessing in my case (absent bound to /dev/shm I guess):CODE,Potential New Issues and Requests
13469,I don't think it's due to floating point error.,Potential New Issues and Requests
13470,"@eamartin there have been a number of changes since the beginning of March by @alextp to speed up feed_dict; when the memory is aligned with 16 bytes, I think we share buffers with numpy, so nightly releases may be faster for you.",Potential New Issues and Requests
13471,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
13472,**Dockerfile**CODEbuilt withCODE,Potential New Issues and Requests
13473,"Got this error in version 1.7.3: Traceback (most recent call last):File ""<stdin>"", line 1, in <module>File ""/home/ktyao/anaconda3/envs/python27/lib/python2.7/site-packages/spacy/language.py"", line 350, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 207, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:7730)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:u'Meet Linux.Mirai Trojan, a DDoS nightmare'",Potential New Issues and Requests
13474,"I'm also running in this issue on 1.8.2, nevertheless only after processing multiple documents in parallel:CODE",Potential New Issues and Requests
13475,"@rth could the CODE failure be because of floating point error (i.e. a small number was in Xt.data instead of 0, and so was not removed)?",Potential New Issues and Requests
13476,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
13477,#589 issue still exists.,Potential New Issues and Requests
13478,Is the match proliferation expected for your use-case?,Potential New Issues and Requests
13479,Was wondering if spacy gives a direct method to find similarity between 2 sentences?,Potential New Issues and Requests
13480,2)         Similarity between entities can be kind of fun. Here's what Reddit thinks of Donald Trump: CODE,Potential New Issues and Requests
13481,"We could try to make this test more robust, by just taking a large number of tokens N, hashing them with a hash table size = 1 (or any small number), and checking that with CODE the sum of hashed values is equal to CODE, and that it's strictly lower than CODE if  CODE (since some +1 / -1 are bound to cancel out if N is large enough).",Potential New Issues and Requests
13482,"So, I'd say it's more of a design thing.",Potential New Issues and Requests
13483,"maybe for hobbyists but not for commercial use, where one would need clusters of machines to aim the computing process.",Potential New Issues and Requests
13484,Would it be possible for numpy to share buffers with tensorflow variableswhen they are returned from a session run?,Potential New Issues and Requests
13485,I think this is relevant: https://github.com/spacy-io/spaCy/issues/413,Potential New Issues and Requests
13486,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests
13487,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests
13488,"@nuchi, so did you compile the necessary TensorFlow code from the C API to WebAssembly?",Potential New Issues and Requests
13489,from [kfreebsd-amd64] URL ,Potential New Issues and Requests
13490,PR in #9733,Potential New Issues and Requests
13491,What do you think?,Potential New Issues and Requests
13492,So that is related to the current discussion we are having in https://github.com/scikit-learn/scikit-learn/pull/10523 about deprecating CODE or not.,Potential New Issues and Requests
13493,The segfault is caused by matcher.,Potential New Issues and Requests
13494,"We're in the process of abstracting away particular vector stores (in-memory matrix, sharded on-disk store, approximate kNN index...) from gensim, behind a common API.",Potential New Issues and Requests
13495,"The results at the moment are quite messy, and many of the phrases need to be pruned from the vocab.",Potential New Issues and Requests
13496,CODE -> CODE,Potential New Issues and Requests
13497,But there are also some interesting results in there too.,Potential New Issues and Requests
13498,"There is no central documentation for that, right?",Potential New Issues and Requests
13499,#589 issue still exists.,Potential New Issues and Requests
13500,Do we have a rough plan for the change of APIs?,Potential New Issues and Requests
13501,"However, I think that #3265 would basically want to implement it like this.",Potential New Issues and Requests
13502,You can do: CODE,Potential New Issues and Requests
13503,CODE -> CODE,Potential New Issues and Requests
13504,A reference could be the dropout implementation here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L433-L435,Potential New Issues and Requests
13505,I think I could migrate my class over to this tutorial pretty easily by using static RNN's.,Potential New Issues and Requests
13506,PS: Now I'm getting CODE and I have no idea if it's relevant or not..,Potential New Issues and Requests
13507,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
13508,Example: CODE,Potential New Issues and Requests
13509,"test_pairwise_parallel I had missed, but I also suspect it's something we'll find impossible to debug...",Potential New Issues and Requests
13510,We appear to have the following issues:,Potential New Issues and Requests
13511,CODE -> CODE,Potential New Issues and Requests
13512,"Still, for a Debian release of 0.19.0 I'm not sure how this could work: can you apply some patches on the original .tar.gz to skip tests/modify code when needed?",Potential New Issues and Requests
13513,FWIW -- locally I had only the test_multi_output_classification_partial_fit_parallelism to popup and indeed it was due to inability to do multiprocessing in my case (absent bound to /dev/shm I guess):CODE,Potential New Issues and Requests
13514,@lastmjs I explain in more detail in the link I provided.,Potential New Issues and Requests
13515,Taking logs won't help here.,Potential New Issues and Requests
13516,"@lesshaste For the issue about NaNs as separate category, see https://github.com/scikit-learn/scikit-learn/issues/10465",Potential New Issues and Requests
13517,"We should make feed_dict faster (likely by not copying the numpy.arrays like @yaroslavvb mentioned), but that's orthogonal to this change.",Potential New Issues and Requests
13518,This doesn't explain why I can't reproduce it though.,Potential New Issues and Requests
13519,Trying to narrow the scope of ParserStateError right now.,Potential New Issues and Requests
13520,I think this is relevant: https://github.com/spacy-io/spaCy/issues/413,Potential New Issues and Requests
13521,"maybe for hobbyists but not for commercial use, where one would need clusters of machines to aim the computing process.",Potential New Issues and Requests
13522,I've trained a model on one month of Reddit comments.,Potential New Issues and Requests
13523,"However, I think that #3265 would basically want to implement it like this.",Potential New Issues and Requests
13524,It would be great to be able to plug it in spaCy.,Potential New Issues and Requests
13525,"So the test fails on [this line](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/tests/test_feature_hasher.py#L122), where the expected values are CODE and  CODE (and I get those in the 32bit VM as well).",Potential New Issues and Requests
13526,"This will be used throughout gensim (doc2vec, word2vec, docsim...).",Potential New Issues and Requests
13527,"We're in the process of abstracting away particular vector stores (in-memory matrix, sharded on-disk store, approximate kNN index...) from gensim, behind a common API.",Potential New Issues and Requests
13528,"Among other things, we support a narrower range of platforms.",Potential New Issues and Requests
13529,Is this testing a collision where the sign alternates and hence the valuelands up at 0?,Potential New Issues and Requests
13530,It sounds like you know too much about your variable for a generictransform to be the sort of thing you need.,Potential New Issues and Requests
13531,"I could investigate this later, maybe in another issue.",Potential New Issues and Requests
13532,@lastmjs I explain in more detail in the link I provided.,Potential New Issues and Requests
13533,So unless I missed something it doesn't look like this could be reproducible in Docker.,Potential New Issues and Requests
13534,I want spaCy and Gensim to interoperate sanely.,Potential New Issues and Requests
13535,I am running tf 1.2.1 (GPU)  on ubuntu 16.04 lts.,Potential New Issues and Requests
13536,It seems to think CODE and CODE are very similar: CODE,Potential New Issues and Requests
13537,"@jnothman  To be a little clearer,  I don't know that 22 is significant.",Potential New Issues and Requests
13538,And none of them are about CODE CODE,Potential New Issues and Requests
13539,Short version: I added Webassembly as an XLA compilation target.,Potential New Issues and Requests
13540,PS: Now I'm getting CODE and I have no idea if it's relevant or not..,Potential New Issues and Requests
13541,"Do you know if there's any issue or work being done on removing the copy (at least in some cases, like row-major Numpy arrays with nice strides)?",Potential New Issues and Requests
13542,i had wondered iffinding and data close to 0 would help here.,Potential New Issues and Requests
13543,"I hope to discuss what kinds of behaviour people expect from such ""vector stores"", so we can design a sane API.",Potential New Issues and Requests
13544,"A simple thing to do is to convert all small values to strings, run DictVectorizer as above and then perform feature selection or just use your favorite classifier directly.",Potential New Issues and Requests
13545,I think of it as a demo what you can achieve with JavaScript and neural networks...,Potential New Issues and Requests
13546,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests
13547,PS: Now I'm getting CODE and I have no idea if it's relevant or not..,Potential New Issues and Requests
13548,This only seems to occur when I have more than 1 bucket.,Potential New Issues and Requests
13549,"You can find the install directions and a basic sample at https://github.com/dfoody/headless-glAnd, of course https://deeplearnjs.org for more details.",Potential New Issues and Requests
13550,"Do you know if there's any issue or work being done on removing the copy (at least in some cases, like row-major Numpy arrays with nice strides)?",Potential New Issues and Requests
13551,"I do have a translator that works pretty similar to this one but creates cells through a separate class that allows for inserting bidirectional layers where you want, residuals where you want, merging inputs with concat vs. sum, and a few other things.",Potential New Issues and Requests
13552,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
13553,"How do you use such stores in spaCy, what metrics do you employ, what API signatures?",Potential New Issues and Requests
13554,But there are also some interesting results in there too.,Potential New Issues and Requests
13555,Instead of: CODE,Potential New Issues and Requests
13556,#589 issue still exists.,Potential New Issues and Requests
13557,I am trying to make a QnA system.,Potential New Issues and Requests
13558,Related and possibly of interest: I managed to get TF running in the browser via Webassembly.,Potential New Issues and Requests
13559,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
13560,*         [x] CODE (fixed in #9544),Potential New Issues and Requests
13561,"As for SpaCy, I hope there's a portable way to train/retrieve the word embeddings across domains (pharma, legal, finance, etc) and natural languages.",Potential New Issues and Requests
13562,That would be less dependent on the actual hashing implementation...,Potential New Issues and Requests
13563,I'm facing this error:CODE,Potential New Issues and Requests
13564,That is 22 indicates something specific which is quite different from 21 or 23.,Potential New Issues and Requests
13565,Currently we are accessing the vector space through the https://github.com/3Top/word2vec-api/ project.,Potential New Issues and Requests
13566,I've trained a model on one month of Reddit comments.,Potential New Issues and Requests
13567,The vectors for the verb and noun senses are quite different: CODE,Potential New Issues and Requests
13568,"Searching for ""CountTransformer"" does not give any results",Potential New Issues and Requests
13569,This doesn't explain why I can't reproduce it though.,Potential New Issues and Requests
13570,"Re: fusion of SpaCy and gensim APIs, I personally find the current gensim API tree not as straightforward/simple as scikit-learn (don't mistake me, gensim is extremely uniquely useful, e.g LDA, wikicorpus, etc).",Potential New Issues and Requests
13571,The vectors for the verb and noun senses are quite different: CODE,Potential New Issues and Requests
13572,#589 issue still exists.,Potential New Issues and Requests
13573,Or just testing that values are stored in the same spot dueto collision?,Potential New Issues and Requests
13574,PR in ~#9734~ #9830,Potential New Issues and Requests
13575,It would be great to be able to plug it in spaCy.,Potential New Issues and Requests
13576,2)         Similarity between entities can be kind of fun. Here's what Reddit thinks of Donald Trump: CODE,Potential New Issues and Requests
13577,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests
13578,It sounds like you know too much about your variable for a generictransform to be the sort of thing you need.,Potential New Issues and Requests
13579,A HTTP query will return a base 64 encoding of the vector.,Potential New Issues and Requests
13580,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
13581,Is the match proliferation expected for your use-case?,Potential New Issues and Requests
13582,I can easily make the matches list a numpy array if necessary.,Potential New Issues and Requests
13583,we're going to release a bug-fix release in any case.,Potential New Issues and Requests
13584,"I did a little looking around, and it looks like https://github.com/tensorflow/tensorflow/commits?author=alextp&since=2017-03-01T06:00:00Z&until=2017-04-01T05:00:00Z are the relevant commits.",Potential New Issues and Requests
13585,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests
13586,"I'll be writing more about these vectors, and of course releasing the code. I'd like to sharpen up one or two things and run it on more data first.",Potential New Issues and Requests
13587,General directions to install on OSX:CODE,Potential New Issues and Requests
13588,So you're using it for a non-linear discretisation?,Potential New Issues and Requests
13589,I am trying to make a QnA system.,Potential New Issues and Requests
13590,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
13591,"We're in the process of abstracting away particular vector stores (in-memory matrix, sharded on-disk store, approximate kNN index...) from gensim, behind a common API.",Potential New Issues and Requests
13592,I could only find sentence tokenizations and word similarities.,Potential New Issues and Requests
13593,FWIW -- locally I had only the test_multi_output_classification_partial_fit_parallelism to popup and indeed it was due to inability to do multiprocessing in my case (absent bound to /dev/shm I guess):CODE,Potential New Issues and Requests
13594,I've trained a model on one month of Reddit comments.,Potential New Issues and Requests
13595,i had wondered iffinding and data close to 0 would help here.,Potential New Issues and Requests
13596,we're going to release a bug-fix release in any case.,Potential New Issues and Requests
13597,I'm facing this error:CODE,Potential New Issues and Requests
13598,@jnothman any ideas about the CODEtest_pairwise_parallelCODE failure?,Potential New Issues and Requests
13599,See details on the [deeplearn.js] URL  homepage.,Potential New Issues and Requests
13600,The n_jobs=1 issue has been fixed.,Potential New Issues and Requests
13601,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
13602,PR in ~#9734~ #9830,Potential New Issues and Requests
13603,"I did a little looking around, and it looks like https://github.com/tensorflow/tensorflow/commits?author=alextp&since=2017-03-01T06:00:00Z&until=2017-04-01T05:00:00Z are the relevant commits.",Potential New Issues and Requests
13604,"All was fine, until I added some matcher rules and an on_match callback: CODEwhere unit is 'BOPD', for example.",Potential New Issues and Requests
13605,I want spaCy and Gensim to interoperate sanely.,Potential New Issues and Requests
13606,Then you can investigate what's going on.,Potential New Issues and Requests
13607,"I was also asking for the help from @ry to make my personal repository to be supported officially, there are few things we have to do like building some example models especially RNN cases, but unfortunately I'm got to work on other fields and have no time for these few months, if someone is interested in making this be happened, email to me, I'd love to guide you how to start.",Potential New Issues and Requests
13608,Why is it not mean target encoding?,Potential New Issues and Requests
13609,I am running tf 1.2.1 (GPU)  on ubuntu 16.04 lts.,Potential New Issues and Requests
13610,Why is it not mean target encoding?,Potential New Issues and Requests
13611,#589 issue still exists.,Potential New Issues and Requests
13612,It's a result of CODE being the same as CODE on a machine with 1 core.,Potential New Issues and Requests
13613,Using CODE as the first line this works fine for amd64.,Potential New Issues and Requests
13614,Then you can investigate what's going on.,Potential New Issues and Requests
13615,That would be less dependent on the actual hashing implementation...,Potential New Issues and Requests
13616,"First of all - deeplearn.js is a library that only mirrors to some extent ""the style of TensorFlow API"" and operates purely in the browser and the other would be a direct API to whole Tensorflow goodness.",Potential New Issues and Requests
13617,Instead of: CODE,Potential New Issues and Requests
13618,"I am using a customized tokenizer that merges the three tokens, 'Linux', '.' and 'Mirai', into one token.",Potential New Issues and Requests
13619,"I was also asking for the help from @ry to make my personal repository to be supported officially, there are few things we have to do like building some example models especially RNN cases, but unfortunately I'm got to work on other fields and have no time for these few months, if someone is interested in making this be happened, email to me, I'd love to guide you how to start.",Potential New Issues and Requests
13620,*         https://github.com/PAIR-code/deeplearnjs/issues/407,Potential New Issues and Requests
13621,General directions to install on OSX:CODE,Potential New Issues and Requests
13622,Keep in mind it wouldhave to be a backwards compatible change.,Potential New Issues and Requests
13623,It's a result of CODE being the same as CODE on a machine with 1 core.,Potential New Issues and Requests
13624,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests
13625,You can do: CODE,Potential New Issues and Requests
13626,"seeing as you don't use a custom scorer, should we assume that is aseparate issue?",Potential New Issues and Requests
13627,"@jnothman  To be a little clearer,  I don't know that 22 is significant.",Potential New Issues and Requests
13628,We should really think about the organization of the docs.,Potential New Issues and Requests
13629,"@prashantserai Don't exactly know, but what you met seems to be another issue.",Potential New Issues and Requests
13630,"So, I'd say it's more of a design thing.",Potential New Issues and Requests
13631,"I realise this will probably raise all sorts of mutability and stateissues, but these should be avoidable by setting the WRITABLE flag on thereturned numpy arrays to false.",Potential New Issues and Requests
13632,"I have found the ""convert to a string"" and then DictVectorizer method to be very useful for discovering which these are.",Potential New Issues and Requests
13633,"I'm not sure why Eigen was not written to handle unaligned first and last ""packets"" so it wouldn't matter.",Potential New Issues and Requests
13634,General directions to install on OSX:CODE,Potential New Issues and Requests
13635,What do you think?,Potential New Issues and Requests
13636,But I want to leave all the values over 1024 as numerical as I don't think those specific values mean much.,Potential New Issues and Requests
13637,"@jnothman  To be a little clearer,  I don't know that 22 is significant.",Potential New Issues and Requests
13638,#589 issue still exists.,Potential New Issues and Requests
13639,*         https://github.com/PAIR-code/deeplearnjs/issues/238,Potential New Issues and Requests
13640,Then you can investigate what's going on.,Potential New Issues and Requests
13641,"The next release islikely to include a fixed-width discretizer, but following on from a logtransform or a quantile transform it should act quite similar to what youwant...",Potential New Issues and Requests
13642,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests
13643,"I'm afraid I'm getting this, too, in version 1.5.0: CODE",Potential New Issues and Requests
13644,Is this testing a collision where the sign alternates and hence the valuelands up at 0?,Potential New Issues and Requests
13645,have we seen this before:,Potential New Issues and Requests
13646,See details on the [deeplearn.js] URL  homepage.,Potential New Issues and Requests
13647,"I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency.",Potential New Issues and Requests
13648,But there are also some interesting results in there too.,Potential New Issues and Requests
13649,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests
13650,Do you have a link for that?,Potential New Issues and Requests
13651,What do you think?,Potential New Issues and Requests
13652,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests
13653,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests
13654,"From my checking, these didn't make it into TF 1.1 but hopefully will be in 1.2.",Potential New Issues and Requests
13655,"Hi guys, would appreciate your input on issue https://github.com/piskvorky/gensim/issues/527.",Potential New Issues and Requests
13656,Is this testing a collision where the sign alternates and hence the valuelands up at 0?,Potential New Issues and Requests
13657,The former I think.,Potential New Issues and Requests
13658,"test_pairwise_parallel I had missed, but I also suspect it's something we'll find impossible to debug...",Potential New Issues and Requests
13659,Keep in mind it wouldhave to be a backwards compatible change.,Potential New Issues and Requests
13660,"I could investigate this later, maybe in another issue.",Potential New Issues and Requests
13661,Reddit also thinks hot dogs are practically salad: CODE,Potential New Issues and Requests
13662,Short version: I added Webassembly as an XLA compilation target.,Potential New Issues and Requests
13663,I am receiving the same CODE but with CODE.,Potential New Issues and Requests
13664,"It could be a +1 - 1 = 0or a +3 - 2 = 1 (instead of 3+2=5) as long the value in the hash bucketis lower than the sum of the absolute value of hashed terms, it issufficient to determine whether CODE is used or not duringthe hash collisions, I think..",Potential New Issues and Requests
13665,"No matter how much we optimize it, feed_dict will never be the fastest way to feed data into a training job.",Potential New Issues and Requests
13666,I don't think it's due to floating point error.,Potential New Issues and Requests
13667,Or are you using TensorFlow.js?,Potential New Issues and Requests
13668,"*         [x] CODE [arm64] URL ,  [ppc64] URL , [ppc64el] URL , [s390x] URL .",Potential New Issues and Requests
13669,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
13670,Then you can investigate what's going on.,Potential New Issues and Requests
13671,I'm facing this error:CODE,Potential New Issues and Requests
13672,But it does seem like a plausible suspect.,Potential New Issues and Requests
13673,CODE -> CODE,Potential New Issues and Requests
13674,@jhseu You mentioned that you consider removing the CODEfeed_dictCODE copy as orthogonal to this issue.,Potential New Issues and Requests
13675,"First of all - deeplearn.js is a library that only mirrors to some extent ""the style of TensorFlow API"" and operates purely in the browser and the other would be a direct API to whole Tensorflow goodness.",Potential New Issues and Requests
13676,We're not calling eliminate_zeros anywhere.,Potential New Issues and Requests
13677,I just suspect that *some* values are but I don't know which ones or how many there are.,Potential New Issues and Requests
13678,I'm facing this error:CODE,Potential New Issues and Requests
13679,"The nearest neighbour of CODE turns out to be a misspelling, that the POS tagger seems to often tag correctly: CODE",Potential New Issues and Requests
13680,"@rth could the CODE failure be because of floating point error (i.e. a small number was in Xt.data instead of 0, and so was not removed)?",Potential New Issues and Requests
13681,"I have found the ""convert to a string"" and then DictVectorizer method to be very useful for discovering which these are.",Potential New Issues and Requests
13682,I think this is relevant: https://github.com/spacy-io/spaCy/issues/413,Potential New Issues and Requests
13683,Or are you using TensorFlow.js?,Potential New Issues and Requests
13684,I just suspect that *some* values are but I don't know which ones or how many there are.,Potential New Issues and Requests
13685,"(As a side point, @ogrisel, I note there seems to be a lot more joblibparallelisation overhead in master -- on OS X at least -- that wasn't therein 0.14...)",Potential New Issues and Requests
13686,"seeing as you don't use a custom scorer, should we assume that is aseparate issue?",Potential New Issues and Requests
13687,Should I open another issue for that segfault? CODE,Potential New Issues and Requests
13688,"I'm also running in this issue on 1.8.2, nevertheless only after processing multiple documents in parallel:CODE",Potential New Issues and Requests
13689,"The 16 byte alignment issue comes from Eigen, unfortunately, which requires the beginning of the memory addresses to be aligned with 16 bytes.",Potential New Issues and Requests
13690,"Anyway, I think this could be a feature that more people than I might be interested in and should/could possibly be integrated into master.",Potential New Issues and Requests
13691,"but this still wouldn't help unless someone has access to non amd64 platforms and is able to run it there, using the [appropriate Docker Debian image](https://github.com/docker-library/official-images#architectures-other-than-amd64) ...",Potential New Issues and Requests
13692,"The results at the moment are quite messy, and many of the phrases need to be pruned from the vocab.",Potential New Issues and Requests
13693,and I know another WebAssemble research on TensorFlow at here:https://medium.com/@tomasreimers/compiling-tensorflow-for-the-browser-f3387b8e1e1c,Potential New Issues and Requests
13694,Do we have a rough plan for the change of APIs?,Potential New Issues and Requests
13695,"@rth could the CODE failure be because of floating point error (i.e. a small number was in Xt.data instead of 0, and so was not removed)?",Potential New Issues and Requests
13696,Is the match proliferation expected for your use-case?,Potential New Issues and Requests
13697,"The nearest neighbour of CODE turns out to be a misspelling, that the POS tagger seems to often tag correctly: CODE",Potential New Issues and Requests
13698,"The next release islikely to include a fixed-width discretizer, but following on from a logtransform or a quantile transform it should act quite similar to what youwant...",Potential New Issues and Requests
13699,"Also, it adds columns, not replaces, so will not yet work out of the box for string categorical data (but that is more feedback on that PR, not to discuss here).",Potential New Issues and Requests
13700,Say you have an integer numeric feature which takes a large range of values.,Potential New Issues and Requests
13701,"Here is the trace: Traceback (most recent call last):File ""tests/test_spacy_nlp.py"", line 231, in test_should_return_none_when_spacy_parsing_failsdoc = self.spacy_nlp.parse(query)File ""spacy_nlp.py"", line 49, in parsereturn SpacyDoc(self.__instance.parser(query))File ""lib/python3.5/site-packages/spacy/language.py"", line 328, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 146, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:6114)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:'splash On'",Potential New Issues and Requests
13702,Or just testing that values are stored in the same spot dueto collision?,Potential New Issues and Requests
13703,For larger values you suspect this isnât the case.,Potential New Issues and Requests
13704,"I think tensorflow need 2 hyper methods that change the model state, something like torch.",Potential New Issues and Requests
13705,Definitely want to get together on this.,Potential New Issues and Requests
13706,Example: CODE,Potential New Issues and Requests
13707,PR in #9733,Potential New Issues and Requests
13708,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
13709,"If there is any interest, I would be glad to improve the service to enable communication with spaCy.",Potential New Issues and Requests
13710,I can easily make the matches list a numpy array if necessary.,Potential New Issues and Requests
13711,Related and possibly of interest: I managed to get TF running in the browser via Webassembly.,Potential New Issues and Requests
13712,"Also, its not even remotely close to being called an alternative to Tensorflow...",Potential New Issues and Requests
13713,"We could try to make this test more robust, by just taking a large number of tokens N, hashing them with a hash table size = 1 (or any small number), and checking that with CODE the sum of hashed values is equal to CODE, and that it's strictly lower than CODE if  CODE (since some +1 / -1 are bound to cancel out if N is large enough).",Potential New Issues and Requests
13714,"As for SpaCy, I hope there's a portable way to train/retrieve the word embeddings across domains (pharma, legal, finance, etc) and natural languages.",Potential New Issues and Requests
13715,"I'm also running in this issue on 1.8.2, nevertheless only after processing multiple documents in parallel:CODE",Potential New Issues and Requests
13716,We're not calling eliminate_zeros anywhere.,Potential New Issues and Requests
13717,I consistently get the failure about CODE (that was resolved since as far as I understand) but not the one about hashing.,Potential New Issues and Requests
13718,It seems to think CODE and CODE are very similar: CODE,Potential New Issues and Requests
13719,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests
13720,This test assumes that the hash value of the tested tokens always produces the same results (in which case two of those produce a collision).,Potential New Issues and Requests
13721,See https://humantoanimal.com for a demo; I will be providing more details in the future.,Potential New Issues and Requests
13722,"A ""class action"" is only very weakly a type of action: CODE",Potential New Issues and Requests
13723,Discussion of Bill Cosby makes some obvious (and some less obvious) comparisons: CODE,Potential New Issues and Requests
13724,You can do: CODE,Potential New Issues and Requests
13725,"@jnothman  To be a little clearer,  I don't know that 22 is significant.",Potential New Issues and Requests
13726,I think of it as a demo what you can achieve with JavaScript and neural networks...,Potential New Issues and Requests
13727,Will review.,Potential New Issues and Requests
13728,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
13729,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
13730,I don't think it's due to floating point error.,Potential New Issues and Requests
13731,"I could investigate this later, maybe in another issue.",Potential New Issues and Requests
13732,we're going to release a bug-fix release in any case.,Potential New Issues and Requests
13733,Keep in mind it wouldhave to be a backwards compatible change.,Potential New Issues and Requests
13734,It's a result of CODE being the same as CODE on a machine with 1 core.,Potential New Issues and Requests
13735,"From my checking, these didn't make it into TF 1.1 but hopefully will be in 1.2.",Potential New Issues and Requests
13736,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
13737,"It won't grow much after this, I'm just curious how much entities it can hold and how it will affect the memory and performance.",Potential New Issues and Requests
13738,#589 issue still exists.,Potential New Issues and Requests
13739,i had wondered iffinding and data close to 0 would help here.,Potential New Issues and Requests
13740,[change model state](https://github.com/torch/nn/blob/master/doc/module.md#training).,Potential New Issues and Requests
13741,"""fair game"" is not a type of game: CODE",Potential New Issues and Requests
13742,It sounds like you know too much about your variable for a generictransform to be the sort of thing you need.,Potential New Issues and Requests
13743,"A ""class action"" is only very weakly a type of action: CODE",Potential New Issues and Requests
13744,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests
13745,The error points to this function in seq2seq_model.py which is line 142 in seq2seq_model.py: CODE,Potential New Issues and Requests
13746,at the first CODE suggesting there is [a platform conflict] URL .,Potential New Issues and Requests
13747,Example: CODE,Potential New Issues and Requests
13748,Would it be possible for numpy to share buffers with tensorflow variableswhen they are returned from a session run?,Potential New Issues and Requests
13749,"The nearest neighbour of CODE turns out to be a misspelling, that the POS tagger seems to often tag correctly: CODE",Potential New Issues and Requests
13750,i had wondered iffinding and data close to 0 would help here.,Potential New Issues and Requests
13751,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests
13752,"The 16 byte alignment issue comes from Eigen, unfortunately, which requires the beginning of the memory addresses to be aligned with 16 bytes.",Potential New Issues and Requests
13753,A HTTP query will return a base 64 encoding of the vector.,Potential New Issues and Requests
13754,The segfault is caused by matcher.,Potential New Issues and Requests
13755,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
13756,We've been using an external server for word2vec for over a year now.,Potential New Issues and Requests
13757,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
13758,from [kfreebsd-amd64] URL ,Potential New Issues and Requests
13759,"I did a little looking around, and it looks like https://github.com/tensorflow/tensorflow/commits?author=alextp&since=2017-03-01T06:00:00Z&until=2017-04-01T05:00:00Z are the relevant commits.",Potential New Issues and Requests
13760,"It won't grow much after this, I'm just curious how much entities it can hold and how it will affect the memory and performance.",Potential New Issues and Requests
13761,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
13762,"Anyone who came across with this error and managed  to solve this, please help me correct this issue.",Potential New Issues and Requests
13763,Currently we are accessing the vector space through the https://github.com/3Top/word2vec-api/ project.,Potential New Issues and Requests
13764,I just suspect that *some* values are but I don't know which ones or how many there are.,Potential New Issues and Requests
13765,"But it's more important that both libraries stay internally consistent, and they have fairly different API norms.",Potential New Issues and Requests
13766,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
13767,at the first CODE suggesting there is [a platform conflict] URL .,Potential New Issues and Requests
13768,PR in ~#9734~ #9830,Potential New Issues and Requests
13769,"However you suspect that for some small values, the precise value is significant.",Potential New Issues and Requests
13770,Taking logs won't help here.,Potential New Issues and Requests
13771,"Do you know if there's any issue or work being done on removing the copy (at least in some cases, like row-major Numpy arrays with nice strides)?",Potential New Issues and Requests
13772,"I'm afraid I'm getting this, too, in version 1.5.0: CODE",Potential New Issues and Requests
13773,"However you suspect that for some small values, the precise value is significant.",Potential New Issues and Requests
13774,I can easily make the matches list a numpy array if necessary.,Potential New Issues and Requests
13775,So that is related to the current discussion we are having in https://github.com/scikit-learn/scikit-learn/pull/10523 about deprecating CODE or not.,Potential New Issues and Requests
13776,"I could investigate this later, maybe in another issue.",Potential New Issues and Requests
13777,You can do: CODE,Potential New Issues and Requests
13778,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
13779,"@jnothman I just tried, but I'm not able to run e.g. a ppc64 Docker image on my amd64 system.",Potential New Issues and Requests
13780,"So the test fails on [this line](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/tests/test_feature_hasher.py#L122), where the expected values are CODE and  CODE (and I get those in the 32bit VM as well).",Potential New Issues and Requests
13781,It sounds like you know too much about your variable for a generictransform to be the sort of thing you need.,Potential New Issues and Requests
13782,"Tried to build scikit-learn 0.19.2 it in a Debian sid/unstable i386 VM, were scipy and numpy 1.2.1 were installed with apt-get.",Potential New Issues and Requests
13783,I want spaCy and Gensim to interoperate sanely.,Potential New Issues and Requests
13784,"I've been playing with an extension of this idea, where noun chunks and named entities are also merged.",Potential New Issues and Requests
13785,I think this is relevant: https://github.com/spacy-io/spaCy/issues/413,Potential New Issues and Requests
13786,Should I open another issue for that segfault? CODE,Potential New Issues and Requests
13787,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests
13788,"But it's more important that both libraries stay internally consistent, and they have fairly different API norms.",Potential New Issues and Requests
13789,"I hope to discuss what kinds of behaviour people expect from such ""vector stores"", so we can design a sane API.",Potential New Issues and Requests
13790,I am trying to make a QnA system.,Potential New Issues and Requests
13791,have we seen this before:,Potential New Issues and Requests
13792,"Actually, the above Docker setup with conda wouldn't have worked anyway for other platforms, it should have been, something along the lines of, I think,CODE",Potential New Issues and Requests
13793,See Issue #124,Potential New Issues and Requests
13794,I did not use Tensorflow.js in any way.,Potential New Issues and Requests
13795,"Since this basically tests that in CODE we can disable the CODE functionality (enabled by default) and it doesn't validate any new functionality, it might be OK to skip it on failure on 32 bit?",Potential New Issues and Requests
13796,I am receiving the same CODE but with CODE.,Potential New Issues and Requests
13797,Say I suspect that some of the values from 1...1024 are meaningful.,Potential New Issues and Requests
13798,Will review.,Potential New Issues and Requests
13799,"We should make feed_dict faster (likely by not copying the numpy.arrays like @yaroslavvb mentioned), but that's orthogonal to this change.",Potential New Issues and Requests
13800,Related and possibly of interest: I managed to get TF running in the browser via Webassembly.,Potential New Issues and Requests
13801,have we seen this before:,Potential New Issues and Requests
13802,Why is it not mean target encoding?,Potential New Issues and Requests
13803,"@eamartin there have been a number of changes since the beginning of March by @alextp to speed up feed_dict; when the memory is aligned with 16 bytes, I think we share buffers with numpy, so nightly releases may be faster for you.",Potential New Issues and Requests
13804,"Love the link between bacon and broccoli, wonder what adding sentiment into the mix would change about that :P",Potential New Issues and Requests
13805,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
13806,And none of them are about CODE CODE,Potential New Issues and Requests
13807,Do you have a link for that?,Potential New Issues and Requests
13808,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests
13809,I'm facing this error:CODE,Potential New Issues and Requests
13810,"@prashantserai Don't exactly know, but what you met seems to be another issue.",Potential New Issues and Requests
13811,I am trying to make a QnA system.,Potential New Issues and Requests
13812,But the log transform might alone be sufficient in your setting.,Potential New Issues and Requests
13813,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests
13814,The on_match callback is being called.,Potential New Issues and Requests
13815,@jhseu You mentioned that you consider removing the CODEfeed_dictCODE copy as orthogonal to this issue.,Potential New Issues and Requests
13816,Or just testing that values are stored in the same spot dueto collision?,Potential New Issues and Requests
13817,"Unfortunately, that's not the issue here (although it should be fixed):compute_gradient is only ever called with stop=-1.",Potential New Issues and Requests
13818,I don't think it's due to floating point error.,Potential New Issues and Requests
13819,"I'm afraid I'm getting this, too, in version 1.5.0: CODE",Potential New Issues and Requests
13820,have we seen this before:,Potential New Issues and Requests
13821,"Since this basically tests that in CODE we can disable the CODE functionality (enabled by default) and it doesn't validate any new functionality, it might be OK to skip it on failure on 32 bit?",Potential New Issues and Requests
13822,PS: Now I'm getting CODE and I have no idea if it's relevant or not..,Potential New Issues and Requests
13823,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
13824,PS: Now I'm getting CODE and I have no idea if it's relevant or not..,Potential New Issues and Requests
13825,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests
13826,"Searching for ""CountTransformer"" does not give any results",Potential New Issues and Requests
13827,This only seems to occur when I have more than 1 bucket.,Potential New Issues and Requests
13828,We've been using an external server for word2vec for over a year now.,Potential New Issues and Requests
13829,Reddit also thinks hot dogs are practically salad: CODE,Potential New Issues and Requests
13830,"Re: fusion of SpaCy and gensim APIs, I personally find the current gensim API tree not as straightforward/simple as scikit-learn (don't mistake me, gensim is extremely uniquely useful, e.g LDA, wikicorpus, etc).",Potential New Issues and Requests
13831,But the log transform might alone be sufficient in your setting.,Potential New Issues and Requests
13832,"I'd like to minimize the number of mechanisms we have in sklearn, and we definitely need one (more?) for efficient model selection.",Potential New Issues and Requests
13833,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests
13834,*         https://github.com/PAIR-code/deeplearnjs/issues/238,Potential New Issues and Requests
13835,"*         [x] CODE: [mips] URL , [powerpc] URL , [hppa] URL , [ppc64] URL , [s390x] URL , [sparc64] URL  fixed in #9710",Potential New Issues and Requests
13836,I've created a fork of headless-gl that works with deeplearnjs (which in turn works with tensorflow) - this allows models to be run natively on the GPU from node.js (note that it's only been tested on OSX so far).,Potential New Issues and Requests
13837,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
13838,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests
13839,@lastmjs I explain in more detail in the link I provided.,Potential New Issues and Requests
13840,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
13841,For larger values you suspect this isnât the case.,Potential New Issues and Requests
13842,"The results at the moment are quite messy, and many of the phrases need to be pruned from the vocab.",Potential New Issues and Requests
13843,"This will be used throughout gensim (doc2vec, word2vec, docsim...).",Potential New Issues and Requests
13844,"Among other things, we support a narrower range of platforms.",Potential New Issues and Requests
13845,"@lesshaste For the issue about NaNs as separate category, see https://github.com/scikit-learn/scikit-learn/issues/10465",Potential New Issues and Requests
13846,"Here is our test:nlp = spacy.en.English()nlp.matcher.add('splash', 'my entity', {},[ [{LEMMA: 'splash'}, {LEMMA: 'on'}]])nlp('splash On')",Potential New Issues and Requests
13847,The segfault is caused by matcher.,Potential New Issues and Requests
13848,Example: CODE,Potential New Issues and Requests
13849,"However, I think that #3265 would basically want to implement it like this.",Potential New Issues and Requests
13850,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
13851,*         https://github.com/PAIR-code/deeplearnjs/issues/238,Potential New Issues and Requests
13852,"It could be a +1 - 1 = 0or a +3 - 2 = 1 (instead of 3+2=5) as long the value in the hash bucketis lower than the sum of the absolute value of hashed terms, it issufficient to determine whether CODE is used or not duringthe hash collisions, I think..",Potential New Issues and Requests
13853,"It could be a +1 - 1 = 0or a +3 - 2 = 1 (instead of 3+2=5) as long the value in the hash bucketis lower than the sum of the absolute value of hashed terms, it issufficient to determine whether CODE is used or not duringthe hash collisions, I think..",Potential New Issues and Requests
13854,Would it be possible for numpy to share buffers with tensorflow variableswhen they are returned from a session run?,Potential New Issues and Requests
13855,And none of them are about CODE CODE,Potential New Issues and Requests
13856,"I do have a translator that works pretty similar to this one but creates cells through a separate class that allows for inserting bidirectional layers where you want, residuals where you want, merging inputs with concat vs. sum, and a few other things.",Potential New Issues and Requests
13857,"The nearest neighbour of CODE turns out to be a misspelling, that the POS tagger seems to often tag correctly: CODE",Potential New Issues and Requests
13858,#589 issue still exists.,Potential New Issues and Requests
13859,"There is no central documentation for that, right?",Potential New Issues and Requests
13860,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
13861,And none of them are about CODE CODE,Potential New Issues and Requests
13862,*         https://github.com/PAIR-code/deeplearnjs/issues/407,Potential New Issues and Requests
13863,That is 22 indicates something specific which is quite different from 21 or 23.,Potential New Issues and Requests
13864,FWIW -- locally I had only the test_multi_output_classification_partial_fit_parallelism to popup and indeed it was due to inability to do multiprocessing in my case (absent bound to /dev/shm I guess):CODE,Potential New Issues and Requests
13865,The error points to this function in seq2seq_model.py which is line 142 in seq2seq_model.py: CODE,Potential New Issues and Requests
13866,"I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency.",Potential New Issues and Requests
13867,*         [ ] CODE (not listed above): [mips] URL .,Potential New Issues and Requests
13868,This doesn't explain why I can't reproduce it though.,Potential New Issues and Requests
13869,[change model state](https://github.com/torch/nn/blob/master/doc/module.md#training).,Potential New Issues and Requests
13870,"(As a side point, @ogrisel, I note there seems to be a lot more joblibparallelisation overhead in master -- on OS X at least -- that wasn't therein 0.14...)",Potential New Issues and Requests
13871,Should I open another issue for that segfault? CODE,Potential New Issues and Requests
13872,"I'll do it tomorrow, once I know the steps to reproduce it.",Potential New Issues and Requests
13873,A segfault via the Python API (as opposed to the Cython API) is always a bug.,Potential New Issues and Requests
13874,"If you want to further discuss the specific non-linear discretization or mixed numeric/string encoding, feel free to open a new issue.",Potential New Issues and Requests
13875,"I realise this will probably raise all sorts of mutability and stateissues, but these should be avoidable by setting the WRITABLE flag on thereturned numpy arrays to false.",Potential New Issues and Requests
13876,I've trained a model on one month of Reddit comments.,Potential New Issues and Requests
13877,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests
13878,But I want to leave all the values over 1024 as numerical as I don't think those specific values mean much.,Potential New Issues and Requests
13879,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests
13880,I am running tf 1.2.1 (GPU)  on ubuntu 16.04 lts.,Potential New Issues and Requests
13881,"test_pairwise_parallel I had missed, but I also suspect it's something we'll find impossible to debug...",Potential New Issues and Requests
13882,"However, I think that #3265 would basically want to implement it like this.",Potential New Issues and Requests
13883,So that is related to the current discussion we are having in https://github.com/scikit-learn/scikit-learn/pull/10523 about deprecating CODE or not.,Potential New Issues and Requests
13884,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests
13885,We should really think about the organization of the docs.,Potential New Issues and Requests
13886,I am receiving the same CODE but with CODE.,Potential New Issues and Requests
13887,This only seems to occur when I have more than 1 bucket.,Potential New Issues and Requests
13888,it passes just fine when I have /dev/shm mounted and joblib does not complaint.,Potential New Issues and Requests
13889,Say I suspect that some of the values from 1...1024 are meaningful.,Potential New Issues and Requests
13890,"However you suspect that for some small values, the precise value is significant.",Potential New Issues and Requests
13891,So that is related to the current discussion we are having in https://github.com/scikit-learn/scikit-learn/pull/10523 about deprecating CODE or not.,Potential New Issues and Requests
13892,FWIW -- locally I had only the test_multi_output_classification_partial_fit_parallelism to popup and indeed it was due to inability to do multiprocessing in my case (absent bound to /dev/shm I guess):CODE,Potential New Issues and Requests
13893,"*         [x] CODE [arm64] URL ,  [ppc64] URL , [ppc64el] URL , [s390x] URL .",Potential New Issues and Requests
13894,I am receiving the same CODE but with CODE.,Potential New Issues and Requests
13895,We've been using an external server for word2vec for over a year now.,Potential New Issues and Requests
13896,I think I could migrate my class over to this tutorial pretty easily by using static RNN's.,Potential New Issues and Requests
13897,PR in #9733,Potential New Issues and Requests
13898,"I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency.",Potential New Issues and Requests
13899,We appear to have the following issues:,Potential New Issues and Requests
13900,"If you want to further discuss the specific non-linear discretization or mixed numeric/string encoding, feel free to open a new issue.",Potential New Issues and Requests
13901,"Here is the trace: Traceback (most recent call last):File ""tests/test_spacy_nlp.py"", line 231, in test_should_return_none_when_spacy_parsing_failsdoc = self.spacy_nlp.parse(query)File ""spacy_nlp.py"", line 49, in parsereturn SpacyDoc(self.__instance.parser(query))File ""lib/python3.5/site-packages/spacy/language.py"", line 328, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 146, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:6114)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:'splash On'",Potential New Issues and Requests
13902,"maybe for hobbyists but not for commercial use, where one would need clusters of machines to aim the computing process.",Potential New Issues and Requests
13903,I had no idea it worked differently on 64-bit and 32-bit...,Potential New Issues and Requests
13904,"I was also asking for the help from @ry to make my personal repository to be supported officially, there are few things we have to do like building some example models especially RNN cases, but unfortunately I'm got to work on other fields and have no time for these few months, if someone is interested in making this be happened, email to me, I'd love to guide you how to start.",Potential New Issues and Requests
13905,JavaScript APIs for TensorFlow were [announced] URL  earlier this month.,Potential New Issues and Requests
13906,"Also, it adds columns, not replaces, so will not yet work out of the box for string categorical data (but that is more feedback on that PR, not to discuss here).",Potential New Issues and Requests
13907,"seeing as you don't use a custom scorer, should we assume that is aseparate issue?",Potential New Issues and Requests
13908,Or just testing that values are stored in the same spot dueto collision?,Potential New Issues and Requests
13909,"First of all - deeplearn.js is a library that only mirrors to some extent ""the style of TensorFlow API"" and operates purely in the browser and the other would be a direct API to whole Tensorflow goodness.",Potential New Issues and Requests
13910,"I did a little looking around, and it looks like https://github.com/tensorflow/tensorflow/commits?author=alextp&since=2017-03-01T06:00:00Z&until=2017-04-01T05:00:00Z are the relevant commits.",Potential New Issues and Requests
13911,See Issue #124,Potential New Issues and Requests
13912,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests
13913,We probably need to raise a CODE if CODE.,Potential New Issues and Requests
13914,I'll submit a PR to reduce precision of the test.,Potential New Issues and Requests
13915,A HTTP query will return a base 64 encoding of the vector.,Potential New Issues and Requests
13916,"It won't grow much after this, I'm just curious how much entities it can hold and how it will affect the memory and performance.",Potential New Issues and Requests
13917,Related and possibly of interest: I managed to get TF running in the browser via Webassembly.,Potential New Issues and Requests
13918,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests
13919,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests
13920,So unless I missed something it doesn't look like this could be reproducible in Docker.,Potential New Issues and Requests
13921,The n_jobs=1 issue has been fixed.,Potential New Issues and Requests
13922,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests
13923,But it does seem like a plausible suspect.,Potential New Issues and Requests
13924,I am receiving the same CODE but with CODE.,Potential New Issues and Requests
13925,Should I open another issue for that segfault? CODE,Potential New Issues and Requests
13926,We appear to have the following issues:,Potential New Issues and Requests
13927,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests
13928,I think of it as a demo what you can achieve with JavaScript and neural networks...,Potential New Issues and Requests
13929,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
13930,Would it be possible for numpy to share buffers with tensorflow variableswhen they are returned from a session run?,Potential New Issues and Requests
13931,"But it's more important that both libraries stay internally consistent, and they have fairly different API norms.",Potential New Issues and Requests
13932,This doesn't explain why I can't reproduce it though.,Potential New Issues and Requests
13933,"I was also asking for the help from @ry to make my personal repository to be supported officially, there are few things we have to do like building some example models especially RNN cases, but unfortunately I'm got to work on other fields and have no time for these few months, if someone is interested in making this be happened, email to me, I'd love to guide you how to start.",Potential New Issues and Requests
13934,"The next release islikely to include a fixed-width discretizer, but following on from a logtransform or a quantile transform it should act quite similar to what youwant...",Potential New Issues and Requests
13935,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests
13936,Currently we are accessing the vector space through the https://github.com/3Top/word2vec-api/ project.,Potential New Issues and Requests
13937,"Here is our test:nlp = spacy.en.English()nlp.matcher.add('splash', 'my entity', {},[ [{LEMMA: 'splash'}, {LEMMA: 'on'}]])nlp('splash On')",Potential New Issues and Requests
13938,"@jnothman  To be a little clearer,  I don't know that 22 is significant.",Potential New Issues and Requests
13939,"I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency.",Potential New Issues and Requests
13940,"With the CODE below I get an error,CODE",Potential New Issues and Requests
13941,@jhseu You mentioned that you consider removing the CODEfeed_dictCODE copy as orthogonal to this issue.,Potential New Issues and Requests
13942,"I've been playing with an extension of this idea, where noun chunks and named entities are also merged.",Potential New Issues and Requests
13943,And a quick sample to show how it's used together with deeplearnjs:CODE,Potential New Issues and Requests
13944,"I hope to discuss what kinds of behaviour people expect from such ""vector stores"", so we can design a sane API.",Potential New Issues and Requests
13945,"""fair game"" is not a type of game: CODE",Potential New Issues and Requests
13946,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests
13947,We probably need to raise a CODE if CODE.,Potential New Issues and Requests
13948,"Among other things, we support a narrower range of platforms.",Potential New Issues and Requests
13949,I'm guessing Gensim would hesitate to depend on spaCy.,Potential New Issues and Requests
13950,"The results at the moment are quite messy, and many of the phrases need to be pruned from the vocab.",Potential New Issues and Requests
13951,Short version: I added Webassembly as an XLA compilation target.,Potential New Issues and Requests
13952,"Since this basically tests that in CODE we can disable the CODE functionality (enabled by default) and it doesn't validate any new functionality, it might be OK to skip it on failure on 32 bit?",Potential New Issues and Requests
13953,"Also, it adds columns, not replaces, so will not yet work out of the box for string categorical data (but that is more feedback on that PR, not to discuss here).",Potential New Issues and Requests
13954,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests
13955,"I do have a translator that works pretty similar to this one but creates cells through a separate class that allows for inserting bidirectional layers where you want, residuals where you want, merging inputs with concat vs. sum, and a few other things.",Potential New Issues and Requests
13956,Instead of: CODE,Potential New Issues and Requests
13957,"@lesshaste For the issue about NaNs as separate category, see https://github.com/scikit-learn/scikit-learn/issues/10465",Potential New Issues and Requests
13958,"test_pairwise_parallel I had missed, but I also suspect it's something we'll find impossible to debug...",Potential New Issues and Requests
13959,"We should make feed_dict faster (likely by not copying the numpy.arrays like @yaroslavvb mentioned), but that's orthogonal to this change.",Potential New Issues and Requests
13960,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
13961,Would it be possible for numpy to share buffers with tensorflow variableswhen they are returned from a session run?,Potential New Issues and Requests
13962,"I'll do it tomorrow, once I know the steps to reproduce it.",Potential New Issues and Requests
13963,Reddit also thinks hot dogs are practically salad: CODE,Potential New Issues and Requests
13964,The n_jobs=1 issue has been fixed.,Potential New Issues and Requests
13965,See https://humantoanimal.com for a demo; I will be providing more details in the future.,Potential New Issues and Requests
13966,"I've been playing with an extension of this idea, where noun chunks and named entities are also merged.",Potential New Issues and Requests
13967,"In the coordinate decent algorithms, the CODE option was introduced exactly for this purpose.",Potential New Issues and Requests
13968,I am running tf 1.2.1 (GPU)  on ubuntu 16.04 lts.,Potential New Issues and Requests
13969,I don't think it's due to floating point error.,Potential New Issues and Requests
13970,I had no idea it worked differently on 64-bit and 32-bit...,Potential New Issues and Requests
13971,"I'm afraid I'm getting this, too, in version 1.5.0: CODE",Potential New Issues and Requests
13972,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests
13973,Would it be possible for numpy to share buffers with tensorflow variableswhen they are returned from a session run?,Potential New Issues and Requests
13974,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests
13975,"We could try to make this test more robust, by just taking a large number of tokens N, hashing them with a hash table size = 1 (or any small number), and checking that with CODE the sum of hashed values is equal to CODE, and that it's strictly lower than CODE if  CODE (since some +1 / -1 are bound to cancel out if N is large enough).",Potential New Issues and Requests
13976,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests
13977,That is 22 indicates something specific which is quite different from 21 or 23.,Potential New Issues and Requests
13978,Any ideas how to fix here?,Potential New Issues and Requests
13979,I think of it as a demo what you can achieve with JavaScript and neural networks...,Potential New Issues and Requests
13980,"So the test fails on [this line](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/tests/test_feature_hasher.py#L122), where the expected values are CODE and  CODE (and I get those in the 32bit VM as well).",Potential New Issues and Requests
13981,"All was fine, until I added some matcher rules and an on_match callback: CODEwhere unit is 'BOPD', for example.",Potential New Issues and Requests
13982,Discussion of Bill Cosby makes some obvious (and some less obvious) comparisons: CODE,Potential New Issues and Requests
13983,We should really think about the organization of the docs.,Potential New Issues and Requests
13984,Or just testing that values are stored in the same spot dueto collision?,Potential New Issues and Requests
13985,"So the test fails on [this line](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/tests/test_feature_hasher.py#L122), where the expected values are CODE and  CODE (and I get those in the 32bit VM as well).",Potential New Issues and Requests
13986,"A ""class action"" is only very weakly a type of action: CODE",Potential New Issues and Requests
13987,"I've been playing with an extension of this idea, where noun chunks and named entities are also merged.",Potential New Issues and Requests
13988,"@jnothman  To be a little clearer,  I don't know that 22 is significant.",Potential New Issues and Requests
13989,And a quick sample to show how it's used together with deeplearnjs:CODE,Potential New Issues and Requests
13990,"We could try to make this test more robust, by just taking a large number of tokens N, hashing them with a hash table size = 1 (or any small number), and checking that with CODE the sum of hashed values is equal to CODE, and that it's strictly lower than CODE if  CODE (since some +1 / -1 are bound to cancel out if N is large enough).",Potential New Issues and Requests
13991,Do we have a rough plan for the change of APIs?,Potential New Issues and Requests
13992,"Since this basically tests that in CODE we can disable the CODE functionality (enabled by default) and it doesn't validate any new functionality, it might be OK to skip it on failure on 32 bit?",Potential New Issues and Requests
13993,CODE -> CODE,Potential New Issues and Requests
13994,*         [ ] CODE (not listed above): [mips] URL .,Potential New Issues and Requests
13995,"test_pairwise_parallel I had missed, but I also suspect it's something we'll find impossible to debug...",Potential New Issues and Requests
13996,"I've been playing with an extension of this idea, where noun chunks and named entities are also merged.",Potential New Issues and Requests
13997,"Could SpaCy keep an eye on Apache Flink, Apache Spark, and TensorFlow's about-to-be-released distributed processing framework as well?",Potential New Issues and Requests
13998,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
13999,*         https://github.com/PAIR-code/deeplearnjs/issues/238,Potential New Issues and Requests
14000,"Do you know if there's any issue or work being done on removing the copy (at least in some cases, like row-major Numpy arrays with nice strides)?",Potential New Issues and Requests
14001,2)         Similarity between entities can be kind of fun. Here's what Reddit thinks of Donald Trump: CODE,Potential New Issues and Requests
14002,"@prashantserai Don't exactly know, but what you met seems to be another issue.",Potential New Issues and Requests
14003,"I'm not sure why Eigen was not written to handle unaligned first and last ""packets"" so it wouldn't matter.",Potential New Issues and Requests
14004,Should I open another issue for that segfault? CODE,Potential New Issues and Requests
14005,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests
14006,"Since this basically tests that in CODE we can disable the CODE functionality (enabled by default) and it doesn't validate any new functionality, it might be OK to skip it on failure on 32 bit?",Potential New Issues and Requests
14007,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests
14008,"From my checking, these didn't make it into TF 1.1 but hopefully will be in 1.2.",Potential New Issues and Requests
14009,PR in #9733,Potential New Issues and Requests
14010,So that is related to the current discussion we are having in https://github.com/scikit-learn/scikit-learn/pull/10523 about deprecating CODE or not.,Potential New Issues and Requests
14011,"A simple thing to do is to convert all small values to strings, run DictVectorizer as above and then perform feature selection or just use your favorite classifier directly.",Potential New Issues and Requests
14012,"I think it'd be great to introduce an API lineage of scikit-learn flavour, or that simple.",Potential New Issues and Requests
14013,"I hope to discuss what kinds of behaviour people expect from such ""vector stores"", so we can design a sane API.",Potential New Issues and Requests
14014,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests
14015,**Dockerfile**CODEbuilt withCODE,Potential New Issues and Requests
14016,2)         Similarity between entities can be kind of fun. Here's what Reddit thinks of Donald Trump: CODE,Potential New Issues and Requests
14017,You can do: CODE,Potential New Issues and Requests
14018,I think this should fix the segfault too â I think they were related.,Potential New Issues and Requests
14019,*         https://github.com/PAIR-code/deeplearnjs/issues/407,Potential New Issues and Requests
14020,This test assumes that the hash value of the tested tokens always produces the same results (in which case two of those produce a collision).,Potential New Issues and Requests
14021,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
14022,"I'd like to minimize the number of mechanisms we have in sklearn, and we definitely need one (more?) for efficient model selection.",Potential New Issues and Requests
14023,*         https://github.com/PAIR-code/deeplearnjs/issues/238,Potential New Issues and Requests
14024,"I realise this will probably raise all sorts of mutability and stateissues, but these should be avoidable by setting the WRITABLE flag on thereturned numpy arrays to false.",Potential New Issues and Requests
14025,Do you have a link for that?,Potential New Issues and Requests
14026,"We should make feed_dict faster (likely by not copying the numpy.arrays like @yaroslavvb mentioned), but that's orthogonal to this change.",Potential New Issues and Requests
14027,I've created a fork of headless-gl that works with deeplearnjs (which in turn works with tensorflow) - this allows models to be run natively on the GPU from node.js (note that it's only been tested on OSX so far).,Potential New Issues and Requests
14028,"A ""class action"" is only very weakly a type of action: CODE",Potential New Issues and Requests
14029,We should really think about the organization of the docs.,Potential New Issues and Requests
14030,"We should make feed_dict faster (likely by not copying the numpy.arrays like @yaroslavvb mentioned), but that's orthogonal to this change.",Potential New Issues and Requests
14031,"Here is the trace: Traceback (most recent call last):File ""tests/test_spacy_nlp.py"", line 231, in test_should_return_none_when_spacy_parsing_failsdoc = self.spacy_nlp.parse(query)File ""spacy_nlp.py"", line 49, in parsereturn SpacyDoc(self.__instance.parser(query))File ""lib/python3.5/site-packages/spacy/language.py"", line 328, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 146, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:6114)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:'splash On'",Potential New Issues and Requests
14032,full traceback:CODE,Potential New Issues and Requests
14033,"There is no central documentation for that, right?",Potential New Issues and Requests
14034,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
14035,That last failure is not confusing after a little investigation.,Potential New Issues and Requests
14036,This test assumes that the hash value of the tested tokens always produces the same results (in which case two of those produce a collision).,Potential New Issues and Requests
14037,"I've been playing with an extension of this idea, where noun chunks and named entities are also merged.",Potential New Issues and Requests
14038,But it does seem like a plausible suspect.,Potential New Issues and Requests
14039,"How do you use such stores in spaCy, what metrics do you employ, what API signatures?",Potential New Issues and Requests
14040,I just suspect that *some* values are but I don't know which ones or how many there are.,Potential New Issues and Requests
14041,"We'd like to end up with something that is flexible enough to cover all standard use cases (CODE, CODE, CODE etc) but still concise and clearly scoped.",Potential New Issues and Requests
14042,we're going to release a bug-fix release in any case.,Potential New Issues and Requests
14043,The vectors for the verb and noun senses are quite different: CODE,Potential New Issues and Requests
14044,@jnothman So far I am not able to reproduce the CODE failure above.,Potential New Issues and Requests
14045,I think this should fix the segfault too â I think they were related.,Potential New Issues and Requests
14046,"Hi, We are getting a parser state error.",Potential New Issues and Requests
14047,We've been using an external server for word2vec for over a year now.,Potential New Issues and Requests
14048,But a class action _lawsuit_ is definitely a type of lawsuit: CODE,Potential New Issues and Requests
14049,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests
14050,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests
14051,I had no idea it worked differently on 64-bit and 32-bit...,Potential New Issues and Requests
14052,See details on the [deeplearn.js] URL  homepage.,Potential New Issues and Requests
14053,"There is no central documentation for that, right?",Potential New Issues and Requests
14054,I think this is relevant: https://github.com/spacy-io/spaCy/issues/413,Potential New Issues and Requests
14055,"Tried to build scikit-learn 0.19.2 it in a Debian sid/unstable i386 VM, were scipy and numpy 1.2.1 were installed with apt-get.",Potential New Issues and Requests
14056,Related and possibly of interest: I managed to get TF running in the browser via Webassembly.,Potential New Issues and Requests
14057,"I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency.",Potential New Issues and Requests
14058,And none of them are about CODE CODE,Potential New Issues and Requests
14059,"Among other things, we support a narrower range of platforms.",Potential New Issues and Requests
14060,Then you can investigate what's going on.,Potential New Issues and Requests
14061,"seeing as you don't use a custom scorer, should we assume that is aseparate issue?",Potential New Issues and Requests
14062,"We're in the process of abstracting away particular vector stores (in-memory matrix, sharded on-disk store, approximate kNN index...) from gensim, behind a common API.",Potential New Issues and Requests
14063,have we seen this before:,Potential New Issues and Requests
14064,"I am using a customized tokenizer that merges the three tokens, 'Linux', '.' and 'Mirai', into one token.",Potential New Issues and Requests
14065,The on_match callback is being called.,Potential New Issues and Requests
14066,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests
14067,"All was fine, until I added some matcher rules and an on_match callback: CODEwhere unit is 'BOPD', for example.",Potential New Issues and Requests
14068,"A simple thing to do is to convert all small values to strings, run DictVectorizer as above and then perform feature selection or just use your favorite classifier directly.",Potential New Issues and Requests
14069,The on_match callback is being called.,Potential New Issues and Requests
14070,A segfault via the Python API (as opposed to the Cython API) is always a bug.,Potential New Issues and Requests
14071,Will review.,Potential New Issues and Requests
14072,"test_pairwise_parallel I had missed, but I also suspect it's something we'll find impossible to debug...",Potential New Issues and Requests
14073,I'm guessing Gensim would hesitate to depend on spaCy.,Potential New Issues and Requests
14074,"I think tensorflow need 2 hyper methods that change the model state, something like torch.",Potential New Issues and Requests
14075,"maybe for hobbyists but not for commercial use, where one would need clusters of machines to aim the computing process.",Potential New Issues and Requests
14076,"@jnothman I just tried, but I'm not able to run e.g. a ppc64 Docker image on my amd64 system.",Potential New Issues and Requests
14077,"(As a side point, @ogrisel, I note there seems to be a lot more joblibparallelisation overhead in master -- on OS X at least -- that wasn't therein 0.14...)",Potential New Issues and Requests
14078,CODE -> CODE,Potential New Issues and Requests
14079,+1,Social Conversation
14080,"wow, you will enjoy it!",Social Conversation
14081,Please forgive typos and briefness.â,Social Conversation
14082,+1,Social Conversation
14083,-- Eric,Social Conversation
14084,@lesteve: Thank you for the solution!,Social Conversation
14085,"thanks,",Social Conversation
14086,"That would be great, I currently don't have the cycles to do that myself.",Social Conversation
14087,No worries.,Social Conversation
14088,"@larsmans , you are completely right.",Social Conversation
14089,Looking forward to it.,Social Conversation
14090,I see now that the bug title references Node.js directly.,Social Conversation
14091,"Jesus christ, stop sending people useless notifications, there's a reason GitHub introduced ð and ð reactions.",Social Conversation
14092,+1!,Social Conversation
14093,Thanks @Lucidyan for giving it a try.,Social Conversation
14094,"Sure, no problem.",Social Conversation
14095,"@kdavis-mozilla that sounds interesting, but the link appears to be dead.",Social Conversation
14096,I kinda had wanted to deprecate it but then we didn't...,Social Conversation
14097,"How about we LOVE ""badly"" designed languages?",Social Conversation
14098,Looking forward to it.,Social Conversation
14099,"Sounds great, thanks a lot !",Social Conversation
14100,+1,Social Conversation
14101,ð,Social Conversation
14102,:+1:,Social Conversation
14103,Same problem here.,Social Conversation
14104,+1,Social Conversation
14105,"I don't know TF as well as others here, so please take my comments with some skepticism:",Social Conversation
14106,+1,Social Conversation
14107,I don't know what the notebook makes of the CODE.,Social Conversation
14108,Fair enough.,Social Conversation
14109,Just my 2 cents.,Social Conversation
14110,Just to clarify a few things for anyone who might stumble on this post.,Social Conversation
14111,**+1**,Social Conversation
14112,"But whether this difference is important in practice, I don't know.",Social Conversation
14113,"No, I must have sorted these things incorrectly.",Social Conversation
14114,Sounds awesome and I will definitely try this out later.,Social Conversation
14115,I've spent a little time looking into this now.,Social Conversation
14116,Wanted to let you know I migrated from queues to Dataset and it's been great.,Social Conversation
14117,+1,Social Conversation
14118,+1.,Social Conversation
14119,Just got confused by this problem last week and wasted 3 days of training...,Social Conversation
14120,Will continue onwards and let you know about my results when I get them!,Social Conversation
14121,Thank you.,Social Conversation
14122,Why so?,Social Conversation
14123,"@bwesen yes,you were right .",Social Conversation
14124,"@kdavis-mozilla that sounds interesting, but the link appears to be dead.",Social Conversation
14125,Thanks a ton!,Social Conversation
14126,"But would like to keep this one focused on the original issue, i.e. the *naming* and organisation in different classes of the CategoricalEncoder/OneHotEncoder.",Social Conversation
14127,+1,Social Conversation
14128,"@AyalaSaenzJorge this is a place for informative comments, not an opinionated-firestarters.",Social Conversation
14129,+1,Social Conversation
14130,This is definitely a feature we want.,Social Conversation
14131,Disclaimer: This example might be pedantic because the differences in termsof the learned weights is minimal - but conceptually they are IMHO totallydifferent things...,Social Conversation
14132,@priidukull Thanks for the log.,Social Conversation
14133,Thank you once again :),Social Conversation
14134,-- Eric,Social Conversation
14135,"@dfoody thank you for sharing this with the community but the statement ""which in turn works with tensorflow"" is incorrect.",Social Conversation
14136,Hope it helps the community.,Social Conversation
14137,It might be the case.,Social Conversation
14138,Let's revive the discussion.,Social Conversation
14139,"I understand that we all have the desire to support this case but can only deduct that on github's closest thing to ""vote"" functionality is implemented with ""reactions"" not with a count of comments in the thread...",Social Conversation
14140,-- Eric,Social Conversation
14141,Fair enough.,Social Conversation
14142,+1,Social Conversation
14143,Ok sorry for the comment.,Social Conversation
14144,+1,Social Conversation
14145,@yaroslavvb correct me if I'm wrong but this isn't entirely right.,Social Conversation
14146,@7ammer propelml.org looks rather promising.,Social Conversation
14147,"Hi @honnibal First of all, thank you for this great tool, we use it as part of NLP in our product.",Social Conversation
14148,And that's a FACT and it's never going away sorry lol,Social Conversation
14149,Thank you.,Social Conversation
14150,"So, if you ever want to upgrade, you now know what to do!",Social Conversation
14151,+1 ð,Social Conversation
14152,Please forgive typos and briefness.â,Social Conversation
14153,Thanks for the hard work.,Social Conversation
14154,@brando90 you're right.,Social Conversation
14155,+1,Social Conversation
14156,But --- progress :),Social Conversation
14157,Please support node.js.,Social Conversation
14158,"I'll figure this out, thanks.",Social Conversation
14159,"Hi guys,",Social Conversation
14160,@djimoh5 Awesome thoughts on JavaScript to Python full-featured APIs!,Social Conversation
14161,"@kratzert, that's precisely what @taion means by",Social Conversation
14162,"Edit: Sorry, it totally works.",Social Conversation
14163,Hope it helps the community.,Social Conversation
14164,Is there another reference?,Social Conversation
14165,@burui11087 I completely forgot about symlinking.,Social Conversation
14166,That way we can build consensus around your vision and help it be the best vision possible.,Social Conversation
14167,Does anyone know if there has been any healthy discussion regarding tensorflow and node anywhere else as these +1's don't seem to be doing much :(,Social Conversation
14168,"OK thanks a lot for this, at least we have a deterministic snippet now.",Social Conversation
14169,"Sure, no problem.",Social Conversation
14170,+1,Social Conversation
14171,I think at the moment this is quite confusing.,Social Conversation
14172,"so in my haste, I decided this issue was resolved.",Social Conversation
14173,I'm using it now and loving it.,Social Conversation
14174,"Talking about ""deeplearn.js"" and ""Tensorflow API for Javascript"" is like talking about apples & pears.",Social Conversation
14175,Looks like the TensorFlow team is making this a top priority now: https://js.tensorflow.org/faq/,Social Conversation
14176,The only.,Social Conversation
14177,Thank you very much.,Social Conversation
14178,+1,Social Conversation
14179,"I'm grateful to @mikepb , @aborsu and others for their contributions to the discussion here.",Social Conversation
14180,+1,Social Conversation
14181,-- Eric,Social Conversation
14182,+1,Social Conversation
14183,I'll start from the beginning:,Social Conversation
14184,"@honnibal thank you for quick answer,",Social Conversation
14185,Thank you so much @honnibal !,Social Conversation
14186,"I'll discuss the design decision here, so that we can consider the trade-offs.",Social Conversation
14187,Right.,Social Conversation
14188,+1,Social Conversation
14189,"@yorkie It looks interesting, I will try it out!",Social Conversation
14190,Let's revive the discussion.,Social Conversation
14191,I can't reproduce without your data and it would be good to reproduce in shorter time.,Social Conversation
14192,+1,Social Conversation
14193,Also please see my comment from 26 Aug where I explain why deeplearnjs is irrelevant to this debate.,Social Conversation
14194,:+1:,Social Conversation
14195,Not quite satisfying as we don'tunderstand what's going on...,Social Conversation
14196,+1,Social Conversation
14197,"I can't find any of this statement in the post of @taion, but could be a misunderstanding of my side as I'm not a English native speaker.",Social Conversation
14198,Will need to investigate further.,Social Conversation
14199,etc,Social Conversation
14200,a taste of things to come...,Social Conversation
14201,I'm so glad that this has received so much thought and attention!,Social Conversation
14202,I should have come to this on my own!,Social Conversation
14203,Not quite satisfying as we don'tunderstand what's going on...,Social Conversation
14204,+1,Social Conversation
14205,Thank you for your advice @soloice.,Social Conversation
14206,Thanks for the workarounds.,Social Conversation
14207,+1,Social Conversation
14208,@thread :,Social Conversation
14209,Thanks,Social Conversation
14210,Wanted to let you know I migrated from queues to Dataset and it's been great.,Social Conversation
14211,I see now that the bug title references Node.js directly.,Social Conversation
14212,Thanks a ton!,Social Conversation
14213,I welcome any thoughts or suggestions on the approach outlined above.,Social Conversation
14214,So we're absolutely interested in helping the individual devoted to making that happen be successful.,Social Conversation
14215,"We've been at this for so long that I no longer have a good sense of what's obvious or not, and would welcome clarifying documentation for someone with a fresh perspective on the topic.",Social Conversation
14216,Please share your results :),Social Conversation
14217,You are right there are two use cases.,Social Conversation
14218,ok.,Social Conversation
14219,Please share your results :),Social Conversation
14220,@ishaybee Thanks for you help.,Social Conversation
14221,:+1:,Social Conversation
14222,Thanks!,Social Conversation
14223,I hope to see something like this in a future TF.,Social Conversation
14224,Dank u wel for all the clarifications!,Social Conversation
14225,@priidukull thanks for that.,Social Conversation
14226,@amueller Don't read all of the above!,Social Conversation
14227,+1,Social Conversation
14228,The error in my last two comments before this was due to my mistake.,Social Conversation
14229,Thanks @honnibal for your advice.,Social Conversation
14230,"@jasonkriss , I see - thanks!",Social Conversation
14231,(just removed a lot of the previous comment as I was repeating myself).,Social Conversation
14232,+1,Social Conversation
14233,What fresh hell is this :-/,Social Conversation
14234,So I wasn't sure that would be a good idea.,Social Conversation
14235,+1,Social Conversation
14236,;-),Social Conversation
14237,@nuchi Great work!,Social Conversation
14238,Thanks.,Social Conversation
14239,that strategy sounds mostly good.,Social Conversation
14240,Great.,Social Conversation
14241,Updated original comment with more info and code.,Social Conversation
14242,"It's great to hear that it ""just works""!",Social Conversation
14243,+1,Social Conversation
14244,+1!,Social Conversation
14245,(thinking I might actually do this as part of my master thesis :P ),Social Conversation
14246,**more info:**,Social Conversation
14247,:+1:,Social Conversation
14248,Completely agree.,Social Conversation
14249,Keep up the good work.,Social Conversation
14250,I think I got carried away...,Social Conversation
14251,I'm not sure I get the stacking example.,Social Conversation
14252,Hmm.,Social Conversation
14253,@amueller that's fine.,Social Conversation
14254,Great.,Social Conversation
14255,I've spent a little time looking into this now.,Social Conversation
14256,I will go more into depth by providing a generic example of the problem.,Social Conversation
14257,"Good advice, thank you.",Social Conversation
14258,+1,Social Conversation
14259,![image] URL ,Social Conversation
14260,+1,Social Conversation
14261,My apologies if I'm simply repeating what has already been said.,Social Conversation
14262,We got quite some comments on that in the survey :-/,Social Conversation
14263,"Yes, I think you're right.",Social Conversation
14264,Many thanks.,Social Conversation
14265,I need to do that to debug more efficiently.,Social Conversation
14266,+1,Social Conversation
14267,"Sure, no problem.",Social Conversation
14268,Fabio,Social Conversation
14269,+1,Social Conversation
14270,:+1:,Social Conversation
14271,+1,Social Conversation
14272,"@neighthan Sorry, fixed.",Social Conversation
14273,"I started working on a [NodeJS binding for TensorFlow] URL  a while ago, but a haven't had much free time to devote to it lately.",Social Conversation
14274,"I've read about that somewhere recently, probably on stack overflow.",Social Conversation
14275,@fabiofumarola Thank you for the function.,Social Conversation
14276,+1,Social Conversation
14277,I am using the new api CODE now.,Social Conversation
14278,I like this suggestion.,Social Conversation
14279,+1,Social Conversation
14280,Thought I made myself clearer.,Social Conversation
14281,"WOW, yes!",Social Conversation
14282,@shahen94 we all saw that but still...,Social Conversation
14283,Does anyone know if there has been any healthy discussion regarding tensorflow and node anywhere else as these +1's don't seem to be doing much :(,Social Conversation
14284,"Sorry, my internet isn't good for video chatting, but I'm happy to text.",Social Conversation
14285,Very promising!,Social Conversation
14286,+1.,Social Conversation
14287,Let's revive the discussion.,Social Conversation
14288,+1 :+1:,Social Conversation
14289,That's where I would like to see feedback.,Social Conversation
14290,The error in my last two comments before this was due to my mistake.,Social Conversation
14291,+1.,Social Conversation
14292,+1,Social Conversation
14293,"@rasbt Hmm, that's really interesting.",Social Conversation
14294,The new input pipelines are great!,Social Conversation
14295,It is quite demoralizing when the first tensorflow program you ever run spits out a bunch of errors.,Social Conversation
14296,ð,Social Conversation
14297,+1,Social Conversation
14298,guys...thanks for the thread.,Social Conversation
14299,That's where I would like to see feedback.,Social Conversation
14300,I'm surprised nobody is using Windows it seems.,Social Conversation
14301,"Also, if my description is terribly unclear, please let me know and I'll try to clarify.",Social Conversation
14302,Good point.,Social Conversation
14303,"@somombo yes, it looks really interesting.",Social Conversation
14304,Ok.,Social Conversation
14305,Thanks.,Social Conversation
14306,Further note and caution to those looking here..,Social Conversation
14307,Am I right?,Social Conversation
14308,"From my searching, this thread is the best resource for how to use it.",Social Conversation
14309,+1,Social Conversation
14310,"@honnibal Great, thanks very much for these improvements.",Social Conversation
14311,Completely agree.,Social Conversation
14312,I'll start from the beginning:,Social Conversation
14313,Well I do not know what causes the AttributeError...,Social Conversation
14314,"Ah, thanks, I missed that, as it was in an example about text processing.",Social Conversation
14315,ð¯ ð,Social Conversation
14316,Thank you very much.,Social Conversation
14317,+1,Social Conversation
14318,:+1:,Social Conversation
14319,Tricky,Social Conversation
14320,Does anyone know if there has been any healthy discussion regarding tensorflow and node anywhere else as these +1's don't seem to be doing much :(,Social Conversation
14321,Thatâs a shame.,Social Conversation
14322,+1,Social Conversation
14323,"Uups, I missed that.",Social Conversation
14324,Thank you again!,Social Conversation
14325,+1,Social Conversation
14326,+1 :+1:,Social Conversation
14327,Great thanks a lot!,Social Conversation
14328,We can at least pickle our data correctly :),Social Conversation
14329,Just to clarify a few things for anyone who might stumble on this post.,Social Conversation
14330,lukasz; it's hard for me to identify from the various comments which part of the tutorial is faulty in TF 1.0.,Social Conversation
14331,Yes.,Social Conversation
14332,It is a bit hard to follow what you have done @KaisJM.,Social Conversation
14333,I'll test again today/tomorrow and get back to you.,Social Conversation
14334,https://research.googleblog.com/2016/11/celebrating-tensorflows-first-year.html,Social Conversation
14335,"I suppose this is true of most things about Carrot Top, so...Fair play.",Social Conversation
14336,ð Guys please before commenting +1 or +whatever - Please take a look at @k1sul1 's comment,Social Conversation
14337,Sucks that I've trained models for days expecting things to work before seeing that everyone trying to use this feature going crazy.,Social Conversation
14338,thanks :),Social Conversation
14339,+100,Social Conversation
14340,Oh good timing!,Social Conversation
14341,+1,Social Conversation
14342,I will glad for any help.,Social Conversation
14343,I'll try to produce a more reliable report of the behaviour.,Social Conversation
14344,+1,Social Conversation
14345,"Sorry, my internet isn't good for video chatting, but I'm happy to text.",Social Conversation
14346,Let's the do something useful for community in best wishes :),Social Conversation
14347,+10000,Social Conversation
14348,+1,Social Conversation
14349,"@dfoody thank you for sharing this with the community but the statement ""which in turn works with tensorflow"" is incorrect.",Social Conversation
14350,What do you think?,Social Conversation
14351,"Please keep an eye out for other issues, and report them :)",Social Conversation
14352,I should have been more specific.,Social Conversation
14353,I've done some googling on this and nothing so far even hints at a workaround.,Social Conversation
14354,"since its unclear if the implementation will change, I wanted to give a suggestion (note its easy to extend to convolutions and stuff I just didn't paste that code).",Social Conversation
14355,"They are undergoing some changes in management, so they might be slow to respond.",Social Conversation
14356,+1,Social Conversation
14357,that strategy sounds mostly good.,Social Conversation
14358,Happy for this decision.,Social Conversation
14359,"I understand that we all have the desire to support this case but can only deduct that on github's closest thing to ""vote"" functionality is implemented with ""reactions"" not with a count of comments in the thread...",Social Conversation
14360,@jimfleming Good point,Social Conversation
14361,:+1:,Social Conversation
14362,:+1:,Social Conversation
14363,Thanks for your reply!,Social Conversation
14364,I second @lming's sentiment above.,Social Conversation
14365,Ha!,Social Conversation
14366,Thank you very much.,Social Conversation
14367,"@amueller Oh, ok.",Social Conversation
14368,It is a bit hard to follow what you have done @KaisJM.,Social Conversation
14369,"Hi,",Social Conversation
14370,"So, thx, not sure where I went wrong yesterday, but it was clearly on me.",Social Conversation
14371,@kratzert You are right.,Social Conversation
14372,Hmm.,Social Conversation
14373,"Jesus christ, stop sending people useless notifications, there's a reason GitHub introduced ð and ð reactions.",Social Conversation
14374,We're definitely not about to give up working on SpaCy!,Social Conversation
14375,:+1:,Social Conversation
14376,Good question.,Social Conversation
14377,+1,Social Conversation
14378,But really love the work you're doing.,Social Conversation
14379,I am personally in favor of option 1 or 2.,Social Conversation
14380,I think we're in agreement here.,Social Conversation
14381,Great job debugging the issue by the way!,Social Conversation
14382,@shahen94 we all saw that but still...,Social Conversation
14383,thanks :),Social Conversation
14384,(!!!!):tada: :tada: :tada:,Social Conversation
14385,:),Social Conversation
14386,I still don't know much about tensorflow.,Social Conversation
14387,:+1:,Social Conversation
14388,@peterbraden sorry for the prolonged silence.,Social Conversation
14389,Thanks,Social Conversation
14390,Please support node.js.,Social Conversation
14391,@magick93 and all that turn up here!,Social Conversation
14392,Good point.,Social Conversation
14393,I like this suggestion.,Social Conversation
14394,+1,Social Conversation
14395,I'm so happy to hear you're giving this a shot @JIoJIaJIu.,Social Conversation
14396,"Hi,",Social Conversation
14397,:+1:,Social Conversation
14398,+1,Social Conversation
14399,Thanks for the initiative guys!,Social Conversation
14400,No worries.,Social Conversation
14401,I may not understand the distributed settings that TF data input pipeline API is targeting to solve.,Social Conversation
14402,:+1:,Social Conversation
14403,that strategy sounds mostly good.,Social Conversation
14404,+1,Social Conversation
14405,The only.,Social Conversation
14406,Thank you very much.,Social Conversation
14407,**EDIT:**,Social Conversation
14408,+1,Social Conversation
14409,+1,Social Conversation
14410,+1,Social Conversation
14411,"To be honest, I am not sure where we go from this.",Social Conversation
14412,ðPlease !,Social Conversation
14413,"@neighthan Sorry, fixed.",Social Conversation
14414,It might be the case.,Social Conversation
14415,not sure if I'll have time before that :-/,Social Conversation
14416,"Sure, no problem.",Social Conversation
14417,Just my 2 cents.,Social Conversation
14418,@bwesen's [comment](https://github.com/tensorflow/tensorflow/issues/15604#issuecomment-362637994) is correct.,Social Conversation
14419,Or I'm blind.,Social Conversation
14420,:+1:,Social Conversation
14421,+1,Social Conversation
14422,@pavelbulanov It's very kind of you to help me with this!,Social Conversation
14423,just a suggestion..,Social Conversation
14424,+1,Social Conversation
14425,But I hope we can all agree that this is just digging ourselves a deeper hole.,Social Conversation
14426,What fresh hell is this :-/,Social Conversation
14427,+1,Social Conversation
14428,+1,Social Conversation
14429,+1,Social Conversation
14430,+1,Social Conversation
14431,@abrahamrhoffman that's rude.,Social Conversation
14432,just a suggestion..,Social Conversation
14433,Oh good timing!,Social Conversation
14434,The new input pipelines are great!,Social Conversation
14435,Not so!,Social Conversation
14436,Thanks for the workarounds.,Social Conversation
14437,ð,Social Conversation
14438,"I am not sure it this concept has been brought up yet, but I will at least put the problem in my own terms.",Social Conversation
14439,Thank you very much.,Social Conversation
14440,:+1:,Social Conversation
14441,Okay so.,Social Conversation
14442,Will need to investigate further.,Social Conversation
14443,Thank you for your advice @soloice.,Social Conversation
14444,+1 Googolplex!,Social Conversation
14445,"Also, if my description is terribly unclear, please let me know and I'll try to clarify.",Social Conversation
14446,**more info:**,Social Conversation
14447,+1,Social Conversation
14448,+1,Social Conversation
14449,"@dfoody thank you for sharing this with the community but the statement ""which in turn works with tensorflow"" is incorrect.",Social Conversation
14450,Hmmm interesting ...,Social Conversation
14451,Yes i did the same thing.,Social Conversation
14452,@jimfleming you're right again ;),Social Conversation
14453,Just what I was searching for.,Social Conversation
14454,ð,Social Conversation
14455,Thanks!,Social Conversation
14456,I'm not sure I get the stacking example.,Social Conversation
14457,+1,Social Conversation
14458,(just removed a lot of the previous comment as I was repeating myself).,Social Conversation
14459,That was my motivation.,Social Conversation
14460,I'm wholly unfamiliar with Windows development...,Social Conversation
14461,Thank you so much @honnibal !,Social Conversation
14462,+1,Social Conversation
14463,+1,Social Conversation
14464,Of course the code clarity and simplicity of working with the new dataset class is a huge step forward and very welcome.,Social Conversation
14465,It is quite demoralizing when the first tensorflow program you ever run spits out a bunch of errors.,Social Conversation
14466,"How about we LOVE ""badly"" designed languages?",Social Conversation
14467,@jimfleming Good point,Social Conversation
14468,hm ok maybe this is not so important right now.,Social Conversation
14469,+1,Social Conversation
14470,+1,Social Conversation
14471,@ebrevdo Thanks for getting back to this issue.,Social Conversation
14472,"I can't find any of this statement in the post of @taion, but could be a misunderstanding of my side as I'm not a English native speaker.",Social Conversation
14473,Thanks for the workarounds.,Social Conversation
14474,@snnn Yes I know and I do exactly this.,Social Conversation
14475,+1 <3,Social Conversation
14476,Disclaimer: This example might be pedantic because the differences in termsof the learned weights is minimal - but conceptually they are IMHO totallydifferent things...,Social Conversation
14477,We can at least pickle our data correctly :),Social Conversation
14478,+1,Social Conversation
14479,*         @snnn: Thanks for kicking the tires!,Social Conversation
14480,+1,Social Conversation
14481,+1,Social Conversation
14482,Let's the do something useful for community in best wishes :),Social Conversation
14483,+1000,Social Conversation
14484,-- Eric,Social Conversation
14485,What fresh hell is this :-/,Social Conversation
14486,"I don't know if I'm right here, but I have a question about the dataset API.",Social Conversation
14487,Hmmm interesting ...,Social Conversation
14488,what did you guys change...?,Social Conversation
14489,The new input pipelines are great!,Social Conversation
14490,"Anyway, that's just my thoughts.",Social Conversation
14491,Looks like the TensorFlow team is making this a top priority now: https://js.tensorflow.org/faq/,Social Conversation
14492,So nevermind :),Social Conversation
14493,"Hi guys,",Social Conversation
14494,sorry for joining the discussion so late.,Social Conversation
14495,Found this while looking into wether or not bindings existed already.,Social Conversation
14496,Thanks in advance.,Social Conversation
14497,So you can always try.,Social Conversation
14498,+1,Social Conversation
14499,But really love the work you're doing.,Social Conversation
14500,+1 <3,Social Conversation
14501,"No, I must have sorted these things incorrectly.",Social Conversation
14502,I think I got carried away...,Social Conversation
14503,what did you guys change...?,Social Conversation
14504,"Okay, thanks.",Social Conversation
14505,Hmm.,Social Conversation
14506,"WOW, yes!",Social Conversation
14507,This seems important.,Social Conversation
14508,+1,Social Conversation
14509,+1 pweeettyyy pwease!!!,Social Conversation
14510,+1,Social Conversation
14511,@fabiofumarola Thank you for the function.,Social Conversation
14512,O_o;;,Social Conversation
14513,This makes sense.,Social Conversation
14514,"but I haven't tested, so I might be wrong about that :)",Social Conversation
14515,+1,Social Conversation
14516,Thanks in advance for any hints.,Social Conversation
14517,(just removed a lot of the previous comment as I was repeating myself).,Social Conversation
14518,Do you have a minute to video chat about this?,Social Conversation
14519,"@neighthan Sorry, fixed.",Social Conversation
14520,+1,Social Conversation
14521,"Hi @honnibal First of all, thank you for this great tool, we use it as part of NLP in our product.",Social Conversation
14522,"After some thoughts, I think we should see the bigger picture here.",Social Conversation
14523,"I can make here snippet ""complete"" and post for you.",Social Conversation
14524,Great thanks a lot!,Social Conversation
14525,I just quickly checked @ppwwyyxx repo really awesome!,Social Conversation
14526,Thanks.,Social Conversation
14527,**more info:**,Social Conversation
14528,+1,Social Conversation
14529,AYBE YOU NEED READ THIS,Social Conversation
14530,"@jasonkriss , I see - thanks!",Social Conversation
14531,-- Eric,Social Conversation
14532,@sguada FYI,Social Conversation
14533,"I think I have this taken care of, but I'm not 100% sure.",Social Conversation
14534,This sounds great!,Social Conversation
14535,+1,Social Conversation
14536,I can't say the connection between Carrot Top and Kate Mara is obvious to me.,Social Conversation
14537,@miguelalche Glad to see you're interested!,Social Conversation
14538,+1,Social Conversation
14539,+1,Social Conversation
14540,Thank you very much.,Social Conversation
14541,+1 :+1:,Social Conversation
14542,Thank you for your fast reply.,Social Conversation
14543,@ajaanbaahu Still waiting for tf1.2 new seq2seq tutorial.,Social Conversation
14544,@7ammer propelml.org looks rather promising.,Social Conversation
14545,:+1:,Social Conversation
14546,+1,Social Conversation
14547,I can't reproduce without your data and it would be good to reproduce in shorter time.,Social Conversation
14548,"Yeah, sorry about that.",Social Conversation
14549,@priidukull thanks for that.,Social Conversation
14550,All this seems pretty amazing !,Social Conversation
14551,+1,Social Conversation
14552,(just removed a lot of the previous comment as I was repeating myself).,Social Conversation
14553,Updated original comment with more info and code.,Social Conversation
14554,+1,Social Conversation
14555,+1,Social Conversation
14556,Try giving the first comment a thumbs up,Social Conversation
14557,+1,Social Conversation
14558,+1.,Social Conversation
14559,+1,Social Conversation
14560,I read the top post.,Social Conversation
14561,I do see your argument.,Social Conversation
14562,Thanks for the quick feed back so far!,Social Conversation
14563,I don't really see the motivation for that.,Social Conversation
14564,Ok.,Social Conversation
14565,"@zhongyuk awesome, glad to hear that you were able to narrow it down!",Social Conversation
14566,Very nice indeed.,Social Conversation
14567,+1,Social Conversation
14568,"@neighthan Sorry, fixed.",Social Conversation
14569,@zhongyuk Thanks a lot for sharing .,Social Conversation
14570,@Foorack please add me to what ever you can!,Social Conversation
14571,It is a bit hard to follow what you have done @KaisJM.,Social Conversation
14572,"@neighthan Sorry, fixed.",Social Conversation
14573,"Aha, that clarifies our misunderstanding :-)",Social Conversation
14574,@snnn Yes I know and I do exactly this.,Social Conversation
14575,I think it would be confusing.,Social Conversation
14576,Well ok...,Social Conversation
14577,Yes i did the same thing.,Social Conversation
14578,Thank you for your advice @soloice.,Social Conversation
14579,Wow three numpy installed I saw two before but never three ...,Social Conversation
14580,hm ok maybe this is not so important right now.,Social Conversation
14581,+1,Social Conversation
14582,Sorry,Social Conversation
14583,That way we can build consensus around your vision and help it be the best vision possible.,Social Conversation
14584,Similar to what yazabazra is asking above:,Social Conversation
14585,Thanks for the info @vrv (and for the features @alextp ).,Social Conversation
14586,@thread :,Social Conversation
14587,Or I'm blind.,Social Conversation
14588,+1,Social Conversation
14589,Thanks for reminding me.,Social Conversation
14590,This is odd â I definitely thought I'd done this.,Social Conversation
14591,+1,Social Conversation
14592,+1 Googolplex!,Social Conversation
14593,It may be that there is a better solution.,Social Conversation
14594,+1,Social Conversation
14595,Please correct me if I'm wrong.,Social Conversation
14596,Thanks in advance.,Social Conversation
14597,"wow, you will enjoy it!",Social Conversation
14598,We're definitely not about to give up working on SpaCy!,Social Conversation
14599,"@honnibal thank you for quick answer,",Social Conversation
14600,It is a bit hard to follow what you have done @KaisJM.,Social Conversation
14601,I'm so glad that this has received so much thought and attention!,Social Conversation
14602,.,Social Conversation
14603,So nevermind :),Social Conversation
14604,"If we can reproduce, only then can we investigate and try to understand what is happening.",Social Conversation
14605,And I don't wanna break my projects with TF dependency,Social Conversation
14606,I will keep an eye on your project for sure ;-D,Social Conversation
14607,@ajaanbaahu Still waiting for tf1.2 new seq2seq tutorial.,Social Conversation
14608,"@honnibal thank you for quick answer,",Social Conversation
14609,+1,Social Conversation
14610,"UPDATE July 25, 2016:",Social Conversation
14611,+1,Social Conversation
14612,Hooray for node!,Social Conversation
14613,hrm.,Social Conversation
14614,ð,Social Conversation
14615,"but I haven't tested, so I might be wrong about that :)",Social Conversation
14616,Good question.,Social Conversation
14617,+1,Social Conversation
14618,Is thatwhat you are suggesting?,Social Conversation
14619,I just quickly checked @ppwwyyxx repo really awesome!,Social Conversation
14620,Yeah this sounds terrifying.,Social Conversation
14621,Looking forward to it.,Social Conversation
14622,+1,Social Conversation
14623,I'm using it now and loving it.,Social Conversation
14624,+1,Social Conversation
14625,So I wasn't sure that would be a good idea.,Social Conversation
14626,I don't really see the motivation for that.,Social Conversation
14627,"UPDATE July 25, 2016:",Social Conversation
14628,"@rasbt Hmm, that's really interesting.",Social Conversation
14629,Definitely going in the right direction.,Social Conversation
14630,+1,Social Conversation
14631,Keep up the good work!,Social Conversation
14632,I am personally in favor of option 1 or 2.,Social Conversation
14633,Thanks.,Social Conversation
14634,@7ammer propelml.org looks rather promising.,Social Conversation
14635,Cheers.,Social Conversation
14636,"yea my bad, should have been clearer.",Social Conversation
14637,The error in my last two comments before this was due to my mistake.,Social Conversation
14638,+1,Social Conversation
14639,@Foorack please add me to what ever you can!,Social Conversation
14640,"So, if you ever want to upgrade, you now know what to do!",Social Conversation
14641,+1,Social Conversation
14642,I'm so glad that this has received so much thought and attention!,Social Conversation
14643,Thanks again,Social Conversation
14644,@tano297 Thank you.,Social Conversation
14645,It might be the case.,Social Conversation
14646,"@cpple Remember not to add +1s, they cause noise and have been replaced by reactions.",Social Conversation
14647,"Given the above comment regarding the **seq2seq tutorial**, I suspect we are all in the same boat?",Social Conversation
14648,Thanks in advance.,Social Conversation
14649,+1.0000000000000000000000001,Social Conversation
14650,+1,Social Conversation
14651,Will continue onwards and let you know about my results when I get them!,Social Conversation
14652,+1,Social Conversation
14653,hrm.,Social Conversation
14654,:+1:,Social Conversation
14655,+1 and +999 just annoys people and adds no value whatsoever.,Social Conversation
14656,"Also, if my description is terribly unclear, please let me know and I'll try to clarify.",Social Conversation
14657,I have found this a very useful technique.,Social Conversation
14658,that strategy sounds mostly good.,Social Conversation
14659,Please don't give up working on SpaCy.,Social Conversation
14660,Just got confused by this problem last week and wasted 3 days of training...,Social Conversation
14661,:+1:,Social Conversation
14662,Happy Anniversary TensorFlow !,Social Conversation
14663,Thanks @Lucidyan for giving it a try.,Social Conversation
14664,AYBE YOU NEED READ THIS,Social Conversation
14665,@huxuanlai it works!,Social Conversation
14666,:+1:,Social Conversation
14667,Thanks for sharing your analysis @zhongyuk!,Social Conversation
14668,I'm digging the new API.,Social Conversation
14669,+1,Social Conversation
14670,+1,Social Conversation
14671,Bizarre.,Social Conversation
14672,;-),Social Conversation
14673,+1000,Social Conversation
14674,"so in my haste, I decided this issue was resolved.",Social Conversation
14675,+1,Social Conversation
14676,+1,Social Conversation
14677,Wow three numpy installed I saw two before but never three ...,Social Conversation
14678,+1,Social Conversation
14679,"This requires a non negligible amount of time and effort, I completely agree, but without it, I am afraid that there is not much we can do to investigate the problem you are facing.",Social Conversation
14680,LISTEN!,Social Conversation
14681,:+1:,Social Conversation
14682,@djimoh5 Awesome thoughts on JavaScript to Python full-featured APIs!,Social Conversation
14683,+1,Social Conversation
14684,I'll try to produce a more reliable report of the behaviour.,Social Conversation
14685,I started a while back but stopped because of shifting project focuses.,Social Conversation
14686,@pavelbulanov It's very kind of you to help me with this!,Social Conversation
14687,Happy Anniversary TensorFlow !,Social Conversation
14688,:+1:,Social Conversation
14689,@burui11087 I completely forgot about symlinking.,Social Conversation
14690,@BruceHem not really sure how being a js dev correlates with blindly pushing unnecessary spam to the feed...,Social Conversation
14691,Great!,Social Conversation
14692,"The default decay is 0.999, for small datasets such like MNIST, you can choose 0.99 or 0.95, and it warms up in a short time.",Solution Usage
14693,(You can try it by downloading the current nightly build.),Solution Usage
14694,"If I understood correctly if the flag is CODE the network is not efficient, so I should let CODE and then I should collect all the batch_norm updates and run them together.",Solution Usage
14695,"The catch is, I couldn't find a way to iterate over the data more than once (which luckily enough is not my use-case), because the only iterator that won't raise an error when the CODEs spawn the threads is the CODE.",Solution Usage
14696,"(below is an example of the function, in reality i use more layers and neurons). CODE",Solution Usage
14697,"Per value this isn't that much of a difference, but has a big impact when computing vector distances in latent spaces.",Solution Usage
14698,"I thought it should work, but after some experiments, I can't make it work as expected.",Solution Usage
14699,"To save/restore them, you can use tf.global_variables()",Solution Usage
14700,"I also observe that if I remove batch_norm, this problem goes away.",Solution Usage
14701,Had a similar problem and it went away when I used the fused version,Solution Usage
14702,For example this pattern works well: CODE,Solution Usage
14703,"(<tf.Tensor 'arg0:0' shape=(?, 43200) dtype=float32>, <tf.Tensor 'arg1:0' shape=(?, 36) dtype=float32>)",Solution Usage
14704,Use of batch_norm with tf.placeholder CODE,Solution Usage
14705,"However, the drawback of small decay is that its effective range is small: The result is dominated by a few recent samples thus it's not a good estimation of population mean/variance.",Solution Usage
14706,However I'm confused how one does that in this new paradigm.,Solution Usage
14707,I noticed after plotting accuracies in training and test mode that the testing accuracies start climbing after the training accuracies.,Solution Usage
14708,I based my suggestion on the one flat_map code example on the github page you linked.,Solution Usage
14709,As I have lots of them (nested in many layers) - what is the most efficient way of adding them to the list of values to be saved?,Solution Usage
14710,"@dominikandreas If your poor testing performance is caused by statistics not converging, you'd see reasonably good training performance but bad testing performance.",Solution Usage
14711,https://stackoverflow.com/questions/44132307/tf-contrib-data-dataset-repeat-with-shuffle-notice-epoch-end-mixed-epochs,Solution Usage
14712,Would you please update if you diagnose the cause of this behavior?,Solution Usage
14713,"Finally, I write a moving average by myself, and I find it worked!",Solution Usage
14714,It's as follows(based on code on the web and modified by myself) CODE,Solution Usage
14715,@diegoAtAlpine I found the same problems - not sure why this is the case though.,Solution Usage
14716,"Also, I noticed you said it was a placeholder and I didn't need to do it manually.",Solution Usage
14717,Yup that fixed it.,Solution Usage
14718,It tells to do the following: CODE,Solution Usage
14719,3.         useCODE if you don't want to add control dependencies of update op to train_op,Solution Usage
14720,The following should work: CODE,Solution Usage
14721,@ppwwyyxx do you have any example code for combining queues and the new dataset api?,Solution Usage
14722,"*         @guillaumekln ([link](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308789560)) If you want to batch sequences with different lengths, you can use the CODE transformation.",Solution Usage
14723,Is your problem similar ?,Solution Usage
14724,"If you know your batch size is for example 32, then something likeCODE",Solution Usage
14725,"I'm sure I note the following details, but still failed to use the official CODE, with CODE during evaluation(but when I keep CODE unchanged during evaluation, it is ok):",Solution Usage
14726,"Is there any code out there that uses this, even if that code is undocumented?",Solution Usage
14727,"I haven't figured out what I did wrong, I'm planning to use TensorBoard to monitor the parameters.",Solution Usage
14728,"If I understood correctly if the flag is CODE the network is not efficient, so I should let CODE and then I should collect all the batch_norm updates and run them together.",Solution Usage
14729,How does one do that?,Solution Usage
14730,I noticed after plotting accuracies in training and test mode that the testing accuracies start climbing after the training accuracies.,Solution Usage
14731,But that's certainly the gist of it.,Solution Usage
14732,"I also observe that if I remove batch_norm, this problem goes away.",Solution Usage
14733,"Hi @ishaybee,I followed your advice, now my code is:CODE",Solution Usage
14734,@diegoAtAlpine I found the same problems - not sure why this is the case though.,Solution Usage
14735,But still find the problem that how to dynamically feed data to the Dataset.,Solution Usage
14736,This doesn't work for me.,Solution Usage
14737,"In the latter case, the moving mean and variance look more reasonable (with different values), but if I use is_training=False in test time, the performance is also really bad.",Solution Usage
14738,I answered @albertz's Stack Overflow question about doing this [here] URL .,Solution Usage
14739,"Hi @zhongyuk , how did you keep track of the moving mean and variance?",Solution Usage
14740,I am using the same scope and CODE.,Solution Usage
14741,"We will provide methods for creating datasets from tensors, and deriving them from another dataset (e.g. by slicing its elements, repeating its elements, shuffling its elements, batching its elements, mapping a function over its elements, etc.).",Solution Usage
14742,"Without CODEset to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.",Solution Usage
14743,"After doing some runs on my network, I have to say that ~~I can not see any performance difference between using  _updates_collections=None_ in contrast to manually fetching _tf.GraphKeys.UPDATE_OPS_ while graph construction~~. Even with heavy use of batch normalization (in total, my _tf.get_collection(tf.GraphKeys.UPDATE_OPS)_ returns 140 Update-Ops, all of them are BN-ops only)",Solution Usage
14744,I would like to encourage you to use [CODE] URL  or [CODE] URL  to build your model.,Solution Usage
14745,"Edit: After writing this, i found it out: CODE",Solution Usage
14746,"hi,please see my wrapper above.you should use ""with tf.variable_scope(scope, reuse=reuse):"" I think.",Solution Usage
14747,Ex: CODE,Solution Usage
14748,"CODEthe above code prints nothing, just exits after attempting to run past the last batch.",Solution Usage
14749,Is this what you meant? CODE,Solution Usage
14750,3.         useCODE if you don't want to add control dependencies of update op to train_op,Solution Usage
14751,"Just wanted to note that I also have the problem of poor test performance, specifically using small batch sizes (anything smaller than 10 instead of the 200 I used for training diminishes test accuracy).",Solution Usage
14752,"To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size.",Solution Usage
14753,https://stackoverflow.com/questions/44132579/feed-data-into-a-tf-contrib-data-dataset-like-a-queue,Solution Usage
14754,"If I understood correctly if the flag is CODE the network is not efficient, so I should let CODE and then I should collect all the batch_norm updates and run them together.",Solution Usage
14755,try to feed reuse as a python variable (input of the model) and as placeholder.,Solution Usage
14756,I feel like the default code for looping over a dataset is a bit ugly with an exception breaking out of a CODE loop:CODE,Solution Usage
14757,"Since we can only change tensors or placeholders with CODE, I changed CODE intentionally before running the graph.",Solution Usage
14758,CODE,Solution Usage
14759,"The default decay is 0.999, for small datasets such like MNIST, you can choose 0.99 or 0.95, and it warms up in a short time.",Solution Usage
14760,CODE,Solution Usage
14761,"The trick is to build the model twice, but sharing the variables the second time.",Solution Usage
14762,"I also met the problem that I could get good results when using is_training=True for both training and inference, but get bad results when setting is_training=False during inference (worse than the case using is_training=True).",Solution Usage
14763,One thing I notice is that the arguments CODE and CODE from CODE are missing in CODE; does that mean no parallel processing is possible?,Solution Usage
14764,I'd like to see an example of it in use.,Solution Usage
14765,"I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe.",Solution Usage
14766,"If I understood correctly if the flag is CODE the network is not efficient, so I should let CODE and then I should collect all the batch_norm updates and run them together.",Solution Usage
14767,With tf.global_variables() the save files are much larger as I think it includes the gradients; in the end I used: saver = tf.train.Saver([x for x in tf.global_variables() if 'Adam' not in x.name]),Solution Usage
14768,"Since I haven't trained enough steps, the estimated moving mean/variance is not that stable.",Solution Usage
14769,"I believe that for the code to be used ""right out of the box"" the default should be None.",Solution Usage
14770,do I need to set the reuse flag?,Solution Usage
14771,CODE,Solution Usage
14772,@pawni You have to use a Python boolean for CODE.,Solution Usage
14773,"@brando90 @pawni he's code works good, but have to change like below CODE",Solution Usage
14774,@diegoAtAlpine I found the same problems - not sure why this is the case though.,Solution Usage
14775,However I'm confused how one does that in this new paradigm.,Solution Usage
14776,And I am running it in a multi-gpu fashion (for training).,Solution Usage
14777,"but I think that the placeholder value is not being used, because I see no change if I force values to CODE function, and in TensorBoard it's not connected to the graph...",Solution Usage
14778,"That way, we can deserialize a Doc with only the standard vocab.",Solution Usage
14779,Ex: CODE,Solution Usage
14780,I feel like the default code for looping over a dataset is a bit ugly with an exception breaking out of a CODE loop:CODE,Solution Usage
14781,"so if I do .fit([[5]]).transform([[4]]), for which values of n_values,categories and handle_umknown will that raise an error?",Solution Usage
14782,"Hi,I tried to implement a batch normalisation layer with the help of the suggestions in this issue, but I still have a >70% error in validation and testing...",Solution Usage
14783,CODE,Solution Usage
14784,"hi,you need to set different scope for every time you use batch norm and give it the reuse input according to the training/test phase(TRUE when test FALSE when train) that works for me.",Solution Usage
14785,"For example, the following codeCODEgets 3 CODE before getting a CODE.",Solution Usage
14786,"@nmhkahn Regarding your code snippet, may I ask why is CODE set to be CODE when CODE?",Solution Usage
14787,"If the user wants to keep the current behaviour, it can manually specify it as",Solution Usage
14788,P.S. The batch norm layer is used just after the last fully connected layer of the network and before softmax.,Solution Usage
14789,I want to perform batch nomalization.,Solution Usage
14790,"To do this the CODE argument might help, but I'm not sure because I use my own version of bn layer.",Solution Usage
14791,Validation loss goes down very quickly when I set CODE to 0.9.,Solution Usage
14792,I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.,Solution Usage
14793,@pawni @ppwwyyxx did you guys decide if you had to use reuse to true to solve the scoping issue?,Solution Usage
14794,@nmduc @davek44  I wrote some code to track the moving mean and moving variance computed in CODE during training and testing.,Solution Usage
14795,"I also observe that if I remove batch_norm, this problem goes away.",Solution Usage
14796,"Just wanted to note that I also have the problem of poor test performance, specifically using small batch sizes (anything smaller than 10 instead of the 200 I used for training diminishes test accuracy).",Solution Usage
14797,@MisayaZ you don't need to create two batch_norm layers you can just pass train_phase (assuming it is a tf.bool) to batch_norm.,Solution Usage
14798,How does one modify this to get the updated position of the iterator in each dataset?,Solution Usage
14799,I've found my problem= = **It's due to the cold start of moving_mean/moving_variance.**,Solution Usage
14800,"Hi @ishaybee,I followed your advice, now my code is:CODE",Solution Usage
14801,One thing I notice is that the arguments CODE and CODE from CODE are missing in CODE; does that mean no parallel processing is possible?,Solution Usage
14802,"Without CODEset to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.",Solution Usage
14803,"*         @guillaumekln ([link](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308789560)) If you want to batch sequences with different lengths, you can use the CODE transformation.",Solution Usage
14804,"The catch is, I couldn't find a way to iterate over the data more than once (which luckily enough is not my use-case), because the only iterator that won't raise an error when the CODEs spawn the threads is the CODE.",Solution Usage
14805,"You can also use tf.model_variables() which contains the variables of the model, i.e. moving_mean",Solution Usage
14806,"Unless you need to change the behavior of the model dynamically, you don't need to use a placeholder for is_training.",Solution Usage
14807,Do not use tf native CODE.,Solution Usage
14808,"The result turns out to be: the model performs pretty well on training mini-batches (you know at the beginning loss goes down quickly), but validation performance is erratic (because the estimated population mean/variance are not stable enough).",Solution Usage
14809,There are two similar questions in [here] URL  and [here] URL @albertz.,Solution Usage
14810,"@nmhkahn  quick question. When you wrote (for testing): CODE in theory, can bx and by be any data set?",Solution Usage
14811,"Oh I thought you were doing CODE, which is incorrect.",Solution Usage
14812,"There, single string tensors come in (file names) and whole Datasets are emitted in the map function, so that seems pretty clear.",Solution Usage
14813,I did it like this:,Solution Usage
14814,Training seems to work very well.,Solution Usage
14815,"where batch_norm_layer is similar to the examples from @nmhkahn @pawni, conv2d_stride2_valid is just a def to define a convolutional layer, and W_conv1 and b_conv1 are variables holding the weights and biases.",Solution Usage
14816,"As for my comment above [1122](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235433645), I figured out that   tf.get_variable_scope().reuse_variables() takes care of the issue, so  in the training phase the argument reuse of batch_norm should be None.",Solution Usage
14817,"I can confirm that test performance is good when using is_training=False with small batches and even with batch_size=1, since it is not using statistic from the batch, but the statistic learnt during training.",Solution Usage
14818,"conv1 = tf.nn.relu(batch_norm_layer(conv2d_stride2_valid(data, W_conv1) + b_conv1, train_phase, scope=""conv1""))",Solution Usage
14819,then its simple to tell tensorflow which one to use with a feed dictionary as in: CODE,Solution Usage
14820,But that's certainly the gist of it.,Solution Usage
14821,"Since we can only change tensors or placeholders with CODE, I changed CODE intentionally before running the graph.",Solution Usage
14822,It's as follows(based on code on the web and modified by myself) CODE,Solution Usage
14823,anyone has experienced these problems or is BN just like this and I need to do something else to make it work?,Solution Usage
14824,https://stackoverflow.com/questions/44132307/tf-contrib-data-dataset-repeat-with-shuffle-notice-epoch-end-mixed-epochs,Solution Usage
14825,(i.e. just to track the train error),Solution Usage
14826,"This is what I have now, and it handles what I wanted.",Solution Usage
14827,"However, what I **did** find was that, obviously, we should use Tensorflow ops instead of standard comparisons since the result of CODE is a tensor and not a normal array.",Solution Usage
14828,Validation loss goes down very quickly when I set CODE to 0.9.,Solution Usage
14829,"I haven't figured out what I did wrong, I'm planning to use TensorBoard to monitor the parameters.",Solution Usage
14830,"For instance I see no way to ""get an iterator"" in the middle of a dataset.",Solution Usage
14831,Not sure what you want to see how to call it as nmhkahn's examples seems to do the job?,Solution Usage
14832,"In some versions of the code training accuracies are much higher than testing accuracies, which probably mean I am not sharing batch normalization parameters.",Solution Usage
14833,"Hi @zhongyuk , how did you keep track of the moving mean and variance?",Solution Usage
14834,How to set the param of BatchNormLayer and ScaleLayer in Caffe?,Solution Usage
14835,@sguada I am not understanding the right way of using CODE specially concerning the flag CODE.,Solution Usage
14836,2.         using placeholder to switch between train and test evaluation,Solution Usage
14837,Have a look at [how this is used in the NMT model code](https://github.com/tensorflow/nmt/blob/04c8c04a8b4e805f3d0a9c42b4d17c85f1324c55/nmt/utils/iterator_utils.py#L194) for an example.,Solution Usage
14838,I feel like the default code for looping over a dataset is a bit ugly with an exception breaking out of a CODE loop:CODE,Solution Usage
14839,"Looks like the batch dimension is ""?"" (None?), so the predicate always fails...",Solution Usage
14840,"However, the following will print ""hit exception"" forever, unless CODE is used. CODE",Solution Usage
14841,"In contrast, if I maintain is_training_ph=True for test time, it works great.",Solution Usage
14842,The right way to do testing is to define different behaviors for train and test as you mentioned.,Solution Usage
14843,"@dominikandreas If your poor testing performance is caused by statistics not converging, you'd see reasonably good training performance but bad testing performance.",Solution Usage
14844,This doesn't work for me.,Solution Usage
14845,"@abred : Yes, I used CODE, same problem.",Solution Usage
14846,"Other than that, I also tried fetching statistics through CODE within scope during training and reference to monitor the bias.",Solution Usage
14847,One thing I notice is that the arguments CODE and CODE from CODE are missing in CODE; does that mean no parallel processing is possible?,Solution Usage
14848,"I have created a program following the CIFAR example, where my code is structured as in CIFAR:-         Inference-         Loss-         Train",Solution Usage
14849,My script is present here https://github.com/brando90/tensor_flow_experiments/blob/master/tf_tutorials/beginner_tutorial_MNIST_BN.py,Solution Usage
14850,CODE,Solution Usage
14851,CODE,Solution Usage
14852,"I'm not sure what are you trying to do, in most cases using static values solve the problem.",Solution Usage
14853,"I got the following error in the training phase:Variable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?",Solution Usage
14854,"As a follow up, I'm reusing 16 layers of batch_norm.",Solution Usage
14855,"However, the following will print ""hit exception"" forever, unless CODE is used. CODE",Solution Usage
14856,I am currently using a CODE because it does not take CODE by itself.,Solution Usage
14857,"@nirmalthacker Yep, that's essentially what I meant.",Solution Usage
14858,"(I'm doing data parallelization on multiple gpus, and the batch_size is multiple of num_gpus).",Solution Usage
14859,"In other words, if CODE is true, then we should a CODE function for training and another one for testing.",Solution Usage
14860,"The parameter ""allow_smaller_final_batch"" in tf.train.shuffle_batch(...) is useful when I'd like to assure all batches are evenly divisible by number of gpus.",Solution Usage
14861,I've found my problem= = **It's due to the cold start of moving_mean/moving_variance.**,Solution Usage
14862,"but I think that the placeholder value is not being used, because I see no change if I force values to CODE function, and in TensorBoard it's not connected to the graph...",Solution Usage
14863,"As for ""cold start"", as you see above in discussiion, decreasing BatchNorm running average decay (input param) from default 0.999 to something like 0.95 can speed-up start-up",Solution Usage
14864,"The trick is to build the model twice, but sharing the variables the second time.",Solution Usage
14865,How can I use spacy in Spark?,Solution Usage
14866,In response to a few recent questions:,Solution Usage
14867,"I still have to run this on a big dataset and check if there's any performance improvement, but at least it seems to execute correctly.",Solution Usage
14868,You collect the batch_norms updates by doing: CODE.,Solution Usage
14869,I'm using:CODE,Solution Usage
14870,Take a look at the documentation here [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data#creating-an-iterator).,Solution Usage
14871,"As for ""cold start"", as you see above in discussiion, decreasing BatchNorm running average decay (input param) from default 0.999 to something like 0.95 can speed-up start-up",Solution Usage
14872,Obviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers.,Solution Usage
14873,With tf.global_variables() the save files are much larger as I think it includes the gradients; in the end I used: saver = tf.train.Saver([x for x in tf.global_variables() if 'Adam' not in x.name]),Solution Usage
14874,"Hi, Using the above CODE layer in CODE, I'm getting CODE as an output for validation graph while the train graph runs seamlessly.",Solution Usage
14875,The net is working well now.,Solution Usage
14876,@sguada I changed my old one where I manually tell it to train or not (based on a tf.cond) and now it seems the accuracy is up to ~95's again.,Solution Usage
14877,"I would greatly appreciate it if there's an official and complete (which means training, validating, testing are all included) batch normalization example.",Solution Usage
14878,CODE,Solution Usage
14879,I did it like this:,Solution Usage
14880,And I am running it in a multi-gpu fashion (for training).,Solution Usage
14881,"Still, the function description in the documentation seems a bit sparse, consisting of CODE.",Solution Usage
14882,is that not correct?,Solution Usage
14883,Use of batch_norm with tf.placeholder CODE,Solution Usage
14884,"I have created a program following the CIFAR example, where my code is structured as in CIFAR:-         Inference-         Loss-         Train",Solution Usage
14885,Or you may try to run UPDATE_OPS yourself explicitly as one [here](https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-279646674)CODE,Solution Usage
14886,"Oh I thought you were doing CODE, which is incorrect.",Solution Usage
14887,And I am running it in a multi-gpu fashion (for training).,Solution Usage
14888,still don't get good validation and testing results... >70%...,Solution Usage
14889,"The test run results with CODE (CODE is the default setting in CODE)<img width=""784"" alt=""screen shot 2016-11-16 at 2 03 58 pm"" src=""https://cloud.githubusercontent.com/assets/6901075/20361605/31729f5e-ac06-11e6-9736-eb9ad2f15de1.png"">",Solution Usage
14890,So What I am doing is: setting CODE to False while training while CODE to True.,Solution Usage
14891,And I am running it in a multi-gpu fashion (for training).,Solution Usage
14892,"(I'm doing data parallelization on multiple gpus, and the batch_size is multiple of num_gpus).",Solution Usage
14893,(i.e. just to track the train error),Solution Usage
14894,"The default decay is 0.999, for small datasets such like MNIST, you can choose 0.99 or 0.95, and it warms up in a short time.",Solution Usage
14895,However I'm confused how one does that in this new paradigm.,Solution Usage
14896,"so if I do .fit([[5]]).transform([[4]]), for which values of n_values,categories and handle_umknown will that raise an error?",Solution Usage
14897,anyone has experienced these problems or is BN just like this and I need to do something else to make it work?,Solution Usage
14898,"In other words, if CODE is true, then we should a CODE function for training and another one for testing.",Solution Usage
14899,CODE,Solution Usage
14900,"Hi @zhongyuk , how did you keep track of the moving mean and variance?",Solution Usage
14901,"@soloice , notice, how in about [comment](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235928564) the following parameter is passed inside to the layer for calling batch_norm: >  batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}",Solution Usage
14902,i.e. it can still be the **training** set even though we are not training?,Solution Usage
14903,"Howerver, the comment in the code isIf CODE doesn't have a constant value, because it is a CODE,# a CODE or CODE then is_training_value will be None and# CODE will be true.",Solution Usage
14904,CODE,Solution Usage
14905,To make those unique I had to set a scope per layer.,Solution Usage
14906,"@pawni If you don't want to worry about about updating moving_mean and moving_variance set updates_collections=None to make sure they are updated in place, otherwise you need to make sure the update_ops added to tf.GraphKeys.UPDATE_OPS are run during training.",Solution Usage
14907,"For instance I see no way to ""get an iterator"" in the middle of a dataset.",Solution Usage
14908,"I also observe that if I remove batch_norm, this problem goes away.",Solution Usage
14909,"There, single string tensors come in (file names) and whole Datasets are emitted in the map function, so that seems pretty clear.",Solution Usage
14910,"To do that, shouldn't they be only initialized once and then reused in all training steps?",Solution Usage
14911,"If I understood correctly if the flag is CODE the network is not efficient, so I should let CODE and then I should collect all the batch_norm updates and run them together.",Solution Usage
14912,"You can also use tf.model_variables() which contains the variables of the model, i.e. moving_mean",Solution Usage
14913,Is it possible to address a single column in the dataset so that it is treated different from the other column?,Solution Usage
14914,I've used a tf.placeholder to switch between testing/training mode.,Solution Usage
14915,"Then you are free to switch the placeholder to True during train and False during evaluation, with CODE.",Solution Usage
14916,"Say, in my [mnist_bn] URL  code, I controlled dependencies using CODE and set up CODE as a placeholder.",Solution Usage
14917,@nmhkahn how is it different from pawni's suggestion?,Solution Usage
14918,I want to perform batch nomalization.,Solution Usage
14919,CODE,Solution Usage
14920,"If the user wants to keep the current behaviour, it can manually specify it as",Solution Usage
14921,"I'm using slim.batch_norm, but get good training performance and poor validation/test performance.",Solution Usage
14922,"However, CODE evaluates the dynamic, real-time shape of a tensor, so I thought this should work.",Solution Usage
14923,"Hi @zhongyuk , how did you keep track of the moving mean and variance?",Solution Usage
14924,CODE,Solution Usage
14925,"I'd be seeing bad performance during training *and* testing if it hadn't converged, right?",Solution Usage
14926,How does one modify this to get the updated position of the iterator in each dataset?,Solution Usage
14927,"The model trains fine, but the test performance is terrible.",Solution Usage
14928,"To do that, shouldn't they be only initialized once and then reused in all training steps?",Solution Usage
14929,"If the user wants to keep the current behaviour, it can manually specify it as",Solution Usage
14930,"However, what I **did** find was that, obviously, we should use Tensorflow ops instead of standard comparisons since the result of CODE is a tensor and not a normal array.",Solution Usage
14931,I now also use 'is_training' as a constant.,Solution Usage
14932,If you're using a MonitoredSession and its variants you should still be able to do this: CODE,Solution Usage
14933,Hard to scope both functionality and feature set...,Solution Usage
14934,From what I 've been reading in this thread in the training phase I should be using reuse=None.,Solution Usage
14935,But validation performance still is poor if I feed {is_training: False}.,Solution Usage
14936,"I would have preferred to leave it as a placeholder because this way I can do periodic testing during training without redefining the graph, but I decided to use it as a constant and define different behaviors for train vs test, and now the moments are not calculated at test time.",Solution Usage
14937,"hi,you need to set different scope for every time you use batch norm and give it the reuse input according to the training/test phase(TRUE when test FALSE when train) that works for me.",Solution Usage
14938,"I have many different models that use different batch_norm layers, this wouldn't work right?: CODE",Solution Usage
14939,Currently the tutorial says that we can useCODEto get shuffled data.,Solution Usage
14940,"Every few steps in an epoch, I'd like to run a validation op, but the output of this code shows that the iterator never advances ahead of item 0 in either dataset.",Solution Usage
14941,is that not correct?,Solution Usage
14942,"hi,you need to set different scope for every time you use batch norm and give it the reuse input according to the training/test phase(TRUE when test FALSE when train) that works for me.",Solution Usage
14943,I see the same poor test performance with that code.,Solution Usage
14944,"Finally, I write a moving average by myself, and I find it worked!",Solution Usage
14945,@sguada I am not understanding the right way of using CODE specially concerning the flag CODE.,Solution Usage
14946,Here is my code:CODE,Solution Usage
14947,However calling CODE before CODE could lead to the shuffle across multiple epochs.,Solution Usage
14948,"@EdeMeijer That could be -- it's really hard to tell, as the documentation is quite sparse, with no examples.",Solution Usage
14949,"If your feeling is that spacy is really meant for batch processing and that I should use mini-batches if I want to approximate streaming, I can do that.",Solution Usage
14950,(There seem to be two places containing some amount of separate documentation: either on [GitHub] URL  or on [tensorflow.org](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/data/Dataset#flat_map)),Solution Usage
14951,"To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size.",Solution Usage
14952,It would be great if the layer could be added to the documentation with a short explanation how to best handle the change from training to test.,Solution Usage
14953,"Per value this isn't that much of a difference, but has a big impact when computing vector distances in latent spaces.",Solution Usage
14954,CODE,Solution Usage
14955,Why was it that I needed to change updates_collections to be None?,Solution Usage
14956,Just put it in seperate collection-keys: CODE CODE,Solution Usage
14957,"I can confirm that test performance is good when using is_training=False with small batches and even with batch_size=1, since it is not using statistic from the batch, but the statistic learnt during training.",Solution Usage
14958,"I've just been noticing that if I kill the tensorflow process and restart it, my error gets worse for a few epochs (i.e. worse than it should be at the last checkpoint).",Solution Usage
14959,"@zhongyuk thanks, I've run about 5k updates with CODE, so it should've converged and testing performance using large batch sizes is fine.",Solution Usage
14960,Or since I am doing tf.get_variable_scope().reuse_variables() it takes care of itself?,Solution Usage
14961,@brando90 currently I am doing something like: CODE,Solution Usage
14962,"However, the following will print ""hit exception"" forever, unless CODE is used. CODE",Solution Usage
14963,One needs to balance between quick start (small decay) and a longer effective range (large decay).,Solution Usage
14964,Looking forward to hear whether we've just not been using the datasets API right.,Solution Usage
14965,"@nmhkahn  quick question. When you wrote (for testing): CODE in theory, can bx and by be any data set?",Solution Usage
14966,The output of the tensor : CODE present in CODE isCODE,Solution Usage
14967,"@sguada Thanks, I build a network with bathnorm which is implemented as you mentioned above",Solution Usage
14968,"Just wanted to note that I also have the problem of poor test performance, specifically using small batch sizes (anything smaller than 10 instead of the 200 I used for training diminishes test accuracy).",Solution Usage
14969,"-         ~~I don't know how to access _control_flow_ops.with_dependencies()_. How can I access functions within control_flow_ops module? I have seen other examples just using tf.with_dependecies(), but I cannot do that with Tensorflow 0.10.~~ I found it here: _tf.python.control_flow_ops.with_dependencies()_",Solution Usage
14970,How can I use spacy in Spark?,Solution Usage
14971,decay value is 0.9,Solution Usage
14972,"When saving and restoring using:saver = tf.train.Saver()it works, but when saving using:saver = tf.train.Saver(tf.trainable_variables() + [global_step])so that I can save storage space (by not saving the gradients etc)on restore there is an error:""uninitialized value unpool4/convc/bn/moving_mean""",Solution Usage
14973,Is it normal that Batch Normalization makes my experiments **worse**?,Solution Usage
14974,"However, CODE evaluates the dynamic, real-time shape of a tensor, so I thought this should work.",Solution Usage
14975,I feel like the default code for looping over a dataset is a bit ugly with an exception breaking out of a CODE loop:CODE,Solution Usage
14976,"I have created a program following the CIFAR example, where my code is structured as in CIFAR:-         Inference-         Loss-         Train",Solution Usage
14977,How to set the param of BatchNormLayer and ScaleLayer in Caffe?,Solution Usage
14978,is that not correct?,Solution Usage
14979,"The catch is, I couldn't find a way to iterate over the data more than once (which luckily enough is not my use-case), because the only iterator that won't raise an error when the CODEs spawn the threads is the CODE.",Solution Usage
14980,"*         @guillaumekln ([link](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308789560)) If you want to batch sequences with different lengths, you can use the CODE transformation.",Solution Usage
14981,"-         ~~I don't know how to access _control_flow_ops.with_dependencies()_. How can I access functions within control_flow_ops module? I have seen other examples just using tf.with_dependecies(), but I cannot do that with Tensorflow 0.10.~~ I found it here: _tf.python.control_flow_ops.with_dependencies()_",Solution Usage
14982,is that not correct?,Solution Usage
14983,"In the latter case, the moving mean and variance look more reasonable (with different values), but if I use is_training=False in test time, the performance is also really bad.",Solution Usage
14984,Training seems to work very well.,Solution Usage
14985,It would be great if the layer could be added to the documentation with a short explanation how to best handle the change from training to test.,Solution Usage
14986,I want to perform batch nomalization.,Solution Usage
14987,"I've just been noticing that if I kill the tensorflow process and restart it, my error gets worse for a few epochs (i.e. worse than it should be at the last checkpoint).",Solution Usage
14988,"@sguada Thanks, I build a network with bathnorm which is implemented as you mentioned above",Solution Usage
14989,"However, what I **did** find was that, obviously, we should use Tensorflow ops instead of standard comparisons since the result of CODE is a tensor and not a normal array.",Solution Usage
14990,After taking a closer look at the code in contrib I realized what my problem was.,Solution Usage
14991,"The trick is to build the model twice, but sharing the variables the second time.",Solution Usage
14992,I now also use 'is_training' as a constant.,Solution Usage
14993,The net is working well now.,Solution Usage
14994,What is the correct way to change this flag?,Solution Usage
14995,In response to a few recent questions:,Solution Usage
14996,CODE,Solution Usage
14997,"@winston-li seeing ""?"" as shape is because at that point you're looking at the 'static' shape of the tensor, which isn't always defined (the graph doesn't know in advance how many examples there will be).",Solution Usage
14998,I am using the same scope and CODE.,Solution Usage
14999,"conv1 = tf.nn.relu(batch_norm_layer(conv2d_stride2_valid(data, W_conv1) + b_conv1, train_phase, scope=""conv1""))",Solution Usage
15000,still don't get good validation and testing results... >70%...,Solution Usage
15001,use staging area you can even hide all preprocessing and input time.,Solution Usage
15002,"@abred : Yes, I used CODE, same problem.",Solution Usage
15003,But it appeared as if I was doing something wrong during my initial tests.,Solution Usage
15004,"sorry for the spamming, but what is wrong with just using something like this: CODE",Solution Usage
15005,"I would have preferred to leave it as a placeholder because this way I can do periodic testing during training without redefining the graph, but I decided to use it as a constant and define different behaviors for train vs test, and now the moments are not calculated at test time.",Solution Usage
15006,@MisayaZ you don't need to create two batch_norm layers you can just pass train_phase (assuming it is a tf.bool) to batch_norm.,Solution Usage
15007,I'm using python3 and didn't tried with python2.,Solution Usage
15008,"Update: use a small decay (say, 0.9 or 0.95) does help a lot.",Solution Usage
15009,"When saving and restoring using:saver = tf.train.Saver()it works, but when saving using:saver = tf.train.Saver(tf.trainable_variables() + [global_step])so that I can save storage space (by not saving the gradients etc)on restore there is an error:""uninitialized value unpool4/convc/bn/moving_mean""",Solution Usage
15010,So CODE,Solution Usage
15011,CODE,Solution Usage
15012,"If I understood correctly if the flag is CODE the network is not efficient, so I should let CODE and then I should collect all the batch_norm updates and run them together.",Solution Usage
15013,"Or resuming training from the checkpoint (i.e., trained when decay=0.999) is also ok?",Solution Usage
15014,"CODEthe above code prints nothing, just exits after attempting to run past the last batch.",Solution Usage
15015,I'm trying migrating input pipeline from tf.train.string_input_producer & tf.train.shuffle_batch to Dataset APIs.,Solution Usage
15016,"I still have to run this on a big dataset and check if there's any performance improvement, but at least it seems to execute correctly.",Solution Usage
15017,"Unless you need to change the behavior of the model dynamically, you don't need to use a placeholder for is_training.",Solution Usage
15018,Hard to scope both functionality and feature set...,Solution Usage
15019,"I tried it on a 2 layered NN network based on the MNIST beginner tutorial and I consistently get worse results when BN is present: with BN (one with scale and center trained and the other not) accuracy is 0.8423, 0.8221 and without BN accuracy is 0.9477.",Solution Usage
15020,So I have one script for training (similar to cifar10_multigpu.py) and one for testing (similar to cifar10_eval.py).,Solution Usage
15021,"That said, looking at SwitchableDataSet, it seems like implementing new kinds of data feeding use cases will be mostly done by implementing use-case specific classes.",Solution Usage
15022,"For example, the following codeCODEgets 3 CODE before getting a CODE.",Solution Usage
15023,"However, the ValueError should be resolved by the code snippet.",Solution Usage
15024,"Other than that, I also tried fetching statistics through CODE within scope during training and reference to monitor the bias.",Solution Usage
15025,"Just use the CODE function during building a graph, the is_training parameter is a CODE.",Solution Usage
15026,"Without CODEset to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.",Solution Usage
15027,"I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe.",Solution Usage
15028,Are there any concerns about calling CODE before CODE?,Solution Usage
15029,Hard to scope both functionality and feature set...,Solution Usage
15030,Or since I am doing tf.get_variable_scope().reuse_variables() it takes care of itself?,Solution Usage
15031,There are two similar questions in [here] URL  and [here] URL @albertz.,Solution Usage
15032,So What I am doing is: setting CODE to False while training while CODE to True.,Solution Usage
15033,This doesn't work for me.,Solution Usage
15034,"In some versions of the code training accuracies are much higher than testing accuracies, which probably mean I am not sharing batch normalization parameters.",Solution Usage
15035,After taking a closer look at the code in contrib I realized what my problem was.,Solution Usage
15036,I do have a lower decay for non-training calls...,Solution Usage
15037,Can anyone confirm good test performance with small or single data samples using this batch norm layer?,Solution Usage
15038,"In the former case, when investigating the trained model, I found out that the moving mean and moving variance consist of all zeros.",Solution Usage
15039,"sorry for the spamming, but what is wrong with just using something like this: CODE",Solution Usage
15040,"@nirmalthacker Every time you run an iterator init op, it restarts the iterator.",Solution Usage
15041,My script is present here https://github.com/brando90/tensor_flow_experiments/blob/master/tf_tutorials/beginner_tutorial_MNIST_BN.py,Solution Usage
15042,Please help me how to continue training the model.,Solution Usage
15043,"However, I found that reusing 4 layers works.",Solution Usage
15044,As an example here is a piece of code that demonstrates what I'd like to do.,Solution Usage
15045,(i.e. just to track the train error),Solution Usage
15046,Is your problem similar ?,Solution Usage
15047,"The moving mean and moving variance are changed when I used batchnorm like this: def batch_norm_layer(self, x,train_phase, scope_bn):bn_train = batch_norm(x, decay=0.9, center=False, scale=True,updates_collections=None,is_training=True,reuse=None,variables_collections= [UPDATE_OPS_COLLECTION],trainable=True,scope=scope_bn)bn_inference = batch_norm(x, decay=0.9, center=False, scale=True,updates_collections=None,is_training=False,reuse=True,variables_collections= [UPDATE_OPS_COLLECTION],trainable=True,scope=scope_bn)z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)return z",Solution Usage
15048,CODE,Solution Usage
15049,"The problem before was that you were not updating the CODE and CODE after each step, when updates_collections is None it forces the updates as part of the computation.",Solution Usage
15050,After taking a closer look at the code in contrib I realized what my problem was.,Solution Usage
15051,"In the former case, when investigating the trained model, I found out that the moving mean and moving variance consist of all zeros.",Solution Usage
15052,"But even if it didn't, would it result in a difference between training a testing?",Solution Usage
15053,My code is like this now:**Batch Normalisation wrapper**CODE**Model definition**CODE**Training**CODE**Validation**CODE,Solution Usage
15054,Can anyone confirm good test performance with small or single data samples using this batch norm layer?,Solution Usage
15055,Hard to scope both functionality and feature set...,Solution Usage
15056,Just put it in seperate collection-keys: CODE CODE,Solution Usage
15057,use staging area you can even hide all preprocessing and input time.,Solution Usage
15058,As an example here is a piece of code that demonstrates what I'd like to do.,Solution Usage
15059,"Since we can only change tensors or placeholders with CODE, I changed CODE intentionally before running the graph.",Solution Usage
15060,I feel like the default code for looping over a dataset is a bit ugly with an exception breaking out of a CODE loop:CODE,Solution Usage
15061,Maybe here is a good place to refer to my Dataset related questions:,Solution Usage
15062,As an example here is a piece of code that demonstrates what I'd like to do.,Solution Usage
15063,@diegoAtAlpine I found the same problems - not sure why this is the case though.,Solution Usage
15064,So I have one script for training (similar to cifar10_multigpu.py) and one for testing (similar to cifar10_eval.py).,Solution Usage
15065,The following should work: CODE,Solution Usage
15066,"Sorry for the spam, but the documentation doesn't really explain how to use this BN with convolution (maybe should be provided somewhere?).",Solution Usage
15067,"To do this the CODE argument might help, but I'm not sure because I use my own version of bn layer.",Solution Usage
15068,"Also you are passing UPDATE_OPS_COLLECTION variables_collections, which changes which collections are the variables added to.",Solution Usage
15069,"Or resuming training from the checkpoint (i.e., trained when decay=0.999) is also ok?",Solution Usage
15070,"There will be explicit operations for initializing an iterator, so that it can be reused after you have processed all of the elements in a dataset.",Solution Usage
15071,"However, when I passed a placeholder for is_training it said CODEtf.TensorCODEboolCODEif t is not None:CODEif t:CODE and pointed to batch_norm code.",Solution Usage
15072,Just need to make sure that the statistics have converged with default decay=0.999 that implies at least 50k updates.,Solution Usage
15073,One thing I notice is that the arguments CODE and CODE from CODE are missing in CODE; does that mean no parallel processing is possible?,Solution Usage
15074,"CODEthe above code prints nothing, just exits after attempting to run past the last batch.",Solution Usage
15075,But validation performance still is poor if I feed {is_training: False}.,Solution Usage
15076,"Can someone provide an example of how to call the ""def BatchNorm"" function during training and testing so that variable sharing happen correctly.",Solution Usage
15077,"However when a network has many batch_norm layers it is more efficient to collect all the update ops and run them together, so each layer don't need to wait for the update to finish.",Solution Usage
15078,Ex: CODE,Solution Usage
15079,Then I set is_training_ph to True for training and False for testing.,Solution Usage
15080,"BTW, do I need to retrain the model using decay=0.9 from scratch?",Solution Usage
15081,"and I feed CODE and CODE through the feed_dict, but now I get the error CODE",Solution Usage
15082,So CODE,Solution Usage
15083,or I did something wrong?,Solution Usage
15084,Have a look at [how this is used in the NMT model code](https://github.com/tensorflow/nmt/blob/04c8c04a8b4e805f3d0a9c42b4d17c85f1324c55/nmt/utils/iterator_utils.py#L194) for an example.,Solution Usage
15085,"There, single string tensors come in (file names) and whole Datasets are emitted in the map function, so that seems pretty clear.",Solution Usage
15086,Currently the tutorial says that we can useCODEto get shuffled data.,Solution Usage
15087,When the updates_collections=None then the updates happens in-place and it is easier to use a tf.cond() to allow is_training being a Tensor a bit more complicated is when the updates are delayed and the the update_ops are run later.,Solution Usage
15088,I want to perform batch nomalization.,Solution Usage
15089,"Without CODEset to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.",Solution Usage
15090,"However, when I passed a placeholder for is_training it said CODEtf.TensorCODEboolCODEif t is not None:CODEif t:CODE and pointed to batch_norm code.",Solution Usage
15091,"My tf version's filter is broken, but if yours works could you try this instead? CODE",Solution Usage
15092,"I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe.",Solution Usage
15093,"seem fishy, but it couldn't be my learning set up, rate etc. (but I'd assume it shouldn't because BN should be sort of rubust to this)",Solution Usage
15094,"I guess using tf.cond is wrong, otherwise would did the function came with a boolean parameters.",Solution Usage
15095,"I see the reinitializable iterators give us the ability to use the same iterator with multiple datasets but each time you run an init op, it essentially starts over on that dataset.",Solution Usage
15096,Not sure what you want to see how to call it as nmhkahn's examples seems to do the job?,Solution Usage
15097,"@MisayaZ I was having the same behavior using Batchnorm with a placeholder for ""is_training"".",Solution Usage
15098,"The catch is, I couldn't find a way to iterate over the data more than once (which luckily enough is not my use-case), because the only iterator that won't raise an error when the CODEs spawn the threads is the CODE.",Solution Usage
15099,"Howerver, the comment in the code isIf CODE doesn't have a constant value, because it is a CODE,# a CODE or CODE then is_training_value will be None and# CODE will be true.",Solution Usage
15100,"@soloice , notice, how in about [comment](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235928564) the following parameter is passed inside to the layer for calling batch_norm: >  batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}",Solution Usage
15101,"To save/restore them, you can use tf.global_variables()",Solution Usage
15102,I'd like to see an example of it in use.,Solution Usage
15103,So when I did: CODE,Solution Usage
15104,"To do this the CODE argument might help, but I'm not sure because I use my own version of bn layer.",Solution Usage
15105,is that not the official way to use BN?,Solution Usage
15106,CODE,Solution Usage
15107,"The problem before was that you were not updating the CODE and CODE after each step, when updates_collections is None it forces the updates as part of the computation.",Solution Usage
15108,"It seems the only way to use the official batch_norm is to build two graphs, one for train and one for evaluation, with CODE and CODE, respectively.",Solution Usage
15109,I am using the same scope and CODE.,Solution Usage
15110,One thing I notice is that the arguments CODE and CODE from CODE are missing in CODE; does that mean no parallel processing is possible?,Solution Usage
15111,What is the correct way to change this flag?,Solution Usage
15112,"I build batchnorm like this, however, the moving mean and moving variable are updated during test, I can not find the reason.",Solution Usage
15113,Testing is not.,Solution Usage
15114,It seems to work sometimes but I am not too sure.,Solution Usage
15115,"sorry for the spamming, but what is wrong with just using something like this: CODE",Solution Usage
15116,4.         set CODE to appropriate value.,Solution Usage
15117,"When you use slim.batch_norm,be sure to use ""slim.learning.create_train_op"" instead of ""tf.train.GradientDecentOptimizer(lr).minimize(loss)"" or other optimizer.",Solution Usage
15118,I am currently using a CODE because it does not take CODE by itself.,Solution Usage
15119,"And when run in training or test time, CODE",Solution Usage
15120,"so if I do .fit([[5]]).transform([[4]]), for which values of n_values,categories and handle_umknown will that raise an error?",Solution Usage
15121,Looking forward to hear whether we've just not been using the datasets API right.,Solution Usage
15122,because I'm noticing very slight changes with big impact on my accuracy (maybe my definition of performance is just more easily affected by this slight change).,Solution Usage
15123,Just need to make sure that the statistics have converged with default decay=0.999 that implies at least 50k updates.,Solution Usage
15124,It would be great if the layer could be added to the documentation with a short explanation how to best handle the change from training to test.,Solution Usage
15125,"Still, the function description in the documentation seems a bit sparse, consisting of CODE.",Solution Usage
15126,So CODE,Solution Usage
15127,Then I set is_training_ph to True for training and False for testing.,Solution Usage
15128,"I tried it on a 2 layered NN network based on the MNIST beginner tutorial and I consistently get worse results when BN is present: with BN (one with scale and center trained and the other not) accuracy is 0.8423, 0.8221 and without BN accuracy is 0.9477.",Solution Usage
15129,I'm trying migrating input pipeline from tf.train.string_input_producer & tf.train.shuffle_batch to Dataset APIs.,Solution Usage
15130,"I can confirm that test performance is good when using is_training=False with small batches and even with batch_size=1, since it is not using statistic from the batch, but the statistic learnt during training.",Solution Usage
15131,CODE,Solution Usage
15132,"If your feeling is that spacy is really meant for batch processing and that I should use mini-batches if I want to approximate streaming, I can do that.",Solution Usage
15133,@ppwwyyxx do you have any example code for combining queues and the new dataset api?,Solution Usage
15134,2.         Use a smaller decay value will accelerate the warm-up phase.,Solution Usage
15135,"But even if it didn't, would it result in a difference between training a testing?",Solution Usage
15136,I'm trying migrating input pipeline from tf.train.string_input_producer & tf.train.shuffle_batch to Dataset APIs.,Solution Usage
15137,"@ppwwyyxx stated that queues and StagingArea can still be used with the Dataset API, but I still haven't seen a working example of this.",Solution Usage
15138,I now also use 'is_training' as a constant.,Solution Usage
15139,@Alexivia It seems that you are using two different batch normalization layers?,Solution Usage
15140,"When saving and restoring using:saver = tf.train.Saver()it works, but when saving using:saver = tf.train.Saver(tf.trainable_variables() + [global_step])so that I can save storage space (by not saving the gradients etc)on restore there is an error:""uninitialized value unpool4/convc/bn/moving_mean""",Solution Usage
15141,"The result turns out to be: the model performs pretty well on training mini-batches (you know at the beginning loss goes down quickly), but validation performance is erratic (because the estimated population mean/variance are not stable enough).",Solution Usage
15142,"Just use the CODE function during building a graph, the is_training parameter is a CODE.",Solution Usage
15143,And I am running it in a multi-gpu fashion (for training).,Solution Usage
15144,"I use the function like this:conv_normed1 = tf.contrib.layers.batch_norm(conv1 + block1_layer3_1_biases, updates_collections=None, scale=True, decay=batch_norm_decay, center=True, is_training=is_training )",Solution Usage
15145,"@pawni If you don't want to worry about about updating moving_mean and moving_variance set updates_collections=None to make sure they are updated in place, otherwise you need to make sure the update_ops added to tf.GraphKeys.UPDATE_OPS are run during training.",Solution Usage
15146,"If you know your batch size is for example 32, then something likeCODE",Solution Usage
15147,"Thus, I'm guessing I still have a scope issue so that it's not finding the proper existing variables.",Solution Usage
15148,"I see the reinitializable iterators give us the ability to use the same iterator with multiple datasets but each time you run an init op, it essentially starts over on that dataset.",Solution Usage
15149,So What I am doing is: setting CODE to False while training while CODE to True.,Solution Usage
15150,"@vvekic, I experimented a bit with queues and the Dataset API after realising in horror that of the 0.8s/step in my inference loop, 0.2s is data fetching (with GPU at 0% utilization), raising to almost 2 seconds if the HDD is being used by something else at the same time.",Solution Usage
15151,But seems that this call is passing only 1 argument to the function:,Solution Usage
15152,"I got the following error in the training phase:Variable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?",Solution Usage
15153,"Oh I thought you were doing CODE, which is incorrect.",Solution Usage
15154,"and I feed CODE and CODE through the feed_dict, but now I get the error CODE",Solution Usage
15155,"If you know your batch size is for example 32, then something likeCODE",Solution Usage
15156,"seem fishy, but it couldn't be my learning set up, rate etc. (but I'd assume it shouldn't because BN should be sort of rubust to this)",Solution Usage
15157,"Then you are free to switch the placeholder to True during train and False during evaluation, with CODE.",Solution Usage
15158,"I guess using tf.cond is wrong, otherwise would did the function came with a boolean parameters.",Solution Usage
15159,Why was it that I needed to change updates_collections to be None?,Solution Usage
15160,I've used a tf.placeholder to switch between testing/training mode.,Solution Usage
15161,Have I got this part correct?,Solution Usage
15162,Do we have one?,Solution Usage
15163,"I'd be seeing bad performance during training *and* testing if it hadn't converged, right?",Solution Usage
15164,Anyone know why might this be?,Solution Usage
15165,"I guess using tf.cond is wrong, otherwise would did the function came with a boolean parameters.",Solution Usage
15166,"I guess using tf.cond is wrong, otherwise would did the function came with a boolean parameters.",Solution Usage
15167,I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.,Solution Usage
15168,"I did 2 test runs with the exact same code but different CODE settings in the CODE, and my validation/test accuracies seemed more reasonable.",Solution Usage
15169,I am currently using a CODE because it does not take CODE by itself.,Solution Usage
15170,Or you may try to run UPDATE_OPS yourself explicitly as one [here](https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-279646674)CODE,Solution Usage
15171,It works for me now.,Solution Usage
15172,Anyone know why might this be?,Solution Usage
15173,I've used a tf.placeholder to switch between testing/training mode.,Solution Usage
15174,Then I set is_training_ph to True for training and False for testing.,Solution Usage
15175,I am using the same scope and CODE.,Solution Usage
15176,2.         using placeholder to switch between train and test evaluation,Solution Usage
15177,"For example, the following codeCODEgets 3 CODE before getting a CODE.",Solution Usage
15178,To make those unique I had to set a scope per layer.,Solution Usage
15179,"When you use slim.batch_norm,be sure to use ""slim.learning.create_train_op"" instead of ""tf.train.GradientDecentOptimizer(lr).minimize(loss)"" or other optimizer.",Solution Usage
15180,"@sguada Sorry for trouble you, but is it possible to make an example on how to use slim.batch_norm when combined with slim.conv2d/slim.fully_connect in readme.md?",Solution Usage
15181,"I feel like maybe there should be a concrete example of how to do a batch norm with a fully connected net, as well as with CNNs.",Solution Usage
15182,Take a look at the documentation here [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data#creating-an-iterator).,Solution Usage
15183,Could you explain this part with a bit more details?,Solution Usage
15184,It's as follows(based on code on the web and modified by myself) CODE,Solution Usage
15185,Use of batch_norm with tf.placeholder CODE,Solution Usage
15186,"However, when I passed a placeholder for is_training it said CODEtf.TensorCODEboolCODEif t is not None:CODEif t:CODE and pointed to batch_norm code.",Solution Usage
15187,@bhack I haven't been able to make it work with more than one parameter in return from the function given to py_func.,Solution Usage
15188,"@davek44 I'm using the same code framework that you are using and I observed the same thing: when turns on CODE during training phase and turns off CODE for validation and/or testing phase, the model trains well like the paper described (model converges faster and I was able to use a larger learning rate), however the testing performance is terrible.",Solution Usage
15189,"I see the reinitializable iterators give us the ability to use the same iterator with multiple datasets but each time you run an init op, it essentially starts over on that dataset.",Solution Usage
15190,In response to a few recent questions:,Solution Usage
15191,After taking a closer look at the code in contrib I realized what my problem was.,Solution Usage
15192,"Without more details is impossible to know, my guesses are that you only train for a few iterations, so the moving_mean and moving_average haven't converge yet.",Solution Usage
15193,Ex: CODE,Solution Usage
15194,@Alexivia It seems that you are using two different batch normalization layers?,Solution Usage
15195,"It seems the only way to use the official batch_norm is to build two graphs, one for train and one for evaluation, with CODE and CODE, respectively.",Solution Usage
15196,"Being a newer tf user, I found that my test error was crazy and then had to spend a fair amount of time debugging my graph until I realized that batch normalization was the problem.",Solution Usage
15197,"So, developers allow us to change these boolean variables in order to change the behavior of the function.",Solution Usage
15198,How does one do that?,Solution Usage
15199,My pipeline looks as follows: CODE,Solution Usage
15200,"I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe.",Solution Usage
15201,"@mirosval, it seems to me that this might be what CODE is intended for eventually.",Solution Usage
15202,"The test run results with CODE<img width=""784"" alt=""screen shot 2016-11-16 at 1 51 51 pm"" src=""https://cloud.githubusercontent.com/assets/6901075/20361517/dd5dbbd8-ac05-11e6-85ac-5a9e2dec3a2b.png"">",Solution Usage
15203,Would you please update if you diagnose the cause of this behavior?,Solution Usage
15204,or I did something wrong?,Solution Usage
15205,Not sure what you want to see how to call it as nmhkahn's examples seems to do the job?,Solution Usage
15206,"I am confused on how to use it and the SO seems to be outdated and then there is a layer in a different link from the API, just how exactly does one do this?",Solution Usage
15207,"To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size.",Solution Usage
15208,"I'd be seeing bad performance during training *and* testing if it hadn't converged, right?",Solution Usage
15209,What's more:1.         [Here is a full example] URL  on how to use BN layer on MNIST dataset.,Solution Usage
15210,Why was it that I needed to change updates_collections to be None?,Solution Usage
15211,Training seems to work very well.,Solution Usage
15212,I want to perform batch nomalization.,Solution Usage
15213,"As a follow up, I'm reusing 16 layers of batch_norm.",Solution Usage
15214,If you're using a MonitoredSession and its variants you should still be able to do this: CODE,Solution Usage
15215,"We will provide methods for creating datasets from tensors, and deriving them from another dataset (e.g. by slicing its elements, repeating its elements, shuffling its elements, batching its elements, mapping a function over its elements, etc.).",Solution Usage
15216,How does one modify this to get the updated position of the iterator in each dataset?,Solution Usage
15217,CODE where phase_train_py is a python boolean variable and is_training is a placeholder taking a boolean variable.,Solution Usage
15218,"@sguada  I have noticed that you said"" tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial"".",Solution Usage
15219,"The catch is, I couldn't find a way to iterate over the data more than once (which luckily enough is not my use-case), because the only iterator that won't raise an error when the CODEs spawn the threads is the CODE.",Solution Usage
15220,decay value is 0.9,Solution Usage
15221,"As for my comment above [1122](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235433645), I figured out that   tf.get_variable_scope().reuse_variables() takes care of the issue, so  in the training phase the argument reuse of batch_norm should be None.",Solution Usage
15222,"I build batchnorm like this, however, the moving mean and moving variable are updated during test, I can not find the reason.",Solution Usage
15223,"The catch is, I couldn't find a way to iterate over the data more than once (which luckily enough is not my use-case), because the only iterator that won't raise an error when the CODEs spawn the threads is the CODE.",Solution Usage
15224,2.         using placeholder to switch between train and test evaluation,Solution Usage
15225,CODE,Solution Usage
15226,@sguada @brando90CODE,Solution Usage
15227,The inference happens with the function MyModel.,Solution Usage
15228,"When saving and restoring using:saver = tf.train.Saver()it works, but when saving using:saver = tf.train.Saver(tf.trainable_variables() + [global_step])so that I can save storage space (by not saving the gradients etc)on restore there is an error:""uninitialized value unpool4/convc/bn/moving_mean""",Solution Usage
15229,"However, when I passed a placeholder for is_training it said CODEtf.TensorCODEboolCODEif t is not None:CODEif t:CODE and pointed to batch_norm code.",Solution Usage
15230,Is this what you meant? CODE,Solution Usage
15231,"The parameter ""allow_smaller_final_batch"" in tf.train.shuffle_batch(...) is useful when I'd like to assure all batches are evenly divisible by number of gpus.",Solution Usage
15232,Currently the tutorial says that we can useCODEto get shuffled data.,Solution Usage
15233,Anyone know why might this be?,Solution Usage
15234,"In the latter case, the moving mean and variance look more reasonable (with different values), but if I use is_training=False in test time, the performance is also really bad.",Solution Usage
15235,"@nirmalthacker Yep, that's essentially what I meant.",Solution Usage
15236,CODE,Solution Usage
15237,I am currently using a CODE because it does not take CODE by itself.,Solution Usage
15238,"In other words, if CODE is true, then we should a CODE function for training and another one for testing.",Solution Usage
15239,"Though there are many issues on batch normalization, it's hard to find a complete code snippet on how to use it, esp. for how to pass different parameters in different phase.",Solution Usage
15240,"However, CODE evaluates the dynamic, real-time shape of a tensor, so I thought this should work.",Solution Usage
15241,Why was it that I needed to change updates_collections to be None?,Solution Usage
15242,@brando90 currently I am doing something like: CODE,Solution Usage
15243,"I tried creating two models like @sguada said, however, my model where is_training=False just crashes.",Solution Usage
15244,"Unless you need to change the behavior of the model dynamically, you don't need to use a placeholder for is_training.",Solution Usage
15245,"Also you are passing UPDATE_OPS_COLLECTION variables_collections, which changes which collections are the variables added to.",Solution Usage
15246,"I'm not sure what are you trying to do, in most cases using static values solve the problem.",Solution Usage
15247,"CODE In the above, since we run an init each time to get an iterator pointing to its required dataset, we end up running a training and validation on the first item of each dataset, always.",Solution Usage
15248,"Sorry for the spam, but the documentation doesn't really explain how to use this BN with convolution (maybe should be provided somewhere?).",Solution Usage
15249,It would be great if the layer could be added to the documentation with a short explanation how to best handle the change from training to test.,Solution Usage
15250,So set the appropriate decay for your training step numbers.,Solution Usage
15251,@nmduc @davek44  I wrote some code to track the moving mean and moving variance computed in CODE during training and testing.,Solution Usage
15252,"is there a small script with a very simple NN that shows what is the proper way of using this ""official"" BN layer?",Solution Usage
15253,P.S. The batch norm layer is used just after the last fully connected layer of the network and before softmax.,Solution Usage
15254,decay value is 0.9,Solution Usage
15255,"I found the dataset (after batch, prior to filter) was in this form:",Solution Usage
15256,"I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe.",Solution Usage
15257,"Say, in my [mnist_bn] URL  code, I controlled dependencies using CODE and set up CODE as a placeholder.",Solution Usage
15258,"You can also use tf.model_variables() which contains the variables of the model, i.e. moving_mean",Solution Usage
15259,"Since we can only change tensors or placeholders with CODE, I changed CODE intentionally before running the graph.",Solution Usage
15260,I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.,Solution Usage
15261,"I did 2 test runs with the exact same code but different CODE settings in the CODE, and my validation/test accuracies seemed more reasonable.",Solution Usage
15262,"In some versions of the code training accuracies are much higher than testing accuracies, which probably mean I am not sharing batch normalization parameters.",Solution Usage
15263,One thing I notice is that the arguments CODE and CODE from CODE are missing in CODE; does that mean no parallel processing is possible?,Solution Usage
15264,With tf.global_variables() the save files are much larger as I think it includes the gradients; in the end I used: saver = tf.train.Saver([x for x in tf.global_variables() if 'Adam' not in x.name]),Solution Usage
15265,"However when a network has many batch_norm layers it is more efficient to collect all the update ops and run them together, so each layer don't need to wait for the update to finish.",Solution Usage
15266,"I guess using tf.cond is wrong, otherwise would did the function came with a boolean parameters.",Solution Usage
15267,"@brando90 @pawni he's code works good, but have to change like below CODE",Solution Usage
15268,"(below is an example of the function, in reality i use more layers and neurons). CODE",Solution Usage
15269,"I'm not sure what are you trying to do, in most cases using static values solve the problem.",Solution Usage
15270,"I followed the guidelines of dataset README.md, with pseudo code like following: def _parse_function(example_proto):features = {""image"": tf.FixedLenFeature((), tf.string, default_value=""""),""label"": tf.FixedLenFeature((), tf.int32, default_value=0)}parsed_features = tf.parse_single_example(example_proto, features)return parsed_features[""image""], parsed_features[""label""] BATCH_SIZE = 256filenames = [""/var/data/file1.tfrecord"", ""/var/data/file2.tfrecord""]dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(_parse_function)dataset = dataset.batch(BATCH_SIZE)dataset = dataset.filter(lambda imgs, lbls: tf.shape(imgs)[0] == BATCH_SIZE)iterator = dataset.make_initializable_iterator()next_element = iterator.get_next()images, labels = next_element # Training cycles for 100 epochs.for _ in range(100):sess.run(iterator.initializer)while True:try:images_r, labels_r = sess.run([images, labels])print(images_r.shape)except tf.errors.OutOfRangeError:break",Solution Usage
15271,"(Think CODE in C#, CODE in Java and Scala.)",Solution Usage
15272,"@zhongyuk thanks, I've run about 5k updates with CODE, so it should've converged and testing performance using large batch sizes is fine.",Solution Usage
15273,@rogertrullo Generally I setup TensorBoard to track moving mean and variance.,Solution Usage
15274,"I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe.",Solution Usage
15275,I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.,Solution Usage
15276,"@soloice , notice, how in about [comment](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235928564) the following parameter is passed inside to the layer for calling batch_norm: >  batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}",Solution Usage
15277,I tried now with just different CODE and CODE parameters:CODE,Solution Usage
15278,I'm trying to test the example in the [doc](https://www.tensorflow.org/versions/r1.3/programmers_guide/datasets#preprocessing_data_with_datasetmap),Solution Usage
15279,2.         using placeholder to switch between train and test evaluation,Solution Usage
15280,"so if I do .fit([[5]]).transform([[4]]), for which values of n_values,categories and handle_umknown will that raise an error?",Solution Usage
15281,"Is there any code out there that uses this, even if that code is undocumented?",Solution Usage
15282,still don't get good validation and testing results... >70%...,Solution Usage
15283,But still find the problem that how to dynamically feed data to the Dataset.,Solution Usage
15284,"@davek44 I'm using the same code framework that you are using and I observed the same thing: when turns on CODE during training phase and turns off CODE for validation and/or testing phase, the model trains well like the paper described (model converges faster and I was able to use a larger learning rate), however the testing performance is terrible.",Solution Usage
15285,(see attached image)![screen shot 2017-04-03 at 19 54 54] URL ,Solution Usage
15286,I see the same poor test performance with that code.,Solution Usage
15287,"I tried creating two models like @sguada said, however, my model where is_training=False just crashes.",Solution Usage
15288,should do the trick.,Solution Usage
15289,"That said, looking at SwitchableDataSet, it seems like implementing new kinds of data feeding use cases will be mostly done by implementing use-case specific classes.",Solution Usage
15290,"After applied the filter, no data available in training cycles.",Solution Usage
15291,"sorry for the spamming, but what is wrong with just using something like this: CODE",Solution Usage
15292,"I would have preferred to leave it as a placeholder because this way I can do periodic testing during training without redefining the graph, but I decided to use it as a constant and define different behaviors for train vs test, and now the moments are not calculated at test time.",Solution Usage
15293,I would like to encourage you to use [CODE] URL  or [CODE] URL  to build your model.,Solution Usage
15294,(see attached image)![screen shot 2017-04-03 at 19 54 54] URL ,Solution Usage
15295,"Unless you need to change the behavior of the model dynamically, you don't need to use a placeholder for is_training.",Solution Usage
15296,But that's certainly the gist of it.,Solution Usage
15297,How does one do that?,Solution Usage
15298,@rogertrullo Generally I setup TensorBoard to track moving mean and variance.,Solution Usage
15299,"Can someone provide an example of how to call the ""def BatchNorm"" function during training and testing so that variable sharing happen correctly.",Solution Usage
15300,How does one do that?,Solution Usage
15301,"There, single string tensors come in (file names) and whole Datasets are emitted in the map function, so that seems pretty clear.",Solution Usage
15302,"During training and testing we are either updating or reusing four variables (beta, gamma, moving_mean and moving_variance).",Solution Usage
15303,"That said, looking at SwitchableDataSet, it seems like implementing new kinds of data feeding use cases will be mostly done by implementing use-case specific classes.",Solution Usage
15304,"BTW, do I need to retrain the model using decay=0.9 from scratch?",Solution Usage
15305,"Nevertheless, the documentation seams to be out-dated.",Solution Usage
15306,"@vvekic, I experimented a bit with queues and the Dataset API after realising in horror that of the 0.8s/step in my inference loop, 0.2s is data fetching (with GPU at 0% utilization), raising to almost 2 seconds if the HDD is being used by something else at the same time.",Solution Usage
15307,From what I 've been reading in this thread in the training phase I should be using reuse=None.,Solution Usage
15308,CODE,Solution Usage
15309,(i.e. just to track the train error),Solution Usage
15310,Currently the tutorial says that we can useCODEto get shuffled data.,Solution Usage
15311,The right way to do testing is to define different behaviors for train and test as you mentioned.,Solution Usage
15312,"I got the following error in the training phase:Variable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?",Solution Usage
15313,(You can try it by downloading the current nightly build.),Solution Usage
15314,Do we have one?,Solution Usage
15315,So when I did: CODE,Solution Usage
15316,"Finally, in the testing phase, should I have is_training=False and reuse=True?",Solution Usage
15317,"I did 2 test runs with the exact same code but different CODE settings in the CODE, and my validation/test accuracies seemed more reasonable.",Solution Usage
15318,"Just wanted to note that I also have the problem of poor test performance, specifically using small batch sizes (anything smaller than 10 instead of the 200 I used for training diminishes test accuracy).",Solution Usage
15319,The following should work: CODE,Solution Usage
15320,"In some versions of the code training accuracies are much higher than testing accuracies, which probably mean I am not sharing batch normalization parameters.",Solution Usage
15321,"@nirmalthacker Every time you run an iterator init op, it restarts the iterator.",Solution Usage
15322,"However, I found that reusing 4 layers works.",Solution Usage
15323,One needs to balance between quick start (small decay) and a longer effective range (large decay).,Solution Usage
15324,"You can also use tf.model_variables() which contains the variables of the model, i.e. moving_mean",Solution Usage
15325,P.S. The batch norm layer is used just after the last fully connected layer of the network and before softmax.,Solution Usage
15326,With tf.global_variables() the save files are much larger as I think it includes the gradients; in the end I used: saver = tf.train.Saver([x for x in tf.global_variables() if 'Adam' not in x.name]),Solution Usage
15327,"Passing CODE to the CODE call, and following that with CODE will run your CODE function in parallel and should decently increase the performance.",Solution Usage
15328,Could you explain this part with a bit more details?,Solution Usage
15329,"I'm sure I note the following details, but still failed to use the official CODE, with CODE during evaluation(but when I keep CODE unchanged during evaluation, it is ok):",Solution Usage
15330,Why was it that I needed to change updates_collections to be None?,Solution Usage
15331,And the opposite while Testing.,Solution Usage
15332,@nmduc @davek44  I wrote some code to track the moving mean and moving variance computed in CODE during training and testing.,Solution Usage
15333,"In some versions of the code training accuracies are much higher than testing accuracies, which probably mean I am not sharing batch normalization parameters.",Solution Usage
15334,"Though there are many issues on batch normalization, it's hard to find a complete code snippet on how to use it, esp. for how to pass different parameters in different phase.",Solution Usage
15335,I did it like this:,Solution Usage
15336,"During training and testing we are either updating or reusing four variables (beta, gamma, moving_mean and moving_variance).",Solution Usage
15337,"Passing CODE to the CODE call, and following that with CODE will run your CODE function in parallel and should decently increase the performance.",Solution Usage
15338,"In this way, you don't need to switch dynamically between train and evaluation.",Solution Usage
15339,and because the session manager init doesn't initialise them properly: sess.run(tf.variables_initializer([x for x in tf.global_variables() if 'Adam' in x.name])) (Using tf.train.AdamOptimizer),Solution Usage
15340,It cannot be a CODE.,Solution Usage
15341,(You can try it by downloading the current nightly build.),Solution Usage
15342,When the updates_collections=None then the updates happens in-place and it is easier to use a tf.cond() to allow is_training being a Tensor a bit more complicated is when the updates are delayed and the the update_ops are run later.,Solution Usage
15343,I replaced it with _tf.tuple()_,Solution Usage
15344,What's more:1.         [Here is a full example] URL  on how to use BN layer on MNIST dataset.,Solution Usage
15345,CODE,Solution Usage
15346,"Nevertheless, the documentation seams to be out-dated.",Solution Usage
15347,And I am running it in a multi-gpu fashion (for training).,Solution Usage
15348,"The default decay is 0.999, for small datasets such like MNIST, you can choose 0.99 or 0.95, and it warms up in a short time.",Solution Usage
15349,I'm currently using the new CODE and CODE apis along with CODE to accomplish this but is there a more direct/natural way in the works?,Solution Usage
15350,But seems that this call is passing only 1 argument to the function:,Solution Usage
15351,@MisayaZ you don't need to create two batch_norm layers you can just pass train_phase (assuming it is a tf.bool) to batch_norm.,Solution Usage
15352,"-         ~~I don't know how to access _control_flow_ops.with_dependencies()_. How can I access functions within control_flow_ops module? I have seen other examples just using tf.with_dependecies(), but I cannot do that with Tensorflow 0.10.~~ I found it here: _tf.python.control_flow_ops.with_dependencies()_",Solution Usage
15353,"Say, in my [mnist_bn] URL  code, I controlled dependencies using CODE and set up CODE as a placeholder.",Solution Usage
15354,"I've just been noticing that if I kill the tensorflow process and restart it, my error gets worse for a few epochs (i.e. worse than it should be at the last checkpoint).",Solution Usage
15355,https://stackoverflow.com/questions/44132307/tf-contrib-data-dataset-repeat-with-shuffle-notice-epoch-end-mixed-epochs,Solution Usage
15356,CODE,Solution Usage
15357,@nmhkahn how is it different from pawni's suggestion?,Solution Usage
15358,@brando90 I had a small error in my version which was fixed by nmhkahn (changing CODE to CODE),Solution Usage
15359,"After doing some runs on my network, I have to say that ~~I can not see any performance difference between using  _updates_collections=None_ in contrast to manually fetching _tf.GraphKeys.UPDATE_OPS_ while graph construction~~. Even with heavy use of batch normalization (in total, my _tf.get_collection(tf.GraphKeys.UPDATE_OPS)_ returns 140 Update-Ops, all of them are BN-ops only)",Solution Usage
15360,"I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe.",Solution Usage
15361,@rogertrullo Generally I setup TensorBoard to track moving mean and variance.,Solution Usage
15362,"Is there any code out there that uses this, even if that code is undocumented?",Solution Usage
15363,"Without more details is impossible to know, my guesses are that you only train for a few iterations, so the moving_mean and moving_average haven't converge yet.",Solution Usage
15364,Obviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers.,Solution Usage
15365,Just put it in seperate collection-keys: CODE CODE,Solution Usage
15366,People have commented that they want CODE to be a placer holder but thats what I had for my version of it: CODE,Solution Usage
15367,"However, what I **did** find was that, obviously, we should use Tensorflow ops instead of standard comparisons since the result of CODE is a tensor and not a normal array.",Solution Usage
15368,CODE,Solution Usage
15369,@nmhkahn @pawni @ when you do: CODE doesn't that mean that your using CODE as a placeholder?,Solution Usage
15370,Is it normal that Batch Normalization makes my experiments **worse**?,Solution Usage
15371,"My tf version's filter is broken, but if yours works could you try this instead? CODE",Solution Usage
15372,TF 1.0 works but doesn't have devicewrapper api for multiple GPUs.,Solution Usage
15373,I noticed after plotting accuracies in training and test mode that the testing accuracies start climbing after the training accuracies.,Solution Usage
15374,CODE where phase_train_py is a python boolean variable and is_training is a placeholder taking a boolean variable.,Solution Usage
15375,"I have many different models that use different batch_norm layers, this wouldn't work right?: CODE",Solution Usage
15376,CODE,Solution Usage
15377,"(<tf.Tensor 'arg0:0' shape=(?, 43200) dtype=float32>, <tf.Tensor 'arg1:0' shape=(?, 36) dtype=float32>)",Solution Usage
15378,What's more:1.         [Here is a full example] URL  on how to use BN layer on MNIST dataset.,Solution Usage
15379,"As a follow up, I'm reusing 16 layers of batch_norm.",Solution Usage
15380,"Passing CODE to the CODE call, and following that with CODE will run your CODE function in parallel and should decently increase the performance.",Solution Usage
15381,"I see the reinitializable iterators give us the ability to use the same iterator with multiple datasets but each time you run an init op, it essentially starts over on that dataset.",Solution Usage
15382,"I'd be seeing bad performance during training *and* testing if it hadn't converged, right?",Solution Usage
15383,"I got the following error in the training phase:Variable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?",Solution Usage
15384,"And when run in training or test time, CODE",Solution Usage
15385,is that not correct?,Solution Usage
15386,Is it normal that Batch Normalization makes my experiments **worse**?,Solution Usage
15387,Its seems like a non-trivial change (should it None be its default value then if it matters so much?).,Solution Usage
15388,@sguada I changed my old one where I manually tell it to train or not (based on a tf.cond) and now it seems the accuracy is up to ~95's again.,Solution Usage
15389,So set the appropriate decay for your training step numbers.,Solution Usage
15390,How can I use spacy in Spark?,Solution Usage
15391,"During training and testing we are either updating or reusing four variables (beta, gamma, moving_mean and moving_variance).",Solution Usage
15392,"conv1 = tf.nn.relu(batch_norm_layer(conv2d_stride2_valid(data, W_conv1) + b_conv1, train_phase, scope=""conv1""))",Solution Usage
15393,The programmers' guide has [more details](https://www.tensorflow.org/programmers_guide/datasets#creating_an_iterator) about how to use this feature.,Solution Usage
15394,It works for me now.,Solution Usage
15395,One needs to balance between quick start (small decay) and a longer effective range (large decay).,Solution Usage
15396,Is your problem similar ?,Solution Usage
15397,I'm trying migrating input pipeline from tf.train.string_input_producer & tf.train.shuffle_batch to Dataset APIs.,Solution Usage
15398,Is it possible to address a single column in the dataset so that it is treated different from the other column?,Solution Usage
15399,CODE,Solution Usage
15400,"tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.",Solution Usage
15401,"I'm sure I note the following details, but still failed to use the official CODE, with CODE during evaluation(but when I keep CODE unchanged during evaluation, it is ok):",Solution Usage
15402,Have a look at [how this is used in the NMT model code](https://github.com/tensorflow/nmt/blob/04c8c04a8b4e805f3d0a9c42b4d17c85f1324c55/nmt/utils/iterator_utils.py#L194) for an example.,Solution Usage
15403,"@winston-li seeing ""?"" as shape is because at that point you're looking at the 'static' shape of the tensor, which isn't always defined (the graph doesn't know in advance how many examples there will be).",Solution Usage
15404,And the opposite while Testing.,Solution Usage
15405,"tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.",Solution Usage
15406,But still find the problem that how to dynamically feed data to the Dataset.,Solution Usage
15407,"In other words, if CODE is true, then we should a CODE function for training and another one for testing.",Solution Usage
15408,"Nevertheless, the documentation seams to be out-dated.",Solution Usage
15409,"But what it is important is that either you pass [updates_collections=None](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L142) so the moving_mean and moving_variance are updated in-place, otherwise you will need gather the update_ops and make sure they are run.",Solution Usage
15410,You can change the batch_size during test to see how the performance degrades as you make your batch smaller.,Solution Usage
15411,And I am running it in a multi-gpu fashion (for training).,Solution Usage
15412,"I build batchnorm like this, however, the moving mean and moving variable are updated during test, I can not find the reason.",Solution Usage
15413,"@brando90 @pawni he's code works good, but have to change like below CODE",Solution Usage
15414,"hi,you need to set different scope for every time you use batch norm and give it the reuse input according to the training/test phase(TRUE when test FALSE when train) that works for me.",Solution Usage
15415,"I got the following error in the training phase:Variable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?",Solution Usage
15416,"However, the ValueError should be resolved by the code snippet.",Solution Usage
15417,The right way to do testing is to define different behaviors for train and test as you mentioned.,Solution Usage
15418,@brando90 I had a small error in my version which was fixed by nmhkahn (changing CODE to CODE),Solution Usage
15419,The net is working well now.,Solution Usage
15420,CODE,Solution Usage
15421,"tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.",Solution Usage
15422,"@davek44 I'm using the same code framework that you are using and I observed the same thing: when turns on CODE during training phase and turns off CODE for validation and/or testing phase, the model trains well like the paper described (model converges faster and I was able to use a larger learning rate), however the testing performance is terrible.",Solution Usage
15423,https://stackoverflow.com/questions/44132579/feed-data-into-a-tf-contrib-data-dataset-like-a-queue,Solution Usage
15424,The following should work: CODE,Solution Usage
15425,"But even if it didn't, would it result in a difference between training a testing?",Solution Usage
15426,"The moving mean and moving variance are changed when I used batchnorm like this: def batch_norm_layer(self, x,train_phase, scope_bn):bn_train = batch_norm(x, decay=0.9, center=False, scale=True,updates_collections=None,is_training=True,reuse=None,variables_collections= [UPDATE_OPS_COLLECTION],trainable=True,scope=scope_bn)bn_inference = batch_norm(x, decay=0.9, center=False, scale=True,updates_collections=None,is_training=False,reuse=True,variables_collections= [UPDATE_OPS_COLLECTION],trainable=True,scope=scope_bn)z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)return z",Solution Usage
15427,I'm using python3 and didn't tried with python2.,Solution Usage
15428,"For example, the following codeCODEgets 3 CODE before getting a CODE.",Solution Usage
15429,CODE,Solution Usage
15430,"I found the dataset (after batch, prior to filter) was in this form:",Solution Usage
15431,Looking forward to hear whether we've just not been using the datasets API right.,Solution Usage
15432,I tried now with just different CODE and CODE parameters:CODE,Solution Usage
15433,I was trying to use batch norm with a 2 layered densely connected NN with the (flatten) MNIST  (and relu units) data set for the task of auto-encoding  and I keep getting a NaN error.,Solution Usage
15434,I am using the same scope and CODE.,Solution Usage
15435,"There will be explicit operations for initializing an iterator, so that it can be reused after you have processed all of the elements in a dataset.",Solution Usage
15436,"@nirmalthacker Every time you run an iterator init op, it restarts the iterator.",Solution Usage
15437,is that not the official way to use BN?,Solution Usage
15438,Have a look at [how this is used in the NMT model code](https://github.com/tensorflow/nmt/blob/04c8c04a8b4e805f3d0a9c42b4d17c85f1324c55/nmt/utils/iterator_utils.py#L194) for an example.,Solution Usage
15439,"@brando90 @pawni he's code works good, but have to change like below CODE",Solution Usage
15440,Not sure what you want to see how to call it as nmhkahn's examples seems to do the job?,Solution Usage
15441,"Can someone provide an example of how to call the ""def BatchNorm"" function during training and testing so that variable sharing happen correctly.",Solution Usage
15442,"@nmhkahn Regarding your code snippet, may I ask why is CODE set to be CODE when CODE?",Solution Usage
15443,"@vvekic, I experimented a bit with queues and the Dataset API after realising in horror that of the 0.8s/step in my inference loop, 0.2s is data fetching (with GPU at 0% utilization), raising to almost 2 seconds if the HDD is being used by something else at the same time.",Solution Usage
15444,Maybe It could be nice to show how this placeholder thing should be used because it seems I don't understand how its suppose to be used.,Solution Usage
15445,TF 1.0 works but doesn't have devicewrapper api for multiple GPUs.,Solution Usage
15446,"@pawni If you don't want to worry about about updating moving_mean and moving_variance set updates_collections=None to make sure they are updated in place, otherwise you need to make sure the update_ops added to tf.GraphKeys.UPDATE_OPS are run during training.",Solution Usage
15447,2.         using placeholder to switch between train and test evaluation,Solution Usage
15448,"Update: use a small decay (say, 0.9 or 0.95) does help a lot.",Solution Usage
15449,"@brando90 @pawni he's code works good, but have to change like below CODE",Solution Usage
15450,To make those unique I had to set a scope per layer.,Solution Usage
15451,"I got the following error in the training phase:Variable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?",Solution Usage
15452,So set the appropriate decay for your training step numbers.,Solution Usage
15453,"You should use only one BN layer (of course, with different CODE parameter).",Solution Usage
15454,The programmers' guide has [more details](https://www.tensorflow.org/programmers_guide/datasets#creating_an_iterator) about how to use this feature.,Solution Usage
15455,Obviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers.,Solution Usage
15456,Just need to make sure that the statistics have converged with default decay=0.999 that implies at least 50k updates.,Solution Usage
15457,And I am running it in a multi-gpu fashion (for training).,Solution Usage
15458,The programmers' guide has [more details](https://www.tensorflow.org/programmers_guide/datasets#creating_an_iterator) about how to use this feature.,Solution Usage
15459,"If I turns on CODE all the time, the model trains the same as without inserting batch norm layer.",Solution Usage
15460,"The parameter ""allow_smaller_final_batch"" in tf.train.shuffle_batch(...) is useful when I'd like to assure all batches are evenly divisible by number of gpus.",Solution Usage
15461,Then I had to spend more time figuring out that by default the variables tracking the moments don't update unless you use a contrib function for optimization.,Solution Usage
15462,"But even if it didn't, would it result in a difference between training a testing?",Solution Usage
15463,then its simple to tell tensorflow which one to use with a feed dictionary as in: CODE,Solution Usage
15464,"Since we can only change tensors or placeholders with CODE, I changed CODE intentionally before running the graph.",Solution Usage
15465,"hi,please see my wrapper above.you should use ""with tf.variable_scope(scope, reuse=reuse):"" I think.",Solution Usage
15466,https://stackoverflow.com/questions/44132307/tf-contrib-data-dataset-repeat-with-shuffle-notice-epoch-end-mixed-epochs,Solution Usage
15467,"This is what I have now, and it handles what I wanted.",Solution Usage
15468,"Though there are many issues on batch normalization, it's hard to find a complete code snippet on how to use it, esp. for how to pass different parameters in different phase.",Solution Usage
15469,I am currently using a CODE because it does not take CODE by itself.,Solution Usage
15470,"Thus, I'm guessing I still have a scope issue so that it's not finding the proper existing variables.",Solution Usage
15471,2.         using placeholder to switch between train and test evaluation,Solution Usage
15472,"I found the dataset (after batch, prior to filter) was in this form:",Solution Usage
15473,"CODE In the above, since we run an init each time to get an iterator pointing to its required dataset, we end up running a training and validation on the first item of each dataset, always.",Solution Usage
15474,"I can confirm that test performance is good when using is_training=False with small batches and even with batch_size=1, since it is not using statistic from the batch, but the statistic learnt during training.",Solution Usage
15475,The right way to do testing is to define different behaviors for train and test as you mentioned.,Solution Usage
15476,"Hi, Using the above CODE layer in CODE, I'm getting CODE as an output for validation graph while the train graph runs seamlessly.",Solution Usage
15477,Your current way might have problems as well.,Solution Usage
15478,"Hi @ishaybee,I followed your advice, now my code is:CODE",Solution Usage
15479,"During training and testing we are either updating or reusing four variables (beta, gamma, moving_mean and moving_variance).",Solution Usage
15480,Is it normal that Batch Normalization makes my experiments **worse**?,Solution Usage
15481,Use of batch_norm with tf.placeholder CODE,Solution Usage
15482,Had a similar problem and it went away when I used the fused version,Solution Usage
15483,I see the same poor test performance with that code.,Solution Usage
15484,I think it must be due to improper use of CODE or CODE or some other parameters.,Solution Usage
15485,(There seem to be two places containing some amount of separate documentation: either on [GitHub] URL  or on [tensorflow.org](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/data/Dataset#flat_map)),Solution Usage
15486,"so if I do .fit([[5]]).transform([[4]]), for which values of n_values,categories and handle_umknown will that raise an error?",Solution Usage
15487,I'm currently using the new CODE and CODE apis along with CODE to accomplish this but is there a more direct/natural way in the works?,Solution Usage
15488,"To do that, shouldn't they be only initialized once and then reused in all training steps?",Solution Usage
15489,"I also observe that if I remove batch_norm, this problem goes away.",Solution Usage
15490,Yup that fixed it.,Solution Usage
15491,Do you mind explaining me why that gave such a big accuracy difference?,Solution Usage
15492,I'm trying migrating input pipeline from tf.train.string_input_producer & tf.train.shuffle_batch to Dataset APIs.,Solution Usage
15493,Its seems like a non-trivial change (should it None be its default value then if it matters so much?).,Solution Usage
15494,But still find the problem that how to dynamically feed data to the Dataset.,Solution Usage
15495,"Though there are many issues on batch normalization, it's hard to find a complete code snippet on how to use it, esp. for how to pass different parameters in different phase.",Solution Usage
15496,"If your feeling is that spacy is really meant for batch processing and that I should use mini-batches if I want to approximate streaming, I can do that.",Solution Usage
15497,"To save/restore them, you can use tf.global_variables()",Solution Usage
15498,Take a look at the documentation here [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data#creating-an-iterator).,Solution Usage
15499,CODE,Solution Usage
15500,I am currently using a CODE because it does not take CODE by itself.,Solution Usage
15501,"We will provide methods for creating datasets from tensors, and deriving them from another dataset (e.g. by slicing its elements, repeating its elements, shuffling its elements, batching its elements, mapping a function over its elements, etc.).",Solution Usage
15502,when I was trying to reuse.,Solution Usage
15503,Its seems like a non-trivial change (should it None be its default value then if it matters so much?).,Solution Usage
15504,"My dataset contains one column with sequences and one with sequence length which i want treat different, because i want to pad the sequences.",Solution Usage
15505,It seems to work sometimes but I am not too sure.,Solution Usage
15506,CODE,Solution Usage
15507,I did it like this:,Solution Usage
15508,"Finally, in the testing phase, should I have is_training=False and reuse=True?",Solution Usage
15509,"Being a newer tf user, I found that my test error was crazy and then had to spend a fair amount of time debugging my graph until I realized that batch normalization was the problem.",Solution Usage
15510,"If this is true, then since I am using two GPUS, should I do reuse=None in the first GPU and reuse=True in the second?",Solution Usage
15511,and because the session manager init doesn't initialise them properly: sess.run(tf.variables_initializer([x for x in tf.global_variables() if 'Adam' in x.name])) (Using tf.train.AdamOptimizer),Solution Usage
15512,"But even if it didn't, would it result in a difference between training a testing?",Solution Usage
15513,What is the correct way to change this flag?,Solution Usage
15514,Is this what you meant? CODE,Solution Usage
15515,I'm currently using the new CODE and CODE apis along with CODE to accomplish this but is there a more direct/natural way in the works?,Solution Usage
15516,"@vvekic, I experimented a bit with queues and the Dataset API after realising in horror that of the 0.8s/step in my inference loop, 0.2s is data fetching (with GPU at 0% utilization), raising to almost 2 seconds if the HDD is being used by something else at the same time.",Solution Usage
15517,"tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.",Solution Usage
15518,When the updates_collections=None then the updates happens in-place and it is easier to use a tf.cond() to allow is_training being a Tensor a bit more complicated is when the updates are delayed and the the update_ops are run later.,Solution Usage
15519,I'm using:CODE,Solution Usage
15520,"Although, at each validation step, I will reinit the validation iterator and run through the full validation dataset.",Solution Usage
15521,"As for ""cold start"", as you see above in discussiion, decreasing BatchNorm running average decay (input param) from default 0.999 to something like 0.95 can speed-up start-up",Solution Usage
15522,I answered @albertz's Stack Overflow question about doing this [here] URL .,Solution Usage
15523,After taking a closer look at the code in contrib I realized what my problem was.,Solution Usage
15524,"Oh I thought you were doing CODE, which is incorrect.",Solution Usage
15525,"If the user wants to keep the current behaviour, it can manually specify it as",Solution Usage
15526,"I build batchnorm like this, however, the moving mean and moving variable are updated during test, I can not find the reason.",Solution Usage
15527,Just need to make sure that the statistics have converged with default decay=0.999 that implies at least 50k updates.,Solution Usage
15528,"I found the dataset (after batch, prior to filter) was in this form:",Solution Usage
15529,"This is why tools like tf.estimator.Estimator were developed, to allow foreasier separation of concerns between training and inference and to allowfor swapping of input pipelines.",Solution Usage
15530,"The parameter ""allow_smaller_final_batch"" in tf.train.shuffle_batch(...) is useful when I'd like to assure all batches are evenly divisible by number of gpus.",Solution Usage
15531,"Per value this isn't that much of a difference, but has a big impact when computing vector distances in latent spaces.",Solution Usage
15532,2.         Use a smaller decay value will accelerate the warm-up phase.,Solution Usage
15533,@nmhkahn @pawni @ when you do: CODE doesn't that mean that your using CODE as a placeholder?,Solution Usage
15534,CODE,Solution Usage
15535,I'm currently using the new CODE and CODE apis along with CODE to accomplish this but is there a more direct/natural way in the works?,Solution Usage
15536,"Just wanted to note that I also have the problem of poor test performance, specifically using small batch sizes (anything smaller than 10 instead of the 200 I used for training diminishes test accuracy).",Solution Usage
15537,I had exactly the same problem either with tf.slim batchnorm or with tf.cond and input is_training as a placeholder.,Solution Usage
15538,"I have many different models that use different batch_norm layers, this wouldn't work right?: CODE",Solution Usage
15539,@ppwwyyxx well I am doing CODE or is one just supposed to do a CODE and change that outside of the graph when needed?,Solution Usage
15540,decay value is 0.9,Solution Usage
15541,There are two similar questions in [here] URL  and [here] URL @albertz.,Solution Usage
15542,Just put it in seperate collection-keys: CODE CODE,Solution Usage
15543,Can anyone confirm good test performance with small or single data samples using this batch norm layer?,Solution Usage
15544,"is there a small script with a very simple NN that shows what is the proper way of using this ""official"" BN layer?",Solution Usage
15545,The output of the tensor : CODE present in CODE isCODE,Solution Usage
15546,@brando90 I had a small error in my version which was fixed by nmhkahn (changing CODE to CODE),Solution Usage
15547,As an example here is a piece of code that demonstrates what I'd like to do.,Solution Usage
15548,"The moving mean and moving variance are changed when I used batchnorm like this: def batch_norm_layer(self, x,train_phase, scope_bn):bn_train = batch_norm(x, decay=0.9, center=False, scale=True,updates_collections=None,is_training=True,reuse=None,variables_collections= [UPDATE_OPS_COLLECTION],trainable=True,scope=scope_bn)bn_inference = batch_norm(x, decay=0.9, center=False, scale=True,updates_collections=None,is_training=False,reuse=True,variables_collections= [UPDATE_OPS_COLLECTION],trainable=True,scope=scope_bn)z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)return z",Solution Usage
15549,"I build batchnorm like this, however, the moving mean and moving variable are updated during test, I can not find the reason.",Solution Usage
15550,"Can someone provide an example of how to call the ""def BatchNorm"" function during training and testing so that variable sharing happen correctly.",Solution Usage
15551,"I believe that for the code to be used ""right out of the box"" the default should be None.",Solution Usage
15552,"CODEthe above code prints nothing, just exits after attempting to run past the last batch.",Solution Usage
15553,However I'm confused how one does that in this new paradigm.,Solution Usage
15554,"@ppwwyyxx stated that queues and StagingArea can still be used with the Dataset API, but I still haven't seen a working example of this.",Solution Usage
15555,Then I had to spend more time figuring out that by default the variables tracking the moments don't update unless you use a contrib function for optimization.,Solution Usage
15556,This doesn't work for me.,Solution Usage
15557,"I tried it on a 2 layered NN network based on the MNIST beginner tutorial and I consistently get worse results when BN is present: with BN (one with scale and center trained and the other not) accuracy is 0.8423, 0.8221 and without BN accuracy is 0.9477.",Solution Usage
15558,"In other versions of the code I get ""ValueError: Variable conv1/beta already exists, disallowed. Did you mean to set reuse=True in VarScope?"" which seem to indicate that I am trying to relearn the parameter...",Solution Usage
15559,"I see the reinitializable iterators give us the ability to use the same iterator with multiple datasets but each time you run an init op, it essentially starts over on that dataset.",Solution Usage
15560,It works for me now.,Solution Usage
15561,@sguada I changed my old one where I manually tell it to train or not (based on a tf.cond) and now it seems the accuracy is up to ~95's again.,Solution Usage
15562,"(Think CODE in C#, CODE in Java and Scala.)",Solution Usage
15563,@winston-li I think you could just use CODE for that.,Solution Usage
15564,Or you may try to run UPDATE_OPS yourself explicitly as one [here](https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-279646674)CODE,Solution Usage
15565,@nmduc @davek44  I wrote some code to track the moving mean and moving variance computed in CODE during training and testing.,Solution Usage
15566,"I have created a program following the CIFAR example, where my code is structured as in CIFAR:-         Inference-         Loss-         Train",Solution Usage
15567,But validation performance still is poor if I feed {is_training: False}.,Solution Usage
15568,The right way to do testing is to define different behaviors for train and test as you mentioned.,Solution Usage
15569,"However, what I **did** find was that, obviously, we should use Tensorflow ops instead of standard comparisons since the result of CODE is a tensor and not a normal array.",Solution Usage
15570,Its seems like a non-trivial change (should it None be its default value then if it matters so much?).,Solution Usage
15571,Is it possible to address a single column in the dataset so that it is treated different from the other column?,Solution Usage
15572,"That said, looking at SwitchableDataSet, it seems like implementing new kinds of data feeding use cases will be mostly done by implementing use-case specific classes.",Solution Usage
15573,"The result turns out to be: the model performs pretty well on training mini-batches (you know at the beginning loss goes down quickly), but validation performance is erratic (because the estimated population mean/variance are not stable enough).",Solution Usage
15574,Also switching between e.g. training and validation dataset within one session works quite effortless.,Solution Usage
15575,But validation performance still is poor if I feed {is_training: False}.,Solution Usage
15576,"I got the following error in the training phase:Variable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?",Solution Usage
15577,"@dominikandreas If your poor testing performance is caused by statistics not converging, you'd see reasonably good training performance but bad testing performance.",Solution Usage
15578,"The model trains fine, but the test performance is terrible.",Solution Usage
15579,"Hi @zhongyuk , how did you keep track of the moving mean and variance?",Solution Usage
15580,"In contrast, if I maintain is_training_ph=True for test time, it works great.",Solution Usage
15581,"Just wanted to note that I also have the problem of poor test performance, specifically using small batch sizes (anything smaller than 10 instead of the 200 I used for training diminishes test accuracy).",Solution Usage
15582,"To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size.",Solution Usage
15583,"I followed the guidelines of dataset README.md, with pseudo code like following: def _parse_function(example_proto):features = {""image"": tf.FixedLenFeature((), tf.string, default_value=""""),""label"": tf.FixedLenFeature((), tf.int32, default_value=0)}parsed_features = tf.parse_single_example(example_proto, features)return parsed_features[""image""], parsed_features[""label""] BATCH_SIZE = 256filenames = [""/var/data/file1.tfrecord"", ""/var/data/file2.tfrecord""]dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(_parse_function)dataset = dataset.batch(BATCH_SIZE)dataset = dataset.filter(lambda imgs, lbls: tf.shape(imgs)[0] == BATCH_SIZE)iterator = dataset.make_initializable_iterator()next_element = iterator.get_next()images, labels = next_element # Training cycles for 100 epochs.for _ in range(100):sess.run(iterator.initializer)while True:try:images_r, labels_r = sess.run([images, labels])print(images_r.shape)except tf.errors.OutOfRangeError:break",Solution Usage
15584,My code is like this now:**Batch Normalisation wrapper**CODE**Model definition**CODE**Training**CODE**Validation**CODE,Solution Usage
15585,"To do this the CODE argument might help, but I'm not sure because I use my own version of bn layer.",Solution Usage
15586,Are there any concerns about calling CODE before CODE?,Solution Usage
15587,"I am confused on how to use it and the SO seems to be outdated and then there is a layer in a different link from the API, just how exactly does one do this?",Solution Usage
15588,One thing I notice is that the arguments CODE and CODE from CODE are missing in CODE; does that mean no parallel processing is possible?,Solution Usage
15589,So CODE,Solution Usage
15590,"**Another important thing is, be sure to use CODE to create train op**.",Solution Usage
15591,"@OktayGardener not sure what model are you trying to create, it seems that the variables are not saved in your checkpoint.",Solution Usage
15592,My code is like this now:**Batch Normalisation wrapper**CODE**Model definition**CODE**Training**CODE**Validation**CODE,Solution Usage
15593,"-         ~~I don't know how to access _control_flow_ops.with_dependencies()_. How can I access functions within control_flow_ops module? I have seen other examples just using tf.with_dependecies(), but I cannot do that with Tensorflow 0.10.~~ I found it here: _tf.python.control_flow_ops.with_dependencies()_",Solution Usage
15594,"In other versions of the code I get ""ValueError: Variable conv1/beta already exists, disallowed. Did you mean to set reuse=True in VarScope?"" which seem to indicate that I am trying to relearn the parameter...",Solution Usage
15595,@sguada I am not understanding the right way of using CODE specially concerning the flag CODE.,Solution Usage
15596,Had a similar problem and it went away when I used the fused version,Solution Usage
15597,To make those unique I had to set a scope per layer.,Solution Usage
15598,when I was trying to reuse.,Solution Usage
15599,"There, single string tensors come in (file names) and whole Datasets are emitted in the map function, so that seems pretty clear.",Solution Usage
15600,@pawni You have to use a Python boolean for CODE.,Solution Usage
15601,"@sguada  I have noticed that you said"" tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial"".",Solution Usage
15602,"where batch_norm_layer is similar to the examples from @nmhkahn @pawni, conv2d_stride2_valid is just a def to define a convolutional layer, and W_conv1 and b_conv1 are variables holding the weights and biases.",Solution Usage
15603,Here is my code:CODE,Solution Usage
15604,@sguada @brando90CODE,Solution Usage
15605,"Is there any code out there that uses this, even if that code is undocumented?",Solution Usage
15606,But this is a stupid way since you need to build more than one graph.,Solution Usage
15607,"I tried it on a 2 layered NN network based on the MNIST beginner tutorial and I consistently get worse results when BN is present: with BN (one with scale and center trained and the other not) accuracy is 0.8423, 0.8221 and without BN accuracy is 0.9477.",Solution Usage
15608,Do not use tf native CODE.,Solution Usage
15609,"To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size.",Solution Usage
15610,"You can also use tf.model_variables() which contains the variables of the model, i.e. moving_mean",Solution Usage
15611,"*         @guillaumekln ([link](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308789560)) If you want to batch sequences with different lengths, you can use the CODE transformation.",Solution Usage
15612,"@zhongyuk thanks, I've run about 5k updates with CODE, so it should've converged and testing performance using large batch sizes is fine.",Solution Usage
15613,I would like to encourage you to use [CODE] URL  or [CODE] URL  to build your model.,Solution Usage
15614,You can change the batch_size during test to see how the performance degrades as you make your batch smaller.,Solution Usage
15615,CODE,Solution Usage
15616,@Alexivia It seems that you are using two different batch normalization layers?,Solution Usage
15617,Validation loss goes down very quickly when I set CODE to 0.9.,Solution Usage
15618,"is there a small script with a very simple NN that shows what is the proper way of using this ""official"" BN layer?",Solution Usage
15619,I'm trying migrating input pipeline from tf.train.string_input_producer & tf.train.shuffle_batch to Dataset APIs.,Solution Usage
15620,I am using the same scope and CODE.,Solution Usage
15621,"Since we can only change tensors or placeholders with CODE, I changed CODE intentionally before running the graph.",Solution Usage
15622,"It seems the only way to use the official batch_norm is to build two graphs, one for train and one for evaluation, with CODE and CODE, respectively.",Solution Usage
15623,It tells to do the following: CODE,Solution Usage
15624,@Alexivia It seems that you are using two different batch normalization layers?,Solution Usage
15625,"@davek44 I'm using the same code framework that you are using and I observed the same thing: when turns on CODE during training phase and turns off CODE for validation and/or testing phase, the model trains well like the paper described (model converges faster and I was able to use a larger learning rate), however the testing performance is terrible.",Solution Usage
15626,"Without CODEset to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.",Solution Usage
15627,"My tf version's filter is broken, but if yours works could you try this instead? CODE",Solution Usage
15628,I am using the same scope and CODE.,Solution Usage
15629,I'm using python3 and didn't tried with python2.,Solution Usage
15630,Testing is not.,Solution Usage
15631,and because the session manager init doesn't initialise them properly: sess.run(tf.variables_initializer([x for x in tf.global_variables() if 'Adam' in x.name])) (Using tf.train.AdamOptimizer),Solution Usage
15632,Maybe here is a good place to refer to my Dataset related questions:,Solution Usage
15633,Obviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers.,Solution Usage
15634,Can anyone confirm good test performance with small or single data samples using this batch norm layer?,Solution Usage
15635,"However, I found that reusing 4 layers works.",Solution Usage
15636,"But even if it didn't, would it result in a difference between training a testing?",Solution Usage
15637,The net is working well now.,Solution Usage
15638,"@ppwwyyxx stated that queues and StagingArea can still be used with the Dataset API, but I still haven't seen a working example of this.",Solution Usage
15639,2.         using placeholder to switch between train and test evaluation,Solution Usage
15640,"Hi @ishaybee,I followed your advice, now my code is:CODE",Solution Usage
15641,I based my suggestion on the one flat_map code example on the github page you linked.,Solution Usage
15642,@diegoAtAlpine I found the same problems - not sure why this is the case though.,Solution Usage
15643,@pawni You have to use a Python boolean for CODE.,Solution Usage
15644,"hi,you need to set different scope for every time you use batch norm and give it the reuse input according to the training/test phase(TRUE when test FALSE when train) that works for me.",Solution Usage
15645,"If your feeling is that spacy is really meant for batch processing and that I should use mini-batches if I want to approximate streaming, I can do that.",Solution Usage
15646,"(I'm doing data parallelization on multiple gpus, and the batch_size is multiple of num_gpus).",Solution Usage
15647,"Edit: After writing this, i found it out: CODE",Solution Usage
15648,I've used a tf.placeholder to switch between testing/training mode.,Solution Usage
15649,"@abred : Yes, I used CODE, same problem.",Solution Usage
15650,"This is why tools like tf.estimator.Estimator were developed, to allow foreasier separation of concerns between training and inference and to allowfor swapping of input pipelines.",Solution Usage
15651,Can anyone confirm good test performance with small or single data samples using this batch norm layer?,Solution Usage
15652,for me things started to work when I used this wrapper:CODE,Solution Usage
15653,For example this pattern works well: CODE,Solution Usage
15654,"Passing CODE to the CODE call, and following that with CODE will run your CODE function in parallel and should decently increase the performance.",Solution Usage
15655,"Looks like the batch dimension is ""?"" (None?), so the predicate always fails...",Solution Usage
15656,"@nmhkahn  quick question. When you wrote (for testing): CODE in theory, can bx and by be any data set?",Solution Usage
15657,I based my suggestion on the one flat_map code example on the github page you linked.,Solution Usage
15658,and because the session manager init doesn't initialise them properly: sess.run(tf.variables_initializer([x for x in tf.global_variables() if 'Adam' in x.name])) (Using tf.train.AdamOptimizer),Solution Usage
15659,"sorry for the spamming, but what is wrong with just using something like this: CODE",Solution Usage
15660,I noticed after plotting accuracies in training and test mode that the testing accuracies start climbing after the training accuracies.,Solution Usage
15661,After taking a closer look at the code in contrib I realized what my problem was.,Solution Usage
15662,So during testing you would set the value to CODE and the CODE won't be used.,Solution Usage
15663,CODE,Solution Usage
15664,"I haven't figured out what I did wrong, I'm planning to use TensorBoard to monitor the parameters.",Solution Usage
15665,"The result turns out to be: the model performs pretty well on training mini-batches (you know at the beginning loss goes down quickly), but validation performance is erratic (because the estimated population mean/variance are not stable enough).",Solution Usage
15666,"It seems the only way to use the official batch_norm is to build two graphs, one for train and one for evaluation, with CODE and CODE, respectively.",Solution Usage
15667,"**Another important thing is, be sure to use CODE to create train op**.",Solution Usage
15668,So set the appropriate decay for your training step numbers.,Solution Usage
15669,Testing is not.,Solution Usage
15670,"@sguada Thanks, I build a network with bathnorm which is implemented as you mentioned above",Solution Usage
15671,There are two similar questions in [here] URL  and [here] URL @albertz.,Solution Usage
15672,It seems to work sometimes but I am not too sure.,Solution Usage
15673,do I need to set the reuse flag?,Solution Usage
15674,"But what it is important is that either you pass [updates_collections=None](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L142) so the moving_mean and moving_variance are updated in-place, otherwise you will need gather the update_ops and make sure they are run.",Solution Usage
15675,How to set the param of BatchNormLayer and ScaleLayer in Caffe?,Solution Usage
15676,"In the former case, when investigating the trained model, I found out that the moving mean and moving variance consist of all zeros.",Solution Usage
15677,"I would have preferred to leave it as a placeholder because this way I can do periodic testing during training without redefining the graph, but I decided to use it as a constant and define different behaviors for train vs test, and now the moments are not calculated at test time.",Solution Usage
15678,(There seem to be two places containing some amount of separate documentation: either on [GitHub] URL  or on [tensorflow.org](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/data/Dataset#flat_map)),Solution Usage
15679,"I still have to run this on a big dataset and check if there's any performance improvement, but at least it seems to execute correctly.",Solution Usage
15680,Here is my code:CODE,Solution Usage
15681,"I can confirm that test performance is good when using is_training=False with small batches and even with batch_size=1, since it is not using statistic from the batch, but the statistic learnt during training.",Solution Usage
15682,"If you know your batch size is for example 32, then something likeCODE",Solution Usage
15683,It works for me now.,Solution Usage
15684,"I did 2 test runs with the exact same code but different CODE settings in the CODE, and my validation/test accuracies seemed more reasonable.",Solution Usage
15685,Take a look at the documentation here [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data#creating-an-iterator).,Solution Usage
15686,Then I had to spend more time figuring out that by default the variables tracking the moments don't update unless you use a contrib function for optimization.,Solution Usage
15687,"Looks like the batch dimension is ""?"" (None?), so the predicate always fails...",Solution Usage
15688,"I believe that for the code to be used ""right out of the box"" the default should be None.",Solution Usage
15689,With tf.global_variables() the save files are much larger as I think it includes the gradients; in the end I used: saver = tf.train.Saver([x for x in tf.global_variables() if 'Adam' not in x.name]),Solution Usage
15690,I was trying to use batch norm with a 2 layered densely connected NN with the (flatten) MNIST  (and relu units) data set for the task of auto-encoding  and I keep getting a NaN error.,Solution Usage
15691,And the opposite while Testing.,Solution Usage
15692,"Inside your flatmap function, create a new Dataset object with one or multiple examples for every input example.",Solution Usage
15693,"Is there any code out there that uses this, even if that code is undocumented?",Solution Usage
15694,(There seem to be two places containing some amount of separate documentation: either on [GitHub] URL  or on [tensorflow.org](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/data/Dataset#flat_map)),Solution Usage
15695,Just put it in seperate collection-keys: CODE CODE,Solution Usage
15696,"I see the reinitializable iterators give us the ability to use the same iterator with multiple datasets but each time you run an init op, it essentially starts over on that dataset.",Solution Usage
15697,"Without CODEset to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.",Solution Usage
15698,E.g.: CODE,Solution Usage
15699,"Being a newer tf user, I found that my test error was crazy and then had to spend a fair amount of time debugging my graph until I realized that batch normalization was the problem.",Solution Usage
15700,So when I did: CODE,Solution Usage
15701,Then I had to spend more time figuring out that by default the variables tracking the moments don't update unless you use a contrib function for optimization.,Solution Usage
15702,"To save/restore them, you can use tf.global_variables()",Solution Usage
15703,Please help me how to continue training the model.,Solution Usage
15704,So set the appropriate decay for your training step numbers.,Solution Usage
15705,Is it possible to address a single column in the dataset so that it is treated different from the other column?,Solution Usage
15706,@ppwwyyxx do you have any example code for combining queues and the new dataset api?,Solution Usage
15707,"During training and testing we are either updating or reusing four variables (beta, gamma, moving_mean and moving_variance).",Solution Usage
15708,"You can also use tf.model_variables() which contains the variables of the model, i.e. moving_mean",Solution Usage
15709,For example this pattern works well: CODE,Solution Usage
15710,I'm currently using the new CODE and CODE apis along with CODE to accomplish this but is there a more direct/natural way in the works?,Solution Usage
15711,"but I think that the placeholder value is not being used, because I see no change if I force values to CODE function, and in TensorBoard it's not connected to the graph...",Solution Usage
15712,"I followed the guidelines of dataset README.md, with pseudo code like following: def _parse_function(example_proto):features = {""image"": tf.FixedLenFeature((), tf.string, default_value=""""),""label"": tf.FixedLenFeature((), tf.int32, default_value=0)}parsed_features = tf.parse_single_example(example_proto, features)return parsed_features[""image""], parsed_features[""label""] BATCH_SIZE = 256filenames = [""/var/data/file1.tfrecord"", ""/var/data/file2.tfrecord""]dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(_parse_function)dataset = dataset.batch(BATCH_SIZE)dataset = dataset.filter(lambda imgs, lbls: tf.shape(imgs)[0] == BATCH_SIZE)iterator = dataset.make_initializable_iterator()next_element = iterator.get_next()images, labels = next_element # Training cycles for 100 epochs.for _ in range(100):sess.run(iterator.initializer)while True:try:images_r, labels_r = sess.run([images, labels])print(images_r.shape)except tf.errors.OutOfRangeError:break",Solution Usage
15713,I answered @albertz's Stack Overflow question about doing this [here] URL .,Solution Usage
15714,"@nirmalthacker Yep, that's essentially what I meant.",Solution Usage
15715,"@MisayaZ I was having the same behavior using Batchnorm with a placeholder for ""is_training"".",Solution Usage
15716,"@sguada  I have noticed that you said"" tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial"".",Solution Usage
15717,I'm trying to test the example in the [doc](https://www.tensorflow.org/versions/r1.3/programmers_guide/datasets#preprocessing_data_with_datasetmap),Solution Usage
15718,"If you know your batch size is for example 32, then something likeCODE",Solution Usage
15719,"I would have preferred to leave it as a placeholder because this way I can do periodic testing during training without redefining the graph, but I decided to use it as a constant and define different behaviors for train vs test, and now the moments are not calculated at test time.",Solution Usage
15720,"I tried that, and now it stopped complaining about the value...",Solution Usage
15721,"I feel like maybe there should be a concrete example of how to do a batch norm with a fully connected net, as well as with CNNs.",Solution Usage
15722,"I found the dataset (after batch, prior to filter) was in this form:",Solution Usage
15723,"I tried creating two models like @sguada said, however, my model where is_training=False just crashes.",Solution Usage
15724,"Since we can only change tensors or placeholders with CODE, I changed CODE intentionally before running the graph.",Solution Usage
15725,"I have many different models that use different batch_norm layers, this wouldn't work right?: CODE",Solution Usage
15726,Maybe It could be nice to show how this placeholder thing should be used because it seems I don't understand how its suppose to be used.,Solution Usage
15727,Why was it that I needed to change updates_collections to be None?,Solution Usage
15728,In retrospect it make sense since we are collecting dataset statistics for testing.,Solution Usage
15729,for me things started to work when I used this wrapper:CODE,Solution Usage
15730,"@MisayaZ I was having the same behavior using Batchnorm with a placeholder for ""is_training"".",Solution Usage
15731,In retrospect it make sense since we are collecting dataset statistics for testing.,Solution Usage
15732,Have a look at [how this is used in the NMT model code](https://github.com/tensorflow/nmt/blob/04c8c04a8b4e805f3d0a9c42b4d17c85f1324c55/nmt/utils/iterator_utils.py#L194) for an example.,Solution Usage
15733,"I would greatly appreciate it if there's an official and complete (which means training, validating, testing are all included) batch normalization example.",Solution Usage
15734,because I'm noticing very slight changes with big impact on my accuracy (maybe my definition of performance is just more easily affected by this slight change).,Solution Usage
15735,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
15736,We had hoped to release by end oflast month but are getting delayed.,Task Progress
15737,Fixed!,Task Progress
15738,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress
15739,"Yeah for large vector models it would be a necessity, question is though where supporting that is on your timeline & plans for spaCy.",Task Progress
15740,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
15741,We'll plan to have an announcement when it's released.,Task Progress
15742,it's been 2 years and still no luck?,Task Progress
15743,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
15744,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
15745,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
15746,Everything should now pickle.,Task Progress
15747,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
15748,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
15749,Could someone please summarize where this currently stands?,Task Progress
15750,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
15751,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
15752,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
15753,will catch up with the latest commit and regenerate the model.,Task Progress
15754,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
15755,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
15756,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
15757,I made an initial stab at it here: https://github.com/tensorflow/tensorflow/pull/2206 - this is just a proof of concept that gets the version string into nodejs.,Task Progress
15758,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
15759,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
15760,@syllog1sm yes.,Task Progress
15761,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
15762,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
15763,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
15764,Were you able to implement this in spaCy?,Task Progress
15765,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
15766,Will a more stable fix be available in next 1.x releases?,Task Progress
15767,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
15768,"At cursory glance, so far you seem to be doing the right thing.",Task Progress
15769,We're decided to start from a clean slate and redesign the input pipeline API.,Task Progress
15770,"Hi all, I created the Node.js bridging library for Tensorflow at: https://github.com/yorkie/tensorflow-nodejs without SWIG, it has supported ""predefined graph running"" and very simple ""graph construction"", I'm also planing to support more client features in the future :)",Task Progress
15771,We should fix that.,Task Progress
15772,and do we need to fix the other test failures for scikit-learn 0.19 to shipwith Debian?,Task Progress
15773,Just pushed v0.95.,Task Progress
15774,@act65 we are more than keen to get to the bottom of this but we haven't been able to reproduce and it seems like we are getting mixed reports from users so far unfortunately.,Task Progress
15775,I'll probably get back to it week after next.,Task Progress
15776,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
15777,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
15778,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
15779,Or was it a code change?,Task Progress
15780,We had hoped to release by end oflast month but are getting delayed.,Task Progress
15781,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
15782,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
15783,Work in progress for spaCy v2.0!,Task Progress
15784,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
15785,We're working on a new seq2seq tutorial.,Task Progress
15786,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
15787,Could someone please summarize where this currently stands?,Task Progress
15788,Is there any update on this?,Task Progress
15789,No solution yet!?,Task Progress
15790,@syw2014 Did you fix your issue?,Task Progress
15791,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
15792,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
15793,@syllog1sm yes.,Task Progress
15794,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
15795,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
15796,Implemented ð,Task Progress
15797,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress
15798,"But if we want to have it propagate into testing and thus become a part of the next Debian stable release (Whenever that would be) -- yes, should get addressed one way (fixed) or another (disabled)",Task Progress
15799,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
15800,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
15801,it's been 2 years and still no luck?,Task Progress
15802,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
15803,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
15804,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
15805,Will a more stable fix be available in next 1.x releases?,Task Progress
15806,"@geovedi , were you working on Bahasa?",Task Progress
15807,This is still in progress.,Task Progress
15808,Is there any update ??,Task Progress
15809,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
15810,it's been 2 years and still no luck?,Task Progress
15811,No solution yet!?,Task Progress
15812,We're working on a new seq2seq tutorial.,Task Progress
15813,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
15814,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
15815,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
15816,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
15817,Is this in place yet?,Task Progress
15818,is there a way you know to make this work currently?,Task Progress
15819,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
15820,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
15821,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
15822,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress
15823,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
15824,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
15825,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
15826,@bowu - did you have any luck with this?,Task Progress
15827,@geovedi do you have a fork or branch i can check out?,Task Progress
15828,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
15829,it's been 2 years and still no luck?,Task Progress
15830,Working on it.,Task Progress
15831,"Obviously, there's still a lot to do to support more languages.",Task Progress
15832,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
15833,Working on it.,Task Progress
15834,Have you figured it out?,Task Progress
15835,Have you solved it ?,Task Progress
15836,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
15837,"@ebrevdo Congratulations, TF 1.2 just got released - was the new tutorial also released somewhere or is it being released anytime soon?",Task Progress
15838,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
15839,Have you figured it out?,Task Progress
15840,Is there any update on this?,Task Progress
15841,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
15842,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
15843,We're decided to start from a clean slate and redesign the input pipeline API.,Task Progress
15844,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
15845,"Dears,Is this issue resolved with the release of spacy 2.0.",Task Progress
15846,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
15847,But with that switch enabled next releases will work properly on Windows,Task Progress
15848,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
15849,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
15850,@act65 we are more than keen to get to the bottom of this but we haven't been able to reproduce and it seems like we are getting mixed reports from users so far unfortunately.,Task Progress
15851,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
15852,Working on it.,Task Progress
15853,P.S. https://github.com/scikit-learn-contrib/categorical-encoding ?,Task Progress
15854,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
15855,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
15856,@geovedi do you have a fork or branch i can check out?,Task Progress
15857,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
15858,So unfortunately I have to move this out of the milestone.,Task Progress
15859,@geovedi do you have a fork or branch i can check out?,Task Progress
15860,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
15861,Fix should be out soon.,Task Progress
15862,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
15863,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
15864,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
15865,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
15866,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
15867,Or was it a code change?,Task Progress
15868,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress
15869,Work in progress for spaCy v2.0!,Task Progress
15870,It is now implemented in GBRT.,Task Progress
15871,will catch up with the latest commit and regenerate the model.,Task Progress
15872,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
15873,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
15874,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
15875,"Yeah for large vector models it would be a necessity, question is though where supporting that is on your timeline & plans for spaCy.",Task Progress
15876,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
15877,"@yarikoptic, we would like to release.",Task Progress
15878,is there a way you know to make this work currently?,Task Progress
15879,We're hoping for this coming week!,Task Progress
15880,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
15881,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
15882,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
15883,"But if we want to have it propagate into testing and thus become a part of the next Debian stable release (Whenever that would be) -- yes, should get addressed one way (fixed) or another (disabled)",Task Progress
15884,No solution yet!?,Task Progress
15885,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
15886,Have you solved it ?,Task Progress
15887,Working on it.,Task Progress
15888,so no solution yet?,Task Progress
15889,"(and once we agree on that part, there is still a lot to discuss about the actual implementation in the PR :))",Task Progress
15890,it's been awhile tho.,Task Progress
15891,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
15892,But with that switch enabled next releases will work properly on Windows,Task Progress
15893,"Hi all, I created the Node.js bridging library for Tensorflow at: https://github.com/yorkie/tensorflow-nodejs without SWIG, it has supported ""predefined graph running"" and very simple ""graph construction"", I'm also planing to support more client features in the future :)",Task Progress
15894,We're working on a new seq2seq tutorial.,Task Progress
15895,Is this in place yet?,Task Progress
15896,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress
15897,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
15898,will catch up with the latest commit and regenerate the model.,Task Progress
15899,"Dears,Is this issue resolved with the release of spacy 2.0.",Task Progress
15900,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
15901,seems to work for everybody now.,Task Progress
15902,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
15903,"Hi all, I created the Node.js bridging library for Tensorflow at: https://github.com/yorkie/tensorflow-nodejs without SWIG, it has supported ""predefined graph running"" and very simple ""graph construction"", I'm also planing to support more client features in the future :)",Task Progress
15904,"Obviously, there's still a lot to do to support more languages.",Task Progress
15905,@honnibal could we get an update on the current status of this and your thoughts on how best to proceed?,Task Progress
15906,@bowu - did you have any luck with this?,Task Progress
15907,is there a way you know to make this work currently?,Task Progress
15908,I'll try to update the forests with the same mechanism before the release.,Task Progress
15909,I'll probably get back to it week after next.,Task Progress
15910,I'll probably get back to it week after next.,Task Progress
15911,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
15912,Is there any update ??,Task Progress
15913,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
15914,@geovedi do you have a fork or branch i can check out?,Task Progress
15915,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
15916,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
15917,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
15918,We had hoped to release by end oflast month but are getting delayed.,Task Progress
15919,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
15920,I'll probably get back to it week after next.,Task Progress
15921,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
15922,We're hoping for this coming week!,Task Progress
15923,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
15924,https://github.com/tngan/tensornode,Task Progress
15925,well -- for unstable Debian -- no.,Task Progress
15926,Have you solved it ?,Task Progress
15927,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
15928,@bowu - did you have any luck with this?,Task Progress
15929,Will a more stable fix be available in next 1.x releases?,Task Progress
15930,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
15931,I made an initial stab at it here: https://github.com/tensorflow/tensorflow/pull/2206 - this is just a proof of concept that gets the version string into nodejs.,Task Progress
15932,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
15933,Or was it a code change?,Task Progress
15934,"@geovedi , were you working on Bahasa?",Task Progress
15935,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
15936,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
15937,"Obviously, there's still a lot to do to support more languages.",Task Progress
15938,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress
15939,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
15940,We're still refactoring and working on better processes for adding more languages.,Task Progress
15941,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
15942,So my questions are as follows:1)         Is it planned to deal with this issue somehow?,Task Progress
15943,TF1.2 will solve this problem?,Task Progress
15944,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
15945,We had hoped to release by end oflast month but are getting delayed.,Task Progress
15946,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
15947,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
15948,Fix should be out soon.,Task Progress
15949,Were you able to implement this in spaCy?,Task Progress
15950,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
15951,We're decided to start from a clean slate and redesign the input pipeline API.,Task Progress
15952,seems to work for everybody now.,Task Progress
15953,No solution yet!?,Task Progress
15954,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
15955,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress
15956,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
15957,Have you figured it out?,Task Progress
15958,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
15959,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
15960,@syllog1sm yes.,Task Progress
15961,@bowu - did you have any luck with this?,Task Progress
15962,@geovedi do you have a fork or branch i can check out?,Task Progress
15963,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
15964,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
15965,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
15966,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
15967,Will a more stable fix be available in next 1.x releases?,Task Progress
15968,But with that switch enabled next releases will work properly on Windows,Task Progress
15969,Will a more stable fix be available in next 1.x releases?,Task Progress
15970,So my questions are as follows:1)         Is it planned to deal with this issue somehow?,Task Progress
15971,Fixed!,Task Progress
15972,Work in progress for spaCy v2.0!,Task Progress
15973,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
15974,We should fix that.,Task Progress
15975,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
15976,"Need to update other modules to reflect the change, and do testing.",Task Progress
15977,will catch up with the latest commit and regenerate the model.,Task Progress
15978,"So I tried to put the above logic in code (will push some updates to the PR), and I have one more question for the case of integer data when CODE or CODE is not set (typical case for 'legacy_mode').",Task Progress
15979,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
15980,"Yeah for large vector models it would be a necessity, question is though where supporting that is on your timeline & plans for spaCy.",Task Progress
15981,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
15982,"We're still finishing up the blog post etc, but the model is uploaded and can be used from spaCy 0.100.7.",Task Progress
15983,Have you figured it out?,Task Progress
15984,We'll plan to have an announcement when it's released.,Task Progress
15985,TF1.2 will solve this problem?,Task Progress
15986,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
15987,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
15988,Have you guys solved this problem?,Task Progress
15989,Is this in place yet?,Task Progress
15990,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress
15991,No solution yet!?,Task Progress
15992,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
15993,"But if we want to have it propagate into testing and thus become a part of the next Debian stable release (Whenever that would be) -- yes, should get addressed one way (fixed) or another (disabled)",Task Progress
15994,TF1.2 will solve this problem?,Task Progress
15995,Is there any update on this?,Task Progress
15996,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
15997,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
15998,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
15999,The next steps would be to define the areas that the bindings would initially cover (must be within the C++ API ) and start implementing the SWIG interface files for these.,Task Progress
16000,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16001,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
16002,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16003,Fixed!,Task Progress
16004,I'll probably get back to it week after next.,Task Progress
16005,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
16006,Thats my next step.,Task Progress
16007,it's been 2 years and still no luck?,Task Progress
16008,"From what I see, in version 2.0 the problem still exists.",Task Progress
16009,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16010,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16011,"At cursory glance, so far you seem to be doing the right thing.",Task Progress
16012,and do we need to fix the other test failures for scikit-learn 0.19 to shipwith Debian?,Task Progress
16013,Will a more stable fix be available in next 1.x releases?,Task Progress
16014,We should fix that.,Task Progress
16015,is there a way you know to make this work currently?,Task Progress
16016,https://github.com/node-tensorflow/node-tensorflow/tree/1.0.0,Task Progress
16017,Will a more stable fix be available in next 1.x releases?,Task Progress
16018,Could someone please summarize where this currently stands?,Task Progress
16019,"Dears,Is this issue resolved with the release of spacy 2.0.",Task Progress
16020,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16021,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress
16022,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16023,Have you figured it out?,Task Progress
16024,Is there any update ??,Task Progress
16025,Will a more stable fix be available in next 1.x releases?,Task Progress
16026,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress
16027,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16028,@geovedi do you have a fork or branch i can check out?,Task Progress
16029,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
16030,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
16031,Work in progress for spaCy v2.0!,Task Progress
16032,@syw2014 Did you fix your issue?,Task Progress
16033,Or was it a code change?,Task Progress
16034,Fix should be out soon.,Task Progress
16035,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
16036,The next steps would be to define the areas that the bindings would initially cover (must be within the C++ API ) and start implementing the SWIG interface files for these.,Task Progress
16037,This is still in progress.,Task Progress
16038,Is there any update on this?,Task Progress
16039,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
16040,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
16041,well -- for unstable Debian -- no.,Task Progress
16042,Everything should now pickle.,Task Progress
16043,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
16044,"But if we want to have it propagate into testing and thus become a part of the next Debian stable release (Whenever that would be) -- yes, should get addressed one way (fixed) or another (disabled)",Task Progress
16045,well -- for unstable Debian -- no.,Task Progress
16046,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
16047,I made an initial stab at it here: https://github.com/tensorflow/tensorflow/pull/2206 - this is just a proof of concept that gets the version string into nodejs.,Task Progress
16048,No solution yet!?,Task Progress
16049,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
16050,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
16051,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
16052,I'll try to update the forests with the same mechanism before the release.,Task Progress
16053,No solution yet!?,Task Progress
16054,"Yeah for large vector models it would be a necessity, question is though where supporting that is on your timeline & plans for spaCy.",Task Progress
16055,We should fix that.,Task Progress
16056,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16057,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16058,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
16059,Fixed!,Task Progress
16060,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
16061,it's been awhile tho.,Task Progress
16062,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
16063,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
16064,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16065,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16066,will catch up with the latest commit and regenerate the model.,Task Progress
16067,Fix should be out soon.,Task Progress
16068,P.S. https://github.com/scikit-learn-contrib/categorical-encoding ?,Task Progress
16069,will catch up with the latest commit and regenerate the model.,Task Progress
16070,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
16071,@honnibal could we get an update on the current status of this and your thoughts on how best to proceed?,Task Progress
16072,Could someone please summarize where this currently stands?,Task Progress
16073,Is this in place yet?,Task Progress
16074,Does anybody plan to add a support for Russian?,Task Progress
16075,The proposal is released here with current progress.,Task Progress
16076,"Obviously, there's still a lot to do to support more languages.",Task Progress
16077,Have you solved it ?,Task Progress
16078,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
16079,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
16080,The proposal is released here with current progress.,Task Progress
16081,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
16082,We'll plan to have an announcement when it's released.,Task Progress
16083,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
16084,Just pushed v0.95.,Task Progress
16085,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
16086,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
16087,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
16088,Have you solved it ?,Task Progress
16089,I'll probably get back to it week after next.,Task Progress
16090,We're hoping for this coming week!,Task Progress
16091,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
16092,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
16093,https://github.com/node-tensorflow/node-tensorflow/tree/1.0.0,Task Progress
16094,So unfortunately I have to move this out of the milestone.,Task Progress
16095,and do we need to fix the other test failures for scikit-learn 0.19 to shipwith Debian?,Task Progress
16096,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16097,We're still refactoring and working on better processes for adding more languages.,Task Progress
16098,Will a more stable fix be available in next 1.x releases?,Task Progress
16099,Implemented ð,Task Progress
16100,so no solution yet?,Task Progress
16101,First documentation on master under CODE: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data,Task Progress
16102,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16103,@geovedi do you have a fork or branch i can check out?,Task Progress
16104,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
16105,Or was it a code change?,Task Progress
16106,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16107,Fix should be out soon.,Task Progress
16108,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
16109,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
16110,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
16111,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
16112,Have you solved it ?,Task Progress
16113,We're working on a new seq2seq tutorial.,Task Progress
16114,We're still refactoring and working on better processes for adding more languages.,Task Progress
16115,We'll plan to have an announcement when it's released.,Task Progress
16116,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
16117,it's been 2 years and still no luck?,Task Progress
16118,"@yarikoptic, we would like to release.",Task Progress
16119,Were you able to implement this in spaCy?,Task Progress
16120,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16121,The proposal is released here with current progress.,Task Progress
16122,and do we need to fix the other test failures for scikit-learn 0.19 to shipwith Debian?,Task Progress
16123,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16124,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress
16125,Thats my next step.,Task Progress
16126,"So I tried to put the above logic in code (will push some updates to the PR), and I have one more question for the case of integer data when CODE or CODE is not set (typical case for 'legacy_mode').",Task Progress
16127,Have you figured it out?,Task Progress
16128,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16129,"Obviously, there's still a lot to do to support more languages.",Task Progress
16130,The next steps would be to define the areas that the bindings would initially cover (must be within the C++ API ) and start implementing the SWIG interface files for these.,Task Progress
16131,Have you solved it ?,Task Progress
16132,Just pushed v0.95.,Task Progress
16133,well -- for unstable Debian -- no.,Task Progress
16134,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
16135,well -- for unstable Debian -- no.,Task Progress
16136,https://github.com/tngan/tensornode,Task Progress
16137,P.S. https://github.com/scikit-learn-contrib/categorical-encoding ?,Task Progress
16138,This is still in progress.,Task Progress
16139,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
16140,"@ebrevdo Congratulations, TF 1.2 just got released - was the new tutorial also released somewhere or is it being released anytime soon?",Task Progress
16141,I'll try to update the forests with the same mechanism before the release.,Task Progress
16142,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
16143,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16144,First documentation on master under CODE: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data,Task Progress
16145,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16146,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
16147,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16148,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16149,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
16150,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress
16151,I'll probably get back to it week after next.,Task Progress
16152,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16153,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
16154,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
16155,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
16156,Implemented ð,Task Progress
16157,it's been 2 years and still no luck?,Task Progress
16158,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
16159,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
16160,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16161,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
16162,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16163,We should fix that.,Task Progress
16164,Thats my next step.,Task Progress
16165,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
16166,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16167,Were you able to implement this in spaCy?,Task Progress
16168,Thats my next step.,Task Progress
16169,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
16170,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
16171,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
16172,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16173,seems to work for everybody now.,Task Progress
16174,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16175,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16176,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16177,Just pushed v0.95.,Task Progress
16178,Fixed!,Task Progress
16179,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
16180,well -- for unstable Debian -- no.,Task Progress
16181,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16182,Is anybody working on this?,Task Progress
16183,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
16184,"So I tried to put the above logic in code (will push some updates to the PR), and I have one more question for the case of integer data when CODE or CODE is not set (typical case for 'legacy_mode').",Task Progress
16185,Just pushed v0.95.,Task Progress
16186,will catch up with the latest commit and regenerate the model.,Task Progress
16187,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
16188,it's been awhile tho.,Task Progress
16189,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
16190,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16191,"Hi all, I created the Node.js bridging library for Tensorflow at: https://github.com/yorkie/tensorflow-nodejs without SWIG, it has supported ""predefined graph running"" and very simple ""graph construction"", I'm also planing to support more client features in the future :)",Task Progress
16192,Is anybody working on this?,Task Progress
16193,"We're still finishing up the blog post etc, but the model is uploaded and can be used from spaCy 0.100.7.",Task Progress
16194,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16195,"At cursory glance, so far you seem to be doing the right thing.",Task Progress
16196,We're still refactoring and working on better processes for adding more languages.,Task Progress
16197,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
16198,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
16199,"Hi all, I created the Node.js bridging library for Tensorflow at: https://github.com/yorkie/tensorflow-nodejs without SWIG, it has supported ""predefined graph running"" and very simple ""graph construction"", I'm also planing to support more client features in the future :)",Task Progress
16200,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
16201,No solution yet!?,Task Progress
16202,"@ebrevdo Congratulations, TF 1.2 just got released - was the new tutorial also released somewhere or is it being released anytime soon?",Task Progress
16203,seems to work for everybody now.,Task Progress
16204,Is there any update on this?,Task Progress
16205,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
16206,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
16207,is there a way you know to make this work currently?,Task Progress
16208,"At cursory glance, so far you seem to be doing the right thing.",Task Progress
16209,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
16210,But with that switch enabled next releases will work properly on Windows,Task Progress
16211,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
16212,Have you guys solved this problem?,Task Progress
16213,@bowu - did you have any luck with this?,Task Progress
16214,TF1.2 will solve this problem?,Task Progress
16215,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16216,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
16217,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
16218,This is still in progress.,Task Progress
16219,The next steps would be to define the areas that the bindings would initially cover (must be within the C++ API ) and start implementing the SWIG interface files for these.,Task Progress
16220,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16221,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16222,@syw2014 Did you fix your issue?,Task Progress
16223,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
16224,Work in progress for spaCy v2.0!,Task Progress
16225,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16226,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16227,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
16228,"Obviously, there's still a lot to do to support more languages.",Task Progress
16229,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16230,It is now implemented in GBRT.,Task Progress
16231,"Need to update other modules to reflect the change, and do testing.",Task Progress
16232,Thats my next step.,Task Progress
16233,I'll try to update the forests with the same mechanism before the release.,Task Progress
16234,"@geovedi , were you working on Bahasa?",Task Progress
16235,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
16236,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
16237,Work in progress for spaCy v2.0!,Task Progress
16238,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16239,Or is this a TODO?,Task Progress
16240,Or is this a TODO?,Task Progress
16241,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16242,Is there any update ??,Task Progress
16243,Implemented ð,Task Progress
16244,"Obviously, there's still a lot to do to support more languages.",Task Progress
16245,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
16246,We're decided to start from a clean slate and redesign the input pipeline API.,Task Progress
16247,Or is this a TODO?,Task Progress
16248,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
16249,I'll probably get back to it week after next.,Task Progress
16250,We should fix that.,Task Progress
16251,it's been awhile tho.,Task Progress
16252,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16253,It is now implemented in GBRT.,Task Progress
16254,Thats my next step.,Task Progress
16255,Could someone please summarize where this currently stands?,Task Progress
16256,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16257,"But if we want to have it propagate into testing and thus become a part of the next Debian stable release (Whenever that would be) -- yes, should get addressed one way (fixed) or another (disabled)",Task Progress
16258,We're decided to start from a clean slate and redesign the input pipeline API.,Task Progress
16259,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16260,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
16261,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
16262,We had hoped to release by end oflast month but are getting delayed.,Task Progress
16263,It is now implemented in GBRT.,Task Progress
16264,This is still in progress.,Task Progress
16265,"We're still finishing up the blog post etc, but the model is uploaded and can be used from spaCy 0.100.7.",Task Progress
16266,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16267,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16268,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
16269,So unfortunately I have to move this out of the milestone.,Task Progress
16270,I'll try to update the forests with the same mechanism before the release.,Task Progress
16271,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
16272,So unfortunately I have to move this out of the milestone.,Task Progress
16273,seems to work for everybody now.,Task Progress
16274,@geovedi do you have a fork or branch i can check out?,Task Progress
16275,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16276,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
16277,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
16278,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16279,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
16280,Fixed!,Task Progress
16281,@bowu - did you have any luck with this?,Task Progress
16282,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
16283,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
16284,and do we need to fix the other test failures for scikit-learn 0.19 to shipwith Debian?,Task Progress
16285,is there a way you know to make this work currently?,Task Progress
16286,Just pushed v0.95.,Task Progress
16287,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
16288,TF1.2 will solve this problem?,Task Progress
16289,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
16290,https://github.com/node-tensorflow/node-tensorflow/tree/1.0.0,Task Progress
16291,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress
16292,No solution yet!?,Task Progress
16293,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16294,Or was it a code change?,Task Progress
16295,We had hoped to release by end oflast month but are getting delayed.,Task Progress
16296,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
16297,Everything should now pickle.,Task Progress
16298,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
16299,@geovedi do you have a fork or branch i can check out?,Task Progress
16300,"Obviously, there's still a lot to do to support more languages.",Task Progress
16301,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
16302,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress
16303,https://github.com/tngan/tensornode,Task Progress
16304,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
16305,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
16306,Work in progress for spaCy v2.0!,Task Progress
16307,will catch up with the latest commit and regenerate the model.,Task Progress
16308,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
16309,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
16310,So my questions are as follows:1)         Is it planned to deal with this issue somehow?,Task Progress
16311,Or is this a TODO?,Task Progress
16312,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
16313,"So I tried to put the above logic in code (will push some updates to the PR), and I have one more question for the case of integer data when CODE or CODE is not set (typical case for 'legacy_mode').",Task Progress
16314,well -- for unstable Debian -- no.,Task Progress
16315,https://github.com/tngan/tensornode,Task Progress
16316,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16317,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16318,Everything should now pickle.,Task Progress
16319,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
16320,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
16321,@honnibal could we get an update on the current status of this and your thoughts on how best to proceed?,Task Progress
16322,@act65 we are more than keen to get to the bottom of this but we haven't been able to reproduce and it seems like we are getting mixed reports from users so far unfortunately.,Task Progress
16323,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
16324,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
16325,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress
16326,We should fix that.,Task Progress
16327,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16328,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
16329,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
16330,Everything should now pickle.,Task Progress
16331,Is there any update ??,Task Progress
16332,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
16333,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress
16334,so no solution yet?,Task Progress
16335,I'll probably get back to it week after next.,Task Progress
16336,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16337,Implemented ð,Task Progress
16338,I'll probably get back to it week after next.,Task Progress
16339,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
16340,I'll try to update the forests with the same mechanism before the release.,Task Progress
16341,seems to work for everybody now.,Task Progress
16342,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
16343,Fixed!,Task Progress
16344,First documentation on master under CODE: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data,Task Progress
16345,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16346,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16347,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
16348,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
16349,@honnibal could we get an update on the current status of this and your thoughts on how best to proceed?,Task Progress
16350,"@geovedi , were you working on Bahasa?",Task Progress
16351,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16352,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
16353,Could someone please summarize where this currently stands?,Task Progress
16354,@geovedi do you have a fork or branch i can check out?,Task Progress
16355,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
16356,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
16357,"From what I see, in version 2.0 the problem still exists.",Task Progress
16358,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
16359,Just pushed v0.95.,Task Progress
16360,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
16361,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
16362,"@yarikoptic, we would like to release.",Task Progress
16363,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
16364,Is there any update ??,Task Progress
16365,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16366,Is there any update on this?,Task Progress
16367,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
16368,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress
16369,it's been awhile tho.,Task Progress
16370,The next steps would be to define the areas that the bindings would initially cover (must be within the C++ API ) and start implementing the SWIG interface files for these.,Task Progress
16371,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
16372,"Obviously, there's still a lot to do to support more languages.",Task Progress
16373,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
16374,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16375,P.S. https://github.com/scikit-learn-contrib/categorical-encoding ?,Task Progress
16376,so no solution yet?,Task Progress
16377,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16378,it's been 2 years and still no luck?,Task Progress
16379,It is now implemented in GBRT.,Task Progress
16380,seems to work for everybody now.,Task Progress
16381,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16382,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress
16383,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
16384,seems to work for everybody now.,Task Progress
16385,Have you figured it out?,Task Progress
16386,Fix should be out soon.,Task Progress
16387,seems to work for everybody now.,Task Progress
16388,We'll plan to have an announcement when it's released.,Task Progress
16389,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
16390,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16391,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
16392,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16393,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
16394,Fix should be out soon.,Task Progress
16395,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16396,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress
16397,Work in progress for spaCy v2.0!,Task Progress
16398,TF1.2 will solve this problem?,Task Progress
16399,The proposal is released here with current progress.,Task Progress
16400,@bowu - did you have any luck with this?,Task Progress
16401,seems to work for everybody now.,Task Progress
16402,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
16403,So unfortunately I have to move this out of the milestone.,Task Progress
16404,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
16405,Or was it a code change?,Task Progress
16406,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
16407,Will a more stable fix be available in next 1.x releases?,Task Progress
16408,Have you guys solved this problem?,Task Progress
16409,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
16410,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress
16411,So my questions are as follows:1)         Is it planned to deal with this issue somehow?,Task Progress
16412,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16413,Is anybody working on this?,Task Progress
16414,It is now implemented in GBRT.,Task Progress
16415,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16416,Have you figured it out?,Task Progress
16417,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
16418,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
16419,It is now implemented in GBRT.,Task Progress
16420,will catch up with the latest commit and regenerate the model.,Task Progress
16421,"(and once we agree on that part, there is still a lot to discuss about the actual implementation in the PR :))",Task Progress
16422,it's been awhile tho.,Task Progress
16423,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
16424,I'll probably get back to it week after next.,Task Progress
16425,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16426,@act65 we are more than keen to get to the bottom of this but we haven't been able to reproduce and it seems like we are getting mixed reports from users so far unfortunately.,Task Progress
16427,Have you solved it ?,Task Progress
16428,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress
16429,The proposal is released here with current progress.,Task Progress
16430,well -- for unstable Debian -- no.,Task Progress
16431,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
16432,@syllog1sm yes.,Task Progress
16433,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
16434,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16435,Work in progress for spaCy v2.0!,Task Progress
16436,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
16437,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
16438,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress
16439,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16440,so no solution yet?,Task Progress
16441,@honnibal could we get an update on the current status of this and your thoughts on how best to proceed?,Task Progress
16442,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
16443,so no solution yet?,Task Progress
16444,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16445,We're hoping for this coming week!,Task Progress
16446,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
16447,Work in progress for spaCy v2.0!,Task Progress
16448,@syllog1sm yes.,Task Progress
16449,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
16450,TF1.2 will solve this problem?,Task Progress
16451,Could someone please summarize where this currently stands?,Task Progress
16452,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
16453,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16454,Have you solved it ?,Task Progress
16455,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16456,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16457,Fixed!,Task Progress
16458,@syw2014 Did you fix your issue?,Task Progress
16459,Fixed!,Task Progress
16460,But with that switch enabled next releases will work properly on Windows,Task Progress
16461,Just pushed v0.95.,Task Progress
16462,@syllog1sm yes.,Task Progress
16463,We had hoped to release by end oflast month but are getting delayed.,Task Progress
16464,No solution yet!?,Task Progress
16465,The proposal is released here with current progress.,Task Progress
16466,TF1.2 will solve this problem?,Task Progress
16467,Thats my next step.,Task Progress
16468,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16469,Fixed!,Task Progress
16470,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress
16471,so no solution yet?,Task Progress
16472,@syw2014 Did you fix your issue?,Task Progress
16473,Is this in place yet?,Task Progress
16474,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
16475,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
16476,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
16477,We had hoped to release by end oflast month but are getting delayed.,Task Progress
16478,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
16479,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
16480,Were you able to implement this in spaCy?,Task Progress
16481,Have you figured it out?,Task Progress
16482,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
16483,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
16484,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
16485,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
16486,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
16487,"We're still finishing up the blog post etc, but the model is uploaded and can be used from spaCy 0.100.7.",Task Progress
16488,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress
16489,"@geovedi , were you working on Bahasa?",Task Progress
16490,So unfortunately I have to move this out of the milestone.,Task Progress
16491,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16492,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
16493,Thats my next step.,Task Progress
16494,Just pushed v0.95.,Task Progress
16495,We're working on a new seq2seq tutorial.,Task Progress
16496,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
16497,Is there any update on this?,Task Progress
16498,I made an initial stab at it here: https://github.com/tensorflow/tensorflow/pull/2206 - this is just a proof of concept that gets the version string into nodejs.,Task Progress
16499,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
16500,We'll plan to have an announcement when it's released.,Task Progress
16501,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16502,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
16503,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16504,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress
16505,Does anybody plan to add a support for Russian?,Task Progress
16506,@geovedi do you have a fork or branch i can check out?,Task Progress
16507,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
16508,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
16509,We're hoping for this coming week!,Task Progress
16510,We should fix that.,Task Progress
16511,seems to work for everybody now.,Task Progress
16512,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16513,"From what I see, in version 2.0 the problem still exists.",Task Progress
16514,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
16515,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress
16516,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16517,First documentation on master under CODE: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data,Task Progress
16518,"But if we want to have it propagate into testing and thus become a part of the next Debian stable release (Whenever that would be) -- yes, should get addressed one way (fixed) or another (disabled)",Task Progress
16519,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
16520,We had hoped to release by end oflast month but are getting delayed.,Task Progress
16521,P.S. https://github.com/scikit-learn-contrib/categorical-encoding ?,Task Progress
16522,We should fix that.,Task Progress
16523,"(and once we agree on that part, there is still a lot to discuss about the actual implementation in the PR :))",Task Progress
16524,We're hoping for this coming week!,Task Progress
16525,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
16526,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16527,@jwkvam We recently agreed in #2570 to implement this feature using the CODE parameter.,Task Progress
16528,We're decided to start from a clean slate and redesign the input pipeline API.,Task Progress
16529,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
16530,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16531,will catch up with the latest commit and regenerate the model.,Task Progress
16532,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
16533,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16534,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
16535,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
16536,is there a way you know to make this work currently?,Task Progress
16537,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16538,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
16539,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
16540,@syw2014 Did you fix your issue?,Task Progress
16541,Have you guys solved this problem?,Task Progress
16542,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
16543,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
16544,"@geovedi , were you working on Bahasa?",Task Progress
16545,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress
16546,We should fix that.,Task Progress
16547,https://github.com/node-tensorflow/node-tensorflow/tree/1.0.0,Task Progress
16548,"Dears,Is this issue resolved with the release of spacy 2.0.",Task Progress
16549,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16550,So unfortunately I have to move this out of the milestone.,Task Progress
16551,Does anybody plan to add a support for Russian?,Task Progress
16552,First documentation on master under CODE: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data,Task Progress
16553,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16554,Everything should now pickle.,Task Progress
16555,P.S. https://github.com/scikit-learn-contrib/categorical-encoding ?,Task Progress
16556,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
16557,@syw2014 Did you fix your issue?,Task Progress
16558,So unfortunately I have to move this out of the milestone.,Task Progress
16559,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
16560,We're decided to start from a clean slate and redesign the input pipeline API.,Task Progress
16561,Have you solved it ?,Task Progress
16562,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16563,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
16564,Have you figured it out?,Task Progress
16565,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
16566,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
16567,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
16568,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
16569,"At cursory glance, so far you seem to be doing the right thing.",Task Progress
16570,@geovedi do you have a fork or branch i can check out?,Task Progress
16571,@bowu - did you have any luck with this?,Task Progress
16572,Does anybody plan to add a support for Russian?,Task Progress
16573,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
16574,Is anybody working on this?,Task Progress
16575,seems to work for everybody now.,Task Progress
16576,I'll try to update the forests with the same mechanism before the release.,Task Progress
16577,"@yarikoptic, we would like to release.",Task Progress
16578,We're decided to start from a clean slate and redesign the input pipeline API.,Task Progress
16579,well -- for unstable Debian -- no.,Task Progress
16580,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16581,@syllog1sm yes.,Task Progress
16582,"@yarikoptic, we would like to release.",Task Progress
16583,Fix should be out soon.,Task Progress
16584,"At cursory glance, so far you seem to be doing the right thing.",Task Progress
16585,Were you able to implement this in spaCy?,Task Progress
16586,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
16587,Is there any update on this?,Task Progress
16588,it's been awhile tho.,Task Progress
16589,So my questions are as follows:1)         Is it planned to deal with this issue somehow?,Task Progress
16590,Fixed!,Task Progress
16591,Is anybody working on this?,Task Progress
16592,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
16593,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
16594,The proposal is released here with current progress.,Task Progress
16595,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
16596,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
16597,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
16598,"At cursory glance, so far you seem to be doing the right thing.",Task Progress
16599,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16600,Implemented ð,Task Progress
16601,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
16602,@bowu - did you have any luck with this?,Task Progress
16603,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
16604,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
16605,The proposal is released here with current progress.,Task Progress
16606,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
16607,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
16608,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
16609,https://github.com/node-tensorflow/node-tensorflow/tree/1.0.0,Task Progress
16610,"So I tried to put the above logic in code (will push some updates to the PR), and I have one more question for the case of integer data when CODE or CODE is not set (typical case for 'legacy_mode').",Task Progress
16611,Does anybody plan to add a support for Russian?,Task Progress
16612,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16613,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
16614,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
16615,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
16616,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16617,"@geovedi , were you working on Bahasa?",Task Progress
16618,We had hoped to release by end oflast month but are getting delayed.,Task Progress
16619,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress
16620,"Obviously, there's still a lot to do to support more languages.",Task Progress
16621,"Dears,Is this issue resolved with the release of spacy 2.0.",Task Progress
16622,@jwkvam We recently agreed in #2570 to implement this feature using the CODE parameter.,Task Progress
16623,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
16624,Have you figured it out?,Task Progress
16625,We'll plan to have an announcement when it's released.,Task Progress
16626,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
16627,Is this in place yet?,Task Progress
16628,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16629,@geovedi do you have a fork or branch i can check out?,Task Progress
16630,Or is this a TODO?,Task Progress
16631,So unfortunately I have to move this out of the milestone.,Task Progress
16632,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress
16633,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16634,well -- for unstable Debian -- no.,Task Progress
16635,"Need to update other modules to reflect the change, and do testing.",Task Progress
16636,"(and once we agree on that part, there is still a lot to discuss about the actual implementation in the PR :))",Task Progress
16637,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
16638,First documentation on master under CODE: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data,Task Progress
16639,"(and once we agree on that part, there is still a lot to discuss about the actual implementation in the PR :))",Task Progress
16640,We're still refactoring and working on better processes for adding more languages.,Task Progress
16641,"But if we want to have it propagate into testing and thus become a part of the next Debian stable release (Whenever that would be) -- yes, should get addressed one way (fixed) or another (disabled)",Task Progress
16642,so no solution yet?,Task Progress
16643,Is anybody working on this?,Task Progress
16644,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16645,"Obviously, there's still a lot to do to support more languages.",Task Progress
16646,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
16647,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
16648,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
16649,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
16650,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16651,Is there any update on this?,Task Progress
16652,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
16653,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
16654,Is there any update on this?,Task Progress
16655,So unfortunately I have to move this out of the milestone.,Task Progress
16656,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16657,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress
16658,seems to work for everybody now.,Task Progress
16659,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
16660,"At cursory glance, so far you seem to be doing the right thing.",Task Progress
16661,So unfortunately I have to move this out of the milestone.,Task Progress
16662,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16663,"So I tried to put the above logic in code (will push some updates to the PR), and I have one more question for the case of integer data when CODE or CODE is not set (typical case for 'legacy_mode').",Task Progress
16664,"Obviously, there's still a lot to do to support more languages.",Task Progress
16665,We had hoped to release by end oflast month but are getting delayed.,Task Progress
16666,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress
16667,We're working on a new seq2seq tutorial.,Task Progress
16668,https://github.com/tngan/tensornode,Task Progress
16669,@bowu - did you have any luck with this?,Task Progress
16670,"We're still finishing up the blog post etc, but the model is uploaded and can be used from spaCy 0.100.7.",Task Progress
16671,TF1.2 will solve this problem?,Task Progress
16672,Implemented ð,Task Progress
16673,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
16674,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16675,is there a way you know to make this work currently?,Task Progress
16676,it's been awhile tho.,Task Progress
16677,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
16678,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16679,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16680,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
16681,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
16682,This is still in progress.,Task Progress
16683,Is this in place yet?,Task Progress
16684,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress
16685,Is this in place yet?,Task Progress
16686,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16687,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16688,Have you figured it out?,Task Progress
16689,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16690,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16691,will catch up with the latest commit and regenerate the model.,Task Progress
16692,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16693,@jwkvam We recently agreed in #2570 to implement this feature using the CODE parameter.,Task Progress
16694,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
16695,well -- for unstable Debian -- no.,Task Progress
16696,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
16697,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
16698,@geovedi do you have a fork or branch i can check out?,Task Progress
16699,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16700,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
16701,it's been awhile tho.,Task Progress
16702,I'll probably get back to it week after next.,Task Progress
16703,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
16704,@neighthan: yes this is something that @mrry has planned as well :),Task Progress
16705,We'll plan to have an announcement when it's released.,Task Progress
16706,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress
16707,@syw2014 Did you fix your issue?,Task Progress
16708,https://github.com/tngan/tensornode,Task Progress
16709,"From what I see, in version 2.0 the problem still exists.",Task Progress
16710,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16711,@syllog1sm yes.,Task Progress
16712,is there a way you know to make this work currently?,Task Progress
16713,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16714,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
16715,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
16716,"Need to update other modules to reflect the change, and do testing.",Task Progress
16717,https://github.com/node-tensorflow/node-tensorflow/tree/1.0.0,Task Progress
16718,We're working on a new seq2seq tutorial.,Task Progress
16719,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16720,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
16721,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
16722,No solution yet!?,Task Progress
16723,it's been awhile tho.,Task Progress
16724,Have you figured it out?,Task Progress
16725,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
16726,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
16727,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16728,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
16729,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress
16730,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
16731,We'll plan to have an announcement when it's released.,Task Progress
16732,First documentation on master under CODE: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data,Task Progress
16733,"From what I see, in version 2.0 the problem still exists.",Task Progress
16734,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
16735,Is there any update on this?,Task Progress
16736,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
16737,P.S. https://github.com/scikit-learn-contrib/categorical-encoding ?,Task Progress
16738,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16739,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
16740,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
16741,"Need to update other modules to reflect the change, and do testing.",Task Progress
16742,"Hi all, I created the Node.js bridging library for Tensorflow at: https://github.com/yorkie/tensorflow-nodejs without SWIG, it has supported ""predefined graph running"" and very simple ""graph construction"", I'm also planing to support more client features in the future :)",Task Progress
16743,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
16744,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16745,Have you figured it out?,Task Progress
16746,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
16747,We're still refactoring and working on better processes for adding more languages.,Task Progress
16748,"Hi all, I created the Node.js bridging library for Tensorflow at: https://github.com/yorkie/tensorflow-nodejs without SWIG, it has supported ""predefined graph running"" and very simple ""graph construction"", I'm also planing to support more client features in the future :)",Task Progress
16749,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16750,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
16751,But with that switch enabled next releases will work properly on Windows,Task Progress
16752,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
16753,TF1.2 will solve this problem?,Task Progress
16754,"From what I see, in version 2.0 the problem still exists.",Task Progress
16755,The proposal is released here with current progress.,Task Progress
16756,Everything should now pickle.,Task Progress
16757,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
16758,"Obviously, there's still a lot to do to support more languages.",Task Progress
16759,The next steps would be to define the areas that the bindings would initially cover (must be within the C++ API ) and start implementing the SWIG interface files for these.,Task Progress
16760,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
16761,"Yeah for large vector models it would be a necessity, question is though where supporting that is on your timeline & plans for spaCy.",Task Progress
16762,We'll plan to have an announcement when it's released.,Task Progress
16763,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
16764,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
16765,"Obviously, there's still a lot to do to support more languages.",Task Progress
16766,TF1.2 will solve this problem?,Task Progress
16767,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16768,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
16769,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16770,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress
16771,Or is this a TODO?,Task Progress
16772,I'll probably get back to it week after next.,Task Progress
16773,We're working on a new seq2seq tutorial.,Task Progress
16774,Will a more stable fix be available in next 1.x releases?,Task Progress
16775,well -- for unstable Debian -- no.,Task Progress
16776,"Obviously, there's still a lot to do to support more languages.",Task Progress
16777,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
16778,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
16779,We're hoping for this coming week!,Task Progress
16780,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress
16781,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
16782,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress
16783,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
16784,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
16785,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
16786,"@ebrevdo Congratulations, TF 1.2 just got released - was the new tutorial also released somewhere or is it being released anytime soon?",Task Progress
16787,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
16788,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
16789,I made an initial stab at it here: https://github.com/tensorflow/tensorflow/pull/2206 - this is just a proof of concept that gets the version string into nodejs.,Task Progress
16790,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
16791,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
16792,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16793,Fix should be out soon.,Task Progress
16794,https://github.com/node-tensorflow/node-tensorflow/tree/1.0.0,Task Progress
16795,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress
16796,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
16797,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress
16798,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
16799,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress
16800,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
16801,is there a way you know to make this work currently?,Task Progress
16802,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
16803,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
16804,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress
16805,Will a more stable fix be available in next 1.x releases?,Task Progress
16806,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
16807,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16808,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16809,Have you figured it out?,Task Progress
16810,Have you guys solved this problem?,Task Progress
16811,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress
16812,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16813,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16814,Is this in place yet?,Task Progress
16815,Or was it a code change?,Task Progress
16816,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
16817,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress
16818,@syllog1sm yes.,Task Progress
16819,I'll probably get back to it week after next.,Task Progress
16820,well -- for unstable Debian -- no.,Task Progress
16821,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
16822,"@geovedi , were you working on Bahasa?",Task Progress
16823,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16824,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16825,https://github.com/node-tensorflow/node-tensorflow/tree/1.0.0,Task Progress
16826,We're hoping for this coming week!,Task Progress
16827,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
16828,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
16829,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress
16830,@syw2014 Did you fix your issue?,Task Progress
16831,No solution yet!?,Task Progress
16832,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16833,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
16834,@bowu - did you have any luck with this?,Task Progress
16835,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress
16836,"Need to update other modules to reflect the change, and do testing.",Task Progress
16837,The proposal is released here with current progress.,Task Progress
16838,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16839,Does anybody plan to add a support for Russian?,Task Progress
16840,Or was it a code change?,Task Progress
16841,We're still refactoring and working on better processes for adding more languages.,Task Progress
16842,This is still in progress.,Task Progress
16843,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress
16844,We're hoping for this coming week!,Task Progress
16845,Work in progress for spaCy v2.0!,Task Progress
16846,Work in progress for spaCy v2.0!,Task Progress
16847,We'll plan to have an announcement when it's released.,Task Progress
16848,"From what I see, in version 2.0 the problem still exists.",Task Progress
16849,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
16850,Have you figured it out?,Task Progress
16851,I'll probably get back to it week after next.,Task Progress
16852,But with that switch enabled next releases will work properly on Windows,Task Progress
16853,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
16854,Implemented ð,Task Progress
16855,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16856,@geovedi do you have a fork or branch i can check out?,Task Progress
16857,@geovedi do you have a fork or branch i can check out?,Task Progress
16858,This is still in progress.,Task Progress
16859,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
16860,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
16861,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
16862,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress
16863,"@yarikoptic, we would like to release.",Task Progress
16864,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16865,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16866,@bowu - did you have any luck with this?,Task Progress
16867,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16868,Or is this a TODO?,Task Progress
16869,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
16870,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
16871,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress
16872,so no solution yet?,Task Progress
16873,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
16874,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16875,Have you solved it ?,Task Progress
16876,Is this in place yet?,Task Progress
16877,So my questions are as follows:1)         Is it planned to deal with this issue somehow?,Task Progress
16878,is there a way you know to make this work currently?,Task Progress
16879,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress
16880,I made an initial stab at it here: https://github.com/tensorflow/tensorflow/pull/2206 - this is just a proof of concept that gets the version string into nodejs.,Task Progress
16881,@syllog1sm yes.,Task Progress
16882,Is there any update on this?,Task Progress
16883,Or was it a code change?,Task Progress
16884,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
16885,@syw2014 Did you fix your issue?,Task Progress
16886,So unfortunately I have to move this out of the milestone.,Task Progress
16887,"Yeah for large vector models it would be a necessity, question is though where supporting that is on your timeline & plans for spaCy.",Task Progress
16888,"However, I didn't leave a TODO and the status of it got lost.",Task Progress
16889,We're hoping for this coming week!,Task Progress
16890,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress
16891,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
16892,The proposal is released here with current progress.,Task Progress
16893,Work in progress for spaCy v2.0!,Task Progress
16894,"Dears,Is this issue resolved with the release of spacy 2.0.",Task Progress
16895,I'll probably get back to it week after next.,Task Progress
16896,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress
16897,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
16898,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress
16899,This is still in progress.,Task Progress
16900,"I'll think more about this, and probably reach out to Radim about it.",Task Progress
16901,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress
16902,First documentation on master under CODE: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data,Task Progress
16903,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16904,is there a way you know to make this work currently?,Task Progress
16905,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress
16906,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16907,it's been 2 years and still no luck?,Task Progress
16908,Or is this a TODO?,Task Progress
16909,Work in progress for spaCy v2.0!,Task Progress
16910,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress
16911,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress
16912,We'll plan to have an announcement when it's released.,Task Progress
16913,Were you able to implement this in spaCy?,Task Progress
16914,"But if we want to have it propagate into testing and thus become a part of the next Debian stable release (Whenever that would be) -- yes, should get addressed one way (fixed) or another (disabled)",Task Progress
16915,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress
16916,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress
16917,@bowu - did you have any luck with this?,Task Progress
16918,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16919,The proposal is released here with current progress.,Task Progress
16920,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
16921,@syw2014 Did you fix your issue?,Task Progress
16922,it's been 2 years and still no luck?,Task Progress
16923,https://github.com/tngan/tensornode,Task Progress
16924,seems to work for everybody now.,Task Progress
16925,Have you solved it ?,Task Progress
16926,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16927,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
16928,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress
16929,"Dears,Is this issue resolved with the release of spacy 2.0.",Task Progress
16930,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress
16931,Is there any update on this?,Task Progress
16932,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
16933,@syw2014 Did you fix your issue?,Task Progress
16934,"(and once we agree on that part, there is still a lot to discuss about the actual implementation in the PR :))",Task Progress
16935,and do we need to fix the other test failures for scikit-learn 0.19 to shipwith Debian?,Task Progress
16936,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16937,@honnibal could we get an update on the current status of this and your thoughts on how best to proceed?,Task Progress
16938,Is anybody working on this?,Task Progress
16939,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
16940,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
16941,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress
16942,Were you able to implement this in spaCy?,Task Progress
16943,is there a way you know to make this work currently?,Task Progress
16944,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
16945,will catch up with the latest commit and regenerate the model.,Task Progress
16946,It is now implemented in GBRT.,Task Progress
16947,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
16948,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress
16949,@syllog1sm yes.,Task Progress
16950,well -- for unstable Debian -- no.,Task Progress
16951,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16952,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
16953,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
16954,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress
16955,Is there any update on this?,Task Progress
16956,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress
16957,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress
16958,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress
16959,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
16960,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
16961,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
16962,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress
16963,Implemented ð,Task Progress
16964,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress
16965,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress
16966,"At cursory glance, so far you seem to be doing the right thing.",Task Progress
16967,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress
16968,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress
16969,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
16970,https://github.com/tngan/tensornode,Task Progress
16971,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress
16972,Is this in place yet?,Task Progress
16973,Have you guys solved this problem?,Task Progress
16974,seems to work for everybody now.,Task Progress
16975,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress
16976,https://github.com/tngan/tensornode,Task Progress
16977,Work in progress for spaCy v2.0!,Task Progress
16978,Thats my next step.,Task Progress
16979,is there a way you know to make this work currently?,Task Progress
16980,"(and once we agree on that part, there is still a lot to discuss about the actual implementation in the PR :))",Task Progress
16981,"Dears,Is this issue resolved with the release of spacy 2.0.",Task Progress
16982,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress
16983,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16984,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress
16985,No solution yet!?,Task Progress
16986,"Hi all, I created the Node.js bridging library for Tensorflow at: https://github.com/yorkie/tensorflow-nodejs without SWIG, it has supported ""predefined graph running"" and very simple ""graph construction"", I'm also planing to support more client features in the future :)",Task Progress
16987,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress
16988,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16989,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress
16990,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16991,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress
16992,I'll try to update the forests with the same mechanism before the release.,Task Progress
16993,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress
16994,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress
16995,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress
16996,Working on it.,Task Progress
16997,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
16998,But with that switch enabled next releases will work properly on Windows,Task Progress
16999,"@yarikoptic, we would like to release.",Task Progress
17000,P.S. https://github.com/scikit-learn-contrib/categorical-encoding ?,Task Progress
17001,Could someone please summarize where this currently stands?,Task Progress
17002,So my questions are as follows:1)         Is it planned to deal with this issue somehow?,Task Progress
17003,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
17004,seems to work for everybody now.,Task Progress
17005,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress
17006,We're hoping for this coming week!,Task Progress
17007,We're working on a new seq2seq tutorial.,Task Progress
17008,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress
17009,"Yeah for large vector models it would be a necessity, question is though where supporting that is on your timeline & plans for spaCy.",Task Progress
17010,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress
17011,So my questions are as follows:1)         Is it planned to deal with this issue somehow?,Task Progress
17012,@syw2014 Did you fix your issue?,Task Progress
17013,We are working hard at getting a proper NPM build and will release it soon!,Task Progress
17014,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress
17015,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress
17016,Will a more stable fix be available in next 1.x releases?,Task Progress
17017,Could you tell me when the new seq2seq tutorial will be released?,Task Progress
17018,Does anybody plan to add a support for Russian?,Task Progress
17019,Thats my next step.,Task Progress
17020,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress
17021,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17022,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17023,For now the following work-around could help:,Workarounds
17024,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
17025,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17026,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17027,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17028,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17029,"Hopefully, this is logical.",Workarounds
17030,"In my opinion, this would be a very ugly workaround;",Workarounds
17031,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
17032,So is the workaround to downgrade numpy?,Workarounds
17033,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17034,here's a full traceback..,Workarounds
17035,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17036,"Hopefully, this is logical.",Workarounds
17037,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17038,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
17039,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17040,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17041,I am experimenting with this workaround with the 1.x version.,Workarounds
17042,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17043,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
17044,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17045,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17046,The same trick cannot be used with Gradient Boosting.,Workarounds
17047,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17048,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
17049,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17050,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17051,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17052,"Hopefully, this is logical.",Workarounds
17053,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
17054,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17055,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17056,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17057,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17058,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
17059,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17060,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17061,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17062,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17063,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17064,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17065,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17066,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17067,@azar923 Did you try the CODE mitigation above?,Workarounds
17068,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
17069,But with images this can be hardly done for the entire dataset in memory.,Workarounds
17070,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17071,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17072,Download deb (network) from:,Workarounds
17073,[propelml.org] URL  - Looks interesting.,Workarounds
17074,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
17075,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17076,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17077,Example (untested): CODE,Workarounds
17078,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17079,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17080,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
17081,The workaround of using set_frozen does not work.,Workarounds
17082,"Hopefully, this is logical.",Workarounds
17083,So far it is working well.,Workarounds
17084,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17085,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
17086,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17087,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17088,On OSX you can do that with conda which uses MKL by default.,Workarounds
17089,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
17090,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17091,3.         Avoid the CODE methods on the spaCy objects.,Workarounds
17092,"Hopefully, this is logical.",Workarounds
17093,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
17094,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17095,Then: aptitude install cuda-9-0,Workarounds
17096,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
17097,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds
17098,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
17099,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17100,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17101,CODE,Workarounds
17102,CODE,Workarounds
17103,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17104,Summary:-         New CODE keyword argument to CODE,Workarounds
17105,So the workaround doesn't really work.,Workarounds
17106,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17107,I am experimenting with this workaround with the 1.x version.,Workarounds
17108,You can also use OpenBLAS using conda-forge.,Workarounds
17109,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17110,The above works.,Workarounds
17111,The above works.,Workarounds
17112,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17113,Some workarounds are,Workarounds
17114,[propelml.org] URL  - Looks interesting.,Workarounds
17115,"Since serialization is the only way to reuse parsing results in a data pipeline and most real-world docs would have OOV words, this problem is pretty critical.",Workarounds
17116,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17117,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17118,Ref: [v1.5.0_source] URL ,Workarounds
17119,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17120,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17121,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17122,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17123,CODE,Workarounds
17124,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17125,Reverting to TF 1.3 until this is resolved.,Workarounds
17126,"In my opinion, this would be a very ugly workaround;",Workarounds
17127,Download deb (network) from:,Workarounds
17128,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17129,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17130,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17131,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17132,Use synaptic https://github.com/cazala/synaptic,Workarounds
17133,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17134,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
17135,[propelml.org] URL  - Looks interesting.,Workarounds
17136,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
17137,CODE,Workarounds
17138,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17139,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17140,So is the workaround to downgrade numpy?,Workarounds
17141,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds
17142,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17143,Download deb (network) from:,Workarounds
17144,here's a full traceback..,Workarounds
17145,"In my opinion, this would be a very ugly workaround;",Workarounds
17146,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds
17147,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
17148,Reverting to TF 1.3 until this is resolved.,Workarounds
17149,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17150,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17151,Some workarounds are,Workarounds
17152,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
17153,This means that you'll get consistent integer encodings between flushings.,Workarounds
17154,I am experimenting with this workaround with the 1.x version.,Workarounds
17155,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17156,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17157,I fix him for now by:,Workarounds
17158,@azar923 Did you try the CODE mitigation above?,Workarounds
17159,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17160,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
17161,CODE,Workarounds
17162,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17163,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17164,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
17165,Some workarounds are,Workarounds
17166,[propelml.org] URL  - Looks interesting.,Workarounds
17167,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
17168,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17169,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
17170,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17171,So far it is working well.,Workarounds
17172,a cleaner solution must exist; maybe we are missing something?,Workarounds
17173,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17174,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17175,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
17176,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17177,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17178,[propelml.org] URL  - Looks interesting.,Workarounds
17179,But with images this can be hardly done for the entire dataset in memory.,Workarounds
17180,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
17181,I am experimenting with this workaround with the 1.x version.,Workarounds
17182,Then: CODE,Workarounds
17183,For now the following work-around could help:,Workarounds
17184,Summary:-         New CODE keyword argument to CODE,Workarounds
17185,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17186,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17187,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
17188,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17189,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
17190,"In my opinion, this would be a very ugly workaround;",Workarounds
17191,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17192,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17193,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17194,Reverting to TF 1.3 until this is resolved.,Workarounds
17195,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17196,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17197,So is the workaround to downgrade numpy?,Workarounds
17198,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17199,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17200,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
17201,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17202,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17203,So the workaround doesn't really work.,Workarounds
17204,"Hopefully, this is logical.",Workarounds
17205,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17206,For now the following work-around could help:,Workarounds
17207,CODE,Workarounds
17208,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17209,I fix him for now by:,Workarounds
17210,This means that you'll get consistent integer encodings between flushings.,Workarounds
17211,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17212,Some workarounds are,Workarounds
17213,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
17214,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17215,I fix him for now by:,Workarounds
17216,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
17217,But with images this can be hardly done for the entire dataset in memory.,Workarounds
17218,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17219,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
17220,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
17221,"Since serialization is the only way to reuse parsing results in a data pipeline and most real-world docs would have OOV words, this problem is pretty critical.",Workarounds
17222,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
17223,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17224,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17225,The work-around is to not use Accelerate.,Workarounds
17226,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17227,Use synaptic https://github.com/cazala/synaptic,Workarounds
17228,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17229,Reverting to TF 1.3 until this is resolved.,Workarounds
17230,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17231,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17232,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17233,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17234,Then: aptitude update,Workarounds
17235,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17236,CODE,Workarounds
17237,Ref: [v1.5.0_source] URL ,Workarounds
17238,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17239,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
17240,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17241,Reverting to TF 1.3 until this is resolved.,Workarounds
17242,Ref: [v1.5.0_source] URL ,Workarounds
17243,@azar923 Did you try the CODE mitigation above?,Workarounds
17244,So far it is working well.,Workarounds
17245,Use synaptic https://github.com/cazala/synaptic,Workarounds
17246,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17247,So the workaround doesn't really work.,Workarounds
17248,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17249,The work-around is to not use Accelerate.,Workarounds
17250,"Hopefully, this is logical.",Workarounds
17251,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17252,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17253,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17254,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17255,CODE,Workarounds
17256,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
17257,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17258,The work-around is to not use Accelerate.,Workarounds
17259,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17260,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
17261,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17262,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17263,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17264,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17265,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17266,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17267,I'm doing something like this:CODE,Workarounds
17268,For now the following work-around could help:,Workarounds
17269,The above works.,Workarounds
17270,So far it is working well.,Workarounds
17271,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17272,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
17273,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
17274,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
17275,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17276,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
17277,The above works.,Workarounds
17278,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
17279,Then: aptitude update,Workarounds
17280,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
17281,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
17282,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
17283,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17284,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17285,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17286,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17287,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17288,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17289,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17290,So is the workaround to downgrade numpy?,Workarounds
17291,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17292,Gensim recommends the CODE library.,Workarounds
17293,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
17294,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
17295,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17296,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17297,The work-around is to not use Accelerate.,Workarounds
17298,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17299,The workaround of using set_frozen does not work.,Workarounds
17300,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17301,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17302,CODE,Workarounds
17303,You can also use OpenBLAS using conda-forge.,Workarounds
17304,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
17305,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17306,The same trick cannot be used with Gradient Boosting.,Workarounds
17307,I am experimenting with this workaround with the 1.x version.,Workarounds
17308,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17309,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17310,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17311,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
17312,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
17313,Gensim recommends the CODE library.,Workarounds
17314,Example (untested): CODE,Workarounds
17315,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17316,Use synaptic https://github.com/cazala/synaptic,Workarounds
17317,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17318,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17319,For now the following work-around could help:,Workarounds
17320,Download deb (network) from:,Workarounds
17321,"In my opinion, this would be a very ugly workaround;",Workarounds
17322,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17323,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
17324,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17325,here's a full traceback..,Workarounds
17326,Example (untested): CODE,Workarounds
17327,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
17328,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
17329,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
17330,You can also use OpenBLAS using conda-forge.,Workarounds
17331,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17332,The workaround of using set_frozen does not work.,Workarounds
17333,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17334,So far it is working well.,Workarounds
17335,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17336,@azar923 Did you try the CODE mitigation above?,Workarounds
17337,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17338,So is the workaround to downgrade numpy?,Workarounds
17339,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
17340,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
17341,@azar923 Did you try the CODE mitigation above?,Workarounds
17342,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17343,Then: aptitude update,Workarounds
17344,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17345,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17346,Reverting to TF 1.3 until this is resolved.,Workarounds
17347,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
17348,3.         Avoid the CODE methods on the spaCy objects.,Workarounds
17349,Then: aptitude install cuda-9-0,Workarounds
17350,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
17351,The work-around is to not use Accelerate.,Workarounds
17352,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17353,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17354,I fix him for now by:,Workarounds
17355,a cleaner solution must exist; maybe we are missing something?,Workarounds
17356,The workaround of using set_frozen does not work.,Workarounds
17357,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17358,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
17359,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17360,Gensim recommends the CODE library.,Workarounds
17361,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17362,You can also use OpenBLAS using conda-forge.,Workarounds
17363,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17364,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17365,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17366,Call it whenever convenient.,Workarounds
17367,here's a full traceback..,Workarounds
17368,So is the workaround to downgrade numpy?,Workarounds
17369,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
17370,Gensim recommends the CODE library.,Workarounds
17371,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17372,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17373,Example (untested): CODE,Workarounds
17374,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17375,You can also use OpenBLAS using conda-forge.,Workarounds
17376,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17377,3.         Avoid the CODE methods on the spaCy objects.,Workarounds
17378,I fix him for now by:,Workarounds
17379,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
17380,On OSX you can do that with conda which uses MKL by default.,Workarounds
17381,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17382,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17383,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17384,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
17385,So is the workaround to downgrade numpy?,Workarounds
17386,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17387,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
17388,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17389,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
17390,The work-around is to not use Accelerate.,Workarounds
17391,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17392,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17393,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17394,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17395,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
17396,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17397,CODE,Workarounds
17398,You can also use OpenBLAS using conda-forge.,Workarounds
17399,On OSX you can do that with conda which uses MKL by default.,Workarounds
17400,I am experimenting with this workaround with the 1.x version.,Workarounds
17401,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
17402,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
17403,On OSX you can do that with conda which uses MKL by default.,Workarounds
17404,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17405,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
17406,Reverting to TF 1.3 until this is resolved.,Workarounds
17407,CODE,Workarounds
17408,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17409,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
17410,I fix him for now by:,Workarounds
17411,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17412,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
17413,So the workaround doesn't really work.,Workarounds
17414,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
17415,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17416,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17417,So is the workaround to downgrade numpy?,Workarounds
17418,The above works.,Workarounds
17419,Example (untested): CODE,Workarounds
17420,@azar923 Did you try the CODE mitigation above?,Workarounds
17421,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17422,For now the following work-around could help:,Workarounds
17423,I'm doing something like this:CODE,Workarounds
17424,Then: aptitude update,Workarounds
17425,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17426,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17427,"Hopefully, this is logical.",Workarounds
17428,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17429,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
17430,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17431,Ref: [v1.5.0_source] URL ,Workarounds
17432,I am experimenting with this workaround with the 1.x version.,Workarounds
17433,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17434,I am experimenting with this workaround with the 1.x version.,Workarounds
17435,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17436,So far it is working well.,Workarounds
17437,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
17438,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
17439,Use synaptic https://github.com/cazala/synaptic,Workarounds
17440,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17441,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17442,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17443,The workaround of using set_frozen does not work.,Workarounds
17444,Example (untested): CODE,Workarounds
17445,Example (untested): CODE,Workarounds
17446,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17447,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
17448,So the workaround doesn't really work.,Workarounds
17449,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
17450,Then: aptitude install cuda-9-0,Workarounds
17451,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17452,I fix him for now by:,Workarounds
17453,[propelml.org] URL  - Looks interesting.,Workarounds
17454,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17455,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
17456,Then: aptitude update,Workarounds
17457,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17458,So the workaround doesn't really work.,Workarounds
17459,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17460,Summary:-         New CODE keyword argument to CODE,Workarounds
17461,So is the workaround to downgrade numpy?,Workarounds
17462,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17463,For now the following work-around could help:,Workarounds
17464,The same trick cannot be used with Gradient Boosting.,Workarounds
17465,@azar923 Did you try the CODE mitigation above?,Workarounds
17466,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17467,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
17468,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
17469,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17470,So the workaround doesn't really work.,Workarounds
17471,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17472,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17473,The same trick cannot be used with Gradient Boosting.,Workarounds
17474,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17475,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17476,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
17477,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17478,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17479,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17480,"In my opinion, this would be a very ugly workaround;",Workarounds
17481,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17482,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17483,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17484,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
17485,"In my opinion, this would be a very ugly workaround;",Workarounds
17486,Summary:-         New CODE keyword argument to CODE,Workarounds
17487,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17488,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17489,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17490,For now the following work-around could help:,Workarounds
17491,So far it is working well.,Workarounds
17492,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
17493,Download deb (network) from:,Workarounds
17494,I fix him for now by:,Workarounds
17495,Reverting to TF 1.3 until this is resolved.,Workarounds
17496,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17497,@azar923 Did you try the CODE mitigation above?,Workarounds
17498,Then: CODE,Workarounds
17499,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
17500,The above works.,Workarounds
17501,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17502,But with images this can be hardly done for the entire dataset in memory.,Workarounds
17503,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
17504,"In my opinion, this would be a very ugly workaround;",Workarounds
17505,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
17506,3.         Avoid the CODE methods on the spaCy objects.,Workarounds
17507,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17508,So is the workaround to downgrade numpy?,Workarounds
17509,This means that you'll get consistent integer encodings between flushings.,Workarounds
17510,The above works.,Workarounds
17511,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
17512,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17513,For now the following work-around could help:,Workarounds
17514,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
17515,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
17516,Download deb (network) from:,Workarounds
17517,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
17518,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
17519,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17520,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17521,Call it whenever convenient.,Workarounds
17522,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17523,The work-around is to not use Accelerate.,Workarounds
17524,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17525,The above works.,Workarounds
17526,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17527,Use synaptic https://github.com/cazala/synaptic,Workarounds
17528,So the workaround doesn't really work.,Workarounds
17529,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
17530,Some workarounds are,Workarounds
17531,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17532,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17533,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17534,Then: aptitude install cuda-9-0,Workarounds
17535,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17536,Workarounds exist and have been listed in earlier posts.,Workarounds
17537,Download deb (network) from:,Workarounds
17538,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17539,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
17540,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17541,For now the following work-around could help:,Workarounds
17542,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17543,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17544,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17545,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17546,Reverting to TF 1.3 until this is resolved.,Workarounds
17547,Workarounds exist and have been listed in earlier posts.,Workarounds
17548,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
17549,But with images this can be hardly done for the entire dataset in memory.,Workarounds
17550,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
17551,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17552,This means that you'll get consistent integer encodings between flushings.,Workarounds
17553,This means that you'll get consistent integer encodings between flushings.,Workarounds
17554,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
17555,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17556,So the workaround doesn't really work.,Workarounds
17557,Is there a way to reset the StringStore without reloading the model again ?,Workarounds
17558,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17559,So far it is working well.,Workarounds
17560,Example (untested): CODE,Workarounds
17561,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds
17562,I am experimenting with this workaround with the 1.x version.,Workarounds
17563,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17564,here's a full traceback..,Workarounds
17565,Some workarounds are,Workarounds
17566,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17567,Then: CODE,Workarounds
17568,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
17569,So far it is working well.,Workarounds
17570,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17571,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17572,I am experimenting with this workaround with the 1.x version.,Workarounds
17573,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17574,Then: aptitude install cuda-9-0,Workarounds
17575,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17576,You can also use OpenBLAS using conda-forge.,Workarounds
17577,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17578,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17579,"In my opinion, this would be a very ugly workaround;",Workarounds
17580,"Hopefully, this is logical.",Workarounds
17581,The work-around is to not use Accelerate.,Workarounds
17582,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
17583,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
17584,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
17585,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17586,So the workaround doesn't really work.,Workarounds
17587,Then: CODE,Workarounds
17588,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17589,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17590,Download deb (network) from:,Workarounds
17591,I am experimenting with this workaround with the 1.x version.,Workarounds
17592,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
17593,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17594,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17595,[propelml.org] URL  - Looks interesting.,Workarounds
17596,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
17597,here's a full traceback..,Workarounds
17598,The work-around is to not use Accelerate.,Workarounds
17599,You can also use OpenBLAS using conda-forge.,Workarounds
17600,I'm doing something like this:CODE,Workarounds
17601,This means that you'll get consistent integer encodings between flushings.,Workarounds
17602,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17603,Then: aptitude update,Workarounds
17604,Is there a way to reset the StringStore without reloading the model again ?,Workarounds
17605,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
17606,[propelml.org] URL  - Looks interesting.,Workarounds
17607,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
17608,This means that you'll get consistent integer encodings between flushings.,Workarounds
17609,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
17610,Example (untested): CODE,Workarounds
17611,So is the workaround to downgrade numpy?,Workarounds
17612,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17613,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17614,The workaround of using set_frozen does not work.,Workarounds
17615,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
17616,"Hopefully, this is logical.",Workarounds
17617,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
17618,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17619,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17620,Ref: [v1.5.0_source] URL ,Workarounds
17621,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
17622,Then: CODE,Workarounds
17623,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
17624,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17625,Ref: [v1.5.0_source] URL ,Workarounds
17626,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
17627,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17628,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17629,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17630,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17631,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17632,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
17633,On OSX you can do that with conda which uses MKL by default.,Workarounds
17634,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17635,here's a full traceback..,Workarounds
17636,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17637,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
17638,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17639,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds
17640,Then: aptitude update,Workarounds
17641,Then: aptitude install cuda-9-0,Workarounds
17642,[propelml.org] URL  - Looks interesting.,Workarounds
17643,You can also use OpenBLAS using conda-forge.,Workarounds
17644,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
17645,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17646,[propelml.org] URL  - Looks interesting.,Workarounds
17647,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
17648,I fix him for now by:,Workarounds
17649,[propelml.org] URL  - Looks interesting.,Workarounds
17650,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17651,a cleaner solution must exist; maybe we are missing something?,Workarounds
17652,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
17653,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17654,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17655,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17656,So far it is working well.,Workarounds
17657,I'm doing something like this:CODE,Workarounds
17658,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
17659,@azar923 Did you try the CODE mitigation above?,Workarounds
17660,"In my opinion, this would be a very ugly workaround;",Workarounds
17661,For now the following work-around could help:,Workarounds
17662,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
17663,You can also use OpenBLAS using conda-forge.,Workarounds
17664,"Hopefully, this is logical.",Workarounds
17665,The above works.,Workarounds
17666,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
17667,This means that you'll get consistent integer encodings between flushings.,Workarounds
17668,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17669,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17670,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17671,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
17672,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17673,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17674,You can also use OpenBLAS using conda-forge.,Workarounds
17675,Use synaptic https://github.com/cazala/synaptic,Workarounds
17676,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17677,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17678,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17679,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17680,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17681,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
17682,Call it whenever convenient.,Workarounds
17683,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17684,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17685,here's a full traceback..,Workarounds
17686,The workaround of using set_frozen does not work.,Workarounds
17687,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17688,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17689,Workarounds exist and have been listed in earlier posts.,Workarounds
17690,Then: aptitude update,Workarounds
17691,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17692,"In my opinion, this would be a very ugly workaround;",Workarounds
17693,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17694,Gensim recommends the CODE library.,Workarounds
17695,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17696,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17697,You can also use OpenBLAS using conda-forge.,Workarounds
17698,I am experimenting with this workaround with the 1.x version.,Workarounds
17699,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17700,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17701,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17702,@azar923 Did you try the CODE mitigation above?,Workarounds
17703,Call it whenever convenient.,Workarounds
17704,Workarounds exist and have been listed in earlier posts.,Workarounds
17705,Example (untested): CODE,Workarounds
17706,For now the following work-around could help:,Workarounds
17707,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17708,Call it whenever convenient.,Workarounds
17709,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17710,a cleaner solution must exist; maybe we are missing something?,Workarounds
17711,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17712,a cleaner solution must exist; maybe we are missing something?,Workarounds
17713,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17714,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
17715,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17716,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
17717,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17718,Download deb (network) from:,Workarounds
17719,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17720,Gensim recommends the CODE library.,Workarounds
17721,here's a full traceback..,Workarounds
17722,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17723,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17724,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17725,So far it is working well.,Workarounds
17726,The workaround of using set_frozen does not work.,Workarounds
17727,Gensim recommends the CODE library.,Workarounds
17728,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17729,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17730,I am experimenting with this workaround with the 1.x version.,Workarounds
17731,Gensim recommends the CODE library.,Workarounds
17732,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17733,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
17734,Download deb (network) from:,Workarounds
17735,Download deb (network) from:,Workarounds
17736,Then: CODE,Workarounds
17737,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
17738,@azar923 Did you try the CODE mitigation above?,Workarounds
17739,Reverting to TF 1.3 until this is resolved.,Workarounds
17740,3.         Avoid the CODE methods on the spaCy objects.,Workarounds
17741,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17742,CODE,Workarounds
17743,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17744,Gensim recommends the CODE library.,Workarounds
17745,a cleaner solution must exist; maybe we are missing something?,Workarounds
17746,"In my opinion, this would be a very ugly workaround;",Workarounds
17747,Call it whenever convenient.,Workarounds
17748,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17749,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
17750,here's a full traceback..,Workarounds
17751,I am experimenting with this workaround with the 1.x version.,Workarounds
17752,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17753,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17754,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17755,Call it whenever convenient.,Workarounds
17756,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
17757,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17758,3.         Avoid the CODE methods on the spaCy objects.,Workarounds
17759,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17760,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17761,This means that you'll get consistent integer encodings between flushings.,Workarounds
17762,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17763,Use synaptic https://github.com/cazala/synaptic,Workarounds
17764,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17765,You can also use OpenBLAS using conda-forge.,Workarounds
17766,Summary:-         New CODE keyword argument to CODE,Workarounds
17767,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17768,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17769,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17770,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
17771,Gensim recommends the CODE library.,Workarounds
17772,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
17773,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17774,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
17775,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17776,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
17777,Workarounds exist and have been listed in earlier posts.,Workarounds
17778,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17779,This means that you'll get consistent integer encodings between flushings.,Workarounds
17780,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
17781,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17782,@azar923 Did you try the CODE mitigation above?,Workarounds
17783,@azar923 Did you try the CODE mitigation above?,Workarounds
17784,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17785,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17786,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17787,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17788,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17789,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17790,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
17791,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17792,Gensim recommends the CODE library.,Workarounds
17793,So the workaround doesn't really work.,Workarounds
17794,a cleaner solution must exist; maybe we are missing something?,Workarounds
17795,Is there a way to reset the StringStore without reloading the model again ?,Workarounds
17796,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17797,This means that you'll get consistent integer encodings between flushings.,Workarounds
17798,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17799,Gensim recommends the CODE library.,Workarounds
17800,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17801,Then: CODE,Workarounds
17802,On OSX you can do that with conda which uses MKL by default.,Workarounds
17803,The workaround of using set_frozen does not work.,Workarounds
17804,Ref: [v1.5.0_source] URL ,Workarounds
17805,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17806,The work-around is to not use Accelerate.,Workarounds
17807,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
17808,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
17809,So far it is working well.,Workarounds
17810,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
17811,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17812,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
17813,This means that you'll get consistent integer encodings between flushings.,Workarounds
17814,You can also use OpenBLAS using conda-forge.,Workarounds
17815,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
17816,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
17817,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
17818,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
17819,a cleaner solution must exist; maybe we are missing something?,Workarounds
17820,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17821,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17822,Then: aptitude update,Workarounds
17823,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17824,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17825,But with images this can be hardly done for the entire dataset in memory.,Workarounds
17826,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17827,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17828,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17829,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17830,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17831,But with images this can be hardly done for the entire dataset in memory.,Workarounds
17832,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17833,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17834,Ref: [v1.5.0_source] URL ,Workarounds
17835,Gensim recommends the CODE library.,Workarounds
17836,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17837,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
17838,Then: aptitude update,Workarounds
17839,Reverting to TF 1.3 until this is resolved.,Workarounds
17840,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17841,@azar923 Did you try the CODE mitigation above?,Workarounds
17842,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
17843,I am experimenting with this workaround with the 1.x version.,Workarounds
17844,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17845,So far it is working well.,Workarounds
17846,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17847,Reverting to TF 1.3 until this is resolved.,Workarounds
17848,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
17849,You can also use OpenBLAS using conda-forge.,Workarounds
17850,I'm doing something like this:CODE,Workarounds
17851,So the workaround doesn't really work.,Workarounds
17852,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
17853,Then: aptitude install cuda-9-0,Workarounds
17854,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17855,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17856,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
17857,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
17858,3.         Avoid the CODE methods on the spaCy objects.,Workarounds
17859,Workarounds exist and have been listed in earlier posts.,Workarounds
17860,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
17861,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17862,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17863,So far it is working well.,Workarounds
17864,But with images this can be hardly done for the entire dataset in memory.,Workarounds
17865,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
17866,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17867,Call it whenever convenient.,Workarounds
17868,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
17869,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
17870,Then: aptitude install cuda-9-0,Workarounds
17871,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
17872,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17873,So is the workaround to downgrade numpy?,Workarounds
17874,Reverting to TF 1.3 until this is resolved.,Workarounds
17875,Reverting to TF 1.3 until this is resolved.,Workarounds
17876,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
17877,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
17878,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
17879,Workarounds exist and have been listed in earlier posts.,Workarounds
17880,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17881,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds
17882,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17883,here's a full traceback..,Workarounds
17884,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
17885,So far it is working well.,Workarounds
17886,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
17887,CODE,Workarounds
17888,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17889,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17890,Ref: [v1.5.0_source] URL ,Workarounds
17891,The same trick cannot be used with Gradient Boosting.,Workarounds
17892,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17893,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
17894,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17895,The work-around is to not use Accelerate.,Workarounds
17896,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
17897,You can also use OpenBLAS using conda-forge.,Workarounds
17898,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17899,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17900,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds
17901,Use synaptic https://github.com/cazala/synaptic,Workarounds
17902,The same trick cannot be used with Gradient Boosting.,Workarounds
17903,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
17904,Then: CODE,Workarounds
17905,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17906,On OSX you can do that with conda which uses MKL by default.,Workarounds
17907,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
17908,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
17909,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17910,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
17911,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17912,Then: aptitude install cuda-9-0,Workarounds
17913,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17914,Call it whenever convenient.,Workarounds
17915,3.         Avoid the CODE methods on the spaCy objects.,Workarounds
17916,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17917,Gensim recommends the CODE library.,Workarounds
17918,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
17919,So far it is working well.,Workarounds
17920,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
17921,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17922,Use synaptic https://github.com/cazala/synaptic,Workarounds
17923,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
17924,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
17925,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
17926,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17927,Is there a way to reset the StringStore without reloading the model again ?,Workarounds
17928,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
17929,The same trick cannot be used with Gradient Boosting.,Workarounds
17930,For now the following work-around could help:,Workarounds
17931,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
17932,Then: aptitude update,Workarounds
17933,The same trick cannot be used with Gradient Boosting.,Workarounds
17934,Example (untested): CODE,Workarounds
17935,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
17936,a cleaner solution must exist; maybe we are missing something?,Workarounds
17937,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
17938,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
17939,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
17940,I am experimenting with this workaround with the 1.x version.,Workarounds
17941,"Hopefully, this is logical.",Workarounds
17942,Use synaptic https://github.com/cazala/synaptic,Workarounds
17943,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
17944,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
17945,Gensim recommends the CODE library.,Workarounds
17946,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17947,[propelml.org] URL  - Looks interesting.,Workarounds
17948,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
17949,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds
17950,"In my opinion, this would be a very ugly workaround;",Workarounds
17951,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17952,I'm doing something like this:CODE,Workarounds
17953,You can also use OpenBLAS using conda-forge.,Workarounds
17954,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
17955,Here is a complete working code snippet for anybody interested: CODE,Workarounds
17956,So far it is working well.,Workarounds
17957,a cleaner solution must exist; maybe we are missing something?,Workarounds
17958,"Since serialization is the only way to reuse parsing results in a data pipeline and most real-world docs would have OOV words, this problem is pretty critical.",Workarounds
17959,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
17960,I fix him for now by:,Workarounds
17961,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
17962,So is the workaround to downgrade numpy?,Workarounds
17963,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
17964,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
17965,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
17966,Some workarounds are,Workarounds
17967,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
17968,Example (untested): CODE,Workarounds
17969,I'm doing something like this:CODE,Workarounds
17970,a cleaner solution must exist; maybe we are missing something?,Workarounds
17971,So is the workaround to downgrade numpy?,Workarounds
17972,@azar923 Did you try the CODE mitigation above?,Workarounds
17973,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
17974,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
17975,Call it whenever convenient.,Workarounds
17976,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
17977,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
17978,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17979,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
17980,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
17981,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
17982,"In my opinion, this would be a very ugly workaround;",Workarounds
17983,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
17984,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
17985,Reverting to TF 1.3 until this is resolved.,Workarounds
17986,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
17987,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
17988,Note that this only work for RandomForest and ExtraTrees.,Workarounds
17989,The OOV strings are encoded using the hash of the byte string.,Workarounds
17990,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
17991,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
17992,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
17993,Reverting to TF 1.3 until this is resolved.,Workarounds
17994,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
17995,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
17996,You can also use OpenBLAS using conda-forge.,Workarounds
17997,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
17998,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
17999,Some workarounds are,Workarounds
18000,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
18001,But with images this can be hardly done for the entire dataset in memory.,Workarounds
18002,"In my opinion, this would be a very ugly workaround;",Workarounds
18003,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
18004,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
18005,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
18006,3.         Avoid the CODE methods on the spaCy objects.,Workarounds
18007,Use synaptic https://github.com/cazala/synaptic,Workarounds
18008,For now the following work-around could help:,Workarounds
18009,[propelml.org] URL  - Looks interesting.,Workarounds
18010,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
18011,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
18012,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
18013,a cleaner solution must exist; maybe we are missing something?,Workarounds
18014,CODE,Workarounds
18015,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
18016,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
18017,I'm doing something like this:CODE,Workarounds
18018,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
18019,"In my opinion, this would be a very ugly workaround;",Workarounds
18020,Then: CODE,Workarounds
18021,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
18022,Ref: [v1.5.0_source] URL ,Workarounds
18023,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
18024,So the workaround doesn't really work.,Workarounds
18025,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
18026,CODE,Workarounds
18027,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
18028,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
18029,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
18030,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
18031,But with images this can be hardly done for the entire dataset in memory.,Workarounds
18032,You can also use OpenBLAS using conda-forge.,Workarounds
18033,Download deb (network) from:,Workarounds
18034,here's a full traceback..,Workarounds
18035,So far it is working well.,Workarounds
18036,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds
18037,@azar923 Did you try the CODE mitigation above?,Workarounds
18038,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
18039,The OOV strings are encoded using the hash of the byte string.,Workarounds
18040,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
18041,Then: aptitude update,Workarounds
18042,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
18043,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
18044,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
18045,Then: aptitude update,Workarounds
18046,[propelml.org] URL  - Looks interesting.,Workarounds
18047,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
18048,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
18049,The workaround of using set_frozen does not work.,Workarounds
18050,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
18051,a cleaner solution must exist; maybe we are missing something?,Workarounds
18052,This means that you'll get consistent integer encodings between flushings.,Workarounds
18053,Is there a way to reset the StringStore without reloading the model again ?,Workarounds
18054,here's a full traceback..,Workarounds
18055,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
18056,CODE,Workarounds
18057,The work-around is to not use Accelerate.,Workarounds
18058,So is the workaround to downgrade numpy?,Workarounds
18059,The workaround of using set_frozen does not work.,Workarounds
18060,So the workaround doesn't really work.,Workarounds
18061,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
18062,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds
18063,But with images this can be hardly done for the entire dataset in memory.,Workarounds
18064,Workarounds exist and have been listed in earlier posts.,Workarounds
18065,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
18066,This means that you'll get consistent integer encodings between flushings.,Workarounds
18067,On OSX you can do that with conda which uses MKL by default.,Workarounds
18068,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
18069,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
18070,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
18071,You can also use OpenBLAS using conda-forge.,Workarounds
18072,Some workarounds are,Workarounds
18073,The above works.,Workarounds
18074,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
18075,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
18076,I fix him for now by:,Workarounds
18077,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
18078,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
18079,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
18080,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
18081,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
18082,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
18083,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
18084,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
18085,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
18086,The OOV strings are encoded using the hash of the byte string.,Workarounds
18087,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
18088,"Since serialization is the only way to reuse parsing results in a data pipeline and most real-world docs would have OOV words, this problem is pretty critical.",Workarounds
18089,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
18090,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
18091,Some workarounds are,Workarounds
18092,The workaround of using set_frozen does not work.,Workarounds
18093,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
18094,Then: aptitude install cuda-9-0,Workarounds
18095,I am experimenting with this workaround with the 1.x version.,Workarounds
18096,On OSX you can do that with conda which uses MKL by default.,Workarounds
18097,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
18098,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
18099,Is there a way to reset the StringStore without reloading the model again ?,Workarounds
18100,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
18101,The same trick cannot be used with Gradient Boosting.,Workarounds
18102,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
18103,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
18104,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
18105,"Since serialization is the only way to reuse parsing results in a data pipeline and most real-world docs would have OOV words, this problem is pretty critical.",Workarounds
18106,@azar923 Did you try the CODE mitigation above?,Workarounds
18107,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
18108,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
18109,The work-around is to not use Accelerate.,Workarounds
18110,The OOV strings are encoded using the hash of the byte string.,Workarounds
18111,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
18112,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
18113,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
18114,Here is a complete working code snippet for anybody interested: CODE,Workarounds
18115,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
18116,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
18117,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
18118,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
18119,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
18120,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
18121,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
18122,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
18123,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
18124,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
18125,The work-around is to not use Accelerate.,Workarounds
18126,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
18127,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
18128,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds
18129,For now the following work-around could help:,Workarounds
18130,Ref: [v1.5.0_source] URL ,Workarounds
18131,Ref: [v1.5.0_source] URL ,Workarounds
18132,The work-around is to not use Accelerate.,Workarounds
18133,[propelml.org] URL  - Looks interesting.,Workarounds
18134,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
18135,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
18136,So is the workaround to downgrade numpy?,Workarounds
18137,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds
18138,Gensim recommends the CODE library.,Workarounds
18139,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
18140,Gensim recommends the CODE library.,Workarounds
18141,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
18142,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
18143,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
18144,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
18145,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
18146,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
18147,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
18148,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
18149,Download deb (network) from:,Workarounds
18150,"Since serialization is the only way to reuse parsing results in a data pipeline and most real-world docs would have OOV words, this problem is pretty critical.",Workarounds
18151,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
18152,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
18153,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds
18154,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
18155,Then: aptitude install cuda-9-0,Workarounds
18156,Summary:-         New CODE keyword argument to CODE,Workarounds
18157,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
18158,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
18159,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds
18160,I fix him for now by:,Workarounds
18161,"In my opinion, this would be a very ugly workaround;",Workarounds
18162,The OOV strings are encoded using the hash of the byte string.,Workarounds
18163,The above works.,Workarounds
18164,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
18165,Ref: [v1.5.0_source] URL ,Workarounds
18166,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds
18167,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
18168,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
18169,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
18170,So far it is working well.,Workarounds
18171,I am experimenting with this workaround with the 1.x version.,Workarounds
18172,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
18173,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
18174,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
18175,Reverting to TF 1.3 until this is resolved.,Workarounds
18176,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
18177,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
18178,Download deb (network) from:,Workarounds
18179,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
18180,Note that this only work for RandomForest and ExtraTrees.,Workarounds
18181,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
18182,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
18183,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
18184,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
18185,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
18186,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
18187,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds
18188,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
18189,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
18190,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
18191,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
18192,Some workarounds are,Workarounds
18193,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
18194,a cleaner solution must exist; maybe we are missing something?,Workarounds
18195,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
18196,This means that you'll get consistent integer encodings between flushings.,Workarounds
18197,But with images this can be hardly done for the entire dataset in memory.,Workarounds
18198,I fix him for now by:,Workarounds
18199,[propelml.org] URL  - Looks interesting.,Workarounds
18200,Then: CODE,Workarounds
18201,Some workarounds are,Workarounds
18202,"Since serialization is the only way to reuse parsing results in a data pipeline and most real-world docs would have OOV words, this problem is pretty critical.",Workarounds
18203,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
18204,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
18205,I'm doing something like this:CODE,Workarounds
18206,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
18207,The OOV strings are encoded using the hash of the byte string.,Workarounds
18208,For now the following work-around could help:,Workarounds
18209,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
18210,"In my opinion, this would be a very ugly workaround;",Workarounds
18211,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
18212,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
18213,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
18214,Gensim recommends the CODE library.,Workarounds
18215,Then: aptitude update,Workarounds
18216,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
18217,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
18218,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
18219,Reverting to TF 1.3 until this is resolved.,Workarounds
18220,I am experimenting with this workaround with the 1.x version.,Workarounds
18221,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
18222,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
18223,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
18224,Ref: [v1.5.0_source] URL ,Workarounds
18225,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
18226,Reverting to TF 1.3 until this is resolved.,Workarounds
18227,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds
18228,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds
18229,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
18230,The same trick cannot be used with Gradient Boosting.,Workarounds
18231,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
18232,The same trick cannot be used with Gradient Boosting.,Workarounds
18233,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
18234,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
18235,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds
18236,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds
18237,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds
18238,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds
18239,Then: aptitude install cuda-9-0,Workarounds
18240,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
18241,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
18242,here's a full traceback..,Workarounds
18243,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
18244,Use synaptic https://github.com/cazala/synaptic,Workarounds
18245,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds
18246,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
18247,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
18248,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
18249,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
18250,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
18251,Download deb (network) from:,Workarounds
18252,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds
18253,a cleaner solution must exist; maybe we are missing something?,Workarounds
18254,Gensim recommends the CODE library.,Workarounds
18255,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
18256,Reverting to TF 1.3 until this is resolved.,Workarounds
18257,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds
18258,Note that this only work for RandomForest and ExtraTrees.,Workarounds
18259,Reverting to TF 1.3 until this is resolved.,Workarounds
18260,Then: CODE,Workarounds
18261,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds
18262,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
18263,Then: aptitude update,Workarounds
18264,@azar923 Did you try the CODE mitigation above?,Workarounds
18265,I am experimenting with this workaround with the 1.x version.,Workarounds
18266,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
18267,The same trick cannot be used with Gradient Boosting.,Workarounds
18268,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds
18269,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds
18270,Then: aptitude update,Workarounds
18271,Reverting to TF 1.3 until this is resolved.,Workarounds
18272,Then: aptitude update,Workarounds
18273,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds
18274,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
18275,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds
18276,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds
18277,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
18278,Call it whenever convenient.,Workarounds
18279,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
18280,Some workarounds are,Workarounds
18281,Then: CODE,Workarounds
18282,Download deb (network) from:,Workarounds
18283,The workaround of using set_frozen does not work.,Workarounds
18284,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
18285,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds
18286,Is there a way to reset the StringStore without reloading the model again ?,Workarounds
18287,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
18288,a cleaner solution must exist; maybe we are missing something?,Workarounds
18289,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
18290,Download deb (network) from:,Workarounds
18291,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds
18292,Workarounds exist and have been listed in earlier posts.,Workarounds
18293,I am experimenting with this workaround with the 1.x version.,Workarounds
18294,None of those workarounds worked for me with Tensorflow 1.1,Workarounds
18295,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds
18296,Gensim recommends the CODE library.,Workarounds
18297,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds
18298,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds
18299,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds
18300,@azar923 Did you try the CODE mitigation above?,Workarounds
18301,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
18302,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds
18303,CODE,Workarounds
18304,"Hopefully, this is logical.",Workarounds
18305,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
18306,"Hopefully, this is logical.",Workarounds
18307,Is there a way to reset the StringStore without reloading the model again ?,Workarounds
18308,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
18309,Gensim recommends the CODE library.,Workarounds
18310,But with images this can be hardly done for the entire dataset in memory.,Workarounds
18311,Use synaptic https://github.com/cazala/synaptic,Workarounds
18312,This means that you'll get consistent integer encodings between flushings.,Workarounds
18313,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds
18314,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
18315,Reverting to TF 1.3 until this is resolved.,Workarounds
18316,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds
18317,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds
18318,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds
18319,[propelml.org] URL  - Looks interesting.,Workarounds
18320,This means that you'll get consistent integer encodings between flushings.,Workarounds
18321,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
18322,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds
18323,Example (untested): CODE,Workarounds
18324,a cleaner solution must exist; maybe we are missing something?,Workarounds
18325,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds
18326,I'm doing something like this:CODE,Workarounds
18327,Use synaptic https://github.com/cazala/synaptic,Workarounds
18328,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds
18329,Is there a way to reset the StringStore without reloading the model again ?,Workarounds
18330,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
18331,"Since serialization is the only way to reuse parsing results in a data pipeline and most real-world docs would have OOV words, this problem is pretty critical.",Workarounds
18332,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds
18333,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds
18334,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds
18335,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds
18336,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds
18337,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds
18338,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds
18339,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds
18340,Example (untested): CODE,Workarounds
18341,"2.         Make your own similarity server, that does the central look-up for you",Workarounds
18342,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds
