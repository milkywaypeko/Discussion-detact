[{
  "url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122",
  "repository_url": "https://api.github.com/repos/tensorflow/tensorflow",
  "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122/labels{/name}",
  "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122/comments",
  "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122/events",
  "html_url": "https://github.com/tensorflow/tensorflow/issues/1122",
  "id": 133980206,
  "node_id": "MDU6SXNzdWUxMzM5ODAyMDY=",
  "number": 1122,
  "title": "Easy to use batch norm layer.",
  "user": {
    "login": "cesarsalgado",
    "id": 1115209,
    "node_id": "MDQ6VXNlcjExMTUyMDk=",
    "avatar_url": "https://avatars2.githubusercontent.com/u/1115209?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/cesarsalgado",
    "html_url": "https://github.com/cesarsalgado",
    "followers_url": "https://api.github.com/users/cesarsalgado/followers",
    "following_url": "https://api.github.com/users/cesarsalgado/following{/other_user}",
    "gists_url": "https://api.github.com/users/cesarsalgado/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/cesarsalgado/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/cesarsalgado/subscriptions",
    "organizations_url": "https://api.github.com/users/cesarsalgado/orgs",
    "repos_url": "https://api.github.com/users/cesarsalgado/repos",
    "events_url": "https://api.github.com/users/cesarsalgado/events{/privacy}",
    "received_events_url": "https://api.github.com/users/cesarsalgado/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 299643928,
      "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=",
      "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome",
      "name": "stat:contributions welcome",
      "color": "f4b400",
      "default": false
    },
    {
      "id": 284443156,
      "node_id": "MDU6TGFiZWwyODQ0NDMxNTY=",
      "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:docs",
      "name": "type:docs",
      "color": "159b2e",
      "default": false
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": {
    "login": "sguada",
    "id": 1766524,
    "node_id": "MDQ6VXNlcjE3NjY1MjQ=",
    "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/sguada",
    "html_url": "https://github.com/sguada",
    "followers_url": "https://api.github.com/users/sguada/followers",
    "following_url": "https://api.github.com/users/sguada/following{/other_user}",
    "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/sguada/subscriptions",
    "organizations_url": "https://api.github.com/users/sguada/orgs",
    "repos_url": "https://api.github.com/users/sguada/repos",
    "events_url": "https://api.github.com/users/sguada/events{/privacy}",
    "received_events_url": "https://api.github.com/users/sguada/received_events",
    "type": "User",
    "site_admin": false
  },
  "assignees": [
    {
      "login": "sguada",
      "id": 1766524,
      "node_id": "MDQ6VXNlcjE3NjY1MjQ=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sguada",
      "html_url": "https://github.com/sguada",
      "followers_url": "https://api.github.com/users/sguada/followers",
      "following_url": "https://api.github.com/users/sguada/following{/other_user}",
      "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sguada/subscriptions",
      "organizations_url": "https://api.github.com/users/sguada/orgs",
      "repos_url": "https://api.github.com/users/sguada/repos",
      "events_url": "https://api.github.com/users/sguada/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sguada/received_events",
      "type": "User",
      "site_admin": false
    }
  ],
  "milestone": null,
  "comments": 127,
  "created_at": "2016-02-16T13:18:56Z",
  "updated_at": "2018-02-07T23:17:07Z",
  "closed_at": "2018-02-07T23:17:07Z",
  "author_association": "CONTRIBUTOR",
  "body": "Many non-experts are using the following code http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow?answertab=votes#tab-top.\n\nIt would be nice to have an official batch norm layer given its importance in training DNNs.\n",
  "closed_by": {
    "login": "annarev",
    "id": 22060313,
    "node_id": "MDQ6VXNlcjIyMDYwMzEz",
    "avatar_url": "https://avatars0.githubusercontent.com/u/22060313?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/annarev",
    "html_url": "https://github.com/annarev",
    "followers_url": "https://api.github.com/users/annarev/followers",
    "following_url": "https://api.github.com/users/annarev/following{/other_user}",
    "gists_url": "https://api.github.com/users/annarev/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/annarev/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/annarev/subscriptions",
    "organizations_url": "https://api.github.com/users/annarev/orgs",
    "repos_url": "https://api.github.com/users/annarev/repos",
    "events_url": "https://api.github.com/users/annarev/events{/privacy}",
    "received_events_url": "https://api.github.com/users/annarev/received_events",
    "type": "User",
    "site_admin": false
  }
},{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/184698029", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-184698029", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 184698029, "node_id": "MDEyOklzc3VlQ29tbWVudDE4NDY5ODAyOQ==", "user": {"login": "vincentvanhoucke", "id": 15737127, "node_id": "MDQ6VXNlcjE1NzM3MTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/15737127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincentvanhoucke", "html_url": "https://github.com/vincentvanhoucke", "followers_url": "https://api.github.com/users/vincentvanhoucke/followers", "following_url": "https://api.github.com/users/vincentvanhoucke/following{/other_user}", "gists_url": "https://api.github.com/users/vincentvanhoucke/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincentvanhoucke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincentvanhoucke/subscriptions", "organizations_url": "https://api.github.com/users/vincentvanhoucke/orgs", "repos_url": "https://api.github.com/users/vincentvanhoucke/repos", "events_url": "https://api.github.com/users/vincentvanhoucke/events{/privacy}", "received_events_url": "https://api.github.com/users/vincentvanhoucke/received_events", "type": "User", "site_admin": false}, "created_at": "2016-02-16T14:19:56Z", "updated_at": "2016-02-16T14:19:56Z", "author_association": "MEMBER", "body": "I'm working on some parts of that.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/224945267", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-224945267", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 224945267, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNDk0NTI2Nw==", "user": {"login": "vincentvanhoucke", "id": 15737127, "node_id": "MDQ6VXNlcjE1NzM3MTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/15737127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincentvanhoucke", "html_url": "https://github.com/vincentvanhoucke", "followers_url": "https://api.github.com/users/vincentvanhoucke/followers", "following_url": "https://api.github.com/users/vincentvanhoucke/following{/other_user}", "gists_url": "https://api.github.com/users/vincentvanhoucke/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincentvanhoucke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincentvanhoucke/subscriptions", "organizations_url": "https://api.github.com/users/vincentvanhoucke/orgs", "repos_url": "https://api.github.com/users/vincentvanhoucke/repos", "events_url": "https://api.github.com/users/vincentvanhoucke/events{/privacy}", "received_events_url": "https://api.github.com/users/vincentvanhoucke/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-09T16:12:25Z", "updated_at": "2016-06-09T16:12:25Z", "author_association": "MEMBER", "body": "There is now a `batch_norm` layer:\nhttps://github.com/tensorflow/tensorflow/blob/b826b79718e3e93148c3545e7aa3f90891744cc0/tensorflow/contrib/layers/python/layers/layers.py#L100\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/226928192", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-226928192", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 226928192, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNjkyODE5Mg==", "user": {"login": "Mahdizade", "id": 5513062, "node_id": "MDQ6VXNlcjU1MTMwNjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/5513062?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mahdizade", "html_url": "https://github.com/Mahdizade", "followers_url": "https://api.github.com/users/Mahdizade/followers", "following_url": "https://api.github.com/users/Mahdizade/following{/other_user}", "gists_url": "https://api.github.com/users/Mahdizade/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mahdizade/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mahdizade/subscriptions", "organizations_url": "https://api.github.com/users/Mahdizade/orgs", "repos_url": "https://api.github.com/users/Mahdizade/repos", "events_url": "https://api.github.com/users/Mahdizade/events{/privacy}", "received_events_url": "https://api.github.com/users/Mahdizade/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-18T07:55:49Z", "updated_at": "2016-06-18T11:55:25Z", "author_association": "NONE", "body": "I think some thing wrong with this layer. in training every thing is OK and loss decrease very good. but in testing I get zero accuracy.\nBy the way in testing when I use is_training=False, I get zero acc.\nI know batch normalization behave different in train and test phase, as describe in [How does batch normalization behave differently at training time and test time? - Quora](https://www.quora.com/How-does-batch-normalization-behave-differently-at-training-time-and-test-time). I think this implementation is unclear\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227278967", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-227278967", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 227278967, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzI3ODk2Nw==", "user": {"login": "pawni", "id": 2412413, "node_id": "MDQ6VXNlcjI0MTI0MTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2412413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pawni", "html_url": "https://github.com/pawni", "followers_url": "https://api.github.com/users/pawni/followers", "following_url": "https://api.github.com/users/pawni/following{/other_user}", "gists_url": "https://api.github.com/users/pawni/gists{/gist_id}", "starred_url": "https://api.github.com/users/pawni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pawni/subscriptions", "organizations_url": "https://api.github.com/users/pawni/orgs", "repos_url": "https://api.github.com/users/pawni/repos", "events_url": "https://api.github.com/users/pawni/events{/privacy}", "received_events_url": "https://api.github.com/users/pawni/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-20T21:43:28Z", "updated_at": "2016-06-20T21:43:28Z", "author_association": "NONE", "body": "Same here, I have experienced some unexpected behavior with is_training=False. What is the correct way to change this flag? I am currently using a `tf.cond` because it does not take `tf.placeholders` by itself.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227280884", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-227280884", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 227280884, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzI4MDg4NA==", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-20T21:51:13Z", "updated_at": "2016-06-20T21:51:13Z", "author_association": "CONTRIBUTOR", "body": "@pawni You have to use a Python boolean for `is_training`. It cannot be a `tf.cond`.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227281902", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-227281902", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 227281902, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzI4MTkwMg==", "user": {"login": "pawni", "id": 2412413, "node_id": "MDQ6VXNlcjI0MTI0MTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2412413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pawni", "html_url": "https://github.com/pawni", "followers_url": "https://api.github.com/users/pawni/followers", "following_url": "https://api.github.com/users/pawni/following{/other_user}", "gists_url": "https://api.github.com/users/pawni/gists{/gist_id}", "starred_url": "https://api.github.com/users/pawni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pawni/subscriptions", "organizations_url": "https://api.github.com/users/pawni/orgs", "repos_url": "https://api.github.com/users/pawni/repos", "events_url": "https://api.github.com/users/pawni/events{/privacy}", "received_events_url": "https://api.github.com/users/pawni/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-20T21:55:28Z", "updated_at": "2016-06-20T21:55:28Z", "author_association": "NONE", "body": "@ppwwyyxx well I am doing `tf.cond(placeholder, batch_norm(.., is_training = True), batch_norm(.., is_training = False))` or is one just supposed to do a `batch_norm(.., is_training=variable)` and change that outside of the graph when needed?\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227285926", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-227285926", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 227285926, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzI4NTkyNg==", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-20T22:12:49Z", "updated_at": "2016-06-20T22:12:49Z", "author_association": "CONTRIBUTOR", "body": "Oh I thought you were doing `batch_norm(.., is_training=tf.cond(placeholder))`, which is incorrect.\nYour current way might have problems as well. You'll need to double check that the two `batch_norm` op you created share the same scope, otherwise they won't share the underlying mean/variance statistics.\n\nTo do this the `reuse` argument might help, but I'm not sure because I use my own version of bn layer.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227287664", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-227287664", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 227287664, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzI4NzY2NA==", "user": {"login": "pawni", "id": 2412413, "node_id": "MDQ6VXNlcjI0MTI0MTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2412413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pawni", "html_url": "https://github.com/pawni", "followers_url": "https://api.github.com/users/pawni/followers", "following_url": "https://api.github.com/users/pawni/following{/other_user}", "gists_url": "https://api.github.com/users/pawni/gists{/gist_id}", "starred_url": "https://api.github.com/users/pawni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pawni/subscriptions", "organizations_url": "https://api.github.com/users/pawni/orgs", "repos_url": "https://api.github.com/users/pawni/repos", "events_url": "https://api.github.com/users/pawni/events{/privacy}", "received_events_url": "https://api.github.com/users/pawni/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-20T22:21:03Z", "updated_at": "2016-06-20T22:21:03Z", "author_association": "NONE", "body": "I am using the same scope and `reuse=True`. It seems to work sometimes but I am not too sure. It would be great if the layer could be added to the documentation with a short explanation how to best handle the change from training to test.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227316757", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-227316757", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 227316757, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzMxNjc1Nw==", "user": {"login": "vincentvanhoucke", "id": 15737127, "node_id": "MDQ6VXNlcjE1NzM3MTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/15737127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincentvanhoucke", "html_url": "https://github.com/vincentvanhoucke", "followers_url": "https://api.github.com/users/vincentvanhoucke/followers", "following_url": "https://api.github.com/users/vincentvanhoucke/following{/other_user}", "gists_url": "https://api.github.com/users/vincentvanhoucke/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincentvanhoucke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincentvanhoucke/subscriptions", "organizations_url": "https://api.github.com/users/vincentvanhoucke/orgs", "repos_url": "https://api.github.com/users/vincentvanhoucke/repos", "events_url": "https://api.github.com/users/vincentvanhoucke/events{/privacy}", "received_events_url": "https://api.github.com/users/vincentvanhoucke/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-21T01:29:05Z", "updated_at": "2016-06-21T01:29:05Z", "author_association": "MEMBER", "body": "@sguada FYI\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227335440", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-227335440", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 227335440, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzMzNTQ0MA==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-21T04:05:45Z", "updated_at": "2016-06-21T04:05:45Z", "author_association": "MEMBER", "body": "Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227335632", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-227335632", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 227335632, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzMzNTYzMg==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-21T04:07:39Z", "updated_at": "2016-06-21T04:07:57Z", "author_association": "MEMBER", "body": "@pawni If you don't want to worry about about updating moving_mean and moving_variance set updates_collections=None to make sure they are updated in place, otherwise you need to make sure the update_ops added to tf.GraphKeys.UPDATE_OPS are run during training.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227337871", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-227337871", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 227337871, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzMzNzg3MQ==", "user": {"login": "Mahdizade", "id": 5513062, "node_id": "MDQ6VXNlcjU1MTMwNjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/5513062?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mahdizade", "html_url": "https://github.com/Mahdizade", "followers_url": "https://api.github.com/users/Mahdizade/followers", "following_url": "https://api.github.com/users/Mahdizade/following{/other_user}", "gists_url": "https://api.github.com/users/Mahdizade/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mahdizade/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mahdizade/subscriptions", "organizations_url": "https://api.github.com/users/Mahdizade/orgs", "repos_url": "https://api.github.com/users/Mahdizade/repos", "events_url": "https://api.github.com/users/Mahdizade/events{/privacy}", "received_events_url": "https://api.github.com/users/Mahdizade/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-21T04:30:18Z", "updated_at": "2016-06-21T04:30:18Z", "author_association": "NONE", "body": "I think tensorflow need 2 hyper methods that change the model state, something like torch. [change model state](https://github.com/torch/nn/blob/master/doc/module.md#training). I think it is very straightforward. \n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231855028", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-231855028", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 231855028, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTg1NTAyOA==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-11T20:30:40Z", "updated_at": "2016-07-11T20:30:40Z", "author_association": "NONE", "body": "is there a small script with a very simple NN that shows what is the proper way of using this \"official\" BN layer? I'd really appreciate it.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231857525", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-231857525", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 231857525, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTg1NzUyNQ==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-11T20:39:28Z", "updated_at": "2016-07-11T20:40:11Z", "author_association": "NONE", "body": "sorry if this is a little repetitive, but it seems the API talks about BN in a different interface: https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#batch_normalization\n\nis that not the official way to use BN? I am confused on how to use it and the SO seems to be outdated and then there is a layer in a different link from the API, just how exactly does one do this? I am unclear if to go to SO or ask here.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231908288", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-231908288", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 231908288, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTkwODI4OA==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-12T00:51:27Z", "updated_at": "2016-07-12T00:51:55Z", "author_association": "NONE", "body": "sorry for the spamming, but what is wrong with just using something like this:\n\n```\ndef standard_batch_norm(l, x, n_out, phase_train, scope='BN'):\n    \"\"\"\n    Batch normalization on feedforward maps.\n    Args:\n        x:           Vector\n        n_out:       integer, depth of input maps\n        phase_train: boolean tf.Varialbe, true indicates training phase\n        scope:       string, variable scope\n    Return:\n        normed:      batch-normalized maps\n    \"\"\"\n    with tf.variable_scope(scope+l):\n        #beta = tf.Variable(tf.constant(0.0, shape=[n_out], dtype=tf.float64 ), name='beta', trainable=True, dtype=tf.float64 )\n        #gamma = tf.Variable(tf.constant(1.0, shape=[n_out],dtype=tf.float64 ), name='gamma', trainable=True, dtype=tf.float64 )\n        init_beta = tf.constant(0.0, shape=[n_out], dtype=tf.float64)\n        init_gamma = tf.constant(1.0, shape=[n_out],dtype=tf.float64)\n        beta = tf.get_variable(name='beta'+l, dtype=tf.float64, initializer=init_beta, regularizer=None, trainable=True)\n        gamma = tf.get_variable(name='gamma'+l, dtype=tf.float64, initializer=init_gamma, regularizer=None, trainable=True)\n        batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n        ema = tf.train.ExponentialMovingAverage(decay=0.5)\n\n        def mean_var_with_update():\n            ema_apply_op = ema.apply([batch_mean, batch_var])\n            with tf.control_dependencies([ema_apply_op]):\n                return tf.identity(batch_mean), tf.identity(batch_var)\n\n        mean, var = tf.cond(phase_train, mean_var_with_update, lambda: (ema.average(batch_mean), ema.average(batch_var)))\n        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n    return normed\n```\n\nthen its simple to tell tensorflow which one to use with a feed dictionary as in:\n\n```\nfeed_dict = {x: Xminibatch, y_: Yminibatch, phase_train: True}\nsess.run(fetches=[merged,train_step], feed_dict=feed_dict)\n```\n\nsince its unclear if the implementation will change, I wanted to give a suggestion (note its easy to extend to convolutions and stuff I just didn't paste that code).\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231913876", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-231913876", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 231913876, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTkxMzg3Ng==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-12T01:33:15Z", "updated_at": "2016-07-12T01:33:15Z", "author_association": "NONE", "body": "@pawni @ppwwyyxx did you guys decide if you had to use reuse to true to solve the scoping issue?\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/231917736", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-231917736", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 231917736, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTkxNzczNg==", "user": {"login": "pawni", "id": 2412413, "node_id": "MDQ6VXNlcjI0MTI0MTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2412413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pawni", "html_url": "https://github.com/pawni", "followers_url": "https://api.github.com/users/pawni/followers", "following_url": "https://api.github.com/users/pawni/following{/other_user}", "gists_url": "https://api.github.com/users/pawni/gists{/gist_id}", "starred_url": "https://api.github.com/users/pawni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pawni/subscriptions", "organizations_url": "https://api.github.com/users/pawni/orgs", "repos_url": "https://api.github.com/users/pawni/repos", "events_url": "https://api.github.com/users/pawni/events{/privacy}", "received_events_url": "https://api.github.com/users/pawni/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-12T02:01:40Z", "updated_at": "2016-07-12T02:01:40Z", "author_association": "NONE", "body": "@brando90 currently I am doing something like:\n\n```\ndef BatchNorm(inputT, is_training=True, scope=None):\n    return tf.cond(isTraining,\n                lambda: batch_norm(inputT, is_training=True,\n                                   center=False, updates_collections=None, scope=scope),\n                lambda: batch_norm(inputT, is_training=False,\n                                   updates_collections=None, center=False, scope=scope, reuse = True))\n```\n\nHowever, I think that #3265 would basically want to implement it like this. A reference could be the dropout implementation here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L433-L435\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/232202067", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-232202067", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 232202067, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMjIwMjA2Nw==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-12T22:31:13Z", "updated_at": "2016-07-12T22:31:13Z", "author_association": "MEMBER", "body": "When the updates_collections=None then the updates happens in-place and it is easier to use a tf.cond() to allow is_training being a Tensor a bit more complicated is when the updates are delayed and the the update_ops are run later.\nI will try to get the first part in soon.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/232535426", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-232535426", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 232535426, "node_id": "MDEyOklzc3VlQ29tbWVudDIzMjUzNTQyNg==", "user": {"login": "nmhkahn", "id": 16869368, "node_id": "MDQ6VXNlcjE2ODY5MzY4", "avatar_url": "https://avatars0.githubusercontent.com/u/16869368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nmhkahn", "html_url": "https://github.com/nmhkahn", "followers_url": "https://api.github.com/users/nmhkahn/followers", "following_url": "https://api.github.com/users/nmhkahn/following{/other_user}", "gists_url": "https://api.github.com/users/nmhkahn/gists{/gist_id}", "starred_url": "https://api.github.com/users/nmhkahn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nmhkahn/subscriptions", "organizations_url": "https://api.github.com/users/nmhkahn/orgs", "repos_url": "https://api.github.com/users/nmhkahn/repos", "events_url": "https://api.github.com/users/nmhkahn/events{/privacy}", "received_events_url": "https://api.github.com/users/nmhkahn/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-14T01:49:35Z", "updated_at": "2016-07-14T01:51:05Z", "author_association": "NONE", "body": "@brando90 @pawni he's code works good, but have to change like below\n\n``` python\ndef BatchNorm(inputT, is_training=True, scope=None):\n    # Note: is_training is tf.placeholder(tf.bool) type\n    return tf.cond(is_training,  \n                lambda: batch_norm(inputT, is_training=True,  \n                                   center=False, updates_collections=None, scope=scope),  \n                lambda: batch_norm(inputT, is_training=False,  \n                                   updates_collections=None, center=False, scope=scope, reuse = True))  \n```\n\nAnd when run in training or test time,\n\n``` python\n# when training \nsess.run([opt, loss], feed_dict={x: bx, y: by, is_training=True})  \n\n# when test \nsess.run([opt, loss], feed_dict={x: bx, y: by, is_training=False})  \n```\n\nThis code works, but like [#3265](https://github.com/tensorflow/tensorflow/issues/3265) says it will be great if `tf.contrib.layers.batch_norm` get `is_training` variable as a `tf.plcaeholer`.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234408791", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-234408791", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 234408791, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDQwODc5MQ==", "user": {"login": "diegoAtAlpine", "id": 19438656, "node_id": "MDQ6VXNlcjE5NDM4NjU2", "avatar_url": "https://avatars1.githubusercontent.com/u/19438656?v=4", "gravatar_id": "", "url": "https://api.github.com/users/diegoAtAlpine", "html_url": "https://github.com/diegoAtAlpine", "followers_url": "https://api.github.com/users/diegoAtAlpine/followers", "following_url": "https://api.github.com/users/diegoAtAlpine/following{/other_user}", "gists_url": "https://api.github.com/users/diegoAtAlpine/gists{/gist_id}", "starred_url": "https://api.github.com/users/diegoAtAlpine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/diegoAtAlpine/subscriptions", "organizations_url": "https://api.github.com/users/diegoAtAlpine/orgs", "repos_url": "https://api.github.com/users/diegoAtAlpine/repos", "events_url": "https://api.github.com/users/diegoAtAlpine/events{/privacy}", "received_events_url": "https://api.github.com/users/diegoAtAlpine/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-21T22:55:26Z", "updated_at": "2016-07-25T15:16:00Z", "author_association": "NONE", "body": "@nmhkahn @pawni thanks for the code snippets. They were very useful in adding batch normalization to my convolution network.  Training seems to work very well. Testing is not.  In some versions of the code training accuracies are much higher than testing accuracies, which probably mean I am not sharing batch normalization parameters.  In other versions of the code I get \"ValueError: Variable conv1/beta already exists, disallowed. Did you mean to set reuse=True in VarScope?\" which seem to indicate that I am trying to relearn the parameter... when I was trying to reuse.\n\nCan someone provide an example of how to call the \"def BatchNorm\" function during training and testing so that variable sharing happen correctly.\n\nThanks for any help.\n\nUPDATE July 25, 2016:\n\n@nmhkahn @pawni thanks for your comments.  After taking a closer look at the code in contrib I realized what my problem was.  During training and testing we are either updating or reusing four variables (beta, gamma, moving_mean and moving_variance). To make those unique I had to set a scope per layer.  I did it like this:\n\nconv1 = tf.nn.relu(batch_norm_layer(conv2d_stride2_valid(data, W_conv1) + b_conv1, train_phase, scope=\"conv1\"))\n\nwhere batch_norm_layer is similar to the examples from @nmhkahn @pawni, conv2d_stride2_valid is just a def to define a convolutional layer, and W_conv1 and b_conv1 are variables holding the weights and biases. I could probably remove the bias term because we are using batch normalization.\n\nThe net is working well now.  I noticed after plotting accuracies in training and test mode that the testing accuracies start climbing after the training accuracies.  In retrospect it make sense since we are collecting dataset statistics for testing.  But it appeared as if I was doing something wrong during my initial tests. Thanks for your comments and making batch normalization available to the community.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234641621", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-234641621", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 234641621, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDY0MTYyMQ==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-22T20:00:07Z", "updated_at": "2016-07-22T20:00:07Z", "author_association": "NONE", "body": "@nmhkahn how is it different from pawni's suggestion?\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234646623", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-234646623", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 234646623, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDY0NjYyMw==", "user": {"login": "pawni", "id": 2412413, "node_id": "MDQ6VXNlcjI0MTI0MTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2412413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pawni", "html_url": "https://github.com/pawni", "followers_url": "https://api.github.com/users/pawni/followers", "following_url": "https://api.github.com/users/pawni/following{/other_user}", "gists_url": "https://api.github.com/users/pawni/gists{/gist_id}", "starred_url": "https://api.github.com/users/pawni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pawni/subscriptions", "organizations_url": "https://api.github.com/users/pawni/orgs", "repos_url": "https://api.github.com/users/pawni/repos", "events_url": "https://api.github.com/users/pawni/events{/privacy}", "received_events_url": "https://api.github.com/users/pawni/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-22T20:22:54Z", "updated_at": "2016-07-22T20:22:54Z", "author_association": "NONE", "body": "@brando90 I had a small error in my version which was fixed by nmhkahn (changing `isTraining` to `is_training`)\n\n@diegoAtAlpine I found the same problems - not sure why this is the case though. However, the ValueError should be resolved by the code snippet. Not sure what you want to see how to call it as nmhkahn's examples seems to do the job?\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234653960", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-234653960", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 234653960, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDY1Mzk2MA==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-22T20:55:01Z", "updated_at": "2016-07-22T20:55:51Z", "author_association": "NONE", "body": "@nmhkahn @pawni @ when you do:\n\n`sess.run([opt, loss], feed_dict={x: bx, y: by, is_training=True})`\n\ndoesn't that mean that your using `is_training` as a placeholder? People have commented that they want `is_training` to be a placer holder but thats what I had for my version of it:\n\n```\ndef batch_norm_layer(x,train_phase,scope_bn):\n\n    bn_train = batch_norm(x, decay=0.999, center=True, scale=True,\n    is_training=True,\n    reuse=None, # is this right?\n    trainable=True,\n    scope=scope_bn)\n    bn_inference = batch_norm(x, decay=0.999, center=True, scale=True,\n    is_training=False,\n    reuse=True, # is this right?\n    trainable=True,\n    scope=scope_bn)\n    z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)\n    return z\n```\n\nis that not correct?\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234655168", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-234655168", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 234655168, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDY1NTE2OA==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-22T20:59:49Z", "updated_at": "2016-07-27T18:49:54Z", "author_association": "MEMBER", "body": "I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training. It will be merged in TF contrib soon.\n\nNow available in\nhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234665881", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-234665881", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 234665881, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDY2NTg4MQ==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-22T21:51:10Z", "updated_at": "2016-07-22T21:51:10Z", "author_association": "NONE", "body": "is it just me or does adding this BN layer noticeably slows down training of a single epoch?\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234666997", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-234666997", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 234666997, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDY2Njk5Nw==", "user": {"login": "pawni", "id": 2412413, "node_id": "MDQ6VXNlcjI0MTI0MTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2412413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pawni", "html_url": "https://github.com/pawni", "followers_url": "https://api.github.com/users/pawni/followers", "following_url": "https://api.github.com/users/pawni/following{/other_user}", "gists_url": "https://api.github.com/users/pawni/gists{/gist_id}", "starred_url": "https://api.github.com/users/pawni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pawni/subscriptions", "organizations_url": "https://api.github.com/users/pawni/orgs", "repos_url": "https://api.github.com/users/pawni/repos", "events_url": "https://api.github.com/users/pawni/events{/privacy}", "received_events_url": "https://api.github.com/users/pawni/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-22T21:56:55Z", "updated_at": "2016-07-22T21:56:55Z", "author_association": "NONE", "body": "@brando90 It slows down training for me as well but I think that this is expected as it needs to calculate some statistics. And your version looks good to me.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/234670633", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-234670633", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 234670633, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNDY3MDYzMw==", "user": {"login": "omoindrot", "id": 13662086, "node_id": "MDQ6VXNlcjEzNjYyMDg2", "avatar_url": "https://avatars3.githubusercontent.com/u/13662086?v=4", "gravatar_id": "", "url": "https://api.github.com/users/omoindrot", "html_url": "https://github.com/omoindrot", "followers_url": "https://api.github.com/users/omoindrot/followers", "following_url": "https://api.github.com/users/omoindrot/following{/other_user}", "gists_url": "https://api.github.com/users/omoindrot/gists{/gist_id}", "starred_url": "https://api.github.com/users/omoindrot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/omoindrot/subscriptions", "organizations_url": "https://api.github.com/users/omoindrot/orgs", "repos_url": "https://api.github.com/users/omoindrot/repos", "events_url": "https://api.github.com/users/omoindrot/events{/privacy}", "received_events_url": "https://api.github.com/users/omoindrot/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-22T22:17:59Z", "updated_at": "2016-07-22T22:17:59Z", "author_association": "CONTRIBUTOR", "body": "BatchNorm is currently very slow (because of all the statistics computed), but they are working on adding a cudnn batchnorm op as said [here](https://github.com/tensorflow/tensorflow/pull/1759#issuecomment-228856467).\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/235082287", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235082287", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 235082287, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTA4MjI4Nw==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-25T20:56:03Z", "updated_at": "2016-07-25T20:56:03Z", "author_association": "NONE", "body": "@nmhkahn  quick question. When you wrote (for testing):\n\n`sess.run([opt, loss], feed_dict={x: bx, y: by, is_training=False})`\n\nin theory, can bx and by be any data set? i.e. it can still be the **training** set even though we are not training? (i.e. just to track the train error) \n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/235159235", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235159235", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 235159235, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTE1OTIzNQ==", "user": {"login": "nmhkahn", "id": 16869368, "node_id": "MDQ6VXNlcjE2ODY5MzY4", "avatar_url": "https://avatars0.githubusercontent.com/u/16869368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nmhkahn", "html_url": "https://github.com/nmhkahn", "followers_url": "https://api.github.com/users/nmhkahn/followers", "following_url": "https://api.github.com/users/nmhkahn/following{/other_user}", "gists_url": "https://api.github.com/users/nmhkahn/gists{/gist_id}", "starred_url": "https://api.github.com/users/nmhkahn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nmhkahn/subscriptions", "organizations_url": "https://api.github.com/users/nmhkahn/orgs", "repos_url": "https://api.github.com/users/nmhkahn/repos", "events_url": "https://api.github.com/users/nmhkahn/events{/privacy}", "received_events_url": "https://api.github.com/users/nmhkahn/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-26T04:23:08Z", "updated_at": "2016-07-26T04:23:08Z", "author_association": "NONE", "body": "@brando90 you're right.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/235433645", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235433645", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 235433645, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTQzMzY0NQ==", "user": {"login": "papadopav", "id": 20671213, "node_id": "MDQ6VXNlcjIwNjcxMjEz", "avatar_url": "https://avatars3.githubusercontent.com/u/20671213?v=4", "gravatar_id": "", "url": "https://api.github.com/users/papadopav", "html_url": "https://github.com/papadopav", "followers_url": "https://api.github.com/users/papadopav/followers", "following_url": "https://api.github.com/users/papadopav/following{/other_user}", "gists_url": "https://api.github.com/users/papadopav/gists{/gist_id}", "starred_url": "https://api.github.com/users/papadopav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/papadopav/subscriptions", "organizations_url": "https://api.github.com/users/papadopav/orgs", "repos_url": "https://api.github.com/users/papadopav/repos", "events_url": "https://api.github.com/users/papadopav/events{/privacy}", "received_events_url": "https://api.github.com/users/papadopav/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-26T23:08:51Z", "updated_at": "2016-07-26T23:08:51Z", "author_association": "NONE", "body": "I am also confused regarding is_training and reuse flags. I have created a program following the CIFAR example, where my code is structured as in CIFAR:\n- Inference\n- Loss\n- Train\n\nAnd I am running it in a multi-gpu fashion (for training).\nSo I have one script for training (similar to cifar10_multigpu.py) and one for testing (similar to cifar10_eval.py). \nSo \n\n```\nfor ii in xrange(2):  # Num of GPU\n  with tf.device('/gpu:%d' % ii):\n    with tf.name_scope('device_%d' % ii) as scope:\n\n      data_batch, label_batch = factory.GetShuffleBatch(batch_size)\n\n      unnormalized_logits = factory.MyModel(dataBatch=data_batch, numClasses=numClasses,\n                                                 isTraining=True)\n\n      More stuff happening\n      tf.get_variable_scope().reuse_variables()\n```\n\nThe inference happens with the function MyModel. (below is an example of the function, in reality i use more layers and neurons). \n\n```\ndef MyModel(data_batch, num_classes, feature_dim):\n\n  # Hidden Layer 1\n  with tf.variable_scope('hidden1') as scope:\n    weights = variable_on_cpu('weights',[feature_dim, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden1 = tf.nn.relu(tf.matmul(data_batch, weights) + biases, name=scope.name)\n\n  # Hidden Layer 2\n  with tf.variable_scope('hidden2') as scope:\n    weights = variable_on_cpu('weights',[256, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases, name=scope.name)\n\n  # output, unnormalized softmax\n  with tf.variable_scope('softmax_unnorm') as scope:\n\n    weights = variable_on_cpu('weights', [256, num_classes], tf.truncated_normal_initializer(stddev=1/num_classes))\n    biases = variable_on_cpu('biases', [num_classes], tf.constant_initializer(0.0))\n    softmax_un = tf.add(tf.matmul(hidden2, weights), biases, name=scope.name)\n\n  return softmax_un\n```\n\nI want to perform batch nomalization. So when I did:\n\n```\ndef MyModel(data_batch, num_classes, feature_dim, isTraining):\n\n  with tf.variable_scope('bnormalization') as scope:\n    norm_data_batch = tcl.batch_norm(inputs=dataBatch, epsilon=0.0001, is_training=isTraining, \n                                      reuse=True, scope=scope)\n\n  # Hidden Layer 1\n  with tf.variable_scope('hidden1') as scope:\n    weights = variable_on_cpu('weights',[feature_dim, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden1 = tf.nn.relu(tf.matmul(data_batch, weights) + biases, name=scope.name)\n```\n\nI got the following error in the training phase:\nVariable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?\n\nFrom what I 've been reading in this thread in the training phase I should be using reuse=None. Have I got this part correct? If this is true, then since I am using two GPUS, should I do reuse=None in the first GPU and reuse=True in the second? Or since I am doing tf.get_variable_scope().reuse_variables() it takes care of itself?\n\nFinally, in the testing phase, should I have is_training=False and reuse=True?\n\nAny help is greatly appreciated. \n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/235682812", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235682812", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 235682812, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTY4MjgxMg==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-27T18:50:29Z", "updated_at": "2016-07-27T18:50:29Z", "author_association": "MEMBER", "body": "Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training \n\nhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/235805769", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235805769", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 235805769, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTgwNTc2OQ==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-28T05:57:03Z", "updated_at": "2016-07-28T05:57:03Z", "author_association": "NONE", "body": "Is it normal that Batch Normalization makes my experiments **worse**? I tried it on a 2 layered NN network based on the MNIST beginner tutorial and I consistently get worse results when BN is present: with BN (one with scale and center trained and the other not) accuracy is 0.8423, 0.8221 and without BN accuracy is 0.9477.\n\nMy script is present here https://github.com/brando90/tensor_flow_experiments/blob/master/tf_tutorials/beginner_tutorial_MNIST_BN.py\n\nanyone has experienced these problems or is BN just like this and I need to do something else to make it work?\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/235928564", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235928564", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 235928564, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTkyODU2NA==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-28T15:22:08Z", "updated_at": "2016-07-28T15:22:08Z", "author_association": "MEMBER", "body": "The latest version of [tf.contrib.layers.batch_norm](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L110) now accepts a placeholder for is_training so not need to do it yourself.\n\nBut what it is important is that either you pass [updates_collections=None](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L142) so the moving_mean and moving_variance are updated in-place, otherwise you will need gather the update_ops and make sure they are run.\n\nI would like to encourage you to use [`tf.contrib.layers`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/layers) or [`tf.contrib.slim`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim) to build your model.\n\n```\nslim = tf.contrib.slim\n\ndef build_NN_two_hidden_layers(x, is_training):\n batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}\n with slim.arg_scope([slim.fully_connected], \n    activation_fn=tf.nn.relu,\n    weigths_initializer=tf.contrib.layers.xavier_initializer(),\n    biases_initializer=tf.constant_initializer(0.1),\n    normalizer_fn=slim.batch_norm,\n    normalizer_params=batch_norm_params):\n   net = slim.fully_connected(x, 50, scope='A1')\n   net = slim.fully_connected(net, 49, scope='A2')\n   y = slim.fully_connected(net, 10, activation_fn=tf.nn.softmax, normalizer_fn=None, scope='A3')\n return y\n\n\n```\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/235958803", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235958803", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 235958803, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTk1ODgwMw==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-28T17:03:29Z", "updated_at": "2016-07-28T17:07:49Z", "author_association": "NONE", "body": "@sguada I changed my old one where I manually tell it to train or not (based on a tf.cond) and now it seems the accuracy is up to ~95's again. Why was it that I needed to change updates_collections to be None? Do you mind explaining me why that gave such a big accuracy difference? Its seems like a non-trivial change (should it None be its default value then if it matters so much?). Thanks! :)\n\nAlso, I noticed you said it was a placeholder and I didn't need to do it manually. However, when I passed a placeholder for is_training it said \n\n`TypeError: Using a`tf.Tensor`as a Python`bool`is not allowed. Use`if t is not None:`instead of`if t:`to test if a tensor is defined, and use the logical TensorFlow ops to test the value of a tensor.`\n\nand pointed to batch_norm code. Maybe It could be nice to show how this placeholder thing should be used because it seems I don't understand how its suppose to be used. Thanks! :)\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/235966259", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235966259", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 235966259, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTk2NjI1OQ==", "user": {"login": "papadopav", "id": 20671213, "node_id": "MDQ6VXNlcjIwNjcxMjEz", "avatar_url": "https://avatars3.githubusercontent.com/u/20671213?v=4", "gravatar_id": "", "url": "https://api.github.com/users/papadopav", "html_url": "https://github.com/papadopav", "followers_url": "https://api.github.com/users/papadopav/followers", "following_url": "https://api.github.com/users/papadopav/following{/other_user}", "gists_url": "https://api.github.com/users/papadopav/gists{/gist_id}", "starred_url": "https://api.github.com/users/papadopav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/papadopav/subscriptions", "organizations_url": "https://api.github.com/users/papadopav/orgs", "repos_url": "https://api.github.com/users/papadopav/repos", "events_url": "https://api.github.com/users/papadopav/events{/privacy}", "received_events_url": "https://api.github.com/users/papadopav/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-28T17:30:25Z", "updated_at": "2016-07-28T18:10:06Z", "author_association": "NONE", "body": "@brando90 \nThe relevant part of the code is here [L227-256](https://github.com/tensorflow/tensorflow/blob/98d63de3bb2bab7c9a81f83c8ca864741399300c/tensorflow/contrib/layers/python/layers/layers.py#L227-L256).\n\nAs you will notice is there is a `with ops.control_dependencies` statement that forces the updates. I believe that for the code to be used \"right out of the box\" the default should be None. \n\nAs for my comment above [1122](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235433645), I figured out that   tf.get_variable_scope().reuse_variables() takes care of the issue, so  in the training phase the argument reuse of batch_norm should be None. It has to do with the statement variable_op_scope (read its documentation in tensorflow) \n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/236067965", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-236067965", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 236067965, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNjA2Nzk2NQ==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-29T00:59:48Z", "updated_at": "2016-07-29T01:00:11Z", "author_association": "MEMBER", "body": "Use of batch_norm with tf.placeholder\n\n```\nx = tf.placeholder(tf.float32, [None, 784])\nis_training = tf.placeholder(tf.bool, [], name='is_training')\ny = build_NN_two_hidden_layers(x, is_training)\n\n# For training\nsess.run(y, {is_training: True, x: train_data})\n\n# For eval\nsess.run(y, {is_training: False, x: eval_data})\n\n```\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/236068575", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-236068575", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 236068575, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNjA2ODU3NQ==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-07-29T01:04:51Z", "updated_at": "2016-07-29T01:04:51Z", "author_association": "MEMBER", "body": "The problem before was that you were not updating the `moving_mean` and `moving_variance` after each step, when updates_collections is None it forces the updates as part of the computation.\nHowever when a network has many batch_norm layers it is more efficient to collect all the update ops and run them together, so each layer don't need to wait for the update to finish.\n\n```\ny = build_model_with_batch_norm(x, is_training)\nupdate_ops = tf.group(tf.get_collection(tf.GraphKeys.UPDATE_OPS))\n\nsess.run([y, update_ops])\n\n```\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/238133597", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-238133597", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 238133597, "node_id": "MDEyOklzc3VlQ29tbWVudDIzODEzMzU5Nw==", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-08T03:19:34Z", "updated_at": "2016-08-08T03:19:34Z", "author_association": "NONE", "body": "Has there been any progress made with speeding up batch norm?\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/238818348", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-238818348", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 238818348, "node_id": "MDEyOklzc3VlQ29tbWVudDIzODgxODM0OA==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-10T09:47:42Z", "updated_at": "2016-08-10T15:41:48Z", "author_association": "NONE", "body": "I was trying to use batch norm with a 2 layered densely connected NN with the (flatten) MNIST  (and relu units) data set for the task of auto-encoding  and I keep getting a NaN error. Anyone know why might this be? Is this ever possible with BN? seem fishy, but it couldn't be my learning set up, rate etc. (but I'd assume it shouldn't because BN should be sort of rubust to this)\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/242782793", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-242782793", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 242782793, "node_id": "MDEyOklzc3VlQ29tbWVudDI0Mjc4Mjc5Mw==", "user": {"login": "jpiabrantes", "id": 2369107, "node_id": "MDQ6VXNlcjIzNjkxMDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/2369107?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpiabrantes", "html_url": "https://github.com/jpiabrantes", "followers_url": "https://api.github.com/users/jpiabrantes/followers", "following_url": "https://api.github.com/users/jpiabrantes/following{/other_user}", "gists_url": "https://api.github.com/users/jpiabrantes/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpiabrantes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpiabrantes/subscriptions", "organizations_url": "https://api.github.com/users/jpiabrantes/orgs", "repos_url": "https://api.github.com/users/jpiabrantes/repos", "events_url": "https://api.github.com/users/jpiabrantes/events{/privacy}", "received_events_url": "https://api.github.com/users/jpiabrantes/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-26T16:25:32Z", "updated_at": "2016-08-27T09:23:14Z", "author_association": "NONE", "body": "@sguada I am not understanding the right way of using `batch_norm` specially concerning the flag `updates_collections`. If I understood correctly if the flag is `None` the network is not efficient, so I should let `updates_collections=tf.GraphKeys.UPDATE_OPS` and then I should collect all the batch_norm updates and run them together.\n\nYou collect the batch_norms updates by doing: `update_ops = tf.group(tf.get_collection(tf.GraphKeys.UPDATE_OPS))`.\n\nI have many different models that use different batch_norm layers, this wouldn't work right?:\n\n``` python\n#model 1\ny1 = build_model_with_batch_norm(x, is_training)\nupdate_ops1 = tf.group(tf.get_collection(tf.GraphKeys.UPDATE_OPS))\nsess.run([y1, update_ops1])\n#model 2\ny2 = build_model_with_batch_norm(x, is_training)\nupdate_ops2 = tf.group(tf.get_collection(tf.GraphKeys.UPDATE_OPS))\nsess.run([y2, update_ops2])\n```\n\nCould you explain this part with a bit more details? Thank you very much.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/245667139", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-245667139", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 245667139, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NTY2NzEzOQ==", "user": {"login": "bsautermeister", "id": 2537736, "node_id": "MDQ6VXNlcjI1Mzc3MzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/2537736?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bsautermeister", "html_url": "https://github.com/bsautermeister", "followers_url": "https://api.github.com/users/bsautermeister/followers", "following_url": "https://api.github.com/users/bsautermeister/following{/other_user}", "gists_url": "https://api.github.com/users/bsautermeister/gists{/gist_id}", "starred_url": "https://api.github.com/users/bsautermeister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bsautermeister/subscriptions", "organizations_url": "https://api.github.com/users/bsautermeister/orgs", "repos_url": "https://api.github.com/users/bsautermeister/repos", "events_url": "https://api.github.com/users/bsautermeister/events{/privacy}", "received_events_url": "https://api.github.com/users/bsautermeister/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-08T17:05:14Z", "updated_at": "2016-09-08T17:05:35Z", "author_association": "NONE", "body": "Just put it in seperate collection-keys:\n\n```\n# While building your 1st model...\ntf.contrib.layers.batch_norm(..., updates_collection=\"updates-model1\")\n\n# same for 2nd model with key \"updates-model2\"\n```\n\n```\n#model 1\ny1 = build_model_with_batch_norm(x, is_training)\nupdate_ops1 = tf.group(tf.get_collection(\"updates-model1\"))\nsess.run([y1, update_ops1])\n#model 2\ny2 = build_model_with_batch_norm(x, is_training)\nupdate_ops2 = tf.group(tf.get_collection(\"updates-model1\"))\nsess.run([y2, update_ops2])\n```\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/245668861", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-245668861", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 245668861, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NTY2ODg2MQ==", "user": {"login": "bsautermeister", "id": 2537736, "node_id": "MDQ6VXNlcjI1Mzc3MzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/2537736?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bsautermeister", "html_url": "https://github.com/bsautermeister", "followers_url": "https://api.github.com/users/bsautermeister/followers", "following_url": "https://api.github.com/users/bsautermeister/following{/other_user}", "gists_url": "https://api.github.com/users/bsautermeister/gists{/gist_id}", "starred_url": "https://api.github.com/users/bsautermeister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bsautermeister/subscriptions", "organizations_url": "https://api.github.com/users/bsautermeister/orgs", "repos_url": "https://api.github.com/users/bsautermeister/repos", "events_url": "https://api.github.com/users/bsautermeister/events{/privacy}", "received_events_url": "https://api.github.com/users/bsautermeister/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-08T17:10:54Z", "updated_at": "2016-09-09T09:02:17Z", "author_association": "NONE", "body": "Nevertheless, the documentation seams to be out-dated. It tells to do the following:\n\n```\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nif update_ops:\n    updates = tf.group(update_ops)\n    total_loss = control_flow_ops.with_dependencies([updates], total_loss)\n```\n\nBut:\n- _tf.group()_ does not accept a list. I replaced it with _tf.tuple()_\n- ~~I don't know how to access _control_flow_ops.with_dependencies()_. How can I access functions within control_flow_ops module? I have seen other examples just using tf.with_dependecies(), but I cannot do that with Tensorflow 0.10.~~ I found it here: _tf.python.control_flow_ops.with_dependencies()_\n\n**EDIT:**\n\nThe documentation should be updated to s.th. like this:\n\n```\nfrom tensorflow.python import control_flow_ops\n\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nif update_ops:\n    updates = tf.tuple(update_ops)\n    total_loss = control_flow_ops.with_dependencies(updates, total_loss)\n```\n\n**EDIT 2:** \n\nAfter doing some runs on my network, I have to say that ~~I can not see any performance difference between using  _updates_collections=None_ in contrast to manually fetching _tf.GraphKeys.UPDATE_OPS_ while graph construction~~. Even with heavy use of batch normalization (in total, my _tf.get_collection(tf.GraphKeys.UPDATE_OPS)_ returns 140 Update-Ops, all of them are BN-ops only)\n\nEdit: Hard to say, if my results are correct, but the whole network indeed seams to be 1.5x faster. As far as I know, BN-statistics are calculated on CPU, not GPU so far.\n\nCan anyone of you see any performance benefits as well? Please share your results :)\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/247675019", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-247675019", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 247675019, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NzY3NTAxOQ==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-16T18:35:06Z", "updated_at": "2016-09-16T18:35:06Z", "author_association": "NONE", "body": "Coming back to the performance issue, does the current batch norm layer benfit at all from GPU usage? Anyone has experienced benefits from GPUs with this batch norm implementation?\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/247677802", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-247677802", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 247677802, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NzY3NzgwMg==", "user": {"login": "vincentvanhoucke", "id": 15737127, "node_id": "MDQ6VXNlcjE1NzM3MTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/15737127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincentvanhoucke", "html_url": "https://github.com/vincentvanhoucke", "followers_url": "https://api.github.com/users/vincentvanhoucke/followers", "following_url": "https://api.github.com/users/vincentvanhoucke/following{/other_user}", "gists_url": "https://api.github.com/users/vincentvanhoucke/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincentvanhoucke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincentvanhoucke/subscriptions", "organizations_url": "https://api.github.com/users/vincentvanhoucke/orgs", "repos_url": "https://api.github.com/users/vincentvanhoucke/repos", "events_url": "https://api.github.com/users/vincentvanhoucke/events{/privacy}", "received_events_url": "https://api.github.com/users/vincentvanhoucke/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-16T18:47:33Z", "updated_at": "2016-09-16T18:47:33Z", "author_association": "MEMBER", "body": "You can test for yourself:\nhttps://github.com/tensorflow/tensorflow/blob/4addf4b5806cd731949c6582a83f5824599cd1ef/tensorflow/python/ops/batch_norm_benchmark.py\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/247906416", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-247906416", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 247906416, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NzkwNjQxNg==", "user": {"login": "brando90", "id": 1855278, "node_id": "MDQ6VXNlcjE4NTUyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brando90", "html_url": "https://github.com/brando90", "followers_url": "https://api.github.com/users/brando90/followers", "following_url": "https://api.github.com/users/brando90/following{/other_user}", "gists_url": "https://api.github.com/users/brando90/gists{/gist_id}", "starred_url": "https://api.github.com/users/brando90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brando90/subscriptions", "organizations_url": "https://api.github.com/users/brando90/orgs", "repos_url": "https://api.github.com/users/brando90/repos", "events_url": "https://api.github.com/users/brando90/events{/privacy}", "received_events_url": "https://api.github.com/users/brando90/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-19T03:38:42Z", "updated_at": "2016-09-19T03:38:42Z", "author_association": "NONE", "body": "Sorry for the spam, but the documentation doesn't really explain how to use this BN with convolution (maybe should be provided somewhere?). In short how does it figure out that it should apply and learn the same parameters per feature (rather than per activation)?\n\n(Is there at least a code snippet to do this?)\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/248011646", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-248011646", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 248011646, "node_id": "MDEyOklzc3VlQ29tbWVudDI0ODAxMTY0Ng==", "user": {"login": "vincentvanhoucke", "id": 15737127, "node_id": "MDQ6VXNlcjE1NzM3MTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/15737127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincentvanhoucke", "html_url": "https://github.com/vincentvanhoucke", "followers_url": "https://api.github.com/users/vincentvanhoucke/followers", "following_url": "https://api.github.com/users/vincentvanhoucke/following{/other_user}", "gists_url": "https://api.github.com/users/vincentvanhoucke/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincentvanhoucke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincentvanhoucke/subscriptions", "organizations_url": "https://api.github.com/users/vincentvanhoucke/orgs", "repos_url": "https://api.github.com/users/vincentvanhoucke/repos", "events_url": "https://api.github.com/users/vincentvanhoucke/events{/privacy}", "received_events_url": "https://api.github.com/users/vincentvanhoucke/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-19T14:37:11Z", "updated_at": "2016-09-19T14:37:11Z", "author_association": "MEMBER", "body": "The slim batch_norm wrapper normalizes over the last dimension of your input tensor. So if it's a 2D input tensor coming from a fully connected layer, it normalizes over batch, and thus performs per-activation normalization. If it's a 4D tensor coming from a convolution, it will normalize over the three first dimensions (batch, width, depth), and thus perform per-feature normalization. @sguada maybe forth being a bit more descriptive about this.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/258005625", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-258005625", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 258005625, "node_id": "MDEyOklzc3VlQ29tbWVudDI1ODAwNTYyNQ==", "user": {"login": "zhongyuk", "id": 6901075, "node_id": "MDQ6VXNlcjY5MDEwNzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6901075?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhongyuk", "html_url": "https://github.com/zhongyuk", "followers_url": "https://api.github.com/users/zhongyuk/followers", "following_url": "https://api.github.com/users/zhongyuk/following{/other_user}", "gists_url": "https://api.github.com/users/zhongyuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhongyuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhongyuk/subscriptions", "organizations_url": "https://api.github.com/users/zhongyuk/orgs", "repos_url": "https://api.github.com/users/zhongyuk/repos", "events_url": "https://api.github.com/users/zhongyuk/events{/privacy}", "received_events_url": "https://api.github.com/users/zhongyuk/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-02T21:32:24Z", "updated_at": "2016-11-02T21:38:06Z", "author_association": "CONTRIBUTOR", "body": "@nmhkahn Regarding your code snippet, may I ask why is `reuse` set to be `None` when `is_training=True`? Wouldn't that trigger the scaling parameter `gamma` and the offset parameter `beta` be re-initialized in every training step? I thought in the original paper, `beta` and `gamma` are \"learned along with the original model parameters\". To do that, shouldn't they be only initialized once and then reused in all training steps?\n\n`tf.cond(is_training, \n lambda: batch_norm(inputT, is_training=True,  updates_collections=None, scope=scope), \n lambda: batch_norm(inputT, is_training=False,  updates_collections=None, scope=scope, reuse = True))`\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/259762584", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-259762584", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 259762584, "node_id": "MDEyOklzc3VlQ29tbWVudDI1OTc2MjU4NA==", "user": {"login": "davek44", "id": 172688, "node_id": "MDQ6VXNlcjE3MjY4OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/172688?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davek44", "html_url": "https://github.com/davek44", "followers_url": "https://api.github.com/users/davek44/followers", "following_url": "https://api.github.com/users/davek44/following{/other_user}", "gists_url": "https://api.github.com/users/davek44/gists{/gist_id}", "starred_url": "https://api.github.com/users/davek44/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davek44/subscriptions", "organizations_url": "https://api.github.com/users/davek44/orgs", "repos_url": "https://api.github.com/users/davek44/repos", "events_url": "https://api.github.com/users/davek44/events{/privacy}", "received_events_url": "https://api.github.com/users/davek44/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-10T18:04:48Z", "updated_at": "2016-11-10T18:04:48Z", "author_association": "NONE", "body": "I greatly appreciate the work that the TF team has put in here to make batch_norm available and effective. From my searching, this thread is the best resource for how to use it. There are many different problems and ideas flying around here, and it's difficult to figure out the consensus advice for the simplest standard case of how to use the batch_norm layer. I think there'd be a lot of value in expanding the documentation to specify the exact recommended usage.\n\nMy best attempt to figure that out brought me to the following code:\n\n```\nis_training_ph = tf.placeholder(tf.bool)\n...\nwith tf.variable_scope('bn_test_layer') as vs:\n    layer_output = tf.cond(is_training_ph,\n        lambda: tf.contrib.layers.batch_norm(layer_input, is_training=True, center=True, scale=True, activation_fn=tf.nn.relu, updates_collections=None, scope=vs),\n        lambda: tf.contrib.layers.batch_norm(layer_input, is_training=False, center=True, scale=True, activation_fn=tf.nn.relu, updates_collections=None, scope=vs, reuse=True))\n```\n\nThen I set is_training_ph to True for training and False for testing. This doesn't work for me. The model trains fine, but the test performance is terrible. In contrast, if I maintain is_training_ph=True for test time, it works great. Thus, I'm guessing I still have a scope issue so that it's not finding the proper existing variables. \n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/259782395", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-259782395", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 259782395, "node_id": "MDEyOklzc3VlQ29tbWVudDI1OTc4MjM5NQ==", "user": {"login": "zhongyuk", "id": 6901075, "node_id": "MDQ6VXNlcjY5MDEwNzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6901075?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhongyuk", "html_url": "https://github.com/zhongyuk", "followers_url": "https://api.github.com/users/zhongyuk/followers", "following_url": "https://api.github.com/users/zhongyuk/following{/other_user}", "gists_url": "https://api.github.com/users/zhongyuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhongyuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhongyuk/subscriptions", "organizations_url": "https://api.github.com/users/zhongyuk/orgs", "repos_url": "https://api.github.com/users/zhongyuk/repos", "events_url": "https://api.github.com/users/zhongyuk/events{/privacy}", "received_events_url": "https://api.github.com/users/zhongyuk/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-10T19:22:39Z", "updated_at": "2016-11-10T19:22:39Z", "author_association": "CONTRIBUTOR", "body": "@davek44 I'm using the same code framework that you are using and I observed the same thing: when turns on `is_training=True` during training phase and turns off `is_training=False` for validation and/or testing phase, the model trains well like the paper described (model converges faster and I was able to use a larger learning rate), however the testing performance is terrible. If I turns on `is_training=True` all the time, the model trains the same as without inserting batch norm layer. I haven't figured out what I did wrong, I'm planning to use TensorBoard to monitor the parameters. Would you please update if you diagnose the cause of this behavior? \n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/259834510", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-259834510", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 259834510, "node_id": "MDEyOklzc3VlQ29tbWVudDI1OTgzNDUxMA==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-10T23:05:26Z", "updated_at": "2016-11-10T23:05:26Z", "author_association": "MEMBER", "body": "tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.\n\n```\nis_training_ph = tf.placeholder(tf.bool)\n\noutputs = tf.contrib.layers.batch_norm(layer_input, is_training=is_training_ph, center=True, scale=True, activation_fn=tf.nn.relu, updates_collections=None, scope='batch_norm'),\n```\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/259886443", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-259886443", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 259886443, "node_id": "MDEyOklzc3VlQ29tbWVudDI1OTg4NjQ0Mw==", "user": {"login": "davek44", "id": 172688, "node_id": "MDQ6VXNlcjE3MjY4OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/172688?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davek44", "html_url": "https://github.com/davek44", "followers_url": "https://api.github.com/users/davek44/followers", "following_url": "https://api.github.com/users/davek44/following{/other_user}", "gists_url": "https://api.github.com/users/davek44/gists{/gist_id}", "starred_url": "https://api.github.com/users/davek44/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davek44/subscriptions", "organizations_url": "https://api.github.com/users/davek44/orgs", "repos_url": "https://api.github.com/users/davek44/repos", "events_url": "https://api.github.com/users/davek44/events{/privacy}", "received_events_url": "https://api.github.com/users/davek44/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-11T05:50:14Z", "updated_at": "2016-11-11T05:50:14Z", "author_association": "NONE", "body": "I see the same poor test performance with that code.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/260092525", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-260092525", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 260092525, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDA5MjUyNQ==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-12T01:33:48Z", "updated_at": "2016-11-12T01:33:48Z", "author_association": "MEMBER", "body": "Without more details is impossible to know, my guesses are that you only train for a few iterations, so the moving_mean and moving_average haven't converge yet.\n\nYou can change the batch_size during test to see how the performance degrades as you make your batch smaller.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/260908570", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-260908570", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 260908570, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDkwODU3MA==", "user": {"login": "nmduc", "id": 2166977, "node_id": "MDQ6VXNlcjIxNjY5Nzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/2166977?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nmduc", "html_url": "https://github.com/nmduc", "followers_url": "https://api.github.com/users/nmduc/followers", "following_url": "https://api.github.com/users/nmduc/following{/other_user}", "gists_url": "https://api.github.com/users/nmduc/gists{/gist_id}", "starred_url": "https://api.github.com/users/nmduc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nmduc/subscriptions", "organizations_url": "https://api.github.com/users/nmduc/orgs", "repos_url": "https://api.github.com/users/nmduc/repos", "events_url": "https://api.github.com/users/nmduc/events{/privacy}", "received_events_url": "https://api.github.com/users/nmduc/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-16T10:20:57Z", "updated_at": "2016-11-16T10:20:57Z", "author_association": "NONE", "body": "> I see the same poor test performance with that code.\n\nI had exactly the same problem either with tf.slim batchnorm or with tf.cond and input is_training as a placeholder.\nIn the former case, when investigating the trained model, I found out that the moving mean and moving variance consist of all zeros. \nIn the latter case, the moving mean and variance look more reasonable (with different values), but if I use is_training=False in test time, the performance is also really bad. Using is_training=True, it works better but I think it only uses the moving mean and variance inside the test batch.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/261041193", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-261041193", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 261041193, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTA0MTE5Mw==", "user": {"login": "zhongyuk", "id": 6901075, "node_id": "MDQ6VXNlcjY5MDEwNzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6901075?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhongyuk", "html_url": "https://github.com/zhongyuk", "followers_url": "https://api.github.com/users/zhongyuk/followers", "following_url": "https://api.github.com/users/zhongyuk/following{/other_user}", "gists_url": "https://api.github.com/users/zhongyuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhongyuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhongyuk/subscriptions", "organizations_url": "https://api.github.com/users/zhongyuk/orgs", "repos_url": "https://api.github.com/users/zhongyuk/repos", "events_url": "https://api.github.com/users/zhongyuk/events{/privacy}", "received_events_url": "https://api.github.com/users/zhongyuk/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-16T19:09:16Z", "updated_at": "2016-11-16T19:11:23Z", "author_association": "CONTRIBUTOR", "body": "@nmduc @davek44  I wrote some code to track the moving mean and moving variance computed in `tf.contrib.layers.batch_norm` during training and testing. I found out that the value of `decay` matters a lot (they use exponential decay to compute moving average and moving variance), with a `decay` setting closer to 1.0 (i.e. `decay=.999`), moving mean drops to a value closer to 0. I did 2 test runs with the exact same code but different `decay` settings in the `tf.contrib.layers.batch_norm`, and my validation/test accuracies seemed more reasonable.\n\nThe test run results with `decay=0.9`\n<img width=\"784\" alt=\"screen shot 2016-11-16 at 1 51 51 pm\" src=\"https://cloud.githubusercontent.com/assets/6901075/20361517/dd5dbbd8-ac05-11e6-85ac-5a9e2dec3a2b.png\">\n\nThe test run results with `decay=0.999` (`decay=0.999` is the default setting in `tf.contrib.layers.batch_norm`)\n<img width=\"784\" alt=\"screen shot 2016-11-16 at 2 03 58 pm\" src=\"https://cloud.githubusercontent.com/assets/6901075/20361605/31729f5e-ac06-11e6-9736-eb9ad2f15de1.png\">\n\n(also seems like larger decay value would require the model to train longer to see validation accuracy change )\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/261163343", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-261163343", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 261163343, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTE2MzM0Mw==", "user": {"login": "davek44", "id": 172688, "node_id": "MDQ6VXNlcjE3MjY4OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/172688?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davek44", "html_url": "https://github.com/davek44", "followers_url": "https://api.github.com/users/davek44/followers", "following_url": "https://api.github.com/users/davek44/following{/other_user}", "gists_url": "https://api.github.com/users/davek44/gists{/gist_id}", "starred_url": "https://api.github.com/users/davek44/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davek44/subscriptions", "organizations_url": "https://api.github.com/users/davek44/orgs", "repos_url": "https://api.github.com/users/davek44/repos", "events_url": "https://api.github.com/users/davek44/events{/privacy}", "received_events_url": "https://api.github.com/users/davek44/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-17T06:03:50Z", "updated_at": "2016-11-17T06:03:50Z", "author_association": "NONE", "body": "Yup that fixed it. Thanks for sharing your analysis @zhongyuk!\n\nI encourage the developers to consider making decay=0.9 the default. Even 0.99 doesn't work well for me. That's the default value in Torch's implementation, too; see the momentum parameter in https://github.com/torch/nn/blob/master/BatchNormalization.lua\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/261189235", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-261189235", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 261189235, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTE4OTIzNQ==", "user": {"login": "nmduc", "id": 2166977, "node_id": "MDQ6VXNlcjIxNjY5Nzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/2166977?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nmduc", "html_url": "https://github.com/nmduc", "followers_url": "https://api.github.com/users/nmduc/followers", "following_url": "https://api.github.com/users/nmduc/following{/other_user}", "gists_url": "https://api.github.com/users/nmduc/gists{/gist_id}", "starred_url": "https://api.github.com/users/nmduc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nmduc/subscriptions", "organizations_url": "https://api.github.com/users/nmduc/orgs", "repos_url": "https://api.github.com/users/nmduc/repos", "events_url": "https://api.github.com/users/nmduc/events{/privacy}", "received_events_url": "https://api.github.com/users/nmduc/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-17T08:50:04Z", "updated_at": "2016-11-17T08:50:04Z", "author_association": "NONE", "body": "@zhongyuk Thanks a lot for sharing . It works for me now. \n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/261307730", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-261307730", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 261307730, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTMwNzczMA==", "user": {"login": "vincentvanhoucke", "id": 15737127, "node_id": "MDQ6VXNlcjE1NzM3MTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/15737127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincentvanhoucke", "html_url": "https://github.com/vincentvanhoucke", "followers_url": "https://api.github.com/users/vincentvanhoucke/followers", "following_url": "https://api.github.com/users/vincentvanhoucke/following{/other_user}", "gists_url": "https://api.github.com/users/vincentvanhoucke/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincentvanhoucke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincentvanhoucke/subscriptions", "organizations_url": "https://api.github.com/users/vincentvanhoucke/orgs", "repos_url": "https://api.github.com/users/vincentvanhoucke/repos", "events_url": "https://api.github.com/users/vincentvanhoucke/events{/privacy}", "received_events_url": "https://api.github.com/users/vincentvanhoucke/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-17T17:12:42Z", "updated_at": "2016-11-17T17:12:42Z", "author_association": "MEMBER", "body": "This seems important. @sguada we should consider the right course of action here before 1.0. In the short term, can one of the interested parties send me a PR documenting the fact that `decay` might have to be significantly lowered when experiencing poor eval performance? I am pretty sure I've never had to tweak that parameter, but it might be a side effect of the distributed setting.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/261378314", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-261378314", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 261378314, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTM3ODMxNA==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-17T21:40:42Z", "updated_at": "2016-11-17T21:40:42Z", "author_association": "MEMBER", "body": "We could change the default to 0.9 or document better its impact in smaller datasets or few updates.\n@vincentvanhoucke in our distributed setting we usually do millions of updates so it is ok, however in other cases like the one here which does only a few hundreds of updates it makes a big difference:\nFor example using decay=0.999 has a 0.36 bias after 1000 updates, but that bias goes down to 0.000045 after 10000 updates and to 0.0 after 50000 updates.\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/261977366", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-261977366", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 261977366, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTk3NzM2Ng==", "user": {"login": "dominikandreas", "id": 13525040, "node_id": "MDQ6VXNlcjEzNTI1MDQw", "avatar_url": "https://avatars2.githubusercontent.com/u/13525040?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dominikandreas", "html_url": "https://github.com/dominikandreas", "followers_url": "https://api.github.com/users/dominikandreas/followers", "following_url": "https://api.github.com/users/dominikandreas/following{/other_user}", "gists_url": "https://api.github.com/users/dominikandreas/gists{/gist_id}", "starred_url": "https://api.github.com/users/dominikandreas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dominikandreas/subscriptions", "organizations_url": "https://api.github.com/users/dominikandreas/orgs", "repos_url": "https://api.github.com/users/dominikandreas/repos", "events_url": "https://api.github.com/users/dominikandreas/events{/privacy}", "received_events_url": "https://api.github.com/users/dominikandreas/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-21T15:53:18Z", "updated_at": "2016-11-21T15:53:18Z", "author_association": "NONE", "body": "Just wanted to note that I also have the problem of poor test performance, specifically using small batch sizes (anything smaller than 10 instead of the 200 I used for training diminishes test accuracy). I've used a tf.placeholder to switch between testing/training mode.\r\n\r\nIt's great that this batch normalization layer works for better training convergence, but if you can't apply the model in production, there isn't much of a point in using it. Can anyone confirm good test performance with small or single data samples using this batch norm layer? "}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/262009535", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-262009535", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 262009535, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MjAwOTUzNQ==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-21T17:35:42Z", "updated_at": "2016-11-21T17:35:42Z", "author_association": "MEMBER", "body": "I can confirm that test performance is good when using is_training=False with small batches and even with batch_size=1, since it is not using statistic from the batch, but the statistic learnt during training. Just need to make sure that the statistics have converged with default decay=0.999 that implies at least 50k updates. "}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/262073900", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-262073900", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 262073900, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MjA3MzkwMA==", "user": {"login": "zhongyuk", "id": 6901075, "node_id": "MDQ6VXNlcjY5MDEwNzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6901075?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhongyuk", "html_url": "https://github.com/zhongyuk", "followers_url": "https://api.github.com/users/zhongyuk/followers", "following_url": "https://api.github.com/users/zhongyuk/following{/other_user}", "gists_url": "https://api.github.com/users/zhongyuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhongyuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhongyuk/subscriptions", "organizations_url": "https://api.github.com/users/zhongyuk/orgs", "repos_url": "https://api.github.com/users/zhongyuk/repos", "events_url": "https://api.github.com/users/zhongyuk/events{/privacy}", "received_events_url": "https://api.github.com/users/zhongyuk/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-21T21:32:53Z", "updated_at": "2016-11-21T21:32:53Z", "author_association": "CONTRIBUTOR", "body": "To follow up with TF developer's confirmation, I track the convergence of the statistics with two different `decay` settings (and training batch_size=1). With `decay=0.99`, the statistics converge (bias<0.001) after 550~600 steps of learning/updates. With `decay=0.9`, the statistics converge (biase<0.001) within within 100 steps of learning/updates."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/262093844", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-262093844", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 262093844, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MjA5Mzg0NA==", "user": {"login": "dominikandreas", "id": 13525040, "node_id": "MDQ6VXNlcjEzNTI1MDQw", "avatar_url": "https://avatars2.githubusercontent.com/u/13525040?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dominikandreas", "html_url": "https://github.com/dominikandreas", "followers_url": "https://api.github.com/users/dominikandreas/followers", "following_url": "https://api.github.com/users/dominikandreas/following{/other_user}", "gists_url": "https://api.github.com/users/dominikandreas/gists{/gist_id}", "starred_url": "https://api.github.com/users/dominikandreas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dominikandreas/subscriptions", "organizations_url": "https://api.github.com/users/dominikandreas/orgs", "repos_url": "https://api.github.com/users/dominikandreas/repos", "events_url": "https://api.github.com/users/dominikandreas/events{/privacy}", "received_events_url": "https://api.github.com/users/dominikandreas/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-21T22:55:00Z", "updated_at": "2016-11-21T22:55:00Z", "author_association": "NONE", "body": "@sguada thanks, does that also mean the output is actually independent of the batch size? because I'm noticing very slight changes with big impact on my accuracy (maybe my definition of performance is just more easily affected by this slight change). To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size. Per value this isn't that much of a difference, but has a big impact when computing vector distances in latent spaces. \r\n\r\n@zhongyuk thanks, I've run about 5k updates with `decay=0.9`, so it should've converged and testing performance using large batch sizes is fine. But even if it didn't, would it result in a difference between training a testing? I'd be seeing bad performance during training *and* testing if it hadn't converged, right?\r\n\r\nI will investigate some more and see if I can reproduce the issue on another task. Thanks for the quick feed back so far!"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/262109231", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-262109231", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 262109231, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MjEwOTIzMQ==", "user": {"login": "zhongyuk", "id": 6901075, "node_id": "MDQ6VXNlcjY5MDEwNzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6901075?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhongyuk", "html_url": "https://github.com/zhongyuk", "followers_url": "https://api.github.com/users/zhongyuk/followers", "following_url": "https://api.github.com/users/zhongyuk/following{/other_user}", "gists_url": "https://api.github.com/users/zhongyuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhongyuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhongyuk/subscriptions", "organizations_url": "https://api.github.com/users/zhongyuk/orgs", "repos_url": "https://api.github.com/users/zhongyuk/repos", "events_url": "https://api.github.com/users/zhongyuk/events{/privacy}", "received_events_url": "https://api.github.com/users/zhongyuk/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-22T00:16:14Z", "updated_at": "2016-11-22T00:16:14Z", "author_association": "CONTRIBUTOR", "body": "@dominikandreas If your poor testing performance is caused by statistics not converging, you'd see reasonably good training performance but bad testing performance. Because during training, the batch normalization is done using the training batch statistics only. However, during testing time, it's using the moving average statistics of all the training batches to normalize the input tensor."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/262446709", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-262446709", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 262446709, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MjQ0NjcwOQ==", "user": {"login": "dominikandreas", "id": 13525040, "node_id": "MDQ6VXNlcjEzNTI1MDQw", "avatar_url": "https://avatars2.githubusercontent.com/u/13525040?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dominikandreas", "html_url": "https://github.com/dominikandreas", "followers_url": "https://api.github.com/users/dominikandreas/followers", "following_url": "https://api.github.com/users/dominikandreas/following{/other_user}", "gists_url": "https://api.github.com/users/dominikandreas/gists{/gist_id}", "starred_url": "https://api.github.com/users/dominikandreas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dominikandreas/subscriptions", "organizations_url": "https://api.github.com/users/dominikandreas/orgs", "repos_url": "https://api.github.com/users/dominikandreas/repos", "events_url": "https://api.github.com/users/dominikandreas/events{/privacy}", "received_events_url": "https://api.github.com/users/dominikandreas/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-23T07:12:14Z", "updated_at": "2016-11-23T07:12:14Z", "author_association": "NONE", "body": "I found and error in my code, batch normalization is working fine now :-) thanks for your support"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/263967580", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-263967580", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 263967580, "node_id": "MDEyOklzc3VlQ29tbWVudDI2Mzk2NzU4MA==", "user": {"login": "rogertrullo", "id": 8496304, "node_id": "MDQ6VXNlcjg0OTYzMDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8496304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rogertrullo", "html_url": "https://github.com/rogertrullo", "followers_url": "https://api.github.com/users/rogertrullo/followers", "following_url": "https://api.github.com/users/rogertrullo/following{/other_user}", "gists_url": "https://api.github.com/users/rogertrullo/gists{/gist_id}", "starred_url": "https://api.github.com/users/rogertrullo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rogertrullo/subscriptions", "organizations_url": "https://api.github.com/users/rogertrullo/orgs", "repos_url": "https://api.github.com/users/rogertrullo/repos", "events_url": "https://api.github.com/users/rogertrullo/events{/privacy}", "received_events_url": "https://api.github.com/users/rogertrullo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-30T19:19:22Z", "updated_at": "2016-11-30T19:19:22Z", "author_association": "NONE", "body": "Hi @zhongyuk , how did you keep track of the moving mean and variance? \r\nThanks!"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/264021068", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-264021068", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 264021068, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDAyMTA2OA==", "user": {"login": "zhongyuk", "id": 6901075, "node_id": "MDQ6VXNlcjY5MDEwNzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6901075?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhongyuk", "html_url": "https://github.com/zhongyuk", "followers_url": "https://api.github.com/users/zhongyuk/followers", "following_url": "https://api.github.com/users/zhongyuk/following{/other_user}", "gists_url": "https://api.github.com/users/zhongyuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhongyuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhongyuk/subscriptions", "organizations_url": "https://api.github.com/users/zhongyuk/orgs", "repos_url": "https://api.github.com/users/zhongyuk/repos", "events_url": "https://api.github.com/users/zhongyuk/events{/privacy}", "received_events_url": "https://api.github.com/users/zhongyuk/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-30T22:46:23Z", "updated_at": "2016-11-30T22:46:23Z", "author_association": "CONTRIBUTOR", "body": "@rogertrullo Generally I setup TensorBoard to track moving mean and variance. Other than that, I also tried fetching statistics through `tf.get_variable(\"moving_mean\")` within scope during training and reference to monitor the bias."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/276918228", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-276918228", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 276918228, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NjkxODIyOA==", "user": {"login": "ishaybee", "id": 25502989, "node_id": "MDQ6VXNlcjI1NTAyOTg5", "avatar_url": "https://avatars3.githubusercontent.com/u/25502989?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ishaybee", "html_url": "https://github.com/ishaybee", "followers_url": "https://api.github.com/users/ishaybee/followers", "following_url": "https://api.github.com/users/ishaybee/following{/other_user}", "gists_url": "https://api.github.com/users/ishaybee/gists{/gist_id}", "starred_url": "https://api.github.com/users/ishaybee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ishaybee/subscriptions", "organizations_url": "https://api.github.com/users/ishaybee/orgs", "repos_url": "https://api.github.com/users/ishaybee/repos", "events_url": "https://api.github.com/users/ishaybee/events{/privacy}", "received_events_url": "https://api.github.com/users/ishaybee/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-02T10:15:22Z", "updated_at": "2017-02-02T10:15:22Z", "author_association": "NONE", "body": "hi,\r\nI have same problem as other described that I have good training results but validation/testing is bad after using batch_norm.\r\nI use the function like this:\r\nconv_normed1 = tf.contrib.layers.batch_norm(conv1 + block1_layer3_1_biases, updates_collections=None, scale=True, decay=batch_norm_decay, center=True, is_training=is_training )\r\ndecay value is 0.9\r\ndo I need to set the reuse flag?\r\nI will glad for any help."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/277546936", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-277546936", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 277546936, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NzU0NjkzNg==", "user": {"login": "mshunshin", "id": 1478710, "node_id": "MDQ6VXNlcjE0Nzg3MTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1478710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mshunshin", "html_url": "https://github.com/mshunshin", "followers_url": "https://api.github.com/users/mshunshin/followers", "following_url": "https://api.github.com/users/mshunshin/following{/other_user}", "gists_url": "https://api.github.com/users/mshunshin/gists{/gist_id}", "starred_url": "https://api.github.com/users/mshunshin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mshunshin/subscriptions", "organizations_url": "https://api.github.com/users/mshunshin/orgs", "repos_url": "https://api.github.com/users/mshunshin/repos", "events_url": "https://api.github.com/users/mshunshin/events{/privacy}", "received_events_url": "https://api.github.com/users/mshunshin/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-05T20:33:27Z", "updated_at": "2017-02-05T20:33:27Z", "author_association": "NONE", "body": "I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.\r\n\r\nWhen saving and restoring using:\r\nsaver = tf.train.Saver()\r\nit works,\r\n\r\nbut when saving using:\r\nsaver = tf.train.Saver(tf.trainable_variables() + [global_step])\r\nso that I can save storage space (by not saving the gradients etc)\r\non restore there is an error:\r\n\"uninitialized value unpool4/convc/bn/moving_mean\"\r\n\r\nObviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers. As I have lots of them (nested in many layers) - what is the most efficient way of adding them to the list of values to be saved? Also, given that these are trainable variables, why are they not addded to the trainable_variables collection?\r\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/277560302", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-277560302", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 277560302, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NzU2MDMwMg==", "user": {"login": "DrSleep", "id": 7841432, "node_id": "MDQ6VXNlcjc4NDE0MzI=", "avatar_url": "https://avatars3.githubusercontent.com/u/7841432?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DrSleep", "html_url": "https://github.com/DrSleep", "followers_url": "https://api.github.com/users/DrSleep/followers", "following_url": "https://api.github.com/users/DrSleep/following{/other_user}", "gists_url": "https://api.github.com/users/DrSleep/gists{/gist_id}", "starred_url": "https://api.github.com/users/DrSleep/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DrSleep/subscriptions", "organizations_url": "https://api.github.com/users/DrSleep/orgs", "repos_url": "https://api.github.com/users/DrSleep/repos", "events_url": "https://api.github.com/users/DrSleep/events{/privacy}", "received_events_url": "https://api.github.com/users/DrSleep/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-05T23:45:40Z", "updated_at": "2017-02-05T23:45:40Z", "author_association": "NONE", "body": "@mshunshin moving mean and variance are not trainable variables: there are no gradients coming to them, they are just accumulating statistics across minibatches of examples. \r\nTo save/restore them, you can use tf.global_variables()"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/277616010", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-277616010", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 277616010, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NzYxNjAxMA==", "user": {"login": "ishaybee", "id": 25502989, "node_id": "MDQ6VXNlcjI1NTAyOTg5", "avatar_url": "https://avatars3.githubusercontent.com/u/25502989?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ishaybee", "html_url": "https://github.com/ishaybee", "followers_url": "https://api.github.com/users/ishaybee/followers", "following_url": "https://api.github.com/users/ishaybee/following{/other_user}", "gists_url": "https://api.github.com/users/ishaybee/gists{/gist_id}", "starred_url": "https://api.github.com/users/ishaybee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ishaybee/subscriptions", "organizations_url": "https://api.github.com/users/ishaybee/orgs", "repos_url": "https://api.github.com/users/ishaybee/repos", "events_url": "https://api.github.com/users/ishaybee/events{/privacy}", "received_events_url": "https://api.github.com/users/ishaybee/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-06T08:41:08Z", "updated_at": "2017-02-06T08:41:08Z", "author_association": "NONE", "body": "for me things started to work when I used this wrapper:\r\n`def batch_norm_wrapper(x, phase, decay, scope, reuse):\r\n    with tf.variable_scope(scope, reuse=reuse):\r\n        normed = tf.contrib.layers.batch_norm(x, center=True, scale=True, decay=decay, is_training=phase, scope='bn',updates_collections=None, reuse=reuse)\r\n        return normed`\r\nthe whole using of scopes and reuse is not clear in this thread for my opinion.\r\n    \r\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/277696723", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-277696723", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 277696723, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NzY5NjcyMw==", "user": {"login": "mshunshin", "id": 1478710, "node_id": "MDQ6VXNlcjE0Nzg3MTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1478710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mshunshin", "html_url": "https://github.com/mshunshin", "followers_url": "https://api.github.com/users/mshunshin/followers", "following_url": "https://api.github.com/users/mshunshin/following{/other_user}", "gists_url": "https://api.github.com/users/mshunshin/gists{/gist_id}", "starred_url": "https://api.github.com/users/mshunshin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mshunshin/subscriptions", "organizations_url": "https://api.github.com/users/mshunshin/orgs", "repos_url": "https://api.github.com/users/mshunshin/repos", "events_url": "https://api.github.com/users/mshunshin/events{/privacy}", "received_events_url": "https://api.github.com/users/mshunshin/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-06T14:26:08Z", "updated_at": "2017-02-06T14:26:08Z", "author_association": "NONE", "body": "Many thanks. With tf.global_variables() the save files are much larger as I think it includes the gradients; in the end I used:\r\n\r\nsaver = tf.train.Saver([x for x in tf.global_variables() if 'Adam' not in x.name])\r\n\r\nand because the session manager init doesn't initialise them properly:\r\n\r\nsess.run(tf.variables_initializer([x for x in tf.global_variables() if 'Adam' in x.name]))\r\n\r\n(Using tf.train.AdamOptimizer)"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/277865982", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-277865982", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 277865982, "node_id": "MDEyOklzc3VlQ29tbWVudDI3Nzg2NTk4Mg==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-07T00:59:54Z", "updated_at": "2017-02-07T00:59:54Z", "author_association": "MEMBER", "body": "You can also use tf.model_variables() which contains the variables of the model, i.e. moving_mean"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/280288936", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-280288936", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 280288936, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MDI4ODkzNg==", "user": {"login": "soloice", "id": 8534653, "node_id": "MDQ6VXNlcjg1MzQ2NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/8534653?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soloice", "html_url": "https://github.com/soloice", "followers_url": "https://api.github.com/users/soloice/followers", "following_url": "https://api.github.com/users/soloice/following{/other_user}", "gists_url": "https://api.github.com/users/soloice/gists{/gist_id}", "starred_url": "https://api.github.com/users/soloice/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soloice/subscriptions", "organizations_url": "https://api.github.com/users/soloice/orgs", "repos_url": "https://api.github.com/users/soloice/repos", "events_url": "https://api.github.com/users/soloice/events{/privacy}", "received_events_url": "https://api.github.com/users/soloice/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-16T10:09:57Z", "updated_at": "2017-02-16T10:11:07Z", "author_association": "CONTRIBUTOR", "body": "@sguada Sorry for trouble you, but is it possible to make an example on how to use slim.batch_norm when combined with slim.conv2d/slim.fully_connect in readme.md? \r\n\r\nI'm using slim.batch_norm, but get good training performance and poor validation/test performance. I think it must be due to improper use of `reuse` or `scope` or some other parameters. Though there are many issues on batch normalization, it's hard to find a complete code snippet on how to use it, esp. for how to pass different parameters in different phase.\r\n\r\nSay, in my [mnist_bn](https://github.com/soloice/mnist-bn/blob/master/mnist_bn.py) code, I controlled dependencies using `tf.GraphKeys.UPDATE_OPS` and set up `is_training` as a placeholder. But validation performance still is poor if I feed {is_training: False}.\r\n\r\nI would greatly appreciate it if there's an official and complete (which means training, validating, testing are all included) batch normalization example.\r\n\r\nThank you in advance!"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/280293299", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-280293299", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 280293299, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MDI5MzI5OQ==", "user": {"login": "ishaybee", "id": 25502989, "node_id": "MDQ6VXNlcjI1NTAyOTg5", "avatar_url": "https://avatars3.githubusercontent.com/u/25502989?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ishaybee", "html_url": "https://github.com/ishaybee", "followers_url": "https://api.github.com/users/ishaybee/followers", "following_url": "https://api.github.com/users/ishaybee/following{/other_user}", "gists_url": "https://api.github.com/users/ishaybee/gists{/gist_id}", "starred_url": "https://api.github.com/users/ishaybee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ishaybee/subscriptions", "organizations_url": "https://api.github.com/users/ishaybee/orgs", "repos_url": "https://api.github.com/users/ishaybee/repos", "events_url": "https://api.github.com/users/ishaybee/events{/privacy}", "received_events_url": "https://api.github.com/users/ishaybee/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-16T10:28:40Z", "updated_at": "2017-02-16T10:28:40Z", "author_association": "NONE", "body": "hi,\r\nyou need to set different scope for every time you use batch norm and give it the reuse input according to the training/test phase(TRUE when test FALSE when train) that works for me."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/280325584", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-280325584", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 280325584, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MDMyNTU4NA==", "user": {"login": "soloice", "id": 8534653, "node_id": "MDQ6VXNlcjg1MzQ2NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/8534653?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soloice", "html_url": "https://github.com/soloice", "followers_url": "https://api.github.com/users/soloice/followers", "following_url": "https://api.github.com/users/soloice/following{/other_user}", "gists_url": "https://api.github.com/users/soloice/gists{/gist_id}", "starred_url": "https://api.github.com/users/soloice/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soloice/subscriptions", "organizations_url": "https://api.github.com/users/soloice/orgs", "repos_url": "https://api.github.com/users/soloice/repos", "events_url": "https://api.github.com/users/soloice/events{/privacy}", "received_events_url": "https://api.github.com/users/soloice/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-16T13:07:51Z", "updated_at": "2017-04-27T17:49:18Z", "author_association": "CONTRIBUTOR", "body": "@ishaybee Thanks for you help. I've found my problem= = **It's due to the cold start of moving_mean/moving_variance.**\r\n\r\nSince I haven't trained enough steps, the estimated moving mean/variance is not that stable. The result turns out to be: the model performs pretty well on training mini-batches (you know at the beginning loss goes down quickly), but validation performance is erratic (because the estimated population mean/variance are not stable enough).\r\n\r\nWhen I trained the model longer, validation accuracy becomes prettier, too.\r\n\r\n**Another important thing is, be sure to use `slim.learning.create_train_op` to create train op**. Do not use tf native `tf.train.GradientDescentOptimizer(0.1).minimize(loss)`.\r\n\r\nSo the answer is, I'm using batch normalization correctly, but I haven't fully understood its dynamics during training.\r\n\r\n================\r\nWhat's more:\r\n1. [Here is a full example](https://github.com/soloice/mnist-bn) on how to use BN layer on MNIST dataset.\r\n2. Use a smaller decay value will accelerate the warm-up phase. The default decay is 0.999, for small datasets such like MNIST, you can choose 0.99 or 0.95, and it warms up in a short time."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/280652741", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-280652741", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 280652741, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MDY1Mjc0MQ==", "user": {"login": "pavelbulanov", "id": 14073667, "node_id": "MDQ6VXNlcjE0MDczNjY3", "avatar_url": "https://avatars0.githubusercontent.com/u/14073667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavelbulanov", "html_url": "https://github.com/pavelbulanov", "followers_url": "https://api.github.com/users/pavelbulanov/followers", "following_url": "https://api.github.com/users/pavelbulanov/following{/other_user}", "gists_url": "https://api.github.com/users/pavelbulanov/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavelbulanov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavelbulanov/subscriptions", "organizations_url": "https://api.github.com/users/pavelbulanov/orgs", "repos_url": "https://api.github.com/users/pavelbulanov/repos", "events_url": "https://api.github.com/users/pavelbulanov/events{/privacy}", "received_events_url": "https://api.github.com/users/pavelbulanov/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-17T13:44:05Z", "updated_at": "2017-02-17T13:49:04Z", "author_association": "CONTRIBUTOR", "body": "@soloice , notice, how in about [comment](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235928564) the following parameter is passed inside to the layer for calling batch_norm:\r\n\r\n>  batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}\r\n\r\nWithout `updates_collections `set to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.\r\n\r\nOr you may try to run UPDATE_OPS yourself explicitly as one [here](https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-279646674)\r\n```\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    if update_ops:\r\n        updates = tf.group(*update_ops)\r\n        cross_entropy = control_flow_ops.with_dependencies([updates], cross_entropy)\r\n```\r\n\r\nUpdate - I found that I quoted exactly your code and you do use UPDATE_OPS. \r\n\r\nAs for \"cold start\", as you see above in discussiion, decreasing BatchNorm running average decay (input param) from default 0.999 to something like 0.95 can speed-up start-up"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/280715495", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-280715495", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 280715495, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MDcxNTQ5NQ==", "user": {"login": "soloice", "id": 8534653, "node_id": "MDQ6VXNlcjg1MzQ2NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/8534653?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soloice", "html_url": "https://github.com/soloice", "followers_url": "https://api.github.com/users/soloice/followers", "following_url": "https://api.github.com/users/soloice/following{/other_user}", "gists_url": "https://api.github.com/users/soloice/gists{/gist_id}", "starred_url": "https://api.github.com/users/soloice/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soloice/subscriptions", "organizations_url": "https://api.github.com/users/soloice/orgs", "repos_url": "https://api.github.com/users/soloice/repos", "events_url": "https://api.github.com/users/soloice/events{/privacy}", "received_events_url": "https://api.github.com/users/soloice/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-17T17:35:11Z", "updated_at": "2017-04-21T02:50:48Z", "author_association": "CONTRIBUTOR", "body": "@pavelbulanov It's very kind of you to help me with this! I'll try a smaller value of `decay` to see how this helps.\r\n\r\n================\r\nUpdate: use a small decay (say, 0.9 or 0.95) does help a lot. Validation loss goes down very quickly when I set `decay` to 0.9. However, the drawback of small decay is that its effective range is small: The result is dominated by a few recent samples thus it's not a good estimation of population mean/variance. One needs to balance between quick start (small decay) and a longer effective range (large decay)."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/290937634", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-290937634", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 290937634, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDkzNzYzNA==", "user": {"login": "Alexivia", "id": 23476569, "node_id": "MDQ6VXNlcjIzNDc2NTY5", "avatar_url": "https://avatars1.githubusercontent.com/u/23476569?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Alexivia", "html_url": "https://github.com/Alexivia", "followers_url": "https://api.github.com/users/Alexivia/followers", "following_url": "https://api.github.com/users/Alexivia/following{/other_user}", "gists_url": "https://api.github.com/users/Alexivia/gists{/gist_id}", "starred_url": "https://api.github.com/users/Alexivia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Alexivia/subscriptions", "organizations_url": "https://api.github.com/users/Alexivia/orgs", "repos_url": "https://api.github.com/users/Alexivia/repos", "events_url": "https://api.github.com/users/Alexivia/events{/privacy}", "received_events_url": "https://api.github.com/users/Alexivia/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-01T18:17:58Z", "updated_at": "2017-04-01T18:17:58Z", "author_association": "NONE", "body": "Hi,\r\nI tried to implement a batch normalisation layer with the help of the suggestions in this issue, but I still have a >70% error in validation and testing... I do have a lower decay for non-training calls...\r\n\r\nHere is my code:\r\n```python\r\ndef BatchNorm(inputT, is_training=False, scope=None):\r\n  return tf.cond(\r\n    is_training,\r\n    lambda: tf.contrib.layers.batch_norm(inputT, is_training=True,  reuse=None, decay=0.999, epsilon=1e-5, center=True, scale=True, updates_collections=None, scope=scope),\r\n    lambda: tf.contrib.layers.batch_norm(inputT, is_training=False, reuse=True, decay=0.900, epsilon=1e-5, center=True, scale=True, updates_collections=None, scope=scope)\r\n    )\r\n```\r\n\r\nThank you in advance."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/290960485", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-290960485", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 290960485, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDk2MDQ4NQ==", "user": {"login": "soloice", "id": 8534653, "node_id": "MDQ6VXNlcjg1MzQ2NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/8534653?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soloice", "html_url": "https://github.com/soloice", "followers_url": "https://api.github.com/users/soloice/followers", "following_url": "https://api.github.com/users/soloice/following{/other_user}", "gists_url": "https://api.github.com/users/soloice/gists{/gist_id}", "starred_url": "https://api.github.com/users/soloice/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soloice/subscriptions", "organizations_url": "https://api.github.com/users/soloice/orgs", "repos_url": "https://api.github.com/users/soloice/repos", "events_url": "https://api.github.com/users/soloice/events{/privacy}", "received_events_url": "https://api.github.com/users/soloice/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-02T02:31:05Z", "updated_at": "2017-04-02T02:31:05Z", "author_association": "CONTRIBUTOR", "body": "@Alexivia It seems that you are using two different batch normalization layers? You should use only one BN layer (of course, with different `is_training` parameter)."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/290983146", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-290983146", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 290983146, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDk4MzE0Ng==", "user": {"login": "Alexivia", "id": 23476569, "node_id": "MDQ6VXNlcjIzNDc2NTY5", "avatar_url": "https://avatars1.githubusercontent.com/u/23476569?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Alexivia", "html_url": "https://github.com/Alexivia", "followers_url": "https://api.github.com/users/Alexivia/followers", "following_url": "https://api.github.com/users/Alexivia/following{/other_user}", "gists_url": "https://api.github.com/users/Alexivia/gists{/gist_id}", "starred_url": "https://api.github.com/users/Alexivia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Alexivia/subscriptions", "organizations_url": "https://api.github.com/users/Alexivia/orgs", "repos_url": "https://api.github.com/users/Alexivia/repos", "events_url": "https://api.github.com/users/Alexivia/events{/privacy}", "received_events_url": "https://api.github.com/users/Alexivia/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-02T12:25:32Z", "updated_at": "2017-04-02T12:25:32Z", "author_association": "NONE", "body": "Thank you for your advice @soloice.\r\nI tried now with just different `is_training` and `reuse` parameters:\r\n```python\r\nlambda: tf.contrib.layers.batch_norm(inputT, is_training=True,  reuse=None, decay=0.9, epsilon=1e-5, center=True, scale=True, updates_collections=None, scope=scope),\r\nlambda: tf.contrib.layers.batch_norm(inputT, is_training=False, reuse=True, decay=0.9, epsilon=1e-5, center=True, scale=True, updates_collections=None, scope=scope)\r\n```\r\nstill don't get good validation and testing results... >70%..."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291008094", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-291008094", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 291008094, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTAwODA5NA==", "user": {"login": "ishaybee", "id": 25502989, "node_id": "MDQ6VXNlcjI1NTAyOTg5", "avatar_url": "https://avatars3.githubusercontent.com/u/25502989?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ishaybee", "html_url": "https://github.com/ishaybee", "followers_url": "https://api.github.com/users/ishaybee/followers", "following_url": "https://api.github.com/users/ishaybee/following{/other_user}", "gists_url": "https://api.github.com/users/ishaybee/gists{/gist_id}", "starred_url": "https://api.github.com/users/ishaybee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ishaybee/subscriptions", "organizations_url": "https://api.github.com/users/ishaybee/orgs", "repos_url": "https://api.github.com/users/ishaybee/repos", "events_url": "https://api.github.com/users/ishaybee/events{/privacy}", "received_events_url": "https://api.github.com/users/ishaybee/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-02T19:17:02Z", "updated_at": "2017-04-02T19:17:02Z", "author_association": "NONE", "body": "hi,\r\nplease see my wrapper above.\r\nyou should use \"with tf.variable_scope(scope, reuse=reuse):\" I think."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291195251", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-291195251", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 291195251, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTE5NTI1MQ==", "user": {"login": "Alexivia", "id": 23476569, "node_id": "MDQ6VXNlcjIzNDc2NTY5", "avatar_url": "https://avatars1.githubusercontent.com/u/23476569?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Alexivia", "html_url": "https://github.com/Alexivia", "followers_url": "https://api.github.com/users/Alexivia/followers", "following_url": "https://api.github.com/users/Alexivia/following{/other_user}", "gists_url": "https://api.github.com/users/Alexivia/gists{/gist_id}", "starred_url": "https://api.github.com/users/Alexivia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Alexivia/subscriptions", "organizations_url": "https://api.github.com/users/Alexivia/orgs", "repos_url": "https://api.github.com/users/Alexivia/repos", "events_url": "https://api.github.com/users/Alexivia/events{/privacy}", "received_events_url": "https://api.github.com/users/Alexivia/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-03T16:23:41Z", "updated_at": "2017-04-03T16:23:41Z", "author_association": "NONE", "body": "Hi @ishaybee,\r\nI followed your advice, now my code is:\r\n```python\r\ndef BatchNorm(inputT, is_training=False, reuse=True, scope=None):\r\n  with tf.variable_scope(scope, reuse=reuse):\r\n    return tf.contrib.layers.batch_norm(inputT, is_training=is_training, reuse=reuse, scope=scope, updates_collections=None, decay=0.9, center=True, scale=True)\r\n```\r\nand I feed `is_training` and `reuse` through the feed_dict, but now I get the error `ValueError(\"The reuse parameter must be True or False or None.\")`"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291200434", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-291200434", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 291200434, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTIwMDQzNA==", "user": {"login": "ishaybee", "id": 25502989, "node_id": "MDQ6VXNlcjI1NTAyOTg5", "avatar_url": "https://avatars3.githubusercontent.com/u/25502989?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ishaybee", "html_url": "https://github.com/ishaybee", "followers_url": "https://api.github.com/users/ishaybee/followers", "following_url": "https://api.github.com/users/ishaybee/following{/other_user}", "gists_url": "https://api.github.com/users/ishaybee/gists{/gist_id}", "starred_url": "https://api.github.com/users/ishaybee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ishaybee/subscriptions", "organizations_url": "https://api.github.com/users/ishaybee/orgs", "repos_url": "https://api.github.com/users/ishaybee/repos", "events_url": "https://api.github.com/users/ishaybee/events{/privacy}", "received_events_url": "https://api.github.com/users/ishaybee/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-03T16:41:49Z", "updated_at": "2017-04-03T16:41:49Z", "author_association": "NONE", "body": "try to feed reuse as a python variable (input of the model) and as placeholder."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291239869", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-291239869", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 291239869, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTIzOTg2OQ==", "user": {"login": "Alexivia", "id": 23476569, "node_id": "MDQ6VXNlcjIzNDc2NTY5", "avatar_url": "https://avatars1.githubusercontent.com/u/23476569?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Alexivia", "html_url": "https://github.com/Alexivia", "followers_url": "https://api.github.com/users/Alexivia/followers", "following_url": "https://api.github.com/users/Alexivia/following{/other_user}", "gists_url": "https://api.github.com/users/Alexivia/gists{/gist_id}", "starred_url": "https://api.github.com/users/Alexivia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Alexivia/subscriptions", "organizations_url": "https://api.github.com/users/Alexivia/orgs", "repos_url": "https://api.github.com/users/Alexivia/repos", "events_url": "https://api.github.com/users/Alexivia/events{/privacy}", "received_events_url": "https://api.github.com/users/Alexivia/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-03T18:57:48Z", "updated_at": "2017-04-03T18:57:48Z", "author_association": "NONE", "body": "I tried that, and now it stopped complaining about the value... but I think that the placeholder value is not being used, because I see no change if I force values to `batch_norm` function, and in TensorBoard it's not connected to the graph... (see attached image)\r\n![screen shot 2017-04-03 at 19 54 54](https://cloud.githubusercontent.com/assets/23476569/24625718/cbe90f88-18a7-11e7-80a6-f087d56dd9ad.png)\r\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291242337", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-291242337", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 291242337, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTI0MjMzNw==", "user": {"login": "Alexivia", "id": 23476569, "node_id": "MDQ6VXNlcjIzNDc2NTY5", "avatar_url": "https://avatars1.githubusercontent.com/u/23476569?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Alexivia", "html_url": "https://github.com/Alexivia", "followers_url": "https://api.github.com/users/Alexivia/followers", "following_url": "https://api.github.com/users/Alexivia/following{/other_user}", "gists_url": "https://api.github.com/users/Alexivia/gists{/gist_id}", "starred_url": "https://api.github.com/users/Alexivia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Alexivia/subscriptions", "organizations_url": "https://api.github.com/users/Alexivia/orgs", "repos_url": "https://api.github.com/users/Alexivia/repos", "events_url": "https://api.github.com/users/Alexivia/events{/privacy}", "received_events_url": "https://api.github.com/users/Alexivia/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-03T19:06:19Z", "updated_at": "2017-04-03T19:06:19Z", "author_association": "NONE", "body": "My code is like this now:\r\n**Batch Normalisation wrapper**\r\n```python\r\ndef BatchNorm(inputT, is_training=False, reuse=None, scope=None):\r\n  with tf.variable_scope(scope):\r\n    return tf.contrib.layers.batch_norm(inputT, is_training=is_training, reuse=reuse, scope=scope, updates_collections=None, decay=0.9, center=True, scale=True)\r\n```\r\n**Model definition**\r\n```python\r\ndef model(data, train=False, is_training=False, reuse=None):\r\n  # 1st conv layer\r\n  with tf.name_scope('conv1') as scope:\r\n    conv = tf.nn.conv2d(\r\n    <...>\r\n    norm = BatchNorm(pool, is_training=is_training, reuse=reuse, scope=scope)\r\n```\r\n**Training**\r\n```python\r\nfeed_dict = {train_data_node: batch_data,\r\n      train_labels_node: batch_labels,\r\n      is_training: True,\r\n      reuse: None}\r\n  # Run the optimizer to update weights.\r\n  sess.run(optimizer, feed_dict=feed_dict)\r\n```\r\n**Validation**\r\n```python\r\nbatch_predictions = sess.run(eval_prediction, feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...], is_training: False, reuse: True})\r\n```"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291332856", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-291332856", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 291332856, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTMzMjg1Ng==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-04T00:08:04Z", "updated_at": "2017-04-04T00:08:24Z", "author_association": "MEMBER", "body": "Although is_traning can a placeholder reuse has to be a bool, and it cannot be a tensor nor a placeholder.\r\n\r\nI'm not sure what are you trying to do, in most cases using static values solve the problem. For example this pattern works well:\r\n\r\n```\r\ndef model(data, is_training=False, reuse=None, scope='my_model'):\r\n  # Define a variable scope to contain all the variables of your model\r\n  with tf.variable_scope(scope, 'model', data, reuse=reuse):\r\n    # 1 layer\r\n    net = tf.contrib.layers.conv2d(data, ....)\r\n    ....\r\n    net = tf.contrib.layers.batch_norm(net, is_training)\r\n   return net\r\n\r\ntrain_outputs = model(train_data, is_training=True)\r\neval_outputs = model(eval_data, is_training=False, reuse=True)\r\n\r\neval_predictions = sess.run(eval_outputs, feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})\r\n\r\n```\r\nUnless you need to change the behavior of the model dynamically, you don't need to use a placeholder for is_training. The trick is to build the model twice, but sharing the variables the second time. \r\n\r\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291464544", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-291464544", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 291464544, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTQ2NDU0NA==", "user": {"login": "Alexivia", "id": 23476569, "node_id": "MDQ6VXNlcjIzNDc2NTY5", "avatar_url": "https://avatars1.githubusercontent.com/u/23476569?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Alexivia", "html_url": "https://github.com/Alexivia", "followers_url": "https://api.github.com/users/Alexivia/followers", "following_url": "https://api.github.com/users/Alexivia/following{/other_user}", "gists_url": "https://api.github.com/users/Alexivia/gists{/gist_id}", "starred_url": "https://api.github.com/users/Alexivia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Alexivia/subscriptions", "organizations_url": "https://api.github.com/users/Alexivia/orgs", "repos_url": "https://api.github.com/users/Alexivia/repos", "events_url": "https://api.github.com/users/Alexivia/events{/privacy}", "received_events_url": "https://api.github.com/users/Alexivia/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-04T10:49:44Z", "updated_at": "2017-04-04T10:49:44Z", "author_association": "NONE", "body": "Thank you @sguada ! After applying your suggestions, I finally made it to work!"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291734783", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-291734783", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 291734783, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTczNDc4Mw==", "user": {"login": "danrsc", "id": 11574457, "node_id": "MDQ6VXNlcjExNTc0NDU3", "avatar_url": "https://avatars0.githubusercontent.com/u/11574457?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danrsc", "html_url": "https://github.com/danrsc", "followers_url": "https://api.github.com/users/danrsc/followers", "following_url": "https://api.github.com/users/danrsc/following{/other_user}", "gists_url": "https://api.github.com/users/danrsc/gists{/gist_id}", "starred_url": "https://api.github.com/users/danrsc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danrsc/subscriptions", "organizations_url": "https://api.github.com/users/danrsc/orgs", "repos_url": "https://api.github.com/users/danrsc/repos", "events_url": "https://api.github.com/users/danrsc/events{/privacy}", "received_events_url": "https://api.github.com/users/danrsc/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-05T03:10:30Z", "updated_at": "2017-04-05T03:10:30Z", "author_association": "NONE", "body": "It would be helpful if the API 1.0 documentation reflected that you need to manually add update ops to the graph. Being a newer tf user, I found that my test error was crazy and then had to spend a fair amount of time debugging my graph until I realized that batch normalization was the problem. Then I had to spend more time figuring out that by default the variables tracking the moments don't update unless you use a contrib function for optimization. Since in 1.0 there is no option to set the update_collections to None, there is no indicator from the documentation that this might even be an issue. Additionally, it seems like it might make sense to have a parameter to add the control flow dependencies to the op that runs in the training case."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291752494", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-291752494", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 291752494, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTc1MjQ5NA==", "user": {"login": "soloice", "id": 8534653, "node_id": "MDQ6VXNlcjg1MzQ2NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/8534653?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soloice", "html_url": "https://github.com/soloice", "followers_url": "https://api.github.com/users/soloice/followers", "following_url": "https://api.github.com/users/soloice/following{/other_user}", "gists_url": "https://api.github.com/users/soloice/gists{/gist_id}", "starred_url": "https://api.github.com/users/soloice/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soloice/subscriptions", "organizations_url": "https://api.github.com/users/soloice/orgs", "repos_url": "https://api.github.com/users/soloice/repos", "events_url": "https://api.github.com/users/soloice/events{/privacy}", "received_events_url": "https://api.github.com/users/soloice/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-05T04:41:58Z", "updated_at": "2017-04-05T04:41:58Z", "author_association": "CONTRIBUTOR", "body": "@danrsc Exactly. The usage of BN layer is quite confusing. I suggested to add documents or a complete official tutorial on batch normalization, but unfortunately got no response = ="}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291868380", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-291868380", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 291868380, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTg2ODM4MA==", "user": {"login": "alquraishi", "id": 5205204, "node_id": "MDQ6VXNlcjUyMDUyMDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/5205204?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alquraishi", "html_url": "https://github.com/alquraishi", "followers_url": "https://api.github.com/users/alquraishi/followers", "following_url": "https://api.github.com/users/alquraishi/following{/other_user}", "gists_url": "https://api.github.com/users/alquraishi/gists{/gist_id}", "starred_url": "https://api.github.com/users/alquraishi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alquraishi/subscriptions", "organizations_url": "https://api.github.com/users/alquraishi/orgs", "repos_url": "https://api.github.com/users/alquraishi/repos", "events_url": "https://api.github.com/users/alquraishi/events{/privacy}", "received_events_url": "https://api.github.com/users/alquraishi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-05T13:53:44Z", "updated_at": "2017-04-05T13:53:44Z", "author_association": "NONE", "body": "Completely agree. I think BN usage is very tricky and the documentation is currently beyond inadequate. This ought to be fixed for such a commonly used layer."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/292246990", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-292246990", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 292246990, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjI0Njk5MA==", "user": {"login": "vincentvanhoucke", "id": 15737127, "node_id": "MDQ6VXNlcjE1NzM3MTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/15737127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincentvanhoucke", "html_url": "https://github.com/vincentvanhoucke", "followers_url": "https://api.github.com/users/vincentvanhoucke/followers", "following_url": "https://api.github.com/users/vincentvanhoucke/following{/other_user}", "gists_url": "https://api.github.com/users/vincentvanhoucke/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincentvanhoucke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincentvanhoucke/subscriptions", "organizations_url": "https://api.github.com/users/vincentvanhoucke/orgs", "repos_url": "https://api.github.com/users/vincentvanhoucke/repos", "events_url": "https://api.github.com/users/vincentvanhoucke/events{/privacy}", "received_events_url": "https://api.github.com/users/vincentvanhoucke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-06T17:26:01Z", "updated_at": "2017-04-06T17:26:01Z", "author_association": "MEMBER", "body": "Reopening for visibility of the documentation issues."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/292248126", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-292248126", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 292248126, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjI0ODEyNg==", "user": {"login": "vincentvanhoucke", "id": 15737127, "node_id": "MDQ6VXNlcjE1NzM3MTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/15737127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincentvanhoucke", "html_url": "https://github.com/vincentvanhoucke", "followers_url": "https://api.github.com/users/vincentvanhoucke/followers", "following_url": "https://api.github.com/users/vincentvanhoucke/following{/other_user}", "gists_url": "https://api.github.com/users/vincentvanhoucke/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincentvanhoucke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincentvanhoucke/subscriptions", "organizations_url": "https://api.github.com/users/vincentvanhoucke/orgs", "repos_url": "https://api.github.com/users/vincentvanhoucke/repos", "events_url": "https://api.github.com/users/vincentvanhoucke/events{/privacy}", "received_events_url": "https://api.github.com/users/vincentvanhoucke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-06T17:29:18Z", "updated_at": "2017-04-06T17:29:18Z", "author_association": "MEMBER", "body": "@sguada assigning to you for triaging. Might be worth getting a tech writer on the case."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/296412026", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-296412026", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 296412026, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NjQxMjAyNg==", "user": {"login": "ronghanghu", "id": 6997335, "node_id": "MDQ6VXNlcjY5OTczMzU=", "avatar_url": "https://avatars3.githubusercontent.com/u/6997335?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ronghanghu", "html_url": "https://github.com/ronghanghu", "followers_url": "https://api.github.com/users/ronghanghu/followers", "following_url": "https://api.github.com/users/ronghanghu/following{/other_user}", "gists_url": "https://api.github.com/users/ronghanghu/gists{/gist_id}", "starred_url": "https://api.github.com/users/ronghanghu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ronghanghu/subscriptions", "organizations_url": "https://api.github.com/users/ronghanghu/orgs", "repos_url": "https://api.github.com/users/ronghanghu/repos", "events_url": "https://api.github.com/users/ronghanghu/events{/privacy}", "received_events_url": "https://api.github.com/users/ronghanghu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-23T01:03:51Z", "updated_at": "2017-04-23T01:03:51Z", "author_association": "NONE", "body": "Just got confused by this problem last week and wasted 3 days of training... Hope the docs can be fixed soon, and an official batch normalization example can be added in the API docs."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299124981", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-299124981", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 299124981, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTEyNDk4MQ==", "user": {"login": "MisayaZ", "id": 16910475, "node_id": "MDQ6VXNlcjE2OTEwNDc1", "avatar_url": "https://avatars2.githubusercontent.com/u/16910475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MisayaZ", "html_url": "https://github.com/MisayaZ", "followers_url": "https://api.github.com/users/MisayaZ/followers", "following_url": "https://api.github.com/users/MisayaZ/following{/other_user}", "gists_url": "https://api.github.com/users/MisayaZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/MisayaZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MisayaZ/subscriptions", "organizations_url": "https://api.github.com/users/MisayaZ/orgs", "repos_url": "https://api.github.com/users/MisayaZ/repos", "events_url": "https://api.github.com/users/MisayaZ/events{/privacy}", "received_events_url": "https://api.github.com/users/MisayaZ/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-04T08:27:22Z", "updated_at": "2017-05-05T01:08:16Z", "author_association": "NONE", "body": "@sguada  I have noticed that you said\" tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial\".\r\nHowerver, the comment in the code is\r\n If `is_training` doesn't have a constant value, because it is a `Tensor`,\r\n    # a `Variable` or `Placeholder` then is_training_value will be None and\r\n    # `needs_moments` will be true.\r\nDoes it mean that nees_moments will be true even in test phase if i set is_training as a  placeholder?\r\nAs far as I know, the moments is not needed while testing."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299591558", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-299591558", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 299591558, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTU5MTU1OA==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-05T22:39:04Z", "updated_at": "2017-05-05T22:40:01Z", "author_association": "MEMBER", "body": "So if `is_training` is a `Variable` or a `Placeholder`, it means it can change, so the graph to compute the moments is needed, so the layer builds it.\r\nThen in running time depending on the value being `True` or `False` would use the batch `moments` or the `moving_mean` and `moving_variance`.\r\n\r\nSo during testing you would set the value to `False` and the `moments` won't be used."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299623012", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-299623012", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 299623012, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTYyMzAxMg==", "user": {"login": "MisayaZ", "id": 16910475, "node_id": "MDQ6VXNlcjE2OTEwNDc1", "avatar_url": "https://avatars2.githubusercontent.com/u/16910475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MisayaZ", "html_url": "https://github.com/MisayaZ", "followers_url": "https://api.github.com/users/MisayaZ/followers", "following_url": "https://api.github.com/users/MisayaZ/following{/other_user}", "gists_url": "https://api.github.com/users/MisayaZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/MisayaZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MisayaZ/subscriptions", "organizations_url": "https://api.github.com/users/MisayaZ/orgs", "repos_url": "https://api.github.com/users/MisayaZ/repos", "events_url": "https://api.github.com/users/MisayaZ/events{/privacy}", "received_events_url": "https://api.github.com/users/MisayaZ/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-06T07:51:03Z", "updated_at": "2017-05-06T07:57:11Z", "author_association": "NONE", "body": "@sguada @brando90 \r\n```\r\ndef batch_norm_layer(self, x,train_phase, scope_bn):\r\n        bn_train = batch_norm(x, decay=0.9, center=False, scale=True,\r\n        updates_collections=None,\r\n        is_training=True,\r\n        reuse=None,\r\n        variables_collections= [UPDATE_OPS_COLLECTION],\r\n        trainable=True,\r\n        scope=scope_bn)\r\n        bn_inference = batch_norm(x, decay=0.9, center=False, scale=True,\r\n        updates_collections=None,\r\n        is_training=False,\r\n        reuse=True,\r\n        variables_collections= [UPDATE_OPS_COLLECTION],\r\n        trainable=True,\r\n        scope=scope_bn)\r\n        z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)\r\n        return z\r\n```\r\n\r\n\r\nI build batchnorm like this, however, the moving mean and moving variable are updated during test, I can not find the reason."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299633920", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-299633920", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 299633920, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTYzMzkyMA==", "user": {"login": "OktayGardener", "id": 6593422, "node_id": "MDQ6VXNlcjY1OTM0MjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/6593422?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OktayGardener", "html_url": "https://github.com/OktayGardener", "followers_url": "https://api.github.com/users/OktayGardener/followers", "following_url": "https://api.github.com/users/OktayGardener/following{/other_user}", "gists_url": "https://api.github.com/users/OktayGardener/gists{/gist_id}", "starred_url": "https://api.github.com/users/OktayGardener/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OktayGardener/subscriptions", "organizations_url": "https://api.github.com/users/OktayGardener/orgs", "repos_url": "https://api.github.com/users/OktayGardener/repos", "events_url": "https://api.github.com/users/OktayGardener/events{/privacy}", "received_events_url": "https://api.github.com/users/OktayGardener/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-06T11:34:51Z", "updated_at": "2017-05-06T11:34:51Z", "author_association": "NONE", "body": "I tried creating two models like @sguada said, however, my model where is_training=False just crashes.\r\n\r\n```\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key fully_connected_5/weights not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key fully_connected_6/weights not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key fully_connected_7/biases not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key fully_connected_6/biases not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key fully_connected_7/weights not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key history_embeddings_1 not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key global_step_1 not found in checkpoint\r\n```\r\n\r\nI feel like maybe there should be a concrete example of how to do a batch norm with a fully connected net, as well as with CNNs. Sucks that I've trained models for days expecting things to work before seeing that everyone trying to use this feature going crazy.\r\n\r\nInterestingly enough, it takes a zillion years to get the model restored after training with batch_norm as well. Will most likely wait until TF 2.0 to try something like this again."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299660639", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-299660639", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 299660639, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTY2MDYzOQ==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-06T19:21:29Z", "updated_at": "2017-05-06T19:21:29Z", "author_association": "MEMBER", "body": "@MisayaZ you don't need to create two batch_norm layers you can just pass train_phase (assuming it is a tf.bool) to batch_norm. Also you are passing UPDATE_OPS_COLLECTION variables_collections, which changes which collections are the variables added to.\r\n\r\nThe following should work:\r\n\r\n```\r\nz = batch_norm(x, decay=0.9, center=False, scale=True, updates_collections=None, \r\n                             is_training=train_phase, scope=scope_bn)\r\n\r\n```\r\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299661205", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-299661205", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 299661205, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTY2MTIwNQ==", "user": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-06T19:32:36Z", "updated_at": "2017-05-06T19:32:36Z", "author_association": "MEMBER", "body": "@OktayGardener not sure what model are you trying to create, it seems that the variables are not saved in your checkpoint.\r\n\r\nbatch_norm also works with fully_connected layers.\r\n\r\n```\r\nslim = tf.contrib.slim\r\ndef model(data, is_training=False, reuse=None, scope='my_model'):\r\n  # Define a variable scope to contain all the variables of your model\r\n  with tf.variable_scope(scope, 'model', data, reuse=reuse):\r\n    # Configure arguments of fully_connected layers\r\n    with slim.arg_scope([slim.fully_connected],\r\n                        activation_fn=tf.nn.relu,\r\n                        normalizer_fn=slim.batch_nom):\r\n      # Configure arguments of batch_norm layers\r\n      with slim.arg_scope([slim.batch_norm],\r\n                          decay=0.9,  # Adjust decay to the number of iterations\r\n                          update_collections=None, # Make sure updates happen automatically\r\n                          is_training=is_training, # Switch behavior from training to non-training):\r\n        net = slim.fully_connected(data, 100, scope='fc1')\r\n        net = slim.fully_connected(net, 200, scope='fc2')\r\n        ....\r\n        # Don't use activation_fn nor batch_norm in the last layer        \r\n        net = slim.fully_connected(net, 10, activation_fn=None, normalizer_fn=None, scope='fc10')\r\n       return net\r\n```\r\n\r\n\r\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299697626", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-299697626", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 299697626, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTY5NzYyNg==", "user": {"login": "MisayaZ", "id": 16910475, "node_id": "MDQ6VXNlcjE2OTEwNDc1", "avatar_url": "https://avatars2.githubusercontent.com/u/16910475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MisayaZ", "html_url": "https://github.com/MisayaZ", "followers_url": "https://api.github.com/users/MisayaZ/followers", "following_url": "https://api.github.com/users/MisayaZ/following{/other_user}", "gists_url": "https://api.github.com/users/MisayaZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/MisayaZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MisayaZ/subscriptions", "organizations_url": "https://api.github.com/users/MisayaZ/orgs", "repos_url": "https://api.github.com/users/MisayaZ/repos", "events_url": "https://api.github.com/users/MisayaZ/events{/privacy}", "received_events_url": "https://api.github.com/users/MisayaZ/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-07T10:52:56Z", "updated_at": "2017-05-07T10:54:58Z", "author_association": "NONE", "body": "@sguada Thanks, I build a network with bathnorm which is implemented as you mentioned above\r\n```\r\nz = batch_norm(x, decay=0.9, center=False, scale=True, updates_collections=None, \r\n                             is_training=train_phase, scope=scope_bn)\r\n```\r\nthe speed is slow, I use tensorflow benchmark to get the computation time as below:\r\nI tensorflow/core/util/stat_summarizer.cc:392] ============================== Top by Computation Time ==============================\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t             [node type]\t  [start]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[Name]\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                  Conv2D\t  106.164\t   51.354\t   51.004\t 23.145%\t 23.145%\t   692.224\tconv8/Conv2D\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                  Conv2D\t   85.187\t   19.115\t   19.283\t  8.750%\t 31.896%\t   692.224\tconv7/Conv2D\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t       SquaredDifference\t   11.967\t   15.105\t   14.331\t  6.503%\t 38.399%\t 11075.584\tconv1/batch_norm/moments/sufficient_statistics/SquaredDifference\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                     Mul\t   11.970\t   14.162\t   13.495\t  6.124%\t 44.523%\t 11075.584\tconv1/batch_norm/batchnorm/mul_1\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                  Conv2D\t    3.948\t    8.170\t    7.986\t  3.624%\t 48.146%\t 11075.584\tconv1/Conv2D\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                     Sub\t   11.960\t   10.176\t    7.943\t  3.604%\t 51.751%\t 11075.584\tconv1/batch_norm/moments/sufficient_statistics/Sub\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t       SquaredDifference\t   45.570\t    5.908\t    7.177\t  3.257%\t 55.007%\t  5537.792\tconv2/batch_norm/moments/sufficient_statistics/SquaredDifference\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                     Mul\t   45.574\t    7.755\t    6.902\t  3.132%\t 58.140%\t  5537.792\tconv2/batch_norm/batchnorm/mul_1\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                  Conv2D\t   40.692\t    5.408\t    4.845\t  2.199%\t 60.338%\t  5537.792\tconv2/Conv2D\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                     Sub\t   45.563\t    6.067\t    4.784\t  2.171%\t 62.509%\t  5537.792\tcon\r\n\r\nI don't understand why some op in moment are executed during test and it cost a lot of time, such as conv1/batch_norm/moments/sufficient_statistics/SquaredDifference.\r\n\r\nThe moment is not needed in test, why are some ops under moment executed?\r\n"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/300516567", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-300516567", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 300516567, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDUxNjU2Nw==", "user": {"login": "raghavgoyal14", "id": 2176778, "node_id": "MDQ6VXNlcjIxNzY3Nzg=", "avatar_url": "https://avatars1.githubusercontent.com/u/2176778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raghavgoyal14", "html_url": "https://github.com/raghavgoyal14", "followers_url": "https://api.github.com/users/raghavgoyal14/followers", "following_url": "https://api.github.com/users/raghavgoyal14/following{/other_user}", "gists_url": "https://api.github.com/users/raghavgoyal14/gists{/gist_id}", "starred_url": "https://api.github.com/users/raghavgoyal14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raghavgoyal14/subscriptions", "organizations_url": "https://api.github.com/users/raghavgoyal14/orgs", "repos_url": "https://api.github.com/users/raghavgoyal14/repos", "events_url": "https://api.github.com/users/raghavgoyal14/events{/privacy}", "received_events_url": "https://api.github.com/users/raghavgoyal14/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-10T15:20:05Z", "updated_at": "2017-05-10T18:01:46Z", "author_association": "NONE", "body": "Hi,\r\n\r\nUsing the above `batch_norm` layer in `contrib.layers`, I'm getting `nan` as an output for validation graph while the train graph runs seamlessly. Is there anything that I might be missing ?\r\n\r\nI'm using:\r\n```python\r\ndef batchnormlayer(inputs, numout, train_model):\r\n    with tf.variable_scope(\"batch_norm\") as scope_bn:\r\n        epsilon = 1e-3\r\n        return tf.contrib.layers.batch_norm(inputs, decay=0.9, updates_collections=None,\r\n                                            scale=True, scope=scope_bn,\r\n                                            is_training=train_model, epsilon=epsilon,\r\n                                            fused=True, reuse=scope_bn.reuse)\r\n```\r\nThanks "}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/300781586", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-300781586", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 300781586, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDc4MTU4Ng==", "user": {"login": "raghavgoyal14", "id": 2176778, "node_id": "MDQ6VXNlcjIxNzY3Nzg=", "avatar_url": "https://avatars1.githubusercontent.com/u/2176778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raghavgoyal14", "html_url": "https://github.com/raghavgoyal14", "followers_url": "https://api.github.com/users/raghavgoyal14/followers", "following_url": "https://api.github.com/users/raghavgoyal14/following{/other_user}", "gists_url": "https://api.github.com/users/raghavgoyal14/gists{/gist_id}", "starred_url": "https://api.github.com/users/raghavgoyal14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raghavgoyal14/subscriptions", "organizations_url": "https://api.github.com/users/raghavgoyal14/orgs", "repos_url": "https://api.github.com/users/raghavgoyal14/repos", "events_url": "https://api.github.com/users/raghavgoyal14/events{/privacy}", "received_events_url": "https://api.github.com/users/raghavgoyal14/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-11T13:00:11Z", "updated_at": "2017-05-11T13:48:00Z", "author_association": "NONE", "body": "As a follow up, I'm reusing 16 layers of batch_norm.\r\nHowever, I found that reusing 4 layers works."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/300821227", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-300821227", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 300821227, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDgyMTIyNw==", "user": {"login": "danrsc", "id": 11574457, "node_id": "MDQ6VXNlcjExNTc0NDU3", "avatar_url": "https://avatars0.githubusercontent.com/u/11574457?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danrsc", "html_url": "https://github.com/danrsc", "followers_url": "https://api.github.com/users/danrsc/followers", "following_url": "https://api.github.com/users/danrsc/following{/other_user}", "gists_url": "https://api.github.com/users/danrsc/gists{/gist_id}", "starred_url": "https://api.github.com/users/danrsc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danrsc/subscriptions", "organizations_url": "https://api.github.com/users/danrsc/orgs", "repos_url": "https://api.github.com/users/danrsc/repos", "events_url": "https://api.github.com/users/danrsc/events{/privacy}", "received_events_url": "https://api.github.com/users/danrsc/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-11T15:14:28Z", "updated_at": "2017-05-11T15:14:28Z", "author_association": "NONE", "body": "I've just been noticing that if I kill the tensorflow process and restart it, my error gets worse for a few epochs (i.e. worse than it should be at the last checkpoint). I also observe that if I remove batch_norm, this problem goes away. After looking at the code for a while, I think this may be because the values of the variables are not restored from the shadow variables as they would be if the ExponentialMovingAverages class were used to manage the moving averages. This also means that if I use a separate process to evaluate, I'm getting whatever the last value of the variable was and not the moving average. Am I interpreting this correctly and is this the intended behavior? It seems like you want the shadow variable values to be restored..."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/301046558", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-301046558", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 301046558, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMTA0NjU1OA==", "user": {"login": "raghavgoyal14", "id": 2176778, "node_id": "MDQ6VXNlcjIxNzY3Nzg=", "avatar_url": "https://avatars1.githubusercontent.com/u/2176778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raghavgoyal14", "html_url": "https://github.com/raghavgoyal14", "followers_url": "https://api.github.com/users/raghavgoyal14/followers", "following_url": "https://api.github.com/users/raghavgoyal14/following{/other_user}", "gists_url": "https://api.github.com/users/raghavgoyal14/gists{/gist_id}", "starred_url": "https://api.github.com/users/raghavgoyal14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raghavgoyal14/subscriptions", "organizations_url": "https://api.github.com/users/raghavgoyal14/orgs", "repos_url": "https://api.github.com/users/raghavgoyal14/repos", "events_url": "https://api.github.com/users/raghavgoyal14/events{/privacy}", "received_events_url": "https://api.github.com/users/raghavgoyal14/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-12T10:52:49Z", "updated_at": "2017-05-12T10:52:49Z", "author_association": "NONE", "body": "I caught the problem, the moving variance in my case goes negative after some iterations.\r\n\r\nThe output of the tensor : `Model/clip_logits/batch_norm/moving_variance:0` present in `tf.model_variables()` is \r\n```\r\nMoving variance (shape = (101,)) = \r\n[ 214.70379639   95.36338043    0.57885742  189.49542236  102.72473145\r\n  137.14886475  286.57333374  111.06427002  154.98750305  167.75219727\r\n  207.83955383  211.14007568  158.23495483  171.61665344  116.81361389\r\n  115.77380371   43.59399796  137.75064087  181.75245667  161.37339783\r\n  215.21934509   92.88521576  191.23846436  336.3946228   259.85919189\r\n  299.47039795  186.23222351  165.19311523  262.82446289  170.11567688\r\n  233.56843567  209.35050964  115.96807861  154.34109497  295.5770874\r\n  123.6055603   295.76187134  296.88583374  240.88217163  247.32983398\r\n   87.15661621  217.69897461  133.00698853   -4.80375671  344.77462769\r\n  291.50601196  117.77174377  265.83712769  207.90093994  194.186203\r\n  220.21418762  178.03738403  115.27571869  196.62184143  228.8089447\r\n  191.53205872  331.36807251  151.55435181  197.2951355   179.67504883\r\n  181.09727478   90.09922791  173.30133057  102.6836853   160.9434967\r\n  236.59512329  168.05305481  403.36340332   41.14326096  185.93409729\r\n  130.57434082  266.31509399  101.44387817  163.88059998  290.25015259\r\n  244.52597046  229.86647034  158.14352417  202.68774414  187.78227234\r\n  248.78218079  126.0978241   171.41891479  274.40740967  119.84254456\r\n  202.53045654  200.20608521  214.04730225  111.53284454  222.03184509\r\n  244.81187439  172.23052979  187.09806824  194.62802124  255.26345825\r\n  293.63598633  307.91036987  210.86982727  308.88919067  144.94792175\r\n  229.69013977]\r\n```\r\nAs you can see, there's negative variance for one of the dimension. How is this even possible ?\r\nP.S. The batch norm layer is used just after the last fully connected layer of the network and before softmax."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/302869420", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-302869420", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 302869420, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjg2OTQyMA==", "user": {"login": "abred", "id": 1835958, "node_id": "MDQ6VXNlcjE4MzU5NTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1835958?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abred", "html_url": "https://github.com/abred", "followers_url": "https://api.github.com/users/abred/followers", "following_url": "https://api.github.com/users/abred/following{/other_user}", "gists_url": "https://api.github.com/users/abred/gists{/gist_id}", "starred_url": "https://api.github.com/users/abred/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abred/subscriptions", "organizations_url": "https://api.github.com/users/abred/orgs", "repos_url": "https://api.github.com/users/abred/repos", "events_url": "https://api.github.com/users/abred/events{/privacy}", "received_events_url": "https://api.github.com/users/abred/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-20T12:13:29Z", "updated_at": "2017-05-20T12:13:29Z", "author_association": "NONE", "body": "@raghavgoyal14 are you using it with fused=True? Had a similar problem and it went away when I used the fused version"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/302870951", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-302870951", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 302870951, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjg3MDk1MQ==", "user": {"login": "raghavgoyal14", "id": 2176778, "node_id": "MDQ6VXNlcjIxNzY3Nzg=", "avatar_url": "https://avatars1.githubusercontent.com/u/2176778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raghavgoyal14", "html_url": "https://github.com/raghavgoyal14", "followers_url": "https://api.github.com/users/raghavgoyal14/followers", "following_url": "https://api.github.com/users/raghavgoyal14/following{/other_user}", "gists_url": "https://api.github.com/users/raghavgoyal14/gists{/gist_id}", "starred_url": "https://api.github.com/users/raghavgoyal14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raghavgoyal14/subscriptions", "organizations_url": "https://api.github.com/users/raghavgoyal14/orgs", "repos_url": "https://api.github.com/users/raghavgoyal14/repos", "events_url": "https://api.github.com/users/raghavgoyal14/events{/privacy}", "received_events_url": "https://api.github.com/users/raghavgoyal14/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-20T12:44:21Z", "updated_at": "2017-05-20T12:44:21Z", "author_association": "NONE", "body": "@abred : Yes, I used `fused=True`, same problem."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/313994381", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-313994381", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 313994381, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzk5NDM4MQ==", "user": {"login": "zmlmanly", "id": 22173241, "node_id": "MDQ6VXNlcjIyMTczMjQx", "avatar_url": "https://avatars1.githubusercontent.com/u/22173241?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zmlmanly", "html_url": "https://github.com/zmlmanly", "followers_url": "https://api.github.com/users/zmlmanly/followers", "following_url": "https://api.github.com/users/zmlmanly/following{/other_user}", "gists_url": "https://api.github.com/users/zmlmanly/gists{/gist_id}", "starred_url": "https://api.github.com/users/zmlmanly/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zmlmanly/subscriptions", "organizations_url": "https://api.github.com/users/zmlmanly/orgs", "repos_url": "https://api.github.com/users/zmlmanly/repos", "events_url": "https://api.github.com/users/zmlmanly/events{/privacy}", "received_events_url": "https://api.github.com/users/zmlmanly/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-10T03:40:08Z", "updated_at": "2017-07-10T03:40:08Z", "author_association": "NONE", "body": "@sguada  Hi, sguada, I have a problem.\r\nThe definition of contrib.layers.batch_norm in tensorflow:\r\ndef batch_norm(inputs,\r\ndecay=0.999,\r\ncenter=True,\r\nscale=False,\r\nepsilon=0.001,\r\nactivation_fn=None,\r\nparam_initializers=None,\r\nparam_regularizers=None,\r\nupdates_collections=ops.GraphKeys.UPDATE_OPS,\r\nis_training=True,\r\nreuse=None,\r\nvariables_collections=None,\r\noutputs_collections=None,\r\ntrainable=True,\r\nbatch_weights=None,\r\nfused=False,\r\ndata_format=DATA_FORMAT_NHWC,\r\nzero_debias_moving_mean=False,\r\nscope=None,\r\nrenorm=False,\r\nrenorm_clipping=None,\r\nrenorm_decay=0.99):\r\nscale: If True, multiply by gamma. If False, gamma is\r\nnot used. When the next layer is linear (also e.g. nn.relu), this can be\r\ndisabled since the scaling can be done by the next layer.\r\n\r\nIf I use tf.contrib.layers.batch_norm(input, scale=False) , the\"scale =False\" means whether the gamma is zero in \"y = gamma*x+beta\" while training. Thank you very much."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/313994791", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-313994791", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 313994791, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzk5NDc5MQ==", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-10T03:43:50Z", "updated_at": "2017-07-10T03:43:50Z", "author_association": "CONTRIBUTOR", "body": "When scale=False, gamma is a constant 1."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/314025771", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-314025771", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 314025771, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNDAyNTc3MQ==", "user": {"login": "zmlmanly", "id": 22173241, "node_id": "MDQ6VXNlcjIyMTczMjQx", "avatar_url": "https://avatars1.githubusercontent.com/u/22173241?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zmlmanly", "html_url": "https://github.com/zmlmanly", "followers_url": "https://api.github.com/users/zmlmanly/followers", "following_url": "https://api.github.com/users/zmlmanly/following{/other_user}", "gists_url": "https://api.github.com/users/zmlmanly/gists{/gist_id}", "starred_url": "https://api.github.com/users/zmlmanly/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zmlmanly/subscriptions", "organizations_url": "https://api.github.com/users/zmlmanly/orgs", "repos_url": "https://api.github.com/users/zmlmanly/repos", "events_url": "https://api.github.com/users/zmlmanly/events{/privacy}", "received_events_url": "https://api.github.com/users/zmlmanly/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-10T07:21:05Z", "updated_at": "2017-07-10T07:21:05Z", "author_association": "NONE", "body": "@ppwwyyxx Thank you very much for your help. I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe. How to set the param of BatchNormLayer and ScaleLayer in Caffe?  \r\nThank you very much."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/316716417", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-316716417", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 316716417, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjcxNjQxNw==", "user": {"login": "tano297", "id": 18667639, "node_id": "MDQ6VXNlcjE4NjY3NjM5", "avatar_url": "https://avatars3.githubusercontent.com/u/18667639?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tano297", "html_url": "https://github.com/tano297", "followers_url": "https://api.github.com/users/tano297/followers", "following_url": "https://api.github.com/users/tano297/following{/other_user}", "gists_url": "https://api.github.com/users/tano297/gists{/gist_id}", "starred_url": "https://api.github.com/users/tano297/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tano297/subscriptions", "organizations_url": "https://api.github.com/users/tano297/orgs", "repos_url": "https://api.github.com/users/tano297/repos", "events_url": "https://api.github.com/users/tano297/events{/privacy}", "received_events_url": "https://api.github.com/users/tano297/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-20T14:14:05Z", "updated_at": "2017-07-20T14:14:05Z", "author_association": "CONTRIBUTOR", "body": "@MisayaZ I was having the same behavior using Batchnorm with a placeholder for \"is_training\". I see in the trace that the moments are being calculated even at test time, so I decided to go into the source code and I found this:\r\n\r\n```python\r\n    # If `is_training` doesn't have a constant value, because it is a `Tensor`,\r\n    # a `Variable` or `Placeholder` then is_training_value will be None and\r\n    # `needs_moments` will be true.\r\n    is_training_value = utils.constant_value(is_training)\r\n    need_moments = is_training_value is None or is_training_value\r\n    if need_moments:\r\n        # here it defines the moments\r\n```\r\nIt looks like when \"is_training\" is a variable or a placeholder the moments get defined and also get calculates them at runtime, even when you set the placeholder to \"False\". I would have preferred to leave it as a placeholder because this way I can do periodic testing during training without redefining the graph, but I decided to use it as a constant and define different behaviors for train vs test, and now the moments are not calculated at test time. "}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/316959795", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-316959795", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 316959795, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjk1OTc5NQ==", "user": {"login": "MisayaZ", "id": 16910475, "node_id": "MDQ6VXNlcjE2OTEwNDc1", "avatar_url": "https://avatars2.githubusercontent.com/u/16910475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MisayaZ", "html_url": "https://github.com/MisayaZ", "followers_url": "https://api.github.com/users/MisayaZ/followers", "following_url": "https://api.github.com/users/MisayaZ/following{/other_user}", "gists_url": "https://api.github.com/users/MisayaZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/MisayaZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MisayaZ/subscriptions", "organizations_url": "https://api.github.com/users/MisayaZ/orgs", "repos_url": "https://api.github.com/users/MisayaZ/repos", "events_url": "https://api.github.com/users/MisayaZ/events{/privacy}", "received_events_url": "https://api.github.com/users/MisayaZ/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-21T09:56:14Z", "updated_at": "2017-07-21T09:56:14Z", "author_association": "NONE", "body": "@tano297 Thank you. I now also use 'is_training' as a constant. Leave it as a placeholder and do periodic testing will change the value of moving mean and moving variance. And the inference time will be longer for it will calculate the mean and variance of the inputs and update the moving mean and moving variance. The right way to do testing is to define different behaviors for train and test as you mentioned."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/316977303", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-316977303", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 316977303, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjk3NzMwMw==", "user": {"login": "abred", "id": 1835958, "node_id": "MDQ6VXNlcjE4MzU5NTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1835958?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abred", "html_url": "https://github.com/abred", "followers_url": "https://api.github.com/users/abred/followers", "following_url": "https://api.github.com/users/abred/following{/other_user}", "gists_url": "https://api.github.com/users/abred/gists{/gist_id}", "starred_url": "https://api.github.com/users/abred/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abred/subscriptions", "organizations_url": "https://api.github.com/users/abred/orgs", "repos_url": "https://api.github.com/users/abred/repos", "events_url": "https://api.github.com/users/abred/events{/privacy}", "received_events_url": "https://api.github.com/users/abred/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-21T11:28:03Z", "updated_at": "2017-07-21T11:29:38Z", "author_association": "NONE", "body": "@tano297 @MisayaZ \r\nbut doesn't the \"smart_cond\" in\r\n```\r\nis_training_value = utils.constant_value(is_training)\r\nneed_updates = is_training_value is None or is_training_value\r\nif need_updates:\r\n  ...\r\n  outputs = utils.smart_cond(is_training, _force_updates, no_updates)\r\n```\r\nmake sure that the updates are only calculated and applied if is_training evaluates to True?"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/317039736", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-317039736", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 317039736, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzAzOTczNg==", "user": {"login": "tano297", "id": 18667639, "node_id": "MDQ6VXNlcjE4NjY3NjM5", "avatar_url": "https://avatars3.githubusercontent.com/u/18667639?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tano297", "html_url": "https://github.com/tano297", "followers_url": "https://api.github.com/users/tano297/followers", "following_url": "https://api.github.com/users/tano297/following{/other_user}", "gists_url": "https://api.github.com/users/tano297/gists{/gist_id}", "starred_url": "https://api.github.com/users/tano297/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tano297/subscriptions", "organizations_url": "https://api.github.com/users/tano297/orgs", "repos_url": "https://api.github.com/users/tano297/repos", "events_url": "https://api.github.com/users/tano297/events{/privacy}", "received_events_url": "https://api.github.com/users/tano297/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-21T15:56:55Z", "updated_at": "2017-07-21T15:56:55Z", "author_association": "CONTRIBUTOR", "body": "@abred Yes indeed, but you are referring to line 391, where it does the update of the moving average within _fused_batch_norm():\r\n\r\n```py\r\n    # If `is_training` doesn't have a constant value, because it is a `Tensor`,\r\n    # a `Variable` or `Placeholder` then is_training_value will be None and\r\n    # `need_updates` will be true.\r\n    is_training_value = utils.constant_value(is_training)\r\n    need_updates = is_training_value is None or is_training_value\r\n    if need_updates:\r\n        ...\r\n        outputs = utils.smart_cond(is_training, _force_updates, no_updates)\r\n        ...\r\n```\r\n\r\nI am talking about line 753 within batch_norm():\r\n\r\n```py\r\n    # If `is_training` doesn't have a constant value, because it is a `Tensor`,\r\n    # a `Variable` or `Placeholder` then is_training_value will be None and\r\n    # `needs_moments` will be true.\r\n    is_training_value = utils.constant_value(is_training)\r\n    need_moments = is_training_value is None or is_training_value\r\n    if need_moments:\r\n        ...\r\n        mean, variance = utils.smart_cond(is_training,\r\n                                          _force_updates,\r\n                                          moving_vars_fn) \r\n        ...\r\n```\r\nThe smart condition in that case (as far as I am concerned) decides wether or not to update the moving averages, but the moments still get calculated."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/317062897", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-317062897", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 317062897, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzA2Mjg5Nw==", "user": {"login": "abred", "id": 1835958, "node_id": "MDQ6VXNlcjE4MzU5NTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1835958?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abred", "html_url": "https://github.com/abred", "followers_url": "https://api.github.com/users/abred/followers", "following_url": "https://api.github.com/users/abred/following{/other_user}", "gists_url": "https://api.github.com/users/abred/gists{/gist_id}", "starred_url": "https://api.github.com/users/abred/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abred/subscriptions", "organizations_url": "https://api.github.com/users/abred/orgs", "repos_url": "https://api.github.com/users/abred/repos", "events_url": "https://api.github.com/users/abred/events{/privacy}", "received_events_url": "https://api.github.com/users/abred/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-21T17:29:23Z", "updated_at": "2017-07-21T17:29:23Z", "author_association": "NONE", "body": "@tano297 you right about that, I was in the wrong place, but still:\r\nline 755-770 calculate the moments, but the moments are only used in _force_updates which is only executed if is_training evaluates to True, aren't they?\r\nAnd thus \r\n```\r\nmean, variance = utils.smart_cond(is_training, _force_updates, moving_vars_fn) \r\n```\r\nshould be equivalent to line 804:\r\n```\r\nmean, variance = moving_mean, moving_variance\r\n```\r\nif is_training evalutes to False and thus the \"moments\"-part of the graph is never used and thus shouldn't be executed\r\n\r\nbut I haven't tested, so I might be wrong about that :)"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/317355258", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-317355258", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 317355258, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzM1NTI1OA==", "user": {"login": "MisayaZ", "id": 16910475, "node_id": "MDQ6VXNlcjE2OTEwNDc1", "avatar_url": "https://avatars2.githubusercontent.com/u/16910475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MisayaZ", "html_url": "https://github.com/MisayaZ", "followers_url": "https://api.github.com/users/MisayaZ/followers", "following_url": "https://api.github.com/users/MisayaZ/following{/other_user}", "gists_url": "https://api.github.com/users/MisayaZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/MisayaZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MisayaZ/subscriptions", "organizations_url": "https://api.github.com/users/MisayaZ/orgs", "repos_url": "https://api.github.com/users/MisayaZ/repos", "events_url": "https://api.github.com/users/MisayaZ/events{/privacy}", "received_events_url": "https://api.github.com/users/MisayaZ/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-24T08:34:08Z", "updated_at": "2017-07-24T08:38:18Z", "author_association": "NONE", "body": "@tano297 @abred  you right. The moving mean and moving variance are changed when I used batchnorm like this:\r\n\r\n    def batch_norm_layer(self, x,train_phase, scope_bn):\r\n            bn_train = batch_norm(x, decay=0.9, center=False, scale=True,\r\n            updates_collections=None,\r\n            is_training=True,\r\n            reuse=None,\r\n            variables_collections= [UPDATE_OPS_COLLECTION],\r\n            trainable=True,\r\n            scope=scope_bn)\r\n            bn_inference = batch_norm(x, decay=0.9, center=False, scale=True,\r\n            updates_collections=None,\r\n            is_training=False,\r\n            reuse=True,\r\n            variables_collections= [UPDATE_OPS_COLLECTION],\r\n            trainable=True,\r\n            scope=scope_bn)\r\n            z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)\r\n            return z\r\n\r\nIf you use like following:\r\n\r\n    z = batch_norm(x, decay=0.9, center=False, scale=True, updates_collections=None, \r\n                             is_training=train_phase, scope=scope_bn)\r\n\r\n\r\nThe moving mean and moving variance will not be changed during test, but the speed is very slow."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/320225653", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-320225653", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 320225653, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDIyNTY1Mw==", "user": {"login": "tyshiwo", "id": 19333875, "node_id": "MDQ6VXNlcjE5MzMzODc1", "avatar_url": "https://avatars0.githubusercontent.com/u/19333875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tyshiwo", "html_url": "https://github.com/tyshiwo", "followers_url": "https://api.github.com/users/tyshiwo/followers", "following_url": "https://api.github.com/users/tyshiwo/following{/other_user}", "gists_url": "https://api.github.com/users/tyshiwo/gists{/gist_id}", "starred_url": "https://api.github.com/users/tyshiwo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tyshiwo/subscriptions", "organizations_url": "https://api.github.com/users/tyshiwo/orgs", "repos_url": "https://api.github.com/users/tyshiwo/repos", "events_url": "https://api.github.com/users/tyshiwo/events{/privacy}", "received_events_url": "https://api.github.com/users/tyshiwo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-04T11:26:51Z", "updated_at": "2017-08-04T11:26:51Z", "author_association": "NONE", "body": "Hi @zhongyuk ,\r\n\r\nI also met the problem that I could get good results when using is_training=True for both training and inference, but get bad results when setting is_training=False during inference (worse than the case using is_training=True). According to your analysis, If I understand correctly, by simply setting decay=0.9 in BN can solve this problem. Am I right? \r\n\r\nBTW, do I need to retrain the model using decay=0.9 from scratch? Or resuming training from the checkpoint (i.e., trained when decay=0.999) is also ok?\r\n\r\nThanks!"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/320396314", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-320396314", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 320396314, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDM5NjMxNA==", "user": {"login": "tyshiwo", "id": 19333875, "node_id": "MDQ6VXNlcjE5MzMzODc1", "avatar_url": "https://avatars0.githubusercontent.com/u/19333875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tyshiwo", "html_url": "https://github.com/tyshiwo", "followers_url": "https://api.github.com/users/tyshiwo/followers", "following_url": "https://api.github.com/users/tyshiwo/following{/other_user}", "gists_url": "https://api.github.com/users/tyshiwo/gists{/gist_id}", "starred_url": "https://api.github.com/users/tyshiwo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tyshiwo/subscriptions", "organizations_url": "https://api.github.com/users/tyshiwo/orgs", "repos_url": "https://api.github.com/users/tyshiwo/repos", "events_url": "https://api.github.com/users/tyshiwo/events{/privacy}", "received_events_url": "https://api.github.com/users/tyshiwo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-05T04:25:13Z", "updated_at": "2017-08-05T04:25:13Z", "author_association": "NONE", "body": "@nmduc @davek44 \r\n\r\nHi, I also met the problem that I could get good results when using is_training=True for both training and inference, but get bad results when setting is_training=False during inference (worse than the case using is_training=True). Have you guys solved this problem? Thanks!"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/320425354", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-320425354", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 320425354, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDQyNTM1NA==", "user": {"login": "nmduc", "id": 2166977, "node_id": "MDQ6VXNlcjIxNjY5Nzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/2166977?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nmduc", "html_url": "https://github.com/nmduc", "followers_url": "https://api.github.com/users/nmduc/followers", "following_url": "https://api.github.com/users/nmduc/following{/other_user}", "gists_url": "https://api.github.com/users/nmduc/gists{/gist_id}", "starred_url": "https://api.github.com/users/nmduc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nmduc/subscriptions", "organizations_url": "https://api.github.com/users/nmduc/orgs", "repos_url": "https://api.github.com/users/nmduc/repos", "events_url": "https://api.github.com/users/nmduc/events{/privacy}", "received_events_url": "https://api.github.com/users/nmduc/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-05T07:58:30Z", "updated_at": "2017-08-05T07:58:30Z", "author_association": "NONE", "body": "@tyshiwo I just set decay=0.9 for batch_norm and it works well so far."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/321557881", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-321557881", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 321557881, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMTU1Nzg4MQ==", "user": {"login": "issa-s-ayoub", "id": 26584101, "node_id": "MDQ6VXNlcjI2NTg0MTAx", "avatar_url": "https://avatars2.githubusercontent.com/u/26584101?v=4", "gravatar_id": "", "url": "https://api.github.com/users/issa-s-ayoub", "html_url": "https://github.com/issa-s-ayoub", "followers_url": "https://api.github.com/users/issa-s-ayoub/followers", "following_url": "https://api.github.com/users/issa-s-ayoub/following{/other_user}", "gists_url": "https://api.github.com/users/issa-s-ayoub/gists{/gist_id}", "starred_url": "https://api.github.com/users/issa-s-ayoub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/issa-s-ayoub/subscriptions", "organizations_url": "https://api.github.com/users/issa-s-ayoub/orgs", "repos_url": "https://api.github.com/users/issa-s-ayoub/repos", "events_url": "https://api.github.com/users/issa-s-ayoub/events{/privacy}", "received_events_url": "https://api.github.com/users/issa-s-ayoub/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-10T13:54:40Z", "updated_at": "2017-08-10T13:59:21Z", "author_association": "NONE", "body": "I was confused after all these comments on how to properly use Batch Norm: So here is what I have. Please correct me if I'm wrong.\r\n\r\n`batch_norm = tf.contrib.layers.batch_norm(conv,\r\n                                                             center=True,\r\n                                                             scale=True,\r\n                                                             reuse=phase_train_py,\r\n                                                             scope='bn',\r\n                                                             is_training=is_training)`\r\n\r\nwhere phase_train_py is a python boolean variable and is_training is a placeholder taking a boolean variable. I guess using tf.cond is wrong, otherwise would did the function came with a boolean parameters. In other words, if `tf.cond` is true, then we should a `batch_norm` function for training and another one for testing. So, developers allow us to change these boolean variables in order to change the behavior of the function. So What I am doing is: setting `phase_train_py` to False while training while `is_training` to True. And the opposite while Testing. Since we can only change tensors or placeholders with `sess.run`, I changed `phase_train_py` intentionally before running the graph. Ex: \r\n\r\n`        if condition:\r\n            phase_train_py = False\r\n            sess.run(to_run_list, feed_dict={phase_train: True})\r\n        else:\r\n            phase_train_py = True\r\n            sess.run(to_run_list, feed_dict={phase_train: False})`"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/329943038", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-329943038", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 329943038, "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTk0MzAzOA==", "user": {"login": "zhimengfan1990", "id": 12429412, "node_id": "MDQ6VXNlcjEyNDI5NDEy", "avatar_url": "https://avatars3.githubusercontent.com/u/12429412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhimengfan1990", "html_url": "https://github.com/zhimengfan1990", "followers_url": "https://api.github.com/users/zhimengfan1990/followers", "following_url": "https://api.github.com/users/zhimengfan1990/following{/other_user}", "gists_url": "https://api.github.com/users/zhimengfan1990/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhimengfan1990/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhimengfan1990/subscriptions", "organizations_url": "https://api.github.com/users/zhimengfan1990/orgs", "repos_url": "https://api.github.com/users/zhimengfan1990/repos", "events_url": "https://api.github.com/users/zhimengfan1990/events{/privacy}", "received_events_url": "https://api.github.com/users/zhimengfan1990/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-16T03:51:25Z", "updated_at": "2017-09-16T04:04:29Z", "author_association": "NONE", "body": "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\n                                                                 MAYBE YOU NEED READ THIS\r\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\n\r\n\r\n\r\nIt seems there are still problems with TF v1.3. I'm sure I note the following details, but still failed to use the official `tf.contrib.layers.batch_norm`, with `is_training=False` during evaluation(but when I keep `is_training=True` unchanged during evaluation, it is ok):\r\n1.` decay`,  exponential moving average is actually alpha filter in signal processing, the time to converge is approximately 1/(1-decay) steps of train. For decay=0.999, you need 1/0.001=1000 steps to converge. So set the appropriate decay for your training step numbers.\r\n2. using placeholder to switch between train and test evaluation\r\n3. use` updates_collections=None` if you don't want to add control dependencies of update op to train_op\r\n4. set `reuse` to appropriate value.\r\n\r\nIt seems the only way to use the official batch_norm is to build two graphs, one for train and one for evaluation, with `is_training=True` and `is_training=False`, respectively. In this way, you don't need to switch dynamically between train and evaluation. But this is a stupid way since you need to build more than one graph.\r\n\r\nFinally, I write a moving average by myself, and I find it worked! It's as follows(based on code on the web and modified by myself)\r\n\r\n```\r\ndef bn_layer(x, scope, is_training, epsilon=0.001, decay=0.99, reuse=None):\r\n    \"\"\"\r\n    Performs a batch normalization layer\r\n\r\n    Args:\r\n        x: input tensor\r\n        scope: scope name\r\n        is_training: python boolean value\r\n        epsilon: the variance epsilon - a small float number to avoid dividing by 0\r\n        decay: the moving average decay\r\n\r\n    Returns:\r\n        The ops of a batch normalization layer\r\n    \"\"\"\r\n    with tf.variable_scope(scope, reuse=reuse):\r\n        shape = x.get_shape().as_list()\r\n        # gamma: a trainable scale factor\r\n        gamma = tf.get_variable(\"gamma\", shape[-1], initializer=tf.constant_initializer(1.0), trainable=True)\r\n        # beta: a trainable shift value\r\n        beta = tf.get_variable(\"beta\", shape[-1], initializer=tf.constant_initializer(0.0), trainable=True)\r\n        moving_avg = tf.get_variable(\"moving_avg\", shape[-1], initializer=tf.constant_initializer(0.0), trainable=False)\r\n        moving_var = tf.get_variable(\"moving_var\", shape[-1], initializer=tf.constant_initializer(1.0), trainable=False)\r\n        if is_training:\r\n            # tf.nn.moments == Calculate the mean and the variance of the tensor x\r\n            avg, var = tf.nn.moments(x, np.arange(len(shape)-1), keep_dims=True)\r\n            avg=tf.reshape(avg, [avg.shape.as_list()[-1]])\r\n            var=tf.reshape(var, [var.shape.as_list()[-1]])\r\n            #update_moving_avg = moving_averages.assign_moving_average(moving_avg, avg, decay)\r\n            update_moving_avg=tf.assign(moving_avg, moving_avg*decay+avg*(1-decay))\r\n            #update_moving_var = moving_averages.assign_moving_average(moving_var, var, decay)\r\n            update_moving_var=tf.assign(moving_var, moving_var*decay+var*(1-decay))\r\n            control_inputs = [update_moving_avg, update_moving_var]\r\n        else:\r\n            avg = moving_avg\r\n            var = moving_var\r\n            control_inputs = []\r\n        with tf.control_dependencies(control_inputs):\r\n            output = tf.nn.batch_normalization(x, avg, var, offset=beta, scale=gamma, variance_epsilon=epsilon)\r\n\r\n    return output\r\n\r\n\r\ndef bn_layer_top(x, scope, is_training, epsilon=0.001, decay=0.99):\r\n    \"\"\"\r\n    Returns a batch normalization layer that automatically switch between train and test phases based on the \r\n    tensor is_training\r\n\r\n    Args:\r\n        x: input tensor\r\n        scope: scope name\r\n        is_training: boolean tensor or variable\r\n        epsilon: epsilon parameter - see batch_norm_layer\r\n        decay: epsilon parameter - see batch_norm_layer\r\n\r\n    Returns:\r\n        The correct batch normalization layer based on the value of is_training\r\n    \"\"\"\r\n    #assert isinstance(is_training, (ops.Tensor, variables.Variable)) and is_training.dtype == tf.bool\r\n\r\n    return tf.cond(\r\n        is_training,\r\n        lambda: bn_layer(x=x, scope=scope, epsilon=epsilon, decay=decay, is_training=True, reuse=None),\r\n        lambda: bn_layer(x=x, scope=scope, epsilon=epsilon, decay=decay, is_training=False, reuse=True),\r\n    )\r\n```\r\n    \r\nJust use the `bn_layer_top` function during building a graph, the is_training parameter is a `tf.placeholder`\r\n. Then you are free to switch the placeholder to True during train and False during evaluation, with `feed_dict`.\r\n\r\nHope it helps the community. "}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/349981824", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-349981824", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 349981824, "node_id": "MDEyOklzc3VlQ29tbWVudDM0OTk4MTgyNA==", "user": {"login": "tasx0823", "id": 25676211, "node_id": "MDQ6VXNlcjI1Njc2MjEx", "avatar_url": "https://avatars0.githubusercontent.com/u/25676211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tasx0823", "html_url": "https://github.com/tasx0823", "followers_url": "https://api.github.com/users/tasx0823/followers", "following_url": "https://api.github.com/users/tasx0823/following{/other_user}", "gists_url": "https://api.github.com/users/tasx0823/gists{/gist_id}", "starred_url": "https://api.github.com/users/tasx0823/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tasx0823/subscriptions", "organizations_url": "https://api.github.com/users/tasx0823/orgs", "repos_url": "https://api.github.com/users/tasx0823/repos", "events_url": "https://api.github.com/users/tasx0823/events{/privacy}", "received_events_url": "https://api.github.com/users/tasx0823/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-07T14:25:18Z", "updated_at": "2017-12-07T14:25:18Z", "author_association": "NONE", "body": "When you use slim.batch_norm,be sure to use \"slim.learning.create_train_op\" instead of \"tf.train.GradientDecentOptimizer(lr).minimize(loss)\" or other optimizer. Try it to see if it works! "}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/350537403", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-350537403", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 350537403, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDUzNzQwMw==", "user": {"login": "ZahlGraf", "id": 10481491, "node_id": "MDQ6VXNlcjEwNDgxNDkx", "avatar_url": "https://avatars0.githubusercontent.com/u/10481491?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZahlGraf", "html_url": "https://github.com/ZahlGraf", "followers_url": "https://api.github.com/users/ZahlGraf/followers", "following_url": "https://api.github.com/users/ZahlGraf/following{/other_user}", "gists_url": "https://api.github.com/users/ZahlGraf/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZahlGraf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZahlGraf/subscriptions", "organizations_url": "https://api.github.com/users/ZahlGraf/orgs", "repos_url": "https://api.github.com/users/ZahlGraf/repos", "events_url": "https://api.github.com/users/ZahlGraf/events{/privacy}", "received_events_url": "https://api.github.com/users/ZahlGraf/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-10T10:05:16Z", "updated_at": "2017-12-10T10:05:16Z", "author_association": "NONE", "body": "@vincentvanhoucke You wrote in another post in this thread: \r\n\r\n> The slim batch_norm wrapper normalizes over the last dimension of your input tensor. So if it's a 2D input tensor coming from a fully connected layer, it normalizes over batch, and thus performs per-activation normalization. If it's a 4D tensor coming from a convolution, it will normalize over the three first dimensions (batch, width, depth), and thus perform per-feature normalization. @sguada maybe forth being a bit more descriptive about this.\r\n\r\nDo you mean with \"slim batch_norm wrapper\" the function `tf.contrib.layers.batch_norm`? If so, I would suggest to add this information to the documentation text of this function. Thus it gets very clear, that this function performs the batch normalization exactly like described in the paper... for both FC-Layer and Conv2D-Layer. At the moment there is only the text \"Can be used as a normalizer function for conv2d and fully_connected.\", where it is not clear if this is related to the normalization axis topic."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/350774590", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-350774590", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 350774590, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDc3NDU5MA==", "user": {"login": "vincentvanhoucke", "id": 15737127, "node_id": "MDQ6VXNlcjE1NzM3MTI3", "avatar_url": "https://avatars3.githubusercontent.com/u/15737127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincentvanhoucke", "html_url": "https://github.com/vincentvanhoucke", "followers_url": "https://api.github.com/users/vincentvanhoucke/followers", "following_url": "https://api.github.com/users/vincentvanhoucke/following{/other_user}", "gists_url": "https://api.github.com/users/vincentvanhoucke/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincentvanhoucke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincentvanhoucke/subscriptions", "organizations_url": "https://api.github.com/users/vincentvanhoucke/orgs", "repos_url": "https://api.github.com/users/vincentvanhoucke/repos", "events_url": "https://api.github.com/users/vincentvanhoucke/events{/privacy}", "received_events_url": "https://api.github.com/users/vincentvanhoucke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-11T16:20:58Z", "updated_at": "2017-12-11T16:20:58Z", "author_association": "MEMBER", "body": "@ZahlGraf I'll happily consider a PR that clarifies the documentation. We've been at this for so long that I no longer have a good sense of what's obvious or not, and would welcome clarifying documentation for someone with a fresh perspective on the topic."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/354095283", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-354095283", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 354095283, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NDA5NTI4Mw==", "user": {"login": "Netzeband", "id": 26524132, "node_id": "MDQ6VXNlcjI2NTI0MTMy", "avatar_url": "https://avatars2.githubusercontent.com/u/26524132?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Netzeband", "html_url": "https://github.com/Netzeband", "followers_url": "https://api.github.com/users/Netzeband/followers", "following_url": "https://api.github.com/users/Netzeband/following{/other_user}", "gists_url": "https://api.github.com/users/Netzeband/gists{/gist_id}", "starred_url": "https://api.github.com/users/Netzeband/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Netzeband/subscriptions", "organizations_url": "https://api.github.com/users/Netzeband/orgs", "repos_url": "https://api.github.com/users/Netzeband/repos", "events_url": "https://api.github.com/users/Netzeband/events{/privacy}", "received_events_url": "https://api.github.com/users/Netzeband/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-27T10:50:05Z", "updated_at": "2017-12-27T10:50:05Z", "author_association": "CONTRIBUTOR", "body": "@vincentvanhoucke \r\nI created a PR with a more detailed description, mainly based on your statement in this thread:\r\nhttps://github.com/tensorflow/tensorflow/pull/15653"}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/357027438", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-357027438", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 357027438, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NzAyNzQzOA==", "user": {"login": "tensorflowbutler", "id": 28546240, "node_id": "MDQ6VXNlcjI4NTQ2MjQw", "avatar_url": "https://avatars2.githubusercontent.com/u/28546240?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tensorflowbutler", "html_url": "https://github.com/tensorflowbutler", "followers_url": "https://api.github.com/users/tensorflowbutler/followers", "following_url": "https://api.github.com/users/tensorflowbutler/following{/other_user}", "gists_url": "https://api.github.com/users/tensorflowbutler/gists{/gist_id}", "starred_url": "https://api.github.com/users/tensorflowbutler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tensorflowbutler/subscriptions", "organizations_url": "https://api.github.com/users/tensorflowbutler/orgs", "repos_url": "https://api.github.com/users/tensorflowbutler/repos", "events_url": "https://api.github.com/users/tensorflowbutler/events{/privacy}", "received_events_url": "https://api.github.com/users/tensorflowbutler/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-11T19:01:28Z", "updated_at": "2018-01-11T19:01:28Z", "author_association": "MEMBER", "body": "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/363338535", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-363338535", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 363338535, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MzMzODUzNQ==", "user": {"login": "tensorflowbutler", "id": 28546240, "node_id": "MDQ6VXNlcjI4NTQ2MjQw", "avatar_url": "https://avatars2.githubusercontent.com/u/28546240?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tensorflowbutler", "html_url": "https://github.com/tensorflowbutler", "followers_url": "https://api.github.com/users/tensorflowbutler/followers", "following_url": "https://api.github.com/users/tensorflowbutler/following{/other_user}", "gists_url": "https://api.github.com/users/tensorflowbutler/gists{/gist_id}", "starred_url": "https://api.github.com/users/tensorflowbutler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tensorflowbutler/subscriptions", "organizations_url": "https://api.github.com/users/tensorflowbutler/orgs", "repos_url": "https://api.github.com/users/tensorflowbutler/repos", "events_url": "https://api.github.com/users/tensorflowbutler/events{/privacy}", "received_events_url": "https://api.github.com/users/tensorflowbutler/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-06T07:48:54Z", "updated_at": "2018-02-06T07:48:54Z", "author_association": "MEMBER", "body": "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you."}, {"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/363944494", "html_url": "https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-363944494", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1122", "id": 363944494, "node_id": "MDEyOklzc3VlQ29tbWVudDM2Mzk0NDQ5NA==", "user": {"login": "annarev", "id": 22060313, "node_id": "MDQ6VXNlcjIyMDYwMzEz", "avatar_url": "https://avatars0.githubusercontent.com/u/22060313?v=4", "gravatar_id": "", "url": "https://api.github.com/users/annarev", "html_url": "https://github.com/annarev", "followers_url": "https://api.github.com/users/annarev/followers", "following_url": "https://api.github.com/users/annarev/following{/other_user}", "gists_url": "https://api.github.com/users/annarev/gists{/gist_id}", "starred_url": "https://api.github.com/users/annarev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/annarev/subscriptions", "organizations_url": "https://api.github.com/users/annarev/orgs", "repos_url": "https://api.github.com/users/annarev/repos", "events_url": "https://api.github.com/users/annarev/events{/privacy}", "received_events_url": "https://api.github.com/users/annarev/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-07T23:17:07Z", "updated_at": "2018-02-07T23:17:07Z", "author_association": "MEMBER", "body": "Closing this bug since the original request to add a batch norm layer has been addressed. Some of the more recent issues with documentation seem to have their own PRs\r\nIf you see any issue with batch_norm, please either ask a question on StackOverflow or open another issue."}]