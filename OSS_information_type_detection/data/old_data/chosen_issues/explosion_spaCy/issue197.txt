[{
  "url": "https://api.github.com/repos/explosion/spaCy/issues/197",
  "repository_url": "https://api.github.com/repos/explosion/spaCy",
  "labels_url": "https://api.github.com/repos/explosion/spaCy/issues/197/labels{/name}",
  "comments_url": "https://api.github.com/repos/explosion/spaCy/issues/197/comments",
  "events_url": "https://api.github.com/repos/explosion/spaCy/issues/197/events",
  "html_url": "https://github.com/explosion/spaCy/issues/197",
  "id": 119691141,
  "node_id": "MDU6SXNzdWUxMTk2OTExNDE=",
  "number": 197,
  "title": "Feature Request: Vector \"File\" interface",
  "user": {
    "login": "RXminuS",
    "id": 3949285,
    "node_id": "MDQ6VXNlcjM5NDkyODU=",
    "avatar_url": "https://avatars3.githubusercontent.com/u/3949285?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/RXminuS",
    "html_url": "https://github.com/RXminuS",
    "followers_url": "https://api.github.com/users/RXminuS/followers",
    "following_url": "https://api.github.com/users/RXminuS/following{/other_user}",
    "gists_url": "https://api.github.com/users/RXminuS/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/RXminuS/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/RXminuS/subscriptions",
    "organizations_url": "https://api.github.com/users/RXminuS/orgs",
    "repos_url": "https://api.github.com/users/RXminuS/repos",
    "events_url": "https://api.github.com/users/RXminuS/events{/privacy}",
    "received_events_url": "https://api.github.com/users/RXminuS/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 312256136,
      "node_id": "MDU6TGFiZWwzMTIyNTYxMzY=",
      "url": "https://api.github.com/repos/explosion/spaCy/labels/docs",
      "name": "docs",
      "color": "087EA6",
      "default": false
    },
    {
      "id": 111380487,
      "node_id": "MDU6TGFiZWwxMTEzODA0ODc=",
      "url": "https://api.github.com/repos/explosion/spaCy/labels/enhancement",
      "name": "enhancement",
      "color": "20834E",
      "default": true
    }
  ],
  "state": "closed",
  "locked": true,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 23,
  "created_at": "2015-12-01T10:49:10Z",
  "updated_at": "2018-05-09T08:12:36Z",
  "closed_at": "2016-10-22T15:11:08Z",
  "author_association": "NONE",
  "body": "Just read in an old spaCy tutorial the following \"Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.\"\n\nIs this in place yet? Would love to replace standard vector file and in-memory loading with my own Redis (or any other \"shared-memory-system\") interface to allow a distributed cluster of spacy nodes to share the same \"file\". Would love to contribute, any pointers on where to start looking?\n",
  "closed_by": {
    "login": "ines",
    "id": 13643239,
    "node_id": "MDQ6VXNlcjEzNjQzMjM5",
    "avatar_url": "https://avatars0.githubusercontent.com/u/13643239?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ines",
    "html_url": "https://github.com/ines",
    "followers_url": "https://api.github.com/users/ines/followers",
    "following_url": "https://api.github.com/users/ines/following{/other_user}",
    "gists_url": "https://api.github.com/users/ines/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ines/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ines/subscriptions",
    "organizations_url": "https://api.github.com/users/ines/orgs",
    "repos_url": "https://api.github.com/users/ines/repos",
    "events_url": "https://api.github.com/users/ines/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ines/received_events",
    "type": "User",
    "site_admin": false
  }
},{"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/161708299", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-161708299", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 161708299, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MTcwODI5OQ==", "user": {"login": "honnibal", "id": 8059750, "node_id": "MDQ6VXNlcjgwNTk3NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8059750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/honnibal", "html_url": "https://github.com/honnibal", "followers_url": "https://api.github.com/users/honnibal/followers", "following_url": "https://api.github.com/users/honnibal/following{/other_user}", "gists_url": "https://api.github.com/users/honnibal/gists{/gist_id}", "starred_url": "https://api.github.com/users/honnibal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/honnibal/subscriptions", "organizations_url": "https://api.github.com/users/honnibal/orgs", "repos_url": "https://api.github.com/users/honnibal/repos", "events_url": "https://api.github.com/users/honnibal/events{/privacy}", "received_events_url": "https://api.github.com/users/honnibal/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-03T16:35:02Z", "updated_at": "2015-12-03T16:35:02Z", "author_association": "MEMBER", "body": "Yep, this should work: https://github.com/honnibal/spaCy/blob/master/spacy/vocab.pyx#L320\n\nThanks for mentioning this \u2014 I'll keep this open until we update the docs.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/161844212", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-161844212", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 161844212, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MTg0NDIxMg==", "user": {"login": "RXminuS", "id": 3949285, "node_id": "MDQ6VXNlcjM5NDkyODU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3949285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RXminuS", "html_url": "https://github.com/RXminuS", "followers_url": "https://api.github.com/users/RXminuS/followers", "following_url": "https://api.github.com/users/RXminuS/following{/other_user}", "gists_url": "https://api.github.com/users/RXminuS/gists{/gist_id}", "starred_url": "https://api.github.com/users/RXminuS/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RXminuS/subscriptions", "organizations_url": "https://api.github.com/users/RXminuS/orgs", "repos_url": "https://api.github.com/users/RXminuS/repos", "events_url": "https://api.github.com/users/RXminuS/events{/privacy}", "received_events_url": "https://api.github.com/users/RXminuS/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-04T01:19:38Z", "updated_at": "2015-12-04T01:19:38Z", "author_association": "NONE", "body": "That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx. \n\nHowever I was more looking for a way to have spaCy avoid loading in the vectors in it's own memory and allow for an interface so that I can make this centralised in a shared memory solution. So pre-cook a \"database\" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a \"hashmap\" (like it's currently) or a shared memory source. This makes spaCy much more useable for including in our docker environment where we literally have 100s of these containers running in parallel and memory is wasted for each instance.\n\nI'll hopefully have some spare time soon and will write a little pull request now that I know where to look :-)\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/161953677", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-161953677", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 161953677, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MTk1MzY3Nw==", "user": {"login": "honnibal", "id": 8059750, "node_id": "MDQ6VXNlcjgwNTk3NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8059750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/honnibal", "html_url": "https://github.com/honnibal", "followers_url": "https://api.github.com/users/honnibal/followers", "following_url": "https://api.github.com/users/honnibal/following{/other_user}", "gists_url": "https://api.github.com/users/honnibal/gists{/gist_id}", "starred_url": "https://api.github.com/users/honnibal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/honnibal/subscriptions", "organizations_url": "https://api.github.com/users/honnibal/orgs", "repos_url": "https://api.github.com/users/honnibal/repos", "events_url": "https://api.github.com/users/honnibal/events{/privacy}", "received_events_url": "https://api.github.com/users/honnibal/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-04T12:17:53Z", "updated_at": "2015-12-04T12:17:53Z", "author_association": "MEMBER", "body": "This makes sense.\n\nI'd like to change the current set up, because I want to support vectors keyed by different information, e.g. vectors keyed by lemma and part-of-speech. This lets you see different vectors for `take/VERB` and `take/NOUN`. Digital Reasoning wrote a paper showing this got them good results, and early examination of the vectors is looking good to me too.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162067111", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162067111", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162067111, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjA2NzExMQ==", "user": {"login": "RXminuS", "id": 3949285, "node_id": "MDQ6VXNlcjM5NDkyODU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3949285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RXminuS", "html_url": "https://github.com/RXminuS", "followers_url": "https://api.github.com/users/RXminuS/followers", "following_url": "https://api.github.com/users/RXminuS/following{/other_user}", "gists_url": "https://api.github.com/users/RXminuS/gists{/gist_id}", "starred_url": "https://api.github.com/users/RXminuS/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RXminuS/subscriptions", "organizations_url": "https://api.github.com/users/RXminuS/orgs", "repos_url": "https://api.github.com/users/RXminuS/repos", "events_url": "https://api.github.com/users/RXminuS/events{/privacy}", "received_events_url": "https://api.github.com/users/RXminuS/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-04T19:58:47Z", "updated_at": "2015-12-04T19:58:47Z", "author_association": "NONE", "body": "That's actually a really good idea! Could you link the papers here and I'll have a look at that as well. (thinking I might actually do this as part of my master thesis :P ) \n\nIn a way this information is already contained in word vectors because two verbs will be seen in more similar contexts than adjectives but guess that by reducing ambiguity and \"false positives\" it could make quite a difference.\n\nDo you have some form of basic class design for it yet which I should stick to or shall I just come up with something?\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162082773", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162082773", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162082773, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjA4Mjc3Mw==", "user": {"login": "honnibal", "id": 8059750, "node_id": "MDQ6VXNlcjgwNTk3NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8059750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/honnibal", "html_url": "https://github.com/honnibal", "followers_url": "https://api.github.com/users/honnibal/followers", "following_url": "https://api.github.com/users/honnibal/following{/other_user}", "gists_url": "https://api.github.com/users/honnibal/gists{/gist_id}", "starred_url": "https://api.github.com/users/honnibal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/honnibal/subscriptions", "organizations_url": "https://api.github.com/users/honnibal/orgs", "repos_url": "https://api.github.com/users/honnibal/repos", "events_url": "https://api.github.com/users/honnibal/events{/privacy}", "received_events_url": "https://api.github.com/users/honnibal/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-04T21:10:46Z", "updated_at": "2015-12-04T21:13:08Z", "author_association": "MEMBER", "body": "Here's the paper I mentioned, titled \"sense2vec\": http://arxiv.org/pdf/1511.06388.pdf , by @iamtrask\n\n> In a way this information is already contained in word vectors because two verbs will be seen in more similar contexts than adjectives but guess that by reducing ambiguity and \"false positives\" it could make quite a difference.\n\nNot so! The most similar words to `take/NOUN` might be things like `opinion|NOUN`, while the most similar words to `take/VERB` might be `give|VERB` or `put|VERB`. In normal Word2Vec these two share a key, so there's no way to look at the two different \"senses\" separately.\n\nI've been playing with an extension of this idea, where noun chunks and named entities are also merged. I've trained a model on one month of Reddit comments. The results at the moment are quite messy, and many of the phrases need to be pruned from the vocab. But there are also some interesting results in there too. Example:\n\n```\n>>> model = gensim.models.Word2Vec.load('np_ner_tag_reddit_2015_01-300d.model')\n>>> model.most_similar(['take|NOUN'])\n[(u'personal_stance|NOUN', 0.49355706572532654), (u'best_guess|NOUN', 0.48488736152648926), (u'personal_favorite_song|NOUN', 0.4821690320968628), (u'stance|NOUN', 0.48033151030540466), (u'favorite_track|NOUN', 0.47577959299087524), (u'personal_opinion|NOUN', 0.47202107310295105), (u'favorite_community|NOUN', 0.4700315594673157), (u'personal_view|NOUN', 0.4675809144973755), (u'overall_opinion|NOUN', 0.4594742953777313), (u'first_impression|NOUN', 0.458611398935318)]\n```\n\nThe vectors for the verb and noun senses are quite different:\n\n```\n>>> model.similarity('take|NOUN', 'take|VERB')\n0.13804844694430313\n```\n\nThe nearest neighbour of `take|VERB` turns out to be a misspelling, that the POS tagger seems to often tag correctly:\n\n```\n>>> model.similarity('take|VERB', 'tale|VERB')\n0.49611725495669901\n```\n\nI'll be writing more about these vectors, and of course releasing the code. I'd like to sharpen up one or two things and run it on more data first.\n\nI can give you some code to get you started on the POS tagged vectors, though.\n\nAs much as I dislike dumping state to disk, it's the most practical way to do this. It'd be nice to have the multi-threading sorted out for spaCy, but for now multi-processing is okay, especially for the tagger, which is fast and low-memory. Example:\nhttps://github.com/honnibal/spaCy/blob/master/examples/pos_tag.py\n\nHere's how to train Word2Vec on the output using Gensim. (@piskvorky): \n\n``` python\nfrom __future__ import print_function, unicode_literals, division\nimport io\nimport bz2\nimport logging\nfrom os import path\nimport os\n\nimport plac\nimport ujson\nfrom gensim.models import Word2Vec\n\n\nclass Corpus(object):\n    def __init__(self, directory):\n        self.directory = directory\n\n    def __iter__(self):\n        for filename in os.listdir(self.directory):\n            text_loc = path.join(self.directory, filename)\n            with io.open(text_loc, 'r', encoding='utf8') as file_:\n                for sent_str in file_:\n                    yield sent_str.split()\n\n\n@plac.annotations(\n    in_dir=(\"Location of input directory\"),\n    out_loc=(\"Location of output file\"),\n    n_workers=(\"Number of workers\", \"option\", \"n\", int),\n    size=(\"Dimension of the word vectors\", \"option\", \"d\", int),\n    window=(\"Context window size\", \"option\", \"w\", int),\n    min_count=(\"Min count\", \"option\", \"m\", int)\n)\ndef main(in_dir, out_loc, n_workers=4, window=5, size=128, min_count=10):\n    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n    corpus = Corpus(in_dir)\n    model = Word2Vec(\n        Corpus(in_dir),\n        size=size,\n        window=window,\n        min_count=min_count,\n        workers=n_workers\n    )\n    model.save(out_loc)\n\n\nif __name__ == '__main__':\n    plac.call(main)\n```\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162085226", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162085226", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162085226, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjA4NTIyNg==", "user": {"login": "iamtrask", "id": 4328594, "node_id": "MDQ6VXNlcjQzMjg1OTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4328594?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iamtrask", "html_url": "https://github.com/iamtrask", "followers_url": "https://api.github.com/users/iamtrask/followers", "following_url": "https://api.github.com/users/iamtrask/following{/other_user}", "gists_url": "https://api.github.com/users/iamtrask/gists{/gist_id}", "starred_url": "https://api.github.com/users/iamtrask/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iamtrask/subscriptions", "organizations_url": "https://api.github.com/users/iamtrask/orgs", "repos_url": "https://api.github.com/users/iamtrask/repos", "events_url": "https://api.github.com/users/iamtrask/events{/privacy}", "received_events_url": "https://api.github.com/users/iamtrask/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-04T21:23:10Z", "updated_at": "2015-12-04T21:23:10Z", "author_association": "NONE", "body": "That chunking experiment is fantastic. Love the take -> personal_stance. \n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162086235", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162086235", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162086235, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjA4NjIzNQ==", "user": {"login": "honnibal", "id": 8059750, "node_id": "MDQ6VXNlcjgwNTk3NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8059750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/honnibal", "html_url": "https://github.com/honnibal", "followers_url": "https://api.github.com/users/honnibal/followers", "following_url": "https://api.github.com/users/honnibal/following{/other_user}", "gists_url": "https://api.github.com/users/honnibal/gists{/gist_id}", "starred_url": "https://api.github.com/users/honnibal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/honnibal/subscriptions", "organizations_url": "https://api.github.com/users/honnibal/orgs", "repos_url": "https://api.github.com/users/honnibal/repos", "events_url": "https://api.github.com/users/honnibal/events{/privacy}", "received_events_url": "https://api.github.com/users/honnibal/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-04T21:27:49Z", "updated_at": "2015-12-04T21:27:49Z", "author_association": "MEMBER", "body": "> Do you have some form of basic class design for it yet which I should stick to or shall I just come up with something?\n\nI thought the answer was \"no\", but then I started writing out some \"suggestions\", and I guess I have a clearer idea than I thought :). Most of these things are demanded by consistency with the rest of the library. You can see examples of pretty much all of this in the `Vocab` and `StringsTable` classes:\n\nPython API:\n- Use the `__getitem__`, `__setitem__` and `__iter__` special methods. You don't necessarily have to subclass dict.\n- All vectors in the same `VectorTable` must be the same length. \n- The table should allow the user to pass in a key function, which should take a `spacy.tokens.Token` object as an argument, and return a 64-bit unsigned integer (used to key the table)\n- The hash will be non-reversible, and it won't be possible to iterate over the keys and get back a useful representation of the integer key. This is okay. Otherwise we'll have to store the key strings, which could occupy a lot of memory.\n\nImplementation details:\n- The data should be stored in a PreshMap instance.\n- The table should be keyed by a `feat_t` (64 bit unisnged integer), with values being `weight_t*`, i.e. raw C arrays of floats.\n- Allocate the memory using `cymem.Pool`\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162099682", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162099682", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162099682, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjA5OTY4Mg==", "user": {"login": "honnibal", "id": 8059750, "node_id": "MDQ6VXNlcjgwNTk3NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8059750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/honnibal", "html_url": "https://github.com/honnibal", "followers_url": "https://api.github.com/users/honnibal/followers", "following_url": "https://api.github.com/users/honnibal/following{/other_user}", "gists_url": "https://api.github.com/users/honnibal/gists{/gist_id}", "starred_url": "https://api.github.com/users/honnibal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/honnibal/subscriptions", "organizations_url": "https://api.github.com/users/honnibal/orgs", "repos_url": "https://api.github.com/users/honnibal/repos", "events_url": "https://api.github.com/users/honnibal/events{/privacy}", "received_events_url": "https://api.github.com/users/honnibal/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-04T22:28:01Z", "updated_at": "2015-12-04T22:28:50Z", "author_association": "MEMBER", "body": "A few bonus queries on the chunked model.\n\n1) The vector space seems like it'll give a good way to show compositionality:\n\n\"fair game\" is not a type of game:\n\n```\n>>> model.similarity('fair_game|NOUN', 'game|NOUN')\n0.034977455677555599\n>>> model.similarity('multiplayer_game|NOUN', 'game|NOUN')\n0.54464530644393849\n```\n\nA \"class action\" is only very weakly a type of action:\n\n```\n>>> model.similarity('class_action|NOUN', 'action|NOUN')\n0.14957825452335169\n```\n\nBut a class action _lawsuit_ is definitely a type of lawsuit:\n\n```\n>>> model.similarity('class_action_lawsuit|NOUN', 'lawsuit|NOUN')\n0.69595765453644187\n```\n\n2) Similarity between entities can be kind of fun.\n\nHere's what Reddit thinks of Donald Trump:\n\n```\n>>> model.most_similar(['Donald_Trump|PERSON'])\n[(u'Sarah_Palin|PERSON', 0.5510910749435425), (u'Rick_Perry|PERSON', 0.5508972406387329), (u'Stephen_Colbert|PERSON', 0.5499709844589233), (u'Alex_Jones|PERSON', 0.5492554306983948), (u'Michael_Moore|PERSON', 0.5363447666168213), (u'Charles_Manson|PERSON', 0.5363028645515442), (u'Dick_Cheney|PERSON', 0.5348431468009949), (u'Mark_Zuckerberg|PERSON', 0.5258212089538574), (u'Mark_Wahlberg|PERSON', 0.5251839756965637), (u'Michael_Jackson|PERSON', 0.5229078531265259)]\n```\n\nDiscussion of Bill Cosby makes some obvious (and some less obvious) comparisons:\n\n```\n>>> model.most_similar(['Bill_Cosby|PERSON'])\n[(u'Cosby|ORG', 0.6004706621170044), (u'Cosby|PERSON', 0.5874950885772705), (u'Roman_Polanski|PERSON', 0.5478169918060303), (u'George_Zimmerman|PERSON', 0.5398542881011963), (u'Charles_Manson|PERSON', 0.5387344360351562), (u'OJ_Simpson|PERSON', 0.5228893160820007), (u'Trayvon_Martin|PERSON', 0.514190137386322), (u'Adnan_Syed|PERSON', 0.49992451071739197), (u'rapist|NOUN', 0.49792540073394775), (u'srhbutts|NOUN', 0.49792492389678955)]\n```\n\nSome queries produce more confusing results:\n\n```\n>>> model.most_similar(['Carrot_Top|PERSON'])\n[(u'Kate_Mara|PERSON', 0.5347248911857605), (u'Andy_Samberg|PERSON', 0.5336876511573792), (u'Ryan_Gosling|PERSON', 0.5287898182868958), (u'Emma_Stone|PERSON', 0.5243821740150452), (u'Charlie_Sheen|PERSON', 0.5209298133850098), (u'Joseph_Gordon_Levitt|PERSON', 0.5196050405502319), (u'Jonah_Hill|PERSON', 0.5151286125183105), (u'Zooey_Deschanel|PERSON', 0.514430582523346), (u'Gerard_Butler|PERSON', 0.5115377902984619), (u'Ellen_Page|PERSON', 0.5094753503799438)]\n```\n\nI can't say the connection between Carrot Top and Kate Mara is obvious to me. I suppose this is true of most things about Carrot Top, so...Fair play.\n\n3) Reddit talks about food a lot, and those regions of the vector space seem very well defined:\n\n```\n>>> model.most_similar(['onion_rings|NOUN'])\n[(u'hashbrowns|NOUN', 0.8040812611579895), (u'hot_dogs|NOUN', 0.7978234887123108), (u'chicken_wings|NOUN', 0.793393611907959), (u'sandwiches|NOUN', 0.7903584241867065), (u'fries|NOUN', 0.7885469198226929), (u'tater_tots|NOUN', 0.7821801900863647), (u'bagels|NOUN', 0.7788236141204834), (u'chicken_nuggets|NOUN', 0.7787706255912781), (u'coleslaw|NOUN', 0.7771176099777222), (u'nachos|NOUN', 0.7755396366119385)]\n```\n\nSome of Reddit's ideas about food are kind of...interesting. It seems to think `bacon` and `brocolli` are very similar:\n\n```\n>>> model.similarity('bacon|NOUN', 'broccoli|NOUN')\n0.83276615202851845\n```\n\nReddit also thinks hot dogs are practically salad:\n\n```\n>>> model.similarity('hot_dogs|NOUN', 'salad|NOUN')\n0.76765100035460465\n>>> model.similarity('hot_dogs|NOUN', 'entrails|NOUN')\n0.28360725445449464\n```\n\nJust keep telling yourself that Reddit.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162106499", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162106499", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162106499, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjEwNjQ5OQ==", "user": {"login": "iamtrask", "id": 4328594, "node_id": "MDQ6VXNlcjQzMjg1OTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4328594?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iamtrask", "html_url": "https://github.com/iamtrask", "followers_url": "https://api.github.com/users/iamtrask/followers", "following_url": "https://api.github.com/users/iamtrask/following{/other_user}", "gists_url": "https://api.github.com/users/iamtrask/gists{/gist_id}", "starred_url": "https://api.github.com/users/iamtrask/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iamtrask/subscriptions", "organizations_url": "https://api.github.com/users/iamtrask/orgs", "repos_url": "https://api.github.com/users/iamtrask/repos", "events_url": "https://api.github.com/users/iamtrask/events{/privacy}", "received_events_url": "https://api.github.com/users/iamtrask/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-04T23:08:17Z", "updated_at": "2015-12-04T23:08:17Z", "author_association": "NONE", "body": "Haha that Donald Trump one is quite something.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162110449", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162110449", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162110449, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjExMDQ0OQ==", "user": {"login": "RXminuS", "id": 3949285, "node_id": "MDQ6VXNlcjM5NDkyODU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3949285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RXminuS", "html_url": "https://github.com/RXminuS", "followers_url": "https://api.github.com/users/RXminuS/followers", "following_url": "https://api.github.com/users/RXminuS/following{/other_user}", "gists_url": "https://api.github.com/users/RXminuS/gists{/gist_id}", "starred_url": "https://api.github.com/users/RXminuS/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RXminuS/subscriptions", "organizations_url": "https://api.github.com/users/RXminuS/orgs", "repos_url": "https://api.github.com/users/RXminuS/repos", "events_url": "https://api.github.com/users/RXminuS/events{/privacy}", "received_events_url": "https://api.github.com/users/RXminuS/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-04T23:35:45Z", "updated_at": "2015-12-04T23:35:45Z", "author_association": "NONE", "body": "Love the link between bacon and broccoli, wonder what adding sentiment into the mix would change about that :P\n\n```\nImplementation details:\n\nThe data should be stored in a PreshMap instance.\nThe table should be keyed by a feat_t (64 bit unisnged integer), with values being weight_t*, i.e. raw C arrays of floats.\nAllocate the memory using cymem.Pool\n```\n\nIsn't this what we want to abstract away behind an interface so we can implement different ways of holding the vectors in memory, i.e. local vs central? **Although to be honest...I'm starting to doubt my own idea in terms of if the speed tradeoff is even worth it.** \n\n```\nNot so! The most similar words to take/NOUN might be things like opinion|NOUN, while the most similar words to take/VERB might be give|VERB or put|VERB. In normal Word2Vec these two share a key, so there's no way to look at the two different \"senses\" separately.\n```\n\nagreed, didn't really mean the information was usable or retrievable, rather that the scoring of vectors **not** using POS tagging is influenced by these \"use cases\" and that making this information explicit seems a natural extension. Bit hard to explain my brainfart...but just meant that your idea made sense :)\n\nI'll read the paper and dig through some more code to get into it. But really love the work you're doing. Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162119517", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162119517", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162119517, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjExOTUxNw==", "user": {"login": "honnibal", "id": 8059750, "node_id": "MDQ6VXNlcjgwNTk3NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8059750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/honnibal", "html_url": "https://github.com/honnibal", "followers_url": "https://api.github.com/users/honnibal/followers", "following_url": "https://api.github.com/users/honnibal/following{/other_user}", "gists_url": "https://api.github.com/users/honnibal/gists{/gist_id}", "starred_url": "https://api.github.com/users/honnibal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/honnibal/subscriptions", "organizations_url": "https://api.github.com/users/honnibal/orgs", "repos_url": "https://api.github.com/users/honnibal/repos", "events_url": "https://api.github.com/users/honnibal/events{/privacy}", "received_events_url": "https://api.github.com/users/honnibal/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-05T00:47:59Z", "updated_at": "2015-12-05T00:47:59Z", "author_association": "MEMBER", "body": "> Isn't this what we want to abstract away behind an interface so we can implement different ways of holding the vectors in memory, i.e. local vs central?\n\nHmm, maybe you're right. I was immediately thinking of how the C-level API would look.\n\n> Although to be honest...I'm starting to doubt my own idea in terms of if the speed tradeoff is even worth it.\n\nWe might end up with use-cases where the vectors data is many gigabytes. Like, think trigram vectors, or vectors for subject/verb/object triples. If this occurs, the architecture you had in mind would make a lot of sense to me. A worker takes a few documents off the task queue, aggregates the vocabulary, and asks the vectors service for all vectors active on the batch.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162121904", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162121904", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162121904, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjEyMTkwNA==", "user": {"login": "RXminuS", "id": 3949285, "node_id": "MDQ6VXNlcjM5NDkyODU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3949285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RXminuS", "html_url": "https://github.com/RXminuS", "followers_url": "https://api.github.com/users/RXminuS/followers", "following_url": "https://api.github.com/users/RXminuS/following{/other_user}", "gists_url": "https://api.github.com/users/RXminuS/gists{/gist_id}", "starred_url": "https://api.github.com/users/RXminuS/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RXminuS/subscriptions", "organizations_url": "https://api.github.com/users/RXminuS/orgs", "repos_url": "https://api.github.com/users/RXminuS/repos", "events_url": "https://api.github.com/users/RXminuS/events{/privacy}", "received_events_url": "https://api.github.com/users/RXminuS/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-05T01:15:20Z", "updated_at": "2015-12-05T01:16:30Z", "author_association": "NONE", "body": "Yeah for large vector models it would be a necessity, question is though where supporting that is on your timeline & plans for spaCy. For me it would be brilliant, because I have 100+ [Celery](http://celeryproject.org) workers and the 100M for each instance to load the vector model makes it hard to scale across docker containers. And in the future when we want to load more advanced, and possible context dependant models, and on the fly language switching it would be even more necessary.\n\nWhen you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around. Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :)\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162125895", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162125895", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162125895, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjEyNTg5NQ==", "user": {"login": "honnibal", "id": 8059750, "node_id": "MDQ6VXNlcjgwNTk3NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8059750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/honnibal", "html_url": "https://github.com/honnibal", "followers_url": "https://api.github.com/users/honnibal/followers", "following_url": "https://api.github.com/users/honnibal/following{/other_user}", "gists_url": "https://api.github.com/users/honnibal/gists{/gist_id}", "starred_url": "https://api.github.com/users/honnibal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/honnibal/subscriptions", "organizations_url": "https://api.github.com/users/honnibal/orgs", "repos_url": "https://api.github.com/users/honnibal/repos", "events_url": "https://api.github.com/users/honnibal/events{/privacy}", "received_events_url": "https://api.github.com/users/honnibal/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-05T01:55:58Z", "updated_at": "2015-12-05T01:55:58Z", "author_association": "MEMBER", "body": "I think there's a design problem here that should be fixed, so we may as well fix it sooner rather than later.\n\nSend me an email, matt@spacy.io .\n\nFor now the following work-around could help:\n1. Remove the `vec.bin` file from your data directory, to avoid loading the vectors\n2. Make your own similarity server, that does the central look-up for you\n3. Avoid the `.similarity()` methods on the spaCy objects.\n\nYou might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem . Gensim recommends the `annoy` library. It seems good to me.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162138104", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162138104", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162138104, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjEzODEwNA==", "user": {"login": "piskvorky", "id": 610412, "node_id": "MDQ6VXNlcjYxMDQxMg==", "avatar_url": "https://avatars1.githubusercontent.com/u/610412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/piskvorky", "html_url": "https://github.com/piskvorky", "followers_url": "https://api.github.com/users/piskvorky/followers", "following_url": "https://api.github.com/users/piskvorky/following{/other_user}", "gists_url": "https://api.github.com/users/piskvorky/gists{/gist_id}", "starred_url": "https://api.github.com/users/piskvorky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/piskvorky/subscriptions", "organizations_url": "https://api.github.com/users/piskvorky/orgs", "repos_url": "https://api.github.com/users/piskvorky/repos", "events_url": "https://api.github.com/users/piskvorky/events{/privacy}", "received_events_url": "https://api.github.com/users/piskvorky/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-05T04:26:20Z", "updated_at": "2015-12-06T02:58:09Z", "author_association": "CONTRIBUTOR", "body": "Hi guys, would appreciate your input on issue https://github.com/piskvorky/gensim/issues/527.\n\nWe're in the process of abstracting away particular vector stores (in-memory matrix, sharded on-disk store, approximate kNN index...) from gensim, behind a common API. What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!\n\nHow do you use such stores in spaCy, what metrics do you employ, what API signatures?\n\nWe'd like to end up with something that is flexible enough to cover all standard use cases (`give_me_vector_for_this_key`, `give_me_most_similar_key_to_these_other_keys`, `index_vector_for_this_key` etc) but still concise and clearly scoped. This will be used throughout gensim (doc2vec, word2vec, docsim...).\n\nCC @gojomo @tmylk\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162163086", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162163086", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162163086, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjE2MzA4Ng==", "user": {"login": "honnibal", "id": 8059750, "node_id": "MDQ6VXNlcjgwNTk3NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8059750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/honnibal", "html_url": "https://github.com/honnibal", "followers_url": "https://api.github.com/users/honnibal/followers", "following_url": "https://api.github.com/users/honnibal/following{/other_user}", "gists_url": "https://api.github.com/users/honnibal/gists{/gist_id}", "starred_url": "https://api.github.com/users/honnibal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/honnibal/subscriptions", "organizations_url": "https://api.github.com/users/honnibal/orgs", "repos_url": "https://api.github.com/users/honnibal/repos", "events_url": "https://api.github.com/users/honnibal/events{/privacy}", "received_events_url": "https://api.github.com/users/honnibal/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-05T09:03:17Z", "updated_at": "2015-12-05T09:03:17Z", "author_association": "MEMBER", "body": "Great!\n\nDefinitely want to get together on this. Will review.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162163679", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162163679", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162163679, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjE2MzY3OQ==", "user": {"login": "jli05", "id": 3519667, "node_id": "MDQ6VXNlcjM1MTk2Njc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3519667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jli05", "html_url": "https://github.com/jli05", "followers_url": "https://api.github.com/users/jli05/followers", "following_url": "https://api.github.com/users/jli05/following{/other_user}", "gists_url": "https://api.github.com/users/jli05/gists{/gist_id}", "starred_url": "https://api.github.com/users/jli05/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jli05/subscriptions", "organizations_url": "https://api.github.com/users/jli05/orgs", "repos_url": "https://api.github.com/users/jli05/repos", "events_url": "https://api.github.com/users/jli05/events{/privacy}", "received_events_url": "https://api.github.com/users/jli05/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-05T09:19:07Z", "updated_at": "2015-12-05T09:19:07Z", "author_association": "NONE", "body": "Just to get enlightened: it seems great idea but does that mean that SpaCy and gensim will work together? Do we have a rough plan for the change of APIs?\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162216616", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162216616", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162216616, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjIxNjYxNg==", "user": {"login": "honnibal", "id": 8059750, "node_id": "MDQ6VXNlcjgwNTk3NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8059750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/honnibal", "html_url": "https://github.com/honnibal", "followers_url": "https://api.github.com/users/honnibal/followers", "following_url": "https://api.github.com/users/honnibal/following{/other_user}", "gists_url": "https://api.github.com/users/honnibal/gists{/gist_id}", "starred_url": "https://api.github.com/users/honnibal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/honnibal/subscriptions", "organizations_url": "https://api.github.com/users/honnibal/orgs", "repos_url": "https://api.github.com/users/honnibal/repos", "events_url": "https://api.github.com/users/honnibal/events{/privacy}", "received_events_url": "https://api.github.com/users/honnibal/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-05T16:09:39Z", "updated_at": "2015-12-05T16:09:39Z", "author_association": "MEMBER", "body": "I want spaCy and Gensim to interoperate sanely. But it's more important that both libraries stay internally consistent, and they have fairly different API norms. I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency. I'm guessing Gensim would hesitate to depend on spaCy. Among other things, we support a narrower range of platforms. \n\nSo, I'd say it's more of a design thing. We'd like to figure out what sort of work-flows are required.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162264809", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162264809", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162264809, "node_id": "MDEyOklzc3VlQ29tbWVudDE2MjI2NDgwOQ==", "user": {"login": "piskvorky", "id": 610412, "node_id": "MDQ6VXNlcjYxMDQxMg==", "avatar_url": "https://avatars1.githubusercontent.com/u/610412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/piskvorky", "html_url": "https://github.com/piskvorky", "followers_url": "https://api.github.com/users/piskvorky/followers", "following_url": "https://api.github.com/users/piskvorky/following{/other_user}", "gists_url": "https://api.github.com/users/piskvorky/gists{/gist_id}", "starred_url": "https://api.github.com/users/piskvorky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/piskvorky/subscriptions", "organizations_url": "https://api.github.com/users/piskvorky/orgs", "repos_url": "https://api.github.com/users/piskvorky/repos", "events_url": "https://api.github.com/users/piskvorky/events{/privacy}", "received_events_url": "https://api.github.com/users/piskvorky/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-06T02:40:49Z", "updated_at": "2015-12-08T23:25:48Z", "author_association": "CONTRIBUTOR", "body": "Yes. I hope to discuss what kinds of behaviour people expect from such \"vector stores\", so we can design a sane API.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/162987429", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-162987429", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 162987429, "node_id": "MDEyOklzc3VlQ29tbWVudDE2Mjk4NzQyOQ==", "user": {"login": "lechatpito", "id": 180606, "node_id": "MDQ6VXNlcjE4MDYwNg==", "avatar_url": "https://avatars3.githubusercontent.com/u/180606?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lechatpito", "html_url": "https://github.com/lechatpito", "followers_url": "https://api.github.com/users/lechatpito/followers", "following_url": "https://api.github.com/users/lechatpito/following{/other_user}", "gists_url": "https://api.github.com/users/lechatpito/gists{/gist_id}", "starred_url": "https://api.github.com/users/lechatpito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lechatpito/subscriptions", "organizations_url": "https://api.github.com/users/lechatpito/orgs", "repos_url": "https://api.github.com/users/lechatpito/repos", "events_url": "https://api.github.com/users/lechatpito/events{/privacy}", "received_events_url": "https://api.github.com/users/lechatpito/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-08T19:20:13Z", "updated_at": "2015-12-08T19:20:13Z", "author_association": "NONE", "body": "We've been using an external server for word2vec for over a year now. It would be great to be able to plug it in spaCy. Currently we are accessing the vector space through the https://github.com/3Top/word2vec-api/ project. A HTTP query will return a base 64 encoding of the vector. If there is any interest, I would be glad to improve the service to enable communication with spaCy.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/166623513", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-166623513", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 166623513, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NjYyMzUxMw==", "user": {"login": "jli05", "id": 3519667, "node_id": "MDQ6VXNlcjM1MTk2Njc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3519667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jli05", "html_url": "https://github.com/jli05", "followers_url": "https://api.github.com/users/jli05/followers", "following_url": "https://api.github.com/users/jli05/following{/other_user}", "gists_url": "https://api.github.com/users/jli05/gists{/gist_id}", "starred_url": "https://api.github.com/users/jli05/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jli05/subscriptions", "organizations_url": "https://api.github.com/users/jli05/orgs", "repos_url": "https://api.github.com/users/jli05/repos", "events_url": "https://api.github.com/users/jli05/events{/privacy}", "received_events_url": "https://api.github.com/users/jli05/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-22T13:55:46Z", "updated_at": "2015-12-22T13:56:15Z", "author_association": "NONE", "body": "Re: fusion of SpaCy and gensim APIs, I personally find the current gensim API tree not as straightforward/simple as scikit-learn (don't mistake me, gensim is extremely uniquely useful, e.g LDA, wikicorpus, etc). I think it'd be great to introduce an API lineage of scikit-learn flavour, or that simple.\n\nAs for SpaCy, I hope there's a portable way to train/retrieve the word embeddings across domains (pharma, legal, finance, etc) and natural languages. Could we make the underlying workings of word embeddings compositional/consistent as well (what if we need to do text analysis over legal+finance texts, or multi-lingual texts)?\n\nCould SpaCy keep an eye on Apache Flink, Apache Spark, and TensorFlow's about-to-be-released distributed processing framework as well?\n\nPlease don't give up working on SpaCy. A versatile/portable/production-ready/modern NLP framework is never ever done before!\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/166934204", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-166934204", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 166934204, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NjkzNDIwNA==", "user": {"login": "syllog1sm", "id": 781165, "node_id": "MDQ6VXNlcjc4MTE2NQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/781165?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syllog1sm", "html_url": "https://github.com/syllog1sm", "followers_url": "https://api.github.com/users/syllog1sm/followers", "following_url": "https://api.github.com/users/syllog1sm/following{/other_user}", "gists_url": "https://api.github.com/users/syllog1sm/gists{/gist_id}", "starred_url": "https://api.github.com/users/syllog1sm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syllog1sm/subscriptions", "organizations_url": "https://api.github.com/users/syllog1sm/orgs", "repos_url": "https://api.github.com/users/syllog1sm/repos", "events_url": "https://api.github.com/users/syllog1sm/events{/privacy}", "received_events_url": "https://api.github.com/users/syllog1sm/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-23T16:14:12Z", "updated_at": "2015-12-23T16:14:12Z", "author_association": "COLLABORATOR", "body": "We're definitely not about to give up working on SpaCy! We're barely getting started.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/226451265", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-226451265", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 226451265, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNjQ1MTI2NQ==", "user": {"login": "navesg", "id": 19973297, "node_id": "MDQ6VXNlcjE5OTczMjk3", "avatar_url": "https://avatars3.githubusercontent.com/u/19973297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/navesg", "html_url": "https://github.com/navesg", "followers_url": "https://api.github.com/users/navesg/followers", "following_url": "https://api.github.com/users/navesg/following{/other_user}", "gists_url": "https://api.github.com/users/navesg/gists{/gist_id}", "starred_url": "https://api.github.com/users/navesg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/navesg/subscriptions", "organizations_url": "https://api.github.com/users/navesg/orgs", "repos_url": "https://api.github.com/users/navesg/repos", "events_url": "https://api.github.com/users/navesg/events{/privacy}", "received_events_url": "https://api.github.com/users/navesg/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-16T10:46:15Z", "updated_at": "2016-06-16T10:46:15Z", "author_association": "NONE", "body": "Hi, I am new to spacy and NLP and ML. I was going through the documentation of spacy. I am trying to make a QnA system. Was wondering if spacy gives a direct method to find similarity between 2 sentences? I could only find sentence tokenizations and word similarities.\n"}, {"url": "https://api.github.com/repos/explosion/spaCy/issues/comments/387659016", "html_url": "https://github.com/explosion/spaCy/issues/197#issuecomment-387659016", "issue_url": "https://api.github.com/repos/explosion/spaCy/issues/197", "id": 387659016, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NzY1OTAxNg==", "user": {"login": "lock[bot]", "id": 33595554, "node_id": "MDM6Qm90MzM1OTU1NTQ=", "avatar_url": "https://avatars1.githubusercontent.com/in/6672?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lock%5Bbot%5D", "html_url": "https://github.com/apps/lock", "followers_url": "https://api.github.com/users/lock%5Bbot%5D/followers", "following_url": "https://api.github.com/users/lock%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/lock%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/lock%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lock%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/lock%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/lock%5Bbot%5D/repos", "events_url": "https://api.github.com/users/lock%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/lock%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "created_at": "2018-05-09T08:12:35Z", "updated_at": "2018-05-09T08:12:35Z", "author_association": "NONE", "body": "This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n"}]